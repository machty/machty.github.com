
<!DOCTYPE HTML>
<html>
<head>
	<script data-cfasync="false" type="text/javascript" src="//use.typekit.net/axj3cfp.js"></script>
	<script data-cfasync="false" type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<meta charset="utf-8">
	<title>Ember.js, random thoughts, journal  | machty's thoughtz</title>

<meta name="author" content="Alex Matchneer"> 

<meta name="description" content="I'm on Ember core and contribute to lots of stuff prefixed with "Em"."> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="machty's thoughtz" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script type="text/javascript" src="/javascripts/jquery.fancybox.pack.js"></script>

<script language="Javascript" type="text/javascript">
$(document).ready(
  function() {
    (function($) {
      $(".fancybox[data-content-id]").each(function() {
        this.href = $(this).data('content-id');
      });
      $(".fancybox").fancybox({
        beforeLoad: function() {
          var el, 
              id = $(this.element).data('title-id');

          if (id) {
            el = $('#' + id);

            if (el.length) {
              this.title = el.html();
            }
          }
          if ($(this).data('content')) {
            this.content = $(this).data('content');
          }
        },
        helpers: {
          title: {
            type: 'inside'
          }
        }
      });
    })(jQuery);
  }
);
</script>

	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">machty's thoughtz</a></h1>
<h4>Ember.js, random thoughts, journal</h4>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:machty.github.com">
			</form>
		</div>
	</div>
</nav>


</header>

	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/20/stankonia/">
		
			Stankonia</a>
	</h2>
	<div class="entry-content">
		<h2>Zonebie</h2>

<p>https://github.com/alindeman/zonebie</p>

<p>Ruby gem to randomly change the current timezone to help catch bugs /
false assumptions in your timezone-touching code.</p>

<p>NOTE: trolled myself because i had a <code>_spec.rb</code> file that didn&#8217;t have
<code>require 'spec_helper'</code> at the top and hence Zonebie magic wasn&#8217;t
happening.</p>

<h2>Hellbanning</h2>

<p>http://en.wikipedia.org/wiki/Hellbanning</p>

<p>Aka, shadowbanning. You don&#8217;t know you&#8217;re banned, but no one sees your
stuff, people stuff responding to you. Used on HN.</p>

<h2>Redis SLAVEOF</h2>

<p>http://redis.io/commands/slaveof</p>

<p>Master-slave replication. A slave has its own port, connects to parent
with SYNC, starts a BGSAVE, shares shit, blah blahblah.</p>

<p>You can even pretend to be a slave with netcat.</p>

<pre><code>nc localhost 9595
SYNC
</code></pre>

<p>And then you&#8217;ll get a stream of all the stuff a redis slave server sees.
If you write to the master you&#8217;ll the slave being sent that same write
request.</p>

<p>Slaves can have slaves. If a master disconnects, slaves become
masters&#8230;?</p>

<p>Slaves are read only:</p>

<pre><code>(error) READONLY You can't write against a read only slave.
</code></pre>

<p>If master disconnects, it&#8217;s still a slave until you tell it to
<code>SLAVE NO ONE</code>, then it severs that connection, preserving the
replicated data, and then the old master might connect to the new master
and invert the master-slave relationship. PRETTY RAD. Or you could also
tell the new master to become a slave, but that&#8217;ll mean it loses all of
its data.</p>

<p>Use slave chains if a master is overloaded w forwarding writes to all of
its slaves. Instead of</p>

<pre><code>- MASTER
  - SLAVE 0
  - SLAVE 1
  - SLAVE 2
  - SLAVE 3
</code></pre>

<p>You could do</p>

<pre><code>- MASTER
  - SLAVE 0
    - SLAVE 1
      - SLAVE 2
        - SLAVE 3
</code></pre>

<h2>Git: tags are a flat hierarchy</h2>

<p>You could release multiple versions of a project from different
branches. There&#8217;s no requirement that all the versions you tag are on
<code>master</code> or <code>release</code> or anything like that. Tags, as opposed to branch
names, are a flattened hiearchy.</p>

<p>A branch is just a pointer.</p>

<p>A tag is just a pointer.</p>

<p>The difference is that if you commit to a branch, the pointer moves. A
tag on the other hand stays pointing to that commit SHA.</p>

<p>A client can make sure a master write made it to slave via checking
UUID&#8217;s, and using <code>INFO</code> command to check sync status, etc.</p>

<h2>Redis Sentinel</h2>

<p>http://redis.io/topics/sentinel</p>

<p>Monitors master/slaves, restarts, notifies, failovers, etc.</p>

<h2>Redis-cli</h2>

<pre><code>-x                 Read last argument from STDIN.

Example:
cat /etc/passwd | redis-cli -x set mypasswd
</code></pre>

<p>So that sets <code>mypasswd</code> to the contents of a file.</p>

<pre><code>$ echo "SOMEVALUE" | redis-cli -x set wat
OK
$ redis-cli get wat
</code></pre>

<h2>Redis: MULTI/EXEC doesn&#8217;t mean pipelining</h2>

<p>Pipelining refers to a redis client queueing commands and then sending
them to a Redis server all at once. The Redis server its has its own
concept of queued commands via MULTI/EXEC, but the concepts are separate;
you could invidually send a bunch of commands including MULTI/EXEC, and
get responses to each, but once you&#8217;re in the MULTI/EXEC block, you
start getting QUEUED as a response.</p>

<h2>Redis: WATCH, DISCARD, MULTI</h2>

<p>You can invalidate your own WATCH pretty immediately:</p>

<pre><code>127.0.0.1:6379&gt; WATCH foo
OK
127.0.0.1:6379&gt; SET foo wat
OK
127.0.0.1:6379&gt; MULTI
OK
127.0.0.1:6379&gt; EXEC
(nil)
</code></pre>

<p>Obviously you can&#8217;t put it in a MULTI</p>

<pre><code>127.0.0.1:6379&gt; MULTI
OK
127.0.0.1:6379&gt; WATCH foo
(error) ERR WATCH inside MULTI is not allowed
</code></pre>

<p>DISCARDS must take place within MULTI block.</p>

<pre><code>127.0.0.1:6379&gt; DISCARD
(error) ERR DISCARD without MULTI
</code></pre>

<h2>Optimistic Locking</h2>

<p>http://en.wikipedia.org/wiki/Optimistic_concurrency_control</p>

<p>Redis implements optimistic locking; it never locks a datatype and
prevents someone from writing; rather, transactions can be aborted and
retried if it&#8217;s detected that someone else wrote to the same data
(detected via watch).</p>

<p>Pessimistic locking would be, say, if a DB row was locked and someone
wanting to write to it was blocked til the lock was given up, which
apparently most databases do.</p>

<p>Postgres (and other relational DBs) have other approaches:</p>

<p>http://blog.2ndquadrant.com/postgresql-anti-patterns-read-modify-write-cycles/</p>

<p>TL;DR Avoid read-modify-write</p>

<h2>No pipelining + latency = multiplied awfulness</h2>

<p>Just like w TCP or anything with roundtrips, latency is the multiplier.
Good thing I wrote this.</p>

<h2>Standard Deviation</h2>

<p>http://en.wikipedia.org/wiki/Standard_deviation#History</p>

<blockquote><p>The term standard deviation was first used[10] in writing by Karl Pearson[11] in 1894, following his use of it in lectures.</p></blockquote>

<p>So there&#8217;s no statistical meaning behind the word &#8220;standard&#8221;. We&#8217;re all
just talking about &#8220;deviation&#8221;, using the most basic/default/standard
way of calculating it.</p>

<h2>Ruby blocks v Python context manager</h2>

<p>One thing I noticed regarding <code>return</code>s:</p>

<pre><code>def foo():
  print(1)
  yield
  print(2)

def bar():
  with foo():
    print(999)
    return "LOL"
</code></pre>

<p>In python this yields</p>

<pre><code>1
999
2
</code></pre>

<p>and returns &#8216;LOL&#8217;. This is interesting because the <code>print(2)</code> is still
hit, which isn&#8217;t what would happen in Ruby.</p>

<pre><code>def foo
  puts 1
  yield
  puts 2
end

def bar
  foo { puts "999"; return "LOL" }
end
</code></pre>

<p>yields</p>

<pre><code>1
999
=&gt; "LOL"
</code></pre>

<p>The <code>2</code> isn&#8217;t printed because in Ruby, the return causes the caller to
return.</p>

<h2>Redis ZSETS sort by key when scores equal</h2>

<p>That&#8217;s all.</p>

<h2>Lua</h2>

<p>http://en.wikipedia.org/wiki/Lua_(programming_language)</p>

<p>Why use Lua:</p>

<ul>
<li>you&#8217;re building something that needs to be scriptable</li>
<li>that shouldn&#8217;t have a heavy footprint from the interpreter</li>
<li>that might be in an embedded system</li>
<li>that is easy to grok</li>
<li>that lots of people use already</li>
</ul>


<p><a href="http://en.wikipedia.org/wiki/Wikipedia:Lua">Wikipedia is Lua-extensible</a></p>

<p>Redis offers Lua scripting now, useful in certain cases over
pipelining/multi-exec, since (I think) it allows logic to be placed on
the Redis server rather than having to do all logic on the application
sides and remembering to do all the WATCH/MULTI/EXEC crap.</p>

<h2>Redis: why lock?</h2>

<p>Because WATCH/retry loops quickly degrade as the number of actors
increase; particularly if the WATCH is coarse (only keys can be WATCH&#8217;d,
not specific items in a hash).</p>

<p>Instead of retrying, a lock might make sense in this case.</p>

<p>Implementing locks is error-prone:</p>

<ul>
<li>a process grabs a lock, but takes too long and the lock times out, and
process is blissfully unaware and keeps doing potentially destructive
things</li>
<li>process crashes, doesn&#8217;t releaes lock, and everyone wastes time
waiting for the timeout</li>
<li>process crashes, other blocked processes try to acquire lock at same
time, think they each got the lock. (This is an issue in general but
more likely to happen if many processes attempting-to-lock are blocked
at the same time)</li>
</ul>


<p>SETNX only writes if not already present. It&#8217;s a test and set. Useful
for locks. You can just spin-lock on a sleep(.001) loop.</p>

<p>Increasing the granularity of lock generally improves perf.</p>

<h2>Dogpiling</h2>

<p>http://en.wikipedia.org/wiki/Cache_stampede</p>

<p>aka cache stampede; under very high loads, multiple processes try to
warm the cache at the same time, and performance takes a megahit.</p>

<p>This book seems to suggest a more general phenomenon of the system
taking a hit if lots of people are trying to acquire a lock. Probably
because they&#8217;re all spin locks, and spin lock take processing time.
Couldn&#8217;t we just implement a semaphore w BLPOP and LPUSH?</p>

<h2>Horrible App Store Deploy BS</h2>

<p>http://stackoverflow.com/a/26511924/914123</p>

<h2>Qualcomm: Mobile Station Modem</h2>

<p>http://en.wikipedia.org/wiki/Qualcomm</p>

<p>MSM: The CPU on Nexus, made by Qualcomm. You see in the android source
code a whole bunch.</p>

<p>What is Qualcomm?</p>

<blockquote><p>Qualcomm Incorporated is an American global semiconductor company that designs and markets wireless telecommunications products and services.</p></blockquote>

<h2>ioctl</h2>

<p>Swiss army knife for special io device files.</p>

<h2>Dalvik</h2>

<p>VM for android.</p>

<h2><code>set -e</code></h2>

<p>Makes it so that the shell terminates after the first unsuccessful
command. You can kill a tmux/terminal pane by just doing</p>

<pre><code>set -e
ls somethingthatdoesnotexist
</code></pre>

<p>Boom.</p>

<h2>Heroku Buildpack</h2>

<p><code>compile</code> gets run and apparently passed the app root path</p>

<pre><code>mkdir -p "$1/bin/server"
cp "bin/nginx-$STACK" "$1/bin/server/nginx"
</code></pre>

<h2>Nginx logging</h2>

<p>Customize via <code>error_log</code> and <code>access_log</code> directives, but keep in mind
it&#8217;s going to expect to use <code>./logs/*.log</code> no matter what before it&#8217;s
had time to read your config file (how else would it log a failure to
parse a config file?).</p>

<h2>Render right from config/routes.rb</h2>

<pre><code>get '/horse_ass', :to =&gt; proc { |env|
                                    [
                                      200,
                                      {"Content-Type" =&gt; 'text/plain'},
                                      ["FUDGLES"]
                                    ]
                                  }
</code></pre>

<p>It&#8217;s just the Rack API (anything that <code>respond_to?(:call)</code>).</p>

<h2>Millinery</h2>

<p>Women&#8217;s hats. A Milliner is a person who sells hats.</p>

<h2>Find and replace in project</h2>

<pre><code>ack -l 'pattern' | xargs perl -pi -E 's/pattern/replacement/g'
</code></pre>

<p>could also do</p>

<pre><code>ack -l OLD_TEXT | xargs sed -i "" "s/OLD_TEXT/NEW_TEXT/g
</code></pre>

<p>http://stackoverflow.com/a/8744108</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-20T16:25:00-05:00" pubdate data-updated="true">Nov 20<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/17/redis-the-slack-jawed-yokel/">
		
			Redis the Slack-jawed Yokel</a>
	</h2>
	<div class="entry-content">
		<p>Some stores&#8217;ll never page to disk, but then again, some stores&#8217;ll, like
Redis, the slack-jawed yokel.</p>

<h2>Transparent Huge Pages</h2>

<p>https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Performance_Tuning_Guide/s-memory-transhuge.html</p>

<p>Huge pages are a Linux feature whereby pages, normally 4096 bytes,
can be 2MB or 1 GB. Useful for some applications, difficult to
configure, hence Transparent Huge Pages is provided automagically, I
guess. But it&#8217;s not recommended for database workloads&#8230; why not?</p>

<p>Probably Redis has the answer:</p>

<p>http://redis.io/topics/latency</p>

<p>Redis uses forking for</p>

<ul>
<li>generating RDB snapshot</li>
<li>rewriting AOF</li>
</ul>


<p>Forking is slower in certain virtual settings; EC2 old Xen instances
could take more than a second to fork. Newer ones using HVM
(hardware virtual machine) leverages assistive hardware to make this
efficient.</p>

<p>If you have transparent hugepages, they&#8217;ll need to be COW&#8217;d upon fork,
which is expensive. So you can disable them entirely:</p>

<pre><code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled
</code></pre>

<h2>Hypervisor / Virtual Machine Monitor</h2>

<p>http://en.wikipedia.org/wiki/Hypervisor</p>

<p>Tis what it sounds like. It&#8217;s the thing that schedules processing time
b/w multiple virtual machines. It&#8217;s the host to the guest virtual
machines.</p>

<h2>Multiple values in sysfs</h2>

<p>http://techoverflow.net/blog/2013/08/01/how-to-check-if-hugepages-are-enabled-in-linux/</p>

<pre><code>$ cat /sys/kernel/mm/transparent_hugepage/enabled
always [madvise] never
</code></pre>

<p>I thought this meant the first value (active) was the current value and
the other two were left as documentation, but no, it means madvise is
current value among the other two options. Kinda wacky. Who parses this?</p>

<p>IRC tells me this is a common sysfs pattern.</p>

<pre><code>$ cat /sys/block/xvda/queue/scheduler
[noop]
</code></pre>

<h2>SSR</h2>

<p>Server-side render.</p>

<h2>InfoSec</h2>

<p>Information Security. Usually refers to IT security, but sometimes
physical backups play into it, such as off-site tape backups.</p>

<h2>Which process is using which port?</h2>

<pre><code>lsof -i $PORT
# e.g.
lsof -i :5000
</code></pre>

<p><code>-i</code> just means filter by internet address. The above supplied only a
port, you could also provide a host name.</p>

<h2>Redis Pub Sub</h2>

<p>Not super common because</p>

<ul>
<li>older versions might crash system / OS if clients don&#8217;t read published
messages fast enough, back pressure, bloating outgoing buffer. New
versions disconnect slow readers though.</li>
<li>Unreliable message delivery if there&#8217;s an intermittent disconnect and
reconnect.</li>
</ul>


<h2>Redis Expiration</h2>

<ul>
<li>you can manually DEL or use expiration</li>
<li>expires whole keys, i.e. can&#8217;t expire individual items in a set (hence
more common to use ZSETs with timestamps and manual deletion based on
a range)</li>
</ul>


<h2>Stripe Token Retrieval</h2>

<p>https://stripe.com/docs/api#retrieve_token</p>

<p>This is only interesting since it clarified that a token wraps a card
with details that you can access before you, say, add it to a card.
This is the only way presently to prevent attaching the same card
to a customer twice: retrieve and then add.</p>

<p>But for my purposes I can just add it twice, and check the fingerprint
after word to prevent duplicates on my app&#8217;s Customer obj.</p>

<p>Why doesn&#8217;t Stripe de-dup? https://groups.google.com/a/lists.stripe.com/forum/#!topic/api-discuss/OzmhpQOs_SU</p>

<blockquote><p>We do not check, as many people have their own policies around when
duplicates are acceptable or aren&#8217;t.
However, you can look at the &#8220;fingerprint&#8221; property on cards that you
have saved in order to dedup.</p></blockquote>

<h2>Ruby Enumerators are awesome</h2>

<p>&#8220;Hey how come there&#8217;s <code>each_with_index</code> but not <code>map_with_index</code>?&#8221;</p>

<p>Use enumerators. Lots of the Ruby Enumerables return enumerators if you
don&#8217;t pass a block to them, and they can be chained. For instance you
can create a 1-indexed series via:</p>

<pre><code>10.times.map { |i| i+1 }
</code></pre>

<p>Does this work with lazy enumerators?</p>

<pre><code>(0..Float::INFINITY).lazy.map { |i| i + 1 }.first(10)
</code></pre>

<p>So yeah, just that ranges have no <code>times</code>&#8230; probably more correct to
think of <code>10.times</code> as a range rather than other way around.</p>

<h2>Stripe Checkout is only Web</h2>

<p>There&#8217;s no native ios/android version of Stripe Checkout. It&#8217;s just web.
iOS/Android SDKs offer token exchange utilities and some widgets but
it&#8217;s not the full tailored UI solution that Checkout is.</p>

<h2>Stripe passes through failed CVVs</h2>

<p>https://support.stripe.com/questions/cvc-or-avs-failed-but-payment-succeeded</p>

<p>You can still process a card with the wrong CVV. Though you probably
shouldn&#8217;t.</p>

<p>Test:</p>

<blockquote><p>4000000000000101: cvc_check will fail.</p></blockquote>

<h2>Rx state machine</h2>

<p>https://github.com/logicalguess/rx-state-machine</p>

<p>Basically every transition that occurs maps to a new state machine. You
define a state machine in a classic OO manner but it streamifies it for
you.</p>

<h2>Write amplification w SSDs</h2>

<p>http://en.wikipedia.org/wiki/Write_amplification</p>

<p>When the amount you write to an SSD is amplified by the fact that you
often have to flash much more than you originally intended to write
based on how SSD works. So you wanna be careful about abusing <code>fsync</code>.
Ramdisks might help too.</p>

<h2>MySQL installation n00bness</h2>

<p>There&#8217;s <code>mysql</code> and <code>mysql-server</code>. They&#8217;re separate packages. Derp.
One can connect to a server and issue commands, one actually installs
the database.</p>

<pre><code>/usr/bin/mysqladmin -u root password 'new-password'
</code></pre>

<p><code>mysqld_safe</code> is a script for starting up the daemon (as opposed to
<code>service mysqld start</code>?).</p>

<pre><code>cd /usr ; /usr/bin/mysqld_safe &amp;
</code></pre>

<p>Apparently it&#8217;s helpful because it:</p>

<ul>
<li>restarts the server upon error</li>
<li>runtime logging</li>
</ul>


<p>Apparently MySQL on Linux stores the DB files in</p>

<pre><code>/var/lib/mysql/
</code></pre>

<p>There&#8217;s a secure install script that does a few things:</p>

<pre><code>sudo /usr/bin/mysql_secure_installation
</code></pre>

<ol>
<li>Encourages you to set root password</li>
<li>Require <code>root</code> login must come from <code>localhost</code>; disable remote
logins.</li>
<li>Delete test database</li>
<li>Reload perms table.</li>
</ol>


<h2>PHP FPM</h2>

<p>http://php-fpm.org/</p>

<p>A simple and robust FastCGI Process Manager for PHP</p>

<p>I think this is necessary if you do nginx + php (apache has built in
niceties w php).</p>

<p>I already wrote about this shit and forgot it again:</p>

<blockquote><p>CGI applications are processes spun up by a web server to handle an
incoming request. Unscalable since spinning up processes all the time
takes a toll on the OS, not to mention that there&#8217;s no way to do
resource sharing (DB connection sharing, in-memory caching (because
the process dies at the end of request)).</p>

<p>With FastCGI, there&#8217;s a persisting FastCGI server that owns all of the
CGI programs, and webservers interact with FastCGI via a binary protocol
(over a socket (local) or TCP connection (remote)).</p></blockquote>

<p>So FPM is the thing that stays up and running, and may spawn PHP
instances, but can do the connection sharing.</p>

<h2>WordPress FPM</h2>

<p>http://codingsteps.com/install-php-fpm-nginx-mysql-on-ec2-with-amazon-linux-ami/</p>

<pre><code>location / {
    root   /var/www/html;
    index  index.php index.html index.htm;
}
location ~ \.php$ {
      fastcgi_pass   unix:/var/run/php-fpm/php-fpm.sock;
      fastcgi_index  index.php;
      fastcgi_param  SCRIPT_FILENAME  /usr/share/nginx/
                       html$fastcgi_script_name;
      include        fastcgi_params;
}
</code></pre>

<p>Why location and not server? Isn&#8217;t this gonna be required within
nginx.conf? I guess server means a proxy.</p>

<p>I&#8217;m guessing it&#8217;s expecting this include to be within a server
directive. Which I don&#8217;t want. I want simultaneous blogs, yo.</p>

<p>AH OK figured it out:</p>

<ul>
<li><code>server</code> doesn&#8217;t just mean a proxy; it means nginx will spin up such a
server, bind to the ports, and then proxy or serve the thing itself or
pass to FastCGI, however you&#8217;ve configured it. <code>server</code> must be
within the <code>http</code> context.</li>
<li><code>location</code> must be within <code>server</code> or nested within <code>location</code>
context.</li>
</ul>


<p>So we have</p>

<pre><code>location / { ...
</code></pre>

<p>and</p>

<pre><code>location ~ \.php$ { ... 
</code></pre>

<p>So the first matches root. The second case-insensitive matches anything
ending in .php.</p>

<h2>Nginx FastCGI</h2>

<p>FastCGI is a binary protocol. Nginx implements that protocol. Just in
the same way nginx can match a URL and proxy through to an underlying
server, nginx can match a URL and proxy through to a FastCGI server.</p>

<p>There might be multiple FastCGI-speaking servers that nginx might talk
to. PHP-FPM is an alternative implementation over the default FastCGI.</p>

<p>Nginx won&#8217;t spin up a fastCGI server (in the same way it won&#8217;t spin up a
proxy server that it proxies requests to), but rather expects it to be
already running and answering requests from a unix socket or internet socket.</p>

<p>A fast-cgi process is a process manager. It might spin up 8 worker
instances of, say, php, and reuse these instances efficiently. It might
feature adaptive process spawning, like PHP-FPM does, or it might just
block one request if N+1 requests arrive at the same time. Either way,
it&#8217;s better than:</p>

<ol>
<li>Constant process starting/stopping that plain of CGI entails</li>
<li>Building PHP into apache (<code>mod_php</code>), which means you can&#8217;t restart
PHP (after, say, an upgrade) without restarting Apache. Also, you
lose permissions granularity if it&#8217;s built into Apache, which opens
security holes that could be closed by letting PHP run at a different
uid/group, etc.</li>
</ol>


<p>So what&#8217;s PHP FPM?</p>

<h2>Nginx index causing internal redirect</h2>

<p>http://nginx.org/en/docs/http/ngx_http_index_module.html#index</p>

<p>It should be noted that using an index file causes an internal redirect, and the request can be processed in a different location. For example, with the following configuration:</p>

<p>Interesting. That&#8217;s how you can make a <code>/</code> behave like a PHP and be
processed like a PHP.</p>

<h2>Configure PHP-FPM to create unix domain socket with nginx owner/user</h2>

<p>http://stackoverflow.com/questions/23443398/nginx-error-connect-to-php5-fpm-sock-failed-13-permission-denied</p>

<p>You can configure php-fpm to create a unix domain socket and chown it
to a different user/group. Since nginx workers need to talk to it, it
should be configured to their user/group, which was <code>nginx</code> for me.</p>

<p>Now I&#8217;m getting &#8220;No input file specified.&#8221;</p>

<p>LONG STORY SHORT I was pointing to home/some-user/sites/wordpress and
unless you&#8217;re root, that&#8217;s inaccessible.</p>

<h2>PHP config</h2>

<p>https://www.digitalocean.com/community/tutorials/how-to-install-linux-nginx-mysql-php-lemp-stack-on-ubuntu-12-04</p>

<p>They want me to change <code>cgi.fix_pathinfo</code> to 0, else it will be fuzzy
match a php file for processing, a potential security risk.</p>

<p>Then I have to change PHP FPM to accept requests off a unix domain
socket:</p>

<pre><code>listen = /var/run/php5-fpm.sock
</code></pre>

<p>Makes sense, otherwise it assumes the fast cgi server is localhost 9000.</p>

<p>So&#8230; does nginx spin up a FastCGI server? Is it part of nginx? Is it
just a protocol?</p>

<h2>System V Services</h2>

<p>You don&#8217;t directly start mysqld, you do</p>

<pre><code>service mysqld start
</code></pre>

<h2>CentOS</h2>

<p>http://en.wikipedia.org/wiki/CentOS</p>

<p>Largely a clone of Red Hat Enterprise Linux.</p>

<p>http://unix.stackexchange.com/questions/27323/is-centos-exactly-the-same-as-rhel</p>

<blockquote><p>CentOS is very close to being RHEL without the branding and support. In particular, the library versions are the same, so binaries that work on one will work on the other. The administration tools are the same and configured in similar ways. However, there are a few differences, as the two distributions sometimes apply different minor patches. For example, in this question, it was apparent that RHEL 5 and CentOS 5 apply different rules to identify files under /etc/cron.d.</p>

<p>In other words, at the level of your course, you can treat CentOS and RHEL as interchangeable. But if you needed to look up the precise behavior of a program in a corner of the man page, you may encounter differences.</p></blockquote>

<h2>Alice in Flames</h2>

<p>http://techblog.netflix.com/2014/11/nodejs-in-flames.html</p>

<p>Flame chart things I didn&#8217;t know:</p>

<ul>
<li>X axis isn&#8217;t necessarily passage of time; I think it is in Chrome but
doesn&#8217;t need to be for purposes of flame chart?</li>
<li>Width of a box is aggregate call time;</li>
</ul>


<p>Ehh I guess flame charts do different things? Seems that chrome X axis
is in order. But it doesn&#8217;t need to be, in the same way that the tree
view of calls isn&#8217;t in time order; you care about total elapsed time,
not passage of time.</p>

<h2>Heroku one-off dynos</h2>

<p>https://devcenter.heroku.com/articles/one-off-dynos</p>

<p>TL;dr heroku run console (and any other run) will use a one-off dyno.</p>

<h2>Sampling vs Tracing</h2>

<p>https://www.jetbrains.com/profiler/webhelp/Profiling_Guidelines__Choosing_the_Right_Profiling_Mode.html</p>

<p>Sampling vs Tracing.</p>

<p>TL;DR tracing is more expensive, affects perf, but is more accurate than
sampling.</p>

<h2>Wordpress Admin on SSL</h2>

<p>http://codex.wordpress.org/Administration_Over_SSL</p>

<p>If you&#8217;re reverse-proxying, you have to prevent loops via:</p>

<pre><code>define('FORCE_SSL_ADMIN', true);
if ($_SERVER['HTTP_X_FORWARDED_PROTO'] == 'https')
       $_SERVER['HTTPS']='on';
</code></pre>

<p>Remember that wp-config.php is going to be loaded on every stupid thing.
Right?</p>

<h2>Heroku buildpacks</h2>

<p>Integration-tested via <a href="https://github.com/heroku/hatchet">Hatchet</a>.</p>

<p>https://devcenter.heroku.com/articles/buildpack-api</p>

<ul>
<li>detect: determines whether to apply buildpack to app</li>
<li>compile: apply the transformations</li>
<li>release: provides metadata back to runtime&#8230;?</li>
</ul>


<p>If you want both a node and ruby setup, you can do</p>

<pre><code>https://github.com/ddollar/heroku-buildpack-multi
</code></pre>

<p>and point to the default heroku-provided buildpacks within a .buildpacks
file.</p>

<h2>nginx-buildpack</h2>

<p>https://github.com/ryandotsmith/nginx-buildpack/blob/master/bin/start-nginx</p>

<p>This is a pretty awesome file that uses lots of Linux-y IPC trickery to
get</p>

<p>You must put the following in your Procfile:</p>

<pre><code>web: bin/start-nginx bundle exec unicorn -c config/unicorn.rb
</code></pre>

<p>The start-nginx script spins up processes in the background; nginx
will wait for</p>

<h2>App server</h2>

<p>Unicorn, Puma, Rainbows, zbatery, etc. It&#8217;s the thing that listens to a
socket and runs your application code for you. Rails isn&#8217;t an app
server, but Puma running a rails app is. Rails is an app framework. Puma is
an app server.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-17T08:02:00-05:00" pubdate data-updated="true">Nov 17<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/15/redis-b-hayes/">
		
			Redis B Hayes</a>
	</h2>
	<div class="entry-content">
		<h2>Redis&#8217;n</h2>

<p>This and other notes based on Redis in Action.</p>

<p>Questions:</p>

<ul>
<li>is it really brag-worthy to say in-memory-store? It gets persisted to
disk anyway; don&#8217;t other DBs bring as much into memory as possible for
fast lookups?

<ul>
<li>A: other databases are &#8220;primarily on-disk&#8221; but of course yes memory
caching exists.</li>
</ul>
</li>
</ul>


<p>Relation to memcached:</p>

<ul>
<li>Similar efficiency based on in-memory lookups</li>
<li>Redis features 2 persistence strategies (memcached doesn&#8217;t persist I
guess?)</li>
<li>Redis supports strings + 4 other data structures; memcached is strings</li>
</ul>


<p>ZSETs are hash of string keys to floating points, can be queried by
order, ordered by their weight.</p>

<h2>Databases: row insertion (often) fast</h2>

<p>Because no need for a random read + random write; appending to a file
(what most DBs do) is fast.</p>

<h2>ACID</h2>

<p>Set of properties that guarantee reliable database transactions</p>

<ul>
<li>Atomicity - all or nothing</li>
<li>Consistency - transactions bring database from one valid state to another</li>
<li>Isolation - are partially completed transaction visible to others?</li>
<li>Durability - post-transaction, data is committed even in power loss</li>
</ul>


<h2>Fortnight</h2>

<p>Two weeks.</p>

<h2>Heroku database URL</h2>

<pre><code>postgres://username:password@ec2-xx-xx-xx-xx-xx.compute-1.amazonaws.com:5432/d45d81ucgm3205
</code></pre>

<p>It&#8217;s just username + password at some publicly accessible EC2 URL. Your
cherished postgres instances just live on some EC2 farm. What a crock.</p>

<h2>Docker</h2>

<p>Docker images are read-only templates. Use them to generate containers.
Build other shit on top of containers.</p>

<p>Docker has its own IANA port numbers for REST and secure REST API&#8230;
what does this actually mean?</p>

<p>http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=docker#DOCKER</p>

<p>AH OK I have some more ideas:</p>

<p>Boot2Docker is what you use to run Docker on Mac OS X. Why? Because
docker depends on linux kernel specifics. Boot2Docker runs a Virtual Box
instance of some Linux-y thing</p>

<pre><code># within the virtual instance
$ uname
Linux version 3.16.4-tinycore64 (root@39d2c877bc4f) (gcc version 4.7.2 (Debian 4.7.2-5) ) #1 SMP Thu Oct 23 16:14:24 UTC 2014
</code></pre>

<p>So with the Boot2Docker setup, when you run the <code>docker</code> command on a
Mac terminal, it has to jump through some hoops to run the docker
instance on the Linux virtual box:</p>

<pre><code>Mac `docker` command
Proxy through to docker:tcuser@192.168.59.103
Run `docker` command, which talks to 
docker daemon
</code></pre>

<p>So there&#8217;s no docker daemon on OS X; the only persistent docker thing
you&#8217;ll see is Virtual box instances running the docker virtual instance
that the actual docker daemon lives on:</p>

<pre><code> /Applications/VirtualBox.app/Contents/MacOS/VBoxHeadless --comment boot2docker-vm --startvm 798082c7-01d7-4a4f-89fc-1ebf70bc1a0a --vrde config
 /Applications/VirtualBox.app/Contents/MacOS/VBoxNetDHCP --ip-address 192.168.59.99 --lower-ip 192.168.59.103 --mac-address 08:00:27:93:D3:BC --netmask 255.255.255.0 --network HostInterfaceNetworking-vboxnet0 --trunk-name vboxnet0 --trunk-type netadp --upper-ip 192.168.59.254
</code></pre>

<p>You can ssh into the docker VM box. Either w password or reusing the key
they generate for you when you install boot2docker; put this in
~/.ssh/config</p>

<pre><code>Host docker
  HostName 192.168.59.103
  User docker
  IdentityFile "/Users/machty/.ssh/id_boot2docker"
  IdentitiesOnly yes
</code></pre>

<p>(I realized later that there&#8217;s a convenient command for this:
<code>boot2docker ssh</code>&#8230; whoops!)</p>

<p>So with this config in place I&#8217;m guessing that I can either run
<code>docker version</code> or <code>ssh docker docker version</code> and see the same
thing. BOOYA both produce:</p>

<pre><code>Client version: 1.3.1
Client API version: 1.15
Go version (client): go1.3.3
Git commit (client): 4e9bbfa
OS/Arch (client): linux/amd64
Server version: 1.3.1
Server API version: 1.15
Go version (server): go1.3.3
Git commit (server): 4e9bbfa
</code></pre>

<p>So anyway, you can run commands against a docker image. This spins up a
container, runs the command, and stops the container&#8230; does it delete
the container?</p>

<pre><code>docker ps --help
</code></pre>

<p>Nevermind that I&#8217;ll figure it out later. Let&#8217;s figure out how to get a
Redis container running:</p>

<pre><code>https://registry.hub.docker.com/_/redis/
</code></pre>

<p>Use <code>docker build</code> to build from a Dockerfile, which kinda explains how
it ends up getting mounted to the outside world. So this is how you can
just have a docker instance of a thing that you can run commands
against, even in a Mac OS X setting? I know nothing, Jon Snow.</p>

<p>https://docs.docker.com/examples/running_redis_service/</p>

<pre><code>FROM        ubuntu:12.10
RUN         apt-get update &amp;&amp; apt-get install -y redis-server
EXPOSE      6379
ENTRYPOINT  ["/usr/local/bin/my-dumbass-redis-server"]
</code></pre>

<p>So this starts with the ubuntu:12.10 image, installs redis into the
container created from that image, exposes 6379&#8230; to&#8230;? What does this
mean?</p>

<blockquote><p>The EXPOSE instructions informs Docker that the container will listen on the specified network ports at runtime. Docker uses this information to interconnect containers using links (see the Docker User Guide). Note that EXPOSE only works for inter-container links. It doesn&#8217;t make ports accessible from the host. To expose ports to the host, at runtime, use the -p flag.</p></blockquote>

<p>From http://docs.docker.com/reference/builder/</p>

<p>So it&#8217;s exposed if we&#8217;re linking containers but not someone exposed to
the host app.</p>

<p>Ah I tried</p>

<pre><code>docker run -i --entrypoint=/usr/bin/redis-server dcf91
</code></pre>

<p>and then I couldn&#8217;t ctrl-C because of, something, but if i do</p>

<pre><code>docker run -it --entrypoint=/usr/bin/redis-server dcf91
</code></pre>

<p>then the -t option will attach a pseudo TTY and I can do it. This
stuff is so cray cray. Actually I lied ctrl-C doesn&#8217;t work for TODO
reasons, but Ctrl-P + Ctrl-Q detaches you from it? Seems good.</p>

<p>OK but if I do</p>

<pre><code>docker run -it -p 9191:6379 --entrypoint=/usr/bin/redis-server dcf91
</code></pre>

<p>this will run in interactive mode with ctrl-p ctrl-q supporting
detachability, mapping the container 6379 (default redis port) to the
host port 9191, and overriding the entrypoint because I didn&#8217;t know what
I was doing in the Dockerfile. I should have left it at the default
/usr/bin/redis-server because that&#8217;s where apt-get will put it.</p>

<p>ANYWAY the mapping works, but the problem is i have to SSH into the
docker host VirtualBox first to see it. How do I get beyond the
Boot2Docker wall? Wait I know I&#8217;ll just fuckin use some SSH magic.
Tunnels n shit.</p>

<pre><code>ssh docker -L 9191:localhost:9191
</code></pre>

<p>ah but this will open a login shell, which I don&#8217;t need/want for what
I&#8217;m doing:</p>

<pre><code>ssh docker -N -L 9191:localhost:9191
</code></pre>

<p>The -N stands for &#8220;Do not execute a remote command&#8221;</p>

<p>After which point I could just redis-cli but since I&#8217;m brutally low
level I&#8217;ll do</p>

<pre><code>$ nc localhost 9191
SET WAT WOOT
+OK
GET WAT
$4
WOOT
</code></pre>

<p>Booooooya. So cool.</p>

<p>OK gonna be an idiot. SSH all the way. Is that possible? It means being
able to SSH into container&#8230; sounds like you can&#8217;t do that without
going through</p>

<h2>Docker detach</h2>

<p>Docker attaching/detaching is pretty weird. I don&#8217;t know the rationale
behind it but they make it very easy to attach to a box but then not be
able to attach. Basically you have to always pass -it to run and then
can use ctrl-P ctrl-Q to detach.</p>

<p>Or, you can <code>kill -9</code> the attached processed; if you you just do <code>kill</code>,
that sends SIGTERM and that proxies through and closes the shitty
process, but again Ctrl-C doesn&#8217;t use it.</p>

<h2>Docker forwarding for OS X</h2>

<p>This is a great article</p>

<p>http://viget.com/extend/how-to-use-docker-on-os-x-the-missing-guide</p>

<p>Things learned:</p>

<ul>
<li><code>boot2docker ssh</code></li>
<li>Add <code>dockerhost</code> to /etc/hosts</li>
<li>Use <code>nsenter</code>

<ul>
<li><code>sudo nsenter -m -u -n -i -p -t $PID</code>

<ul>
<li><code>-m</code> use mount namespace of target process</li>
<li><code>-u</code> use UTS namespace of target process (UTS stands for time-sharing? legacy unix thing?)</li>
<li><code>-n</code> use network namespace of target process</li>
<li><code>-i</code> IPC</li>
<li><code>-i</code> IPC</li>
<li><code>-p</code> IPC</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>LXC Containers (vs Docker)</h2>

<p>https://linuxcontainers.org/</p>

<p>Better chroot, comparable to docker containers. Ways of containing
processes, resources, etc., dependent on modern linux kernel features,
mostly on process namespacing.</p>

<p>Excellent article comparing to Docker: http://www.flockport.com/lxc-vs-docker/</p>

<p>Things learned:</p>

<ul>
<li>yuno virtualization?

<ul>
<li>because of performance cost</li>
</ul>
</li>
<li>LXC and Docker are fast</li>
<li>Lightweight VMs</li>
<li>Is Docker a lightweight VM?</li>
</ul>


<p>A Docker container runs a single process:</p>

<blockquote><p>Docker restricts the container to a single process only. The default docker baseimage OS template is not designed to support multiple applications, processes or services like init, cron, syslog, ssh etc. As you can imagine this introduces a certain amount of complexity and has huge implications for day to day usage scenarios. Since current architectures, applications and services are designed to operate in normal multi process OS environments you would need to find a Docker way to do things or use tools that support Docker. When it comes to applications for a LAMP container you would need to build 3 containers that consume services from each other, a PHP container, an Apache container and a MySQL container. Can you build all 3 in one container? You can, but there is no way to run php-fpm, apache and mysqld in the same container without a shell script or install a separate process manager like runit or supervisor.</p></blockquote>

<p>http://docs.docker.com/articles/using_supervisord/</p>

<blockquote><p>Traditionally a Docker container runs a single process when it is launched, for example an Apache daemon or a SSH server daemon.</p></blockquote>

<p>This is the entry point. Note that <code>ubuntu</code> has no entry point. Not sure
if it&#8217;s possible to use <code>run</code> with a container that has an entry point,
since the entry point is the process that gets run.</p>

<p>So it should be possible for me to run an ubuntu netcat and portforward
at the same time:</p>

<p>All from Mac:</p>

<pre><code>$ docker run -i -p 9292:9292 --expose=[9292] ubuntu:14.04 nc -l 0.0.0.0
</code></pre>

<p>9292</p>

<p>Separate Mac terminal window:</p>

<pre><code>$ nc dockerhost 9292
</code></pre>

<p>And now these two assholes talk to each other!</p>

<p>Here are all the options I used</p>

<ul>
<li><code>-i</code>: run container interactively with terminal attached; without
this, nc immediately closes once someone connects to it since STDIN is
presumably dev null</li>
<li><code>-p 9292:9292</code>, map docker host port 9292 to container port 9292</li>
<li><code>--expose=[9292]</code> open the firewall since it wasn&#8217;t listed as exposed
in the dockerfile</li>
</ul>


<p>Shit is SO COOL.</p>

<h2>Docker vs Heroku</h2>

<p>Hmm, not even worth comparing.</p>

<h2>Nested SSH tunnels</h2>

<p>http://superuser.com/questions/96489/ssh-tunnel-via-multiple-hops</p>

<p>Map localhost:9998 to host2&#8217;s port 22.</p>

<pre><code>ssh -L 9998:host2:22 -N host1
</code></pre>

<p>Map localhost:9999 to blahbalhbablh you get the picture.</p>

<pre><code>ssh -L 9999:localhost:1234 -N -p 9998 localhost
</code></pre>

<p>Shit is sooooo crazy. I love this stuff.</p>

<h2>ProxyCommand</h2>

<p>From <code>SSH_CONFIG(5)</code>.</p>

<pre><code> ProxyCommand
         Specifies the command to use to connect to the server.  The command string
         extends to the end of the line, and is executed with the user's shell.  In the
         command string, any occurrence of `%h' will be substituted by the host name to
         connect, `%p' by the port, and `%r' by the remote user name.  The command can be
         basically anything, and should read from its standard input and write to its
         standard output.  It should eventually connect an sshd(8) server running on some
         machine, or execute sshd -i somewhere.  Host key management will be done using
         the HostName of the host being connected (defaulting to the name typed by the
         user).  Setting the command to ``none'' disables this option entirely.  Note
         that CheckHostIP is not available for connects with a proxy command.

         This directive is useful in conjunction with nc(1) and its proxy support.  For
         example, the following directive would connect via an HTTP proxy at 192.0.2.0:

            ProxyCommand /usr/bin/nc -X connect -x 192.0.2.0:8080 %h %p
</code></pre>

<p>So this proxies through an already established HTTP Connect proxy at
192.0.2.0:8080. That&#8217;s so awesome.</p>

<p>netcat even brags of this:</p>

<pre><code> Common uses include:

       o   simple TCP proxies
       o   shell-script based HTTP clients and servers
       o   network daemon testing
       o   a SOCKS or HTTP ProxyCommand for ssh(1)
       o   and much, much more
</code></pre>

<h2>get.docker.com</h2>

<pre><code>curl https://get.docker.com
</code></pre>

<p>It returns a bootstrapping shell script for setting up docker.</p>

<p>You can <code>#include</code> it when booting an EC2 instance. Pretty cool.</p>

<h2>Basic Authentication</h2>

<p>If I spin up a stupid netcat server</p>

<pre><code>nc -l localhost 9191
</code></pre>

<p>and then query it from Chrome</p>

<pre><code>http://user:password@localhost:9191
</code></pre>

<p>Here&#8217;s what I see:</p>

<pre><code>GET / HTTP/1.1
Host: localhost:9191
Connection: keep-alive
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
Cookie: blahblah
</code></pre>

<p>No reference to <code>user</code> or <code>password</code>. Which means that this information
isn&#8217;t sent up front unless the server requests basic authentication by
first sending back a 401 with the <code>WWW-Authenticate</code> header, after which
point the user and password will be sent.</p>

<p>And because it&#8217;s sent as a header (user:pass in base64) it&#8217;s encrypted
if sent over TLS. But it&#8217;ll be plaintext in your address bar :).</p>

<h2>SSH randomart</h2>

<p>You see it when you create a key pair. Why? Because it&#8217;s just an easy
ass visual way to compare keys rather than some Base64 shit.</p>

<p>You can see the randomart for an existing key by printing the
fingerprint in verbose mode:</p>

<pre><code>$ ssh-keygen -lv -f ~/.ssh/id_boot2docker.pub
2048 b2:3e:e4:d3:c1:9d:1b:75:46:0b:53:aa:18:6b:c7:c6  machty@machty.home (RSA)
+--[ RSA 2048]----+
|             ..  |
|            o..  |
|        .   .+ . |
|         * .. +  |
|      ..S.Eo o   |
|      .+oo+      |
|     o.. . o     |
|     .+ . .      |
|      .o         |
+-----------------+
</code></pre>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-15T13:16:00-05:00" pubdate data-updated="true">Nov 15<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/11/shananananananananeeees/">
		
			Shananananananananeeees</a>
	</h2>
	<div class="entry-content">
		<h2>Linux hierachy layout</h2>

<p><code>man hier</code> answers these questions.</p>

<p>Basically, <code>/usr</code> is a secondary hierarchy for libs/bins/other things
that aren&#8217;t strictly required for single-user mode (e.g. root).</p>

<p><code>/usr/local</code> is tertiary. Things you compile yourself might belong
there. Typically implies lower level of permissions. Rationale for
separting from <code>/usr</code> is that <code>/usr</code> might be some read-only thing
mounted and shared across machines, ready to be swapped out and upgraded
at any time, but <code>/usr/local</code> is crap that you can fuck wit.</p>

<p><code>brew</code> expects to install in the tertiary <code>/usr/local</code> directory:
<code>/usr/local/Cellar</code>. So you can have multiple versions of executables
installed via brew, but only one wins on the command line by way of
symlinks within <code>/usr/local/bin</code> pointing to specific executables in
<code>/usr/local/Cellar/projectname/1.23/bleh</code>. Symlinks to the rescue.</p>

<pre><code>$ sudo brew install wat
Error: Cowardly refusing to `sudo brew install`
You can use brew with sudo, but only if the brew executable is owned by root.
However, this is both not recommended and completely unsupported so do so at
your own risk.
</code></pre>

<p>I guess this is nice since it prevents all the ugliness of installing
shared executables at root privileges when they&#8217;re not needed.</p>

<h2>Raptor</h2>

<p>Ruby server. Apparently fast.</p>

<p>http://www.rubyraptor.org/how-we-made-raptor-up-to-4x-faster-than-unicorn-and-up-to-2x-faster-than-puma-torquebox/#zero_copy</p>

<ul>
<li>Uses nginx HTTP parser

<ul>
<li>due to battle-tested reliability</li>
<li>could have used PicoHTTPParser, but not much community adoption
though it claims being faster than nginc</li>
<li>could have used Mongrel&#8217;s Ragel HTTP parser, but lots of
Ruby-specific</li>
</ul>
</li>
<li>Comes w reverse proxy buffer, such as what nginx has but hyper
optimized to typical ruby raptor workflows</li>
<li>Multi-process</li>
<li>Sounds like multi-threadedness will be a paid solution that comes
later.</li>
</ul>


<p>The C++ component of Raptor is the server that consists of:</p>

<ul>
<li>Buffering reverse proxy</li>
<li>HTTP parser</li>
<li>HTTP server</li>
</ul>


<p>Apparently these are all part of the same thing.</p>

<h2>Puma Lopez mode</h2>

<p>Puma Ruby server comes with a Lopez mode named after <code>@brianmario</code> who
suggested it. It&#8217;s a tcp-only (no http) version of puma. To that guy&#8217;s
knowledge Puma is the only threaded/pre-forking Ruby server that offers
such a mode.</p>

<h2>nginx Reverse proxy buffer</h2>

<p>http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_buffering</p>

<p>I think it&#8217;s on by default, but you can disable it, configure buffer
sizes, or enable with <code>X-Accel-Buffer</code>.</p>

<h2>nginx in general</h2>

<ul>
<li>master process

<ul>
<li>manages worker process, reloads config files, etc</li>
</ul>
</li>
<li>worker processes

<ul>
<li>process requests</li>
</ul>
</li>
</ul>


<p>conf files are directives, either one liners or blocks.</p>

<ul>
<li>Block directives

<ul>
<li>same structure as normal directives</li>
<li>but have braces</li>
<li>if braces allow directives inside of them, it&#8217;s called a context</li>
</ul>
</li>
</ul>


<p>Contexts:</p>

<ul>
<li>main

<ul>
<li>events</li>
<li>http

<ul>
<li>server

<ul>
<li>location</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Catch up or move along</h2>

<p>http://unlearningeconomics.wordpress.com/2012/04/03/the-keenkrugman-debate-a-summary/</p>

<h2>30s write delay</h2>

<p>http://oldblog.antirez.com/post/redis-persistence-demystified.html</p>

<p>http://stackoverflow.com/questions/13650134/after-how-many-seconds-are-file-system-write-buffers-typically-flushed</p>

<p>http://brad.livejournal.com/2116715.html</p>

<p>Modified kernel buffers (of files on disk) wait up to 30s to be flushed
to disk. You can &#8220;force&#8221; it was fsync. But then your disks might lie to
you about what actually was persisted (verifiable via a test involving
pulling the power cord).</p>

<h2>Redis persistence</h2>

<p>http://oldblog.antirez.com/post/redis-persistence-demystified.html</p>

<p>It&#8217;s in-memory key-value, so does it ever get saved to disk?</p>

<p>Why yes it does, via:</p>

<ul>
<li>snapshotting; configure min writes since last sync, or a timeout, and
it&#8217;ll persist a snapshot to a .rdb file. Half completed transactions
(via MULTI/EXEC) don&#8217;t show up of course.</li>
<li>append-only AOF files

<ul>
<li>get rewritten based on memory contents if file grows too large</li>
<li>possible for an empty redis db (written and then deleted keys) has a
large AOF file.</li>
</ul>
</li>
</ul>


<p>Both can be enabled; it&#8217;s nice to have rdb files that you can back up.</p>

<blockquote><p>AOF rewrites are generated only using sequential I/O operations, so the whole dump process is efficient even with rotational disks (no random I/O is performed). This is also true for RDB snapshots generation. The complete lack of Random I/O accesses is a rare feature among databases, and is possible mostly because Redis serves read operations from memory, so data on disk does not need to be organized for a random access pattern, but just for a sequential loading on restart.</p></blockquote>

<p>Interesting, so usually a database that stores to disk would need to
organize data for efficient random access, but in Redis-land, everything
is loaded into memory.</p>

<p>This confused me:</p>

<blockquote><p>One of the additional benefits of RDB is the fact for a given database size, the number of I/Os on the system is bound, whatever the activity on the database is. This is a property that most traditional database systems (and the Redis other persistence, the AOF) do not have.</p></blockquote>

<p>In other words, AOFs can be large even for empty databases (due to
deletions).</p>

<p>appendfsync:</p>

<ul>
<li>appendfsync no

<ul>
<li>syncs at kernel whim (30 s on linux)</li>
</ul>
</li>
<li>appendfsync everysec

<ul>
<li>average 1 sec, at most 2 delay before buffers sent to kernel and sync&#8217;d</li>
</ul>
</li>
<li>appendfsync always

<ul>
<li>sync before each client ack</li>
<li>slowest</li>
</ul>
</li>
</ul>


<p>Default is <code>appendfsync everysec</code>, which is pretty good durability
without murdering speed.</p>

<blockquote><p>What Redis implements when appendfsync is set to always is usually called group commit. This means that instead of using an fsync call for every write operation performed, Redis is able to group this commits in a single write+fsync operation performed before sending the request to the group of clients that issued a write operation during the latest event loop iteration.</p></blockquote>

<p>Hmm that&#8217;s interesting&#8230; Redis has an event loop that can answer
multiple clients in a single iteration?</p>

<p>http://pauladamsmith.com/articles/redis-under-the-hood.html#event-loop</p>

<p>Ah, it uses epoll and the like; multiple sockets and events can have
arrived in one go, so it loops through all of those, does the necessary
reads, etc.</p>

<pre><code>/* Include the best multiplexing layer supported by this system.
 * The following should be ordered by performances, descending. */
#ifdef HAVE_EVPORT
#include "ae_evport.c"
#else
    #ifdef HAVE_EPOLL
    #include "ae_epoll.c"
    #else
        #ifdef HAVE_KQUEUE
        #include "ae_kqueue.c"
        #else
        #include "ae_select.c"
        #endif
    #endif
#endif
</code></pre>

<h2>UTF-8</h2>

<p>http://en.wikipedia.org/wiki/UTF-8</p>

<p>I can&#8217;t believe I never sat down and read this shit.</p>

<ul>
<li>backwards compat w ASCII since ascii only used the 7 bits (signed
char) to determine character.</li>
<li>81% of webpages use this encoding</li>
<li>ASCII is valid UTF-8</li>
<li>UTF-8 is variable length; the 8th bit determines length</li>
<li>there are invalid byte sequences (that you have to look out for when
reading files / raw shit)</li>
</ul>


<h2>ISO/IEC 8859</h2>

<p>http://en.wikipedia.org/wiki/ISO/IEC_8859</p>

<ul>
<li>single byte</li>
<li>all ascii is ISO</li>
<li>Seems like standard alphabet is preserved, but other 8 bit range stuff
differs.</li>
</ul>


<h2>Ruby string encoding</h2>

<p>http://stackoverflow.com/questions/20521371/set-utf-8-as-default-for-ruby-1-9-3</p>

<ul>
<li>Ruby 1.8 and below didn&#8217;t knew the concept of string encodings at all. Strings were more or less byte arrays.</li>
<li>Ruby 1.9: default string encoding is US_ASCII everywhere.</li>
<li><p>Ruby 2.0 and above: default string encoding is UTF-8.</p>

<p>  $ ruby -e &#8220;puts &#8221;.encoding&#8221;
  UTF-8</p></li>
</ul>


<h2>hiredis</h2>

<p>https://github.com/redis/hiredis</p>

<p>Presumably stands for &#8220;high(ish) level redis lib&#8221;.</p>

<p>The Ruby gem can optionally use this as a driver but it comes at the
expense of portability (JRuby can&#8217;t use this driver). But by default
Ruby just uses Ruby sockets to talk to redis.</p>

<h2>Public wifi</h2>

<p>Is there any security difference between a password-less public wifi and
one in which literally everyone knows the password?</p>

<h2>/private on os X</h2>

<p>http://unix.stackexchange.com/questions/63555/what-is-darwins-private-directory-for</p>

<p>fun fact: <code>/etc</code> is a symlink for <code>/private/etc</code> on OS X. Wacky.</p>

<h2>WEP, WPA, WPA2</h2>

<p>http://www.howtogeek.com/167783/htg-explains-the-difference-between-wep-wpa-and-wpa2-wireless-encryption-and-why-it-matters/</p>

<ul>
<li>WEP (Wired Equivalent Privacy)

<ul>
<li>oldest</li>
<li>WEP 128 most common even though there&#8217;s 256</li>
<li>major security vulnerabilities based on RC4 stream cipher cracking</li>
<li>on busy network, cracking could happen within a minute; if network
is slow, attacker can send fake packets and get replies that it can
use to crack over time.</li>
<li>passive attacks: you have to collect information. Gather shit.</li>
<li>Shamir (from RSA fame) was one of the crackahs.</li>
</ul>
</li>
<li>WPA

<ul>
<li>PSK (pre-shared key) is most common</li>
<li>256 min (over 64 and 128 WEP garbage)</li>
<li>message integrity checks (detects some MITM)</li>
<li>TKIP (temporal key integrity protocol) is predecessor to AES</li>
<li>too tied to WEP (meant for firmware progressive upgrades) and hence
prone to some WEP vulnerabilities, hence:</li>
</ul>
</li>
<li>WPA2

<ul>
<li>AES</li>
<li>CCMP (replacement for TKIP? but with TKIP fallback)</li>
</ul>
</li>
</ul>


<p>Just disable a thing called WPS and you&#8217;ll be good.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-11T06:43:00-05:00" pubdate data-updated="true">Nov 11<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/08/mr-noah/">
		
			Mr Noah</a>
	</h2>
	<div class="entry-content">
		<h2>Root/apex/base/DNS and things finally clicking</h2>

<p>They the same thing.</p>

<p>http://stackoverflow.com/a/16041655/914123</p>

<p>Also I like</p>

<pre><code>(Note: root, base, apex domains are all the same thing. Using interchangeably for google-foo.)
</code></pre>

<p>CNAME:</p>

<ul>
<li>Canonical Name record: Aliases another name</li>
<li>Use case: define CNAME for <code>ftp</code>, <code>www</code>, etc to point to the
<code>example.com</code> A record so that only the A record&#8217;s IP needs to
change</li>
<li>Can point to any ol domain, not just within <code>example.com</code>. Heroku
and other cloud services use this to have a CNAME pointing to
a domain name under the control of a dynamic name server that
can dish out different A name records (hence different IPs)</li>
<li>Can&#8217;t define CNAMEs for apex domains (e.g. <code>example.com</code>).</li>
<li>Can&#8217;t be shared with other records for that name, e.g. MX. CNAME wins
and fucks over the others, I think.</li>
</ul>


<p>A record:</p>

<ul>
<li>Points to an IP address.</li>
<li>Terminates DNS lookups</li>
</ul>


<p>ALIAS/ANAME:</p>

<p>http://blog.dnsimple.com/2011/11/introducing-alias-record/</p>

<p>http://support.dnsimple.com/articles/differences-between-a-cname-alias-url/</p>

<blockquote><p>Before going further into the details, it’s important to know that A
and CNAME records are standard DNS records, whilst ALIAS and URL
records are custom DNS records provided by DNSimple. Both of them
are translated internally into A records to ensure
compatibility with the DNS protocol.</p></blockquote>

<p>Aliases can coexist with other records at that level (so someone asking
for MX gets MX if defined for that name rather than resolving
elsewhere).</p>

<p>Ok, so DNS hosts just returns CNAMEs and A records (and others too), and
DNS hosts like DNSimple and DNS Made Easy can provide custom record
types that ultimately translate to A records. Makes sense.</p>

<p>So what about URL?</p>

<blockquote><p>This type of record uses an HTTP redirect to redirect visitors from a domain to a web site.</p></blockquote>

<p>So the A record returned from a URL record on DNSimple is going to point
to one of DNSimple&#8217;s server IPs. I set one up for
snaggletooth.alexmatchneer.com => http://www.example.com.</p>

<pre><code>$ curl -H "Host: snaggletooth.alexmatchneer.com" 50.31.209.254
&lt;a href="http://www.example.com"&gt;Moved Permanently&lt;/a&gt;
</code></pre>

<p>I also added a URL record for ugly.alexmatchneer.com to point to some
random s3 image and discovered that browsers in fact follow redirects
for images, hence this works:</p>

<pre><code>&lt;img src="http://ugly.alexmatchneer.com"/&gt;
</code></pre>

<p><img src="http://ugly.alexmatchneer.com" alt="" /></p>

<p>DNSimple is also nice enough to append the path to whatever its
forwarding, so <code>ugly.alexmatchneer.com/wat</code> forwards to the destination
specified in the URL record + <code>/wat</code>.</p>

<h2><code>dig</code> recursion</h2>

<p>Either you tell your DNS server to recurse for you, or you do it
yourself.</p>

<p>Name server does it for you (all these options just get rid of crufty
shit):</p>

<pre><code>dig +noall +answer +additional +recurse alexmatchneer.com
alexmatchneer.com.      3544    IN      A       23.235.39.133
</code></pre>

<p>You do it yourself:</p>

<pre><code>dig +noall +answer +additional +norecurse alexmatchneer.com
FWDR-68.FWDR-237.FWDR-161.FWDR-12. 3600 IN A    68.237.161.12
FWDR-71.FWDR-243.FWDR-0.FWDR-12. 3600 IN A      71.243.0.12
</code></pre>

<p>FWDR is a FiOS thing. These are from the additional section. So I guess
it means I should call them. But at what point do I go through
Verizon&#8217;s DNS? I thought I used like 4.2.2.2?</p>

<pre><code>cat /etc/resolve.conf

#
# Mac OS X Notice
#
# This file is not used by the host name and address resolution
# or the DNS query routing mechanisms used by most processes on
# this Mac OS X system.
#
# This file is automatically generated.
#
domain home
nameserver 192.168.1.1
</code></pre>

<p>I guess DNS is decided when I connect to a router. Ahhh I guess routers
perform DNS? Ok ok ok what if I tell <code>dig</code> which name server to query?</p>

<pre><code>$ dig +noall +answer +additional +norecurse @4.2.2.2 alexmatchneer.com
i.gtld-servers.net.     109080  IN      A       192.43.172.30
k.gtld-servers.net.     109080  IN      A       192.52.178.30
m.gtld-servers.net.     166299  IN      A       192.55.83.30
h.gtld-servers.net.     114566  IN      A       192.54.112.30
b.gtld-servers.net.     133590  IN      A       192.33.14.30
b.gtld-servers.net.     118573  IN      AAAA    2001:503:231d::2:30
a.gtld-servers.net.     159638  IN      A       192.5.6.30
a.gtld-servers.net.     113094  IN      AAAA    2001:503:a83e::2:30
e.gtld-servers.net.     113091  IN      A       192.12.94.30
f.gtld-servers.net.     166299  IN      A       192.35.51.30
j.gtld-servers.net.     166299  IN      A       192.48.79.30
g.gtld-servers.net.     109080  IN      A       192.42.93.30
d.gtld-servers.net.     101447  IN      A       192.31.80.30
l.gtld-servers.net.     136989  IN      A       192.41.162.30
</code></pre>

<p>WORD ok top level domains, makes sense. I bet if I let it recurse for me
it&#8217;ll gimme what I want:</p>

<pre><code>$ dig +noall +answer +additional +recurse @4.2.2.2 alexmatchneer.com
alexmatchneer.com.      3600    IN      A       23.235.46.133
</code></pre>

<p>Word. And if I use my router&#8217;s IP:</p>

<pre><code>dig +noall +answer +additional +norecurse @192.168.1.1 alexmatchneer.com
FWDR-68.FWDR-237.FWDR-161.FWDR-12. 3600 IN A    68.237.161.12
FWDR-71.FWDR-243.FWDR-0.FWDR-12. 3600 IN A      71.243.0.12
</code></pre>

<p>It refers me to some Verizon name server shit. Which is why if I type in
some nonsense domain name, I get redirected to some shitty Verizon
search page. Regardless of whether I&#8217;m in Chrome or in curl:</p>

<pre><code>$ curl oinasiodasd.asdasiodasod.asdoi
&lt;!DOCTYPE ... blah blah http://searchassist.verizon.com/
</code></pre>

<p>So what if I enable VPN? Prediction: my VPN provider will be making
queries on my behalf, presumably not behind some Verizon name server
shit.</p>

<pre><code>$ curl oinasiodasd.asdasiodasod.asdoi
curl: (6) Could not resolve host: oinasiodasd.asdasiodasod.asdoi
</code></pre>

<p>Basically (annoying caching hangover aside) dig will skip the FiOS
forwarding/recursing if I&#8217;m on VPN. All this makes sense. Perfect
sense. COMPLICATED THOUGH JESUS.</p>

<h2>VPNs and private network IPs</h2>

<p>ICANN set aside numbers like 192.168&#8230; and 10&#8230; for private networks.
VPN doesn&#8217;t interfere with that shit because it&#8217;s within that range.
Derp.</p>

<p>Ahhhh that does though that I could still use my router as a DNS, no?</p>

<p>VPN enabled:</p>

<pre><code>$ dig .
;; SERVER: 8.8.4.4#53(8.8.4.4)
</code></pre>

<p>VPN disabled:</p>

<pre><code>$ dig .
;; SERVER: 192.168.1.1#53(192.168.1.1)
</code></pre>

<p>And even w VPN enabled I could still query my Verizon router&#8217;s DNS</p>

<pre><code>$ dig +norecurse @192.168.1.1 .
FWDR-68.FWDR-237.FWDR-161.FWDR-12. 3600 IN A    68.237.161.12
FWDR-71.FWDR-243.FWDR-0.FWDR-12. 3600 IN A      71.243.0.12
</code></pre>

<p>So who the hell decides where I query from?</p>

<h2>DHCP</h2>

<p>Dynamic Host Configuration Protocol.</p>

<p>When you connect to a network, this tells you all sorts of useful
defaults:</p>

<blockquote><p>The DHCP server manages a pool of IP addresses and information about client configuration parameters such as default gateway, domain name, the name servers, and time servers.</p></blockquote>

<p>When you connect to a network, the DHCP broadcasting stuff happens and
you wind up with an IP, bingo bango bongo. When you connect to a network
but can&#8217;t establish an IP, it&#8217;s probably because DHCP hasn&#8217;t finished
yet.</p>

<p>But this is where 192.168.1.1 as a name server comes from; the Verizon
router will use DHCP to tell you to use it. Other routers might do other
things. When I tether to my phone it gives a different DNS.</p>

<h2>TXT Records</h2>

<pre><code>$ dig +short borflex.alexmatchneer.com TXT
"Another dumb thing"
"I am a big dumb ridiculous idiot!"
</code></pre>

<h2>Nested subdomains</h2>

<p>For the <code>alexmatchneer.com</code> domain, I added a CNAME for
<code>e.x.c.alexmatchneer.com</code> to point to expresscheckoutapp.com
and now it just works to nav to http://e.x.c.alexmatchneer.com</p>

<h2>Route 53</h2>

<p>Heyyyy that&#8217;s the port that DNS servers use.</p>

<h2>Rubydns</h2>

<p>https://github.com/ioquatix/rubydns</p>

<p>Pretty cool. You can make your own DNS server. I got mine to tell me I
was an idiot:</p>

<pre><code>$ dig +short @54.165.102.18 barflonkula TXT
"You are a big idiot"
</code></pre>

<h2>SOA Records</h2>

<h2>Pointilism</h2>

<p>Painting with dots. Like that Ferris Bueller painting, or some of Van
Gogh&#8217;s self portraits.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-08T08:29:00-05:00" pubdate data-updated="true">Nov 8<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/06/jaily-dournal/">
		
			Jaily Dournal</a>
	</h2>
	<div class="entry-content">
		<h2><code>rails c --sandbox</code></h2>

<p>Rolls back changes on exit.</p>

<pre><code>(0.4ms)  SAVEPOINT active_record_1
(0.2ms)  ROLLBACK TO SAVEPOINT active_record_1
</code></pre>

<p>Wraps in a transaction which is why you see the above rather than BEGIN
statements</p>

<h2>Temporarily change $stdout</h2>

<p>I wanted to get pretty-print output in Ruby. Solution, using <code>rails c</code>:</p>

<pre><code>f = File.open('tmp', 'w')
stdout_old = $stdout
$stdout = f
pp hash
$stdout = $stdout_old # could also do File.open(1)
</code></pre>

<h2>Review: difference between pipes and sockets</h2>

<ul>
<li>pipes came first in early 70s</li>
<li>pipes are always stream oriented; sockets can also be datagram
oriented.</li>
<li>pipes are unidirectional (and require two pipes for back and forth).
sockets are bi-directional.</li>
</ul>


<h2>FAT doesn&#8217;t support hardlinking</h2>

<p>I was going to try ember-cli-ramdisk mounting on file systems other than
HFS+, hoping that one FS would support more efficient reuse of freed
blocks, which might minimize paging on the grounds that if ramdisks
blocks are being reused, then additional ramdisk file allocations won&#8217;t
occur, hence memory lookups won&#8217;t occur, hence paging can&#8217;t happen.</p>

<p>Anyway, got initial builds working in FAT32, but incremental rebuilds
didn&#8217;t work due to hard-linking:</p>

<p>https://github.com/rlivsey/broccoli-concat/blob/master/index.js#L86</p>

<p>I thought we got rid of those, but then again the above use case is
fine, since hardlinks are only used concat output and not root files.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-06T16:00:00-05:00" pubdate data-updated="true">Nov 6<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/05/oss-cards-against-humanity/">
		
			OSS Cards Against Humanity</a>
	</h2>
	<div class="entry-content">
		<p>Why not.</p>

<h2>Black Cards</h2>

<ul>
<li>&#8220;GamerGate: it&#8217;s actually about <code>__________</code>&#8221;</li>
<li>&#8220;Ember.js: a framework for creating <code>_________</code>&#8221;</li>
</ul>


<h2>White Cards</h2>

<ul>
<li>Ethics in video game journalism</li>
<li><h1>GamerGate</h1></li>
<li>Thought Leadership</li>
<li>Brogrammers</li>
<li>Cracking the Nut</li>
<li>Destroy All Software</li>
<li>Ember.js</li>
<li>AngularJS</li>
<li>React</li>
<li>Two-way data-binding</li>
<li>Unidirectional Data Flow</li>
<li>Handlebars templates</li>
<li>Functional reactive programming</li>
<li>Hacker News</li>
<li>Stability without Stagnation</li>
<li>Ambitious Web Applications</li>
<li>Thirsty Randos</li>
</ul>


		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-05T12:40:00-05:00" pubdate data-updated="true">Nov 5<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/31/troll-toll-to-get-into-this-journal/">
		
			Troll Toll to Get Into This Journal</a>
	</h2>
	<div class="entry-content">
		<h2>HDIutil</h2>

<p>Trying to make some ramdisks on OS X</p>

<pre><code>hdiutil attach -nomount ram://8388608
</code></pre>

<p><code>hdiutil</code> attach will normally try to attach and mount a file system.</p>

<ul>
<li>attach: map a hardware device to some <code>/dev/wat</code> device file</li>
<li>mount: try to read the device, discover its file system, and mount it
as a directory so that you can actually cd into it, access files, etc</li>
</ul>


<p>So <code>-nomount</code> prevents the second step and just generates a dev file
mapped to ram.</p>

<pre><code>diskutil erasevolume HFS+ 'RAM Disk' /dev/wat
</code></pre>

<h2>What is a volume?</h2>

<p>Seems like a higher-level abstraction over disks and partitions.</p>

<p>http://tldp.org/HOWTO/LVM-HOWTO/whatisvolman.html</p>

<ul>
<li>Move things around more easily</li>
<li>give things better names than <code>/dev/sda</code> / sdb etc</li>
</ul>


<p>Basically let&#8217;s you overlay logical volumes on top of physical drives.
Makes it easy to move space around between various drives, make things
more sane.</p>

<pre><code>    hda1   hdc1      (PV:s on partitions or whole disks)                        
       \   /                                                                    
        \ /                                                                     
       diskvg        (VG)                                                       
       /  |  \                                                                  
      /   |   \                                                                 
  usrlv rootlv varlv (LV:s)
    |      |     |                                                              
 ext2  reiserfs  xfs (filesystems)                                        
</code></pre>

<p>Use LVM2 in Linux land.</p>

<h2>tcpdump</h2>

<p>Ahhh got it to work</p>

<pre><code>$ sudo tcpdump -t 'host machty.com'
$ ping machty.com
IP 192.168.109.90 &gt; pages.github.com: ICMP echo request, id 24129, seq 0, length 64
IP pages.github.com &gt; 192.168.109.90: ICMP echo reply, id 24129, seq 0, length 64
IP 192.168.109.90 &gt; pages.github.com: ICMP echo request, id 24129, seq 1, length 64
IP pages.github.com &gt; 192.168.109.90: ICMP echo reply, id 24129, seq 1, length 64
IP 192.168.109.90 &gt; pages.github.com: ICMP echo request, id 24129, seq 2, length 64
IP pages.github.com &gt; 192.168.109.90: ICMP echo reply, id 24129, seq 2, length 64
</code></pre>

<h2>UDP can broad/multicast</h2>

<p>And TCP cannot?</p>

<h2>Sequenced-packet sockets</h2>

<p>Combined aspects of UDP/TCP.</p>

<ul>
<li>Connection oriented</li>
<li>Datagram oriented (message boundaries preserved)</li>
<li>Reliable</li>
</ul>


<p><code>SOCK_SEQPACKET</code> type, available in UNIX domain. TCP/UDP do not support
it, but SCTP does.</p>

<p>Stream Control Transmission Protocol. Allows stream multiplexing,
preserves message boundaries unlike TCP.</p>

<pre><code>socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP);
</code></pre>

<p>So, TCP isn&#8217;t the only internet-domain stream protocol; SCTP is too.
It&#8217;s a stream of messages. Rather than bytes.</p>

<p>UDP + congestion controller = DCCP, Datagram Congestion Control
Protocol.</p>

<h2>Alternative IO</h2>

<ul>
<li><code>select</code>/<code>poll</code> to watch multiple fds for availability;

<ul>
<li>benefit over alternatives is that you don&#8217;t have to manually poll w non-blocking
reads.</li>
<li>doesn&#8217;t scale well w hundreds+ of FDs</li>
</ul>
</li>
<li>signal-driven IO; kernel notifies when IO ready, process can do other
still til its ready for IO; benefit over select/poll is that it
doesn&#8217;t block</li>
<li>epoll

<ul>
<li>application can monitor many file descriptors</li>
<li>linux specific but BSD has kqueue, and there are others</li>
<li>avoids complexities w signal programming</li>
</ul>
</li>
</ul>


<p>There&#8217;s also POSIX async IO (AIO); perform IO but don&#8217;t block, get
notified later when it goes through. Linux has thread implementation but
might have it on kernel now, who knows.</p>

<p>Since <code>epoll</code> is Linux specific, use a lib that provides a portal
evented layer to you process: use epoll if present, else fall back to
select/pool; <code>libevent</code> is one such lib.</p>

<ul>
<li>libevent

<ul>
<li>libev: high perf event loop based on libevent but without bugs

<ul>
<li>only ran on Unix, so node (which originally use libev) needed a
solution</li>
</ul>
</li>
<li>libuv: abstraction around libev or IOCP (Windows-based IO Completion
Port)

<ul>
<li>used in node</li>
<li>used in rust</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Two types of readiness notifications:</p>

<ul>
<li>level-triggered: fd is actually ready, now, for IO

<ul>
<li>poll/select &amp; epoll</li>
<li>Allows you to repeat the poll operation after a small read; no need
to read everything in a buffer at once</li>
</ul>
</li>
<li>edge-triggered: IO has occurred since last poll (but it&#8217;s possible
someone else already took care of it)

<ul>
<li>signals &amp; epoll</li>
<li>Try and read as much as possible because you have no way of knowing
whether there&#8217;s more data (without a non-blocking fail), usually by
non-blocking reads in a loop until EAGAIN or EWOULDBLOCK.</li>
</ul>
</li>
</ul>


<p>Note that epoll can do both. These constraints impact program design.</p>

<p>Non-blocking IO + edge-triggered notifications is common because there
are so many cases where blocking IO will screw you; better to non-block
in a lop and check if data is actually there.</p>

<p><code>poll</code> is like <code>select</code> but instead of grouping by operation you just
provide a list of FDs objects and say which type of IO you&#8217;re interested
in per object.</p>

<p>Readiness means an operation will not block. It doesn&#8217;t mean data will
transfer as it could mean EOF or error. The only guarantee is
non-blockage.</p>

<p>Downsides w poll/select when large number of FDs</p>

<ul>
<li>Need to initialize large structures to pass to kernel</li>
<li>Kernel needs to loop through all file descriptors</li>
<li>Program must inspect all returned FDs</li>
</ul>


<h2>Stripe</h2>

<p>You can do a one time charge, or you can save card to a customer.</p>

<p>You can create a Card in their API, but you must specify a customer or
recipient.</p>

<p>An OAuth access token acts like a secret API key:</p>

<blockquote><p>To swap this for an access_token, which acts like a secret API key&#8230;</p></blockquote>

<p>https://stripe.com/docs/connect/getting-started</p>

<p>So this error: https://support.stripe.com/questions/connect-publishable-key-error-with-shared-customers</p>

<p>Background: every Stripe API request sends in your app&#8217;s secret key for
authentication.</p>

<pre><code>Stripe.api_key = ENV['YOUR_DUMBASS_STRIPE_SECRET_KEY']
</code></pre>

<p>This makes it send automatically, but you can also override per API
request by providing a second parameter.</p>

<pre><code>charge = Stripe::Charge.create({
  ...
}, some_api_key)
</code></pre>

<p>In this case, the issue was that my implicitly provided app api key was
being provided to the API request to make a charge using a token
generated by the connected account.</p>

<p>I don&#8217;t really know why this is a problem; seems like something you
should be able to do, right? But actually you have to provide that
second parameter as the access token from when the account connected to
your app.</p>

<p>Trickay.</p>

<h2>Who&#8217;s using ports in OS X?</h2>

<pre><code>sudo lsof -nP -iTCP -sTCP:LISTEN
</code></pre>

<p>Figured I&#8217;d be able to use netstat for this, should probably look into
why I can&#8217;t.</p>

<h2>Self pipes</h2>

<p>Because <code>pselect</code> isn&#8217;t widely supported, you can use the self pipe
trick to get rid of race conditions surrounding signal handlers and
select. Recall the common race condition:</p>

<ul>
<li>Install signal handler that sets global flag to true</li>
<li>Run an IO loop that checks this global flag in order to decide whether
to perform some action.</li>
</ul>


<p>But if a signal arrives between these steps then you might start looping
without checking the flag, etc.</p>

<p>So you can self-pipe to get around this:</p>

<ol>
<li>Create a unix domain pipe, non-blocking on both ends to prevent any
sort of queueing/blocking behavior.</li>
<li>Within a signal handler, write a single byte into the pipe; <code>write</code>
is async signal safe, so we&#8217;re cool.</li>
<li>Include the pipe in <code>select</code>, always check if self-pipe is in
<code>readfs</code></li>
</ol>


<p>Unicorn uses a self pipe.</p>

<pre><code># We use SELF_PIPE differently in the master and worker processes:
#
# * The master process never closes or reinitializes this once
# initialized.  Signal handlers in the master process will write to
# it to wake up the master from IO.select in exactly the same manner
# djb describes in http://cr.yp.to/docs/selfpipe.html
#
# * The workers immediately close the pipe they inherit.  See the
# Unicorn::Worker class for the pipe workers use.
</code></pre>

<blockquote><p>Richard Stevens&#8217;s 1992 book &#8220;Advanced programming in the UNIX environment&#8221; says that you can&#8217;t safely mix select() or poll() with SIGCHLD (or other signals). The SIGCHLD might go off while select() is starting, too early to interrupt it, too late to change its timeout.</p></blockquote>

<p>This just means race conditions; anyway, Unicorn doesn&#8217;t mix select with
other FDs; rather it uses it as parent-child process communication; the
master will sleep/block on a select of the self pipe, and only the self
pipe, and will awaken, clear the pipe, and continue onward.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-31T06:45:00-04:00" pubdate data-updated="true">Oct 31<span>st</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/29/crowley-girdle/">
		
			Crowley Girdle</a>
	</h2>
	<div class="entry-content">
		<h2>Partial reads/writes for sockets?</h2>

<p>Why/how?</p>

<ul>
<li>reads: fewer bytes in the socket buffer than requested</li>
<li>writes: insufficient buffer space to transfer all requested bytes and

<ul>
<li>interrupt by signal handler (not just a signal, but a
custom-specified signal handler)</li>
<li>NONBLOCK enabled and only some of the bytes could be transferred</li>
</ul>
</li>
</ul>


<p>So it seems that <code>write</code>s just put data into the buffer, rather than
guarantee some transmission. How do you block to make sure all data was
received by the server?</p>

<ul>
<li>UDP: you can&#8217;t, since delivery is unreliable and there&#8217;s no concept of
ack</li>
<li>TCP: you <em>could</em> I guess, but at that point you&#8217;d probably want some
kind of application layer ack</li>
</ul>


<p>Blocking reads/writes only (and immediately) return 0 bytes if EOF.
Non-blocking would fire EAGAIN (or WOULDBLOCK for synack).</p>

<h2>What interrupts a blocking call?</h2>

<p>Signal handlers. And only signal handlers.</p>

<p>This article does a great job explaining why EINTR fires:
http://250bpm.com/blog:12</p>

<p>Basically, if you CTRL-C (or any other interrupt), you can&#8217;t just have
the kernel start you off back on the same syscall that was blocking, or
else you&#8217;ll have no opportunity to respond to a handled interrupt, e.g.
setting a flag in a signal handler that tells the world it&#8217;s quitting.</p>

<p>Also note that yielding the CPU (by way of a blocking sys call) is <em>not</em>
considered an &#8220;interrupt&#8221;; durr, if that were the case, then every
syscall would self-interrupt. This sounds obvious now but this shit is
complicated!</p>

<h2>Shutdown</h2>

<p><code>close</code> closes both sides of socket, shutdown only does half.</p>

<ul>
<li>shutdown read: future reads become eof. Called on UNIX domain socket,
EPIPE and SIGPIPE will happen if the peer continues to write.</li>
<li>shutdown write: Future writes yield SIG/EPIPE. Starts signalling EOF
to reading peer.</li>
</ul>


<p>Shutdown operates on the file description, closing all other descriptors
pointing to the same description. <code>shutdown</code> doesn&#8217;t touch the
descriptor; you still need to close it.</p>

<h2>recv and send</h2>

<p>Basically socket-specific <code>read</code> and <code>write</code>.</p>

<p>Basically allows granularity of read behavior; you can non-block a
read/write rather than performing an ioctl first.</p>

<ul>
<li>DONTWAIT; fire EAGAIN if nothing there (only differs</li>
</ul>


<h2>Giant Ruby IO impedance mismatch</h2>

<p>This has been plaguing me since the beginning of time, particularly as I
tried to apply examples to Ruby code: Ruby&#8217;s default IO methods don&#8217;t
map to the same-named syscalls.</p>

<p>Ruby -> C/syscall</p>

<ul>
<li>IO#read -> fread(n): uses internal C buffer, doesn&#8217;t return less than n
unless EOF</li>
<li>IO#readp -> read(n): no buffers used, only read what&#8217;s there</li>
<li>IO#read_nonblock -> read with <code>NON_BLOCK</code> set</li>
</ul>


<p><code>read_nonblock</code> is like <code>read_partial</code> with nonblock.</p>

<p>SO MORAL OF THE STORY if you&#8217;re reading C code with <code>read()</code> and want
the equivalent Ruby, use <code>readpartial</code>.</p>

<h2>sendfile</h2>

<p>Takes the shortcut between disk file and peer socket, rather than having
to buffer in user space first. Whatever fd you pass to it must be
<code>mmap</code>-able, which usually just means regular files on disk.</p>

<p>Not-unlike the Apache x-sendfile optimization (or nginx x-accel) wherein
rather than having the application logic handle the slow
buffering/serving of a file, let nginx or apache do it for you.
Restrictions obviously apply but whatevs.</p>

<h2>shutdown rd w TCP</h2>

<p>Calling <code>shutdown()</code> on the read side of a TCP socket doesn&#8217;t make a ton
of sense since there&#8217;s no good way to essentially signal an EPIPE on the
sending peer. So don&#8217;t do it, it&#8217;s unreliable.</p>

<h2><code>TIME_WAIT</code></h2>

<p>This is the period of time after an active close that&#8217;s been acked by
the peer; you chill out in this state for a little bit to make sure that
any re-transmitted duplicate packets are received and dropped.</p>

<p>This period of time can be like, 30 seconds to 2 minutes depending on
the implementation. Cray cray. I guess this is why you can&#8217;t bind to a
port immediately after killing the process that was using it.</p>

<p><code>TIME_WAIT</code> is useful for:</p>

<ul>
<li>reliable connection termination</li>
<li>allowing enough time for duplicated packets from an old connection to
not confuse a new connection</li>
</ul>


<p>It allows enough time to send acks and fins and what not.</p>

<p>Noobs try and disable it, as if they don&#8217;t need it, but they probably
do. <code>TIME_WAIT</code> ensures reliability of future connections. You can use
<code>SO_REUSEADDR</code> though, coming soon.</p>

<h2>netstat</h2>

<p>Tells you inet and unix socket information. Including send and receive
queue bytes. I just got Arq so that has a full sendQ for obvious
reasons.</p>

<p>It&#8217;s probably rare that both Send-Q and Recv-Q would be large; it means
a program is sending lots of shit (and the server can&#8217;t transmit it fast
enough) and the program isn&#8217;t reading lots of things out of the buffer.</p>

<p><code>*:*</code> means bound.</p>

<p>Get stats via <code>-s</code>. Stats for tcp <code>-sp tcp</code>.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-29T23:46:00-04:00" pubdate data-updated="true">Oct 29<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/17/gnomons-all-up-on-this-journal/">
		
			Gnomons All Up on This Journal</a>
	</h2>
	<div class="entry-content">
		<h2>timerfd</h2>

<p>Just like any other api that inverts signal-handling API into something
file handle-y, Linux has such an API for expiring timers, which means
you can use these file handles w functions like <code>select</code>, <code>poll</code>, and
<code>epoll</code>.</p>

<h2>CLOEXEC reminder</h2>

<p>I&#8217;ve already kinda learned this but I FORGET. The CLOEXEC flag is
something that appears in <code>open</code> and other APIs that create a file
handle; it means that if <code>exec</code> is ever called on a process with a
CLOEXEC handle, the handle will close rather than leak to a process that
can&#8217;t even really access that file handle.</p>

<h2>spawn = fork + exec</h2>

<p>Allows for greater degree of flexibility in what happens between those
two steps. Node only has spawn because it&#8217;s trying to be cross platform.
There&#8217;s no fork. There&#8217;s no spoon.</p>

<p><code>posix_spawn</code> exists to more directly spawn a process when <code>fork</code> is not
supported.</p>

<h2>Embedded System</h2>

<p>http://en.wikipedia.org/wiki/Embedded_system</p>

<p>Usually means you&#8217;re running software on some piece of hardware with a
dedicated purpose, limited resources, and real-time requirements. It&#8217;s a
computer system embedded into some larger mechanical whole.</p>

<h2>fork</h2>

<p>No guarantee of where parent or child is scheduled to run so don&#8217;t run
into conditions.</p>

<p><code>fork</code>ing can be wasteful especially if immediately <code>exec</code>ing, cept for
the fact that</p>

<ul>
<li>program text is marked read only and often shares the same page
mapping as parent</li>
<li>copy-on-write</li>
</ul>


<p>You can execute code in a single-purpose forked child process without
changing the resource/memory footprint of the parent. Useful if the code
in question is unspeakably/unstoppably leaky or prone to memory fragmentation.</p>

<p>Mmm mmm mmm using pipes.</p>

<pre><code>r,w = IO.pipe

if fork
  w.close
  answer = r.read
  Process.wait
  puts $?.exitstatus
  puts answer
else
  r.close
  w.write("SOME BULLSHIT")
  exit(123)
end
</code></pre>

<p>Useful for when the single byte/octet return code (<code>$?.exitstatus</code>)
won&#8217;t cut it. Insane Posse Clown.</p>

<p>BSD used to have a shit wasteful fork back in the day, then added vfork,
and then everyone else made efficient COW <code>fork</code>s, but still most people
provide an implementation of vfork which:</p>

<ul>
<li>performs zero duplication, even of VM pages (which all forks due, even
if no writes have happened yet under a COW system). Parent memory
shared until <code>exec</code> or <code>_exit</code>.</li>
<li>Parent execution suspended til then</li>
</ul>


<p>This is risky as fuck because:</p>

<ul>
<li>simply returning from a function will impact parent process&#8217;s memory.
It&#8217;s almost like a step-through longjmp, cept, no this totally breaks.
It&#8217;s not like the parent will pick up from wherever the child process
leaves off; the process counters are different between processes, so
if you return from a function in a child, you&#8217;ll fuck with the stack
frame, probably cause some SEGVs, and bite the big one.</li>
</ul>


<p>You can on the other handle futz with file handles in this time
(apparently these are duplicated? just not VM pages?)</p>

<pre><code>vfork -- spawn new process in a virtual memory efficient way
</code></pre>

<p><code>_exit</code> must be used because <code>exit</code> would flush stdio and thus fuck the
parent.</p>

<p>But don&#8217;t use vfork. It sucks. It&#8217;s obsolete. It&#8217;s not even in SUSv4.
It&#8217;s garbage shit-kicker nonsense. <code>fork</code> is pretty much just as fast
when COW exists.</p>

<p>You can actually control whether parent or child runs first via
<code>proc/sys/kernel/sched_child_runs_first</code> (or the sysctl equiv).</p>

<p>The argument for parent-first is that the TLB cache is warm with parent
stuff, so memory lookups are faster yadda yadaa I can&#8217;t imagine this
actually makes a difference unless you&#8217;re forking like a motherforker.</p>

<p>Hehehehe:</p>

<pre><code>3.times { fork }
puts "wat"
</code></pre>

<p>Results in</p>

<pre><code>wat
wat
wat
wat
wat
wat
wat
wat
</code></pre>

<p><code>atexit</code> handlers are shared w <code>fork</code>.</p>

<h2>Process rehash, new learnings</h2>

<p>Even if a parent kills a child, it has to wait or else it remains a
zombie.</p>

<p>There&#8217;s no such thing as a zombie orphan; well actually there are
transient zombie orphans; <code>init</code> will adopt them and immediately <code>wait</code>
on them, and then they&#8217;ll be collected.</p>

<p>Prediction: it gets messy to call <code>wait</code> in a SIGCHLD handler since
signals might coalesce; two SIGCHLDs might coalesce into one, and the
foolish programmer might only wait once. I bet if I looked at unicorn
I&#8217;d find a loop.</p>

<h2>KGIO</h2>

<p>http://bogomips.org/kgio/</p>

<p>Ruby gem w C extensions for Kinder, Gentler IO.</p>

<ul>
<li>Avoids expensive EAGAIN / EINPROGRESS exceptions

<ul>
<li>EAGAIN: non-blocking IO when there&#8217;s no data, so try <em>again</em> later</li>
<li>EINPROGRESS: (less common), similar to EAGAIN but distinguished for
things like <code>connect</code> in mid 3-way handshake</li>
</ul>
</li>
<li>other niceties</li>
</ul>


<p>Used in Unicorn and related Rainbows!. Can&#8217;t use in JRuby obviously but
then again no forking server model is supported in JRuby.</p>

<h2>JRuby Servers</h2>

<p>https://github.com/jruby/jruby/wiki/Servers</p>

<p>Can&#8217;t use unicorn but you can use things like Puma, or Trinidad, which
wraps rack/rails within a Tomcat container. So many things I do not
know!</p>

<h2>Isomorphic Code</h2>

<p>Can run on server or client. Not sure of the roots, but sounds like it
started in 2011, at least as way of describing JS code that runs between
both? React-router is &#8220;isomorphic&#8221;.</p>

<h2>ELF format</h2>

<p>Executable and Linking Format.</p>

<h2>Built-ins</h2>

<p>Sometimes no forking occurs because it&#8217;s quick and efficient, or because
there are desirable side effects that should make it into the current
shell process. Like <code>cd</code> (can&#8217;t change the cwd of the current process
if you&#8217;re forking). Or <code>export</code>.</p>

<h2>Why keep fd&#8217;s open on <code>exec</code>?</h2>

<p>If you&#8217;re exec&#8217;ing, shouldn&#8217;t you lose access to file handles? Not
necessarily; stream redirection via the shell is a good example where
you preserve what 0 1 2 point to.</p>

<h2>Auto-reap zombie child processes</h2>

<p>If you set the signal mask to ignore <code>SIG_CHLD</code>, potential zombie child
processes will be automatically reaped. So no need to <code>wait</code> in that
case.</p>

<p>Also, it&#8217;s implementation-defined (according to SUS) whether <code>exec</code>
resets the <code>SIG_CHLD</code> disposition after an exec (Linux preserves,
Solaris resets to default, etc).</p>

<h2><code>exec</code> clears sig handlers</h2>

<p>Of course, since sig handlers live in the text and text is replaced, so
must handled signals be reset. Everything else about signals is
preserved (cept that <code>SIG_CHLD</code> ignores may not
get reset to <code>DFL</code> depending on the implementation), but since most
processes expect to start with a clean slate, if you didn&#8217;t write the
process, you should reset everything yourself before an exec.</p>

<h2><code>system</code></h2>

<p>Runs a shell command, with all the processing/substitutions of the
command string that you would expect.</p>

<p>Inefficient; fork+execs twice, one for the shell, and one for the
process you intend to run.</p>

<p>set-user-id and set-group-id programs should never use <code>system</code>
since it opens the door to setting weird ENV vars to get unintended
programs to run, and they&#8217;ll inherit the effective user id. The
canonical example is setting IFS to <code>a</code>, and then <code>shar</code> runs and is
interpreted as <code>sh r</code>, and <code>r</code> is some script/executable that is no
running with admin privileges to do whatever it wants. Evil shit!</p>

<p>Note that modern shells reset IFS now as a rule.</p>

<h2><code>clone</code></h2>

<p>A Linux-specific sister of <code>fork</code>; it creates a new process, but starts
at the beginning of a provided function called w a provided arg. The
child process terminates if this function returns (or the exit variants
are called).</p>

<ul>
<li>you can specify termination signal (rather than always CHLD)</li>
<li>flags let you meticulously control a variety of info about what is
actually shared with the new child process: file handles, signal
dispositions, etc.</li>
</ul>


<p>So basically it&#8217;s threads&#8230; but separate processes? Is there a name for
these kinds of threads? LinuxThreads I guess.</p>

<p>Threads/processes are just kernel scheduling entities with differing
degrees of shared attributes. Processes are just, like, organizational
distinctions. Schedule wise, the scheduler doesn&#8217;t care whether it&#8217;s a
thread or a process. Blueskying of course.</p>

<h2>Mode 7</h2>

<p>http://en.wikipedia.org/wiki/Mode_7</p>

<p>The special background layer mode that enabled perspective-y effects, as
well as zooming and other cool things. F-zero relied on it, the map in
Link to Past relied on it. Any zoomy crazy shit that wasn&#8217;t a sprite
relied on it.</p>

<h2>Dyson Sphere</h2>

<p>Shell around the sun.</p>

<p>http://www.islandone.org/LEOBiblio/SETI1.HTM</p>

<p>Other lifeforms smashed apart their planets to build a dyson sphere to
capture energy, support population growth.</p>

<p>We could knock apart Jupiter, use its mass to create a sphere around sun
with a diameter twice that of Earth&#8217;s orbit. The shell would be 10 feet
thick, and make&#8230; something&#8230; habitable?</p>

<h2>Fermi Paradox</h2>

<p>http://waitbutwhy.com/2014/05/fermi-paradox.html</p>

<p>http://en.wikipedia.org/wiki/Fermi_paradox</p>

<p>The apparent contradiction between the high probability of alien life
and the fact that no one has contacted us yet.</p>

<p>Explanation 1: They don&#8217;t exist</p>

<p>Possibly due to a Great Filter; at some point in development, something
wipes them out, or there&#8217;s some point of evolution that&#8217;s reaaaally
really hard to get beyond that filters out people who made it beyond the
previous step.</p>

<p>So where does that leave <em>us</em>?</p>

<p>We&#8217;re</p>

<ul>
<li><p>rare</p>

<ul>
<li>other rare survivors might be reaaaally far away</li>
<li>the filter is behind us</li>
</ul>
</li>
<li><p>first: no one else to communicate with yet</p></li>
<li>fucked: we&#8217;re about to hit our wall like everyone else has</li>
</ul>


<p>Ah I love the potentialy reason for why intelligent life wouldn&#8217;t
broadcast data: there are potential harmful civilizations that would
destroy anyone they could find, and most advanced civilizations are
smart enough not to give away their locations to these fuckers. That&#8217;s
why we only have SETI today, and not METI (messaging to ETs), which most
scientists agree is a profoundly unwise idea.</p>

<p>Eesh, or there&#8217;s only one superpredator species, like humans on Earth,
that would wipe out another species before it got too intelligent.
Nipping the universe in the bud. Fuuuck that.</p>

<p>Or we&#8217;re not using the right technologies to communicate, or even if we
did, other minds might work much faster or slower than ours; it could
take years for them to say hello. Hahaha.</p>

<p>Or we are receiving communications but the gov is hiding it.</p>

<p>Or other civilizations see us, but we&#8217;re a look-don&#8217;t-touch zoo.</p>

<p>Or the higher civilizations are here, but we couldn&#8217;t begin to
understand them, they&#8217;re just so advanced.</p>

<p>Or we&#8217;re just so fundamentally incorrect about reality.</p>

<p>Types of civilization</p>

<ul>
<li>I: ability to use all the energy on the planet (Sagan says we&#8217;re a
0.7; just under the legal limit)</li>
<li>II: ability to harness all power of a star (e.g. Dyson sphere)</li>
<li>III: ability to harness all power of a whole galaxy</li>
</ul>


<p>http://waitbutwhy.com/ seems pretty awesome in general. Three thumbs up.</p>

<h2>fork v vfork</h2>

<p>I&#8217;ve already written about this but followup: vfork is faster, but
considering how slow the followup <code>exec</code> is, this is probably
neglibibilgigible.</p>

<h2><code>time</code> and forking</h2>

<p>Are child process CPU times included?</p>

<pre><code>N = 20000000

def slow_thing
  inc = N / 5
  N.times do |i|
    puts "." if i % inc == 0
  end
end

do_fork = true
if do_fork
  fork do
    slow_thing
  end

  Process.wait
else
  slow_thing
end
</code></pre>

<p>With forking:</p>

<pre><code>real    0m1.565s
user    0m1.544s
sys     0m0.013s
</code></pre>

<p>Without forking:</p>

<pre><code>real    0m1.480s
user    0m1.464s
sys     0m0.011s
</code></pre>

<p>Seems that yes they are (there&#8217;s no difference with the above).
Actually, quick aside: it seems that <code>time</code> is a bash builtin. Not sure
why, but if I use <code>/usr/bin/time</code> as well, not much changes</p>

<pre><code>1.42 real         1.41 user         0.00 sys
1.49 real         1.47 user         0.01 sys
</code></pre>

<p>Ah, <code>time</code> will add together all forked processes. And apparently if you
have two active processes, you might wind up with a CPU time greater
than real time. LET US FIND THE FUCK OUT.</p>

<pre><code>N = 20000000

def slow_thing
  inc = N / 5
  N.times do |i|
    puts "." if i % inc == 0
  end
end

num_forks = 2

num_forks.times do
  fork do
    slow_thing
  end
end

num_forks.times { Process.wait }
</code></pre>

<p>BOO YA</p>

<pre><code>real    0m1.636s
user    0m3.199s
sys     0m0.021s
</code></pre>

<p>How awesome is it when things start clickin.</p>

<p>So how does time actually do it?</p>

<h2>curl + tar</h2>

<pre><code>curl http://mirror.anl.gov/pub/gnu/time/time-1.7.tar.gz | tar -x
</code></pre>

<p>I guess you&#8217;re also supposed to use <code>-z</code> as well, but in my manpages:</p>

<pre><code> -z      (c mode only) Compress the resulting archive with gzip(1).  In extract
         or list modes, this option is ignored.  _Note that, unlike other tar
         implementations, this implementation recognizes gzip compression auto-
         matically when reading archives._
</code></pre>

<p>That&#8217;s so nice of them. And ridiculous that it wouldn&#8217;t always work that
way. Maybe not.</p>

<h2>Threads</h2>

<p>Every process has at least one thread.</p>

<p>Concurrency via processes has some limitations:</p>

<ul>
<li>nothing is shared so communication is limited to IPC, pipes and what
not</li>
<li>expensive due to page table duplication and file descriptor table dups
and all the things that happen during <code>fork</code></li>
</ul>


<p>Most process attributes are shared between threads. Here&#8217;s some stuff
that&#8217;s not:</p>

<ul>
<li>thread ID</li>
<li>signal mask</li>
<li>thread-specific data</li>
<li>alternate signal stack</li>
<li><code>errno</code></li>
<li>floating-point env</li>
<li>scheduling priority/policy</li>
<li>CPU affinity</li>
<li>capabilities</li>
<li>stack</li>
</ul>


<p>Of course you could share stack vars between threads but this runs the
risk of data invalidation once a function returns etc etc etc.</p>

<p>How does errno work if it&#8217;s a variable? Trick question, it&#8217;s a macro
that evals to an lvalue (so you can still manually set it yourself).</p>

<p><code>join</code> is like <code>wait</code>, it seems to free up that thread, and you wouldn&#8217;t
want to call it twice, lest terrible things happen. You must detach or
join. (Seems like the equiv in processland for detach is to set
<code>SIG_CHLD</code> to ignore).</p>

<p>Unlike processes, threads are created as peers. If A spawns B spawns C,
then A can join C. They&#8217;re all siblings in the same process cult.
There&#8217;s no concept of generic <code>Process.wait</code> to join with any ol thread.
This makes sense since some lib function could spawn a thread and you
might clobber its operation and steal its return value.</p>

<p>Once you detach a thread, you can&#8217;t join it. Again keep in mind that
threads can&#8217;t escape the fact that they live in a process; if the
process dies, so do the threads.</p>

<p>Threads can&#8217;t use the full virtual memory address space; they have to
share with all the other threads. Probably not a big deal unless you&#8217;re
doing insane shit, but still.</p>

<p>Mutexes in Linux are implemented in user spaces using futexes (fast user
space mutexes). They only cause system calls when multiple threads lock.</p>

<h2>Pitchblende</h2>

<p>Old school word for Uraninite. Basically ore ready for uranium
processing.</p>

<h2>Javascryptonomicomicon</h2>

<p>http://matasano.com/articles/javascript-cryptography/</p>

<h2>ffs ssl</h2>

<p>http://wingolog.org/archives/2014/10/17/ffs-ssl</p>

<blockquote><p>WTF their price is 49 dollars for a stupid certificate? Your domain name was only 10 dollars, and domain name resolution is an actual ongoing service, unlike certificate issuance that just happens one time.</p></blockquote>

<p>Hmm clearly I need to better understand how this all works&#8230; being a
CA, root or no, definitely requires constant service</p>

<p>Wow this is sneaky: http://thejh.net/misc/website-terminal-copy-paste</p>

<p>Never copy and paste secure stuff from a webpage. I&#8217;m so sad.</p>

<p>Lol &#8220;Well now I have to live with this confidence-inspiring dialog,
because I left off the organization&#8221;</p>

<p>TIL Organization is the name you choose that you want to pop up when
inspecting certifications.</p>

<p>Wow, googlebot still doesn&#8217;t use TLS 1.2.</p>

<h2>Condition variables</h2>

<p>Didn&#8217;t I write about this already? So forgetful!</p>

<pre><code>Loop
  Lock around shared structure
    If shared structure "empty"/unusable, wait on condition variable


(other thread):
Lock around shared structure
  Put data into it
  Signal Condition variable
</code></pre>

<p>If you didn&#8217;t do this, you&#8217;d have some wasteful CPU-hog loop that
constantly locked and unlocked the mutex to check if the shared
structure had data ready.</p>

<ul>
<li>Always re-check the condvar predicate; some other thread might have
invalidated it in the meantime.</li>
<li>Also, a looseness of predicates lends to some flexibility; a producer
doesn&#8217;t need to know the exactly logic that consumer cond var depends
on; producer can just say &#8220;hey interested people, this shared
structure changed, so chiggity check yourselves&#8221;</li>
<li>Some implementations, particularly multi-core, might wake up a cond
var for fucks sake (explicitly allowed by SUSv3</li>
</ul>


<h2>Reentrant revisited</h2>

<p>We already knew thread-safe functions aren&#8217;t necessarily reentrant (e.g.
a signal handler that locks a mutex might be reentered and deadlock the
same mutex on the same thread). A reentrant function is one that doesn&#8217;t
access globals, mutexes included (what if a shared structure, possibly a
mutex is passed on to the function? Deadlock could still occur&#8230; I
guess the answer is that a function might be itself reentrant, but a
caller might not be reentrant so the chain of calls it makes with
whatever global data it&#8217;s using isn&#8217;t going to be reentrant).</p>

<p>Not every function can be reentrant. malloc can&#8217;t be: it <em>must</em> access
global data. A <code>_r</code> suffix implies reentrancy.</p>

<h2><code>pthread_once</code></h2>

<p>The pthreads library provides facilities for ensuring that some kind of
initialization (that occurs in the function you provide it) only happens
once.</p>

<h2>Thread-specific data</h2>

<p>I guess it&#8217;s a thread-local storage, but TLS is an overlay API that&#8217;s
friendlier to program in. In C at least you use the <code>__thread</code> keyword
when declaring a variable and voila you get everything for freeee.</p>

<h2>Thread cancellation</h2>

<p>Threads can be cancelled at cancellation points, SUS-specified
lib/syscall functions, or if you&#8217;re a moron (or you have a 0.001% use
case) you can set cancelability to be async, which means it might
interrupt at any ol machine instruction.</p>

<h2>ncurses</h2>

<p>New curses. Used for writing terminal apps. Cross-terminal. Optimizes
refreshes for our remotely connected friends.</p>

<h2>Thread stacks</h2>

<p>Main thread has mucho size, thread stacks are smaller but configurable
in size.</p>

<h2>Signals and threads</h2>

<p>Horrible combination, avoid when possible. Reason being: signals existed
long before threads and never expected to integrate with them.</p>

<ul>
<li>signal dispositions are process wide (you can&#8217;t have one thread ignore
a signal and another use a specific handler, etc)</li>
<li>signals might be directed to thread or process. Thread directed if

<ul>
<li>signal is result of hardware instruction (SEGV, etc&#8230; same
reason that signals are sometimes synchronous)</li>
<li>SIGPIPE</li>
<li><code>pthread_kill</code> or <code>pthread_sigqueue</code></li>
</ul>
</li>
<li>all others are process wide</li>
<li>kernel selects arbitrary thread to handle signal (as opposed to
multiple threads handling a single sig)</li>
</ul>


<p>Shit. What the fuck is a difference between signal disposition and
signal mask?</p>

<p>Disposition: per-process structure that controls whether a signal
is a) is ignored, b) runs a custom handler, or c) invokes the default
action.</p>

<p>Mask: data structure that knows when signals are temporarily blocked,
the idea being that they should be later unblocked and the signal will
fire.</p>

<p>OK so dispositions are process-wide, but masks are thread-local; so as
one time slice begins, the kernel will look up the mask for that thread
and decide whether a pending signal should fire upon it, and if not,
wait til later. You might have some threads that block all signal
handlers.</p>

<p>Ahhhhhhh SO FUCKING FORGETFUL. Didn&#8217;t I just cover this a few days ago?
Basically I tried writign a ruby program to set the mask, but you don&#8217;t
have access to the mask in Ruby because Ruby uses it internally and is
trying to layer a nice signal API on top of it. I was trying to set up
something where a main thread had a custom handler but all the threads
it spawned blocked SIGINT so that it must be handled by the main thread.</p>

<p>But if I weren&#8217;t too lazy to write the test in C:</p>

<blockquote><p>By manipulating the per-thread signal masks, an application can control which thread(s) may handle a signal that is directed to the whole process.</p></blockquote>

<p>I mostly just wanna know how the kernel selects the thread to wake up.
Does it just loop through each of the sleeping threads and find the one
whose signal mask will allow it?</p>

<p>None of the pthread lib has async-signal-safe functions, so what&#8217;s
recommended:</p>

<ul>
<li>main thread blocks everything, all spawned threads inherit signal mask</li>
<li>single thread deblocks and is responsible for dispatching signals.</li>
</ul>


<p>Reminder: difference b/w reentrant and async-signal-safe:
async-signal-safe is a function you can call in a signal handler because
it as either a) reentrant or b) not interruptible by a signal handler.</p>

<p>So why &#8220;async&#8221;-signal-safe? There are sync signals and async signals
depending on whether hardware issued the signal, whether it&#8217;s a signal
sent to yourself, etc. I think the answer is that async-signal-safe is a
concept that exists even outside of the context of a currently running
signal handler. In other words, if you know <code>foo</code> is NOT async signal
safe, it means <code>foo</code> might be interrupted by an async signal, and if
itself were called, hell might break loose.</p>

<p>So that&#8217;s a useful concept on its own, but when applied to what you&#8217;re
allowed to call within a signal handler, the rule is &#8220;don&#8217;t call non
async-signal-safe functions&#8221; because, within a handler or no, you might
be interrupted by <em>another</em> signal handler and fuck yourself.</p>

<p>So you should always write signal handlers that are themselves reentrant
and only call async-signal-safe functions.</p>

<p>Remember, these async-signal-safe functions might not be reentrant on
their own, but because they block signal handlers from interrupting
them, they are async-signal-safe.</p>

<p><code>exec</code> wipes out all other threads entirely. Gone. No termination /
cancel handlers called.</p>

<p><code>fork</code> kills all other threads than the caller, but mutexes and
conditional variables live on in whatever state. (What about
<code>thread_t</code>s? Probably persist but point to dead threads?). Memory leaks
can happen since the killed threads don&#8217;t have an opportunity to clean
up after themselves.</p>

<p>LOVE.</p>

<p>But you can defined atfork handlers. Otherwise you probably shouldn&#8217;t
fork unless you&#8217;re also <code>exec</code>-ing.</p>

<h2>NPTL</h2>

<p>Native POSIX Threading Lib</p>

<p>The software feature in linux kernel that enabled POSIX-compliant
threads. Red Hat 9 added it first, either as a kernel module or patch to
the OSS kernel.</p>

<h2>Social Engineering</h2>

<pre><code>http://en.wikipedia.org/wiki/Social_engineering_(security)
</code></pre>

<p>It just means sneakily manipulating people into giving away their shit.
Phishing and what not.</p>

<h2>M:N</h2>

<p>aka number of threads map to number of Kernel Scheduling Entities
(processes, threads, etc, schedulable executable things).</p>

<h3>M:1</h3>

<p>Multiple threads to a single KSE. User-level threads aka green threads.
Kernel doesn&#8217;t know about these threads.  Fast context switching, but</p>

<ul>
<li>other slow syscalls block all other threads, e.g. <code>read</code>, since
control is passed from user-spacing threading lib to kernel</li>
<li>kernel can&#8217;t schedule, which means no multi-processor green threads.</li>
</ul>


<p>I&#8217;m guessing the way scheduling worked was to set interval timers and
pre-empty threads. Seems correct.</p>

<h3>1:1</h3>

<p>Kernel-level threads. Pthreads.</p>

<p>Thread creation, context switching, etc, are slower since it requires a
syscall, but it means the kernel can efficiently schedule, put them on
separate cores.</p>

<h3>M:N</h3>

<p>Some kernel, some green.</p>

<p>Keep in mind that this whole <code>M:N</code> nomenclature also applies to
processes vs threads. err, does it? Processes and green threads? I could
be bullsharting right now.</p>

<p>M:N is complex, perhaps not worth it. It was originally the suggested
implementation for NPTL.</p>

<h2>Process Group / Session</h2>

<ul>
<li>Process group

<ul>
<li>Process group leader

<ul>
<li>Process that creates the group, whose PID becomes the process group
ID</li>
</ul>
</li>
<li>New process inherits its parent&#8217;s pgid</li>
<li>Lifetime: from process group creation to when last process leaves
group id</li>
<li>premature question: can a new process take the id of a now-dead
process that used to be pg leader?</li>
<li>processes can leave by terminating or joining another group</li>
<li>pg leader can leave before others, no biggie.</li>
</ul>
</li>
<li>Session

<ul>
<li>collection of PGs</li>
<li>Session leader

<ul>
<li>Process that creates the session, whose PID becomes the session ID</li>
</ul>
</li>
<li>New process inherits its parent&#8217;s pgid</li>
<li>all processes in session share terminal</li>
</ul>
</li>
</ul>


<p>SIGHUP is sent to PG leader when terminal disconnects.</p>

<p>Login:</p>

<ul>
<li>Shell becomes session leader AND process group leader

<ul>
<li>every command it runs, it makes it process group leader (but shell
remains session leader)</li>
<li>any command forks have same process group id (the command&#8217;s pid),
and session id is shell.</li>
<li>shell can create many process groups (commands) and can foreground
one and the rest are background</li>
</ul>
</li>
</ul>


<p>You can only change process group of yourself or your children, else
ESRCH. You can only move a process between groups within the same
session. You can&#8217;t change the process group of the session leader.
You can&#8217;t child the process group of a child if it&#8217;s already called
<code>exec</code> (you might confuse the poor child); I guess this means shells
will fork and then the parent will call setpgid on the child&#8230;? Why
doesn&#8217;t the child just do it itself?</p>

<p>Answer (and I love this book for this shit: go buy the Linux Programming
Interface right now): the parent process needs to be able to send job
control signals to the newly created child (to the new process group
ID it&#8217;ll have), and the child needs to set the new pgid before it
<code>exec</code>s or else all is lost, so how do you guarantee that the new process
group on the child has been set before either the parent or child
proceed? Answer: do it on both and ignore errors on the parent.</p>

<p><code>setsid</code> establishes a process as group and session leader and
disconnects it from any controlling terminal. You can&#8217;t <code>setsid</code> if
you&#8217;re process group leader (EPERM), so you need to <code>fork</code> first to get around
that. This restriction is in place because any other process group
children will still have a pgid that points to this same process group
leader process even if it has a new session id; the only way to ensure
the numbers don&#8217;t point to the same place is to distribute new numbers,
e.g. new process ids, e.g by forking.</p>

<pre><code>if fork
  Process.wait
  puts "done"
else
  # if you hadn't forked, setsid would fail because
  # this process would be PG leader
  Process.setsid
  puts gets
end
</code></pre>

<p>The above code doesn&#8217;t error out like I thought it would&#8230; it still has
access to the terminal, but, it, umm, couldn&#8217;t open the terminal if it
wanted to?</p>

<p>When session leader opens a controlling terminal, it becomes the
controlling process for a terminal. They are LINKED. If a process
has a controlling terminal, it can open special file <code>/dev/tty</code>.</p>

<p>Ah ok so to make the above snippet break, I should have actually done</p>

<pre><code>fork do
  Process.setsid
  File.open('/dev/tty')
end
Process.wait
</code></pre>

<p>which yields</p>

<pre><code>setsid.rb:3:in `initialize': Device not configured - /dev/tty (Errno::ENXIO)
</code></pre>

<p>You open <code>/dev/tty</code> if the shell (or someone else) already redirected
your output (by <code>dup2</code>ing 0 1 2 file descriptors) and you want to get
back in touch with your <code>tty</code>. Call your <code>tty</code>. She&#8217;s your controlling
terminal.</p>

<p>AH HA this is how you can take a program with redirected input and get,
say, the users password from the terminal. Fuckin badass. Let&#8217;s try it.</p>

<pre><code>$ echo "wat" | ruby getpass.rb
here's some stuff from stdin
wat
now type something in: borflex
You wrote borflex
</code></pre>

<p>So many cool shits!</p>

<p>Note that you can also open <code>/dev/tty</code> without it becoming the
controlling terminal.</p>

<p>TTY captures special characters, converts into signals sent to members
of the foreground process group.</p>

<p>This demonstrates how a signal is delivered to literally everyone in the
foreground process group (5 &#8220;omg&#8221;s are printed).</p>

<pre><code>N = 5
N.times do
  fork do
    trap(:INT) do
      puts "omg\n"
      exit
    end
    sleep
  end
end

trap(:INT) do
  puts "main\n"
end

N.times do
  Process.wait
end
</code></pre>

<p>It&#8217;s possible for no one to be the foreground process, but rare, and not
when there&#8217;s a shell that&#8217;s monitoring for foreground process to quit
(via wait or some other signal handle).</p>

<p><code>tcgetpgrp</code> gets the foreground process group of a provided terminal fd.
<code>bash</code> and other shells make use of this when passing the terminal
around to child processes.</p>

<h2>SIGHUP</h2>

<p>This is sent when terminal connection is severed (also sends SIGCONT to
make sure the process is alive). Happens when:</p>

<ul>
<li>terminal driver detects disconnect of one form or another</li>
<li>the last pseudoterminal file handle has been closed (i don&#8217;t
understand this)</li>
</ul>


<p>You can ignore / handle SIGHUP but future reads yield EOF. (What about
output? Same thang?).</p>

<p>SIGHUP is often used to tell a daemon process to reload a config file.
Why SIGHUP? Because daemons have no controlling terminal so the single
is otherwise useless; why not put it to work in some useful way? nginx
and others do this.</p>

<p>When terminal disconnects, the controlling process (the shell) gets a
SIGHUP. Shells will terminate, but before doing that they&#8217;ll send a
SIGHUP to each of the process groups.</p>

<p><code>nohup</code> just forks, sets disposition to ignore HUP, and then <code>exec</code>s.
Easy peasy.</p>

<p>Note that shells won&#8217;t send SIGHUP to any process groups it didn&#8217;t
create.</p>

<pre><code>echo $$
</code></pre>

<p>This is like the thing that trolled me before w <code>ruby -e</code>&#8230; <code>$$</code> in a
shell command is the shell&#8217;s pid.</p>

<p>Background tasks don&#8217;t get sighup&#8217;d when you exit a terminal. SIGHUP
only gets sent to foreground processes. That seems cray cray.</p>

<h2>$$ in Ruby</h2>

<p>Everywhere I look it says it is the id of the running process. As in,
you know, the pid. But if I do</p>

<pre><code>ruby -e "puts Process.pid; puts $$"
</code></pre>

<p>I get two different numbers.</p>

<p>You know why?</p>

<p>Because, of course, <code>$$</code> means something to shells! Before the command
even runs, <code>$$</code> will be substituted with the pid of the shell! If I
change double quotes to single quotes, I get the same numbers, of
course!</p>

<pre><code>ruby -e 'puts Process.pid; puts $$'
</code></pre>

<p>This is why I started going crazy and thinking that the internet was
just wrong and that <code>$$</code> means the session id. Wrong!</p>

<h2>terminfo / termcap</h2>

<p>These are packages that some programs like vi and less make use of for
gracefully switching in and out of screen-controlling modes; vi and less
take over the screen but when you quit, you see the terminal lines from
before you ran them. This uses terminfo, which is a terminal database
which provides facilities such as that.</p>

<h2>sigtstp</h2>

<p>You can catch a suspend ^Z via sigtstp and then signal sigstop to
actually stop the process, but any parent processes listening in will
think you were stopped by sigstop rather than sigtstp, so you can do the
more complicated thing of setting disposition to default, unblocking,
raising tstp (so that it suspends this time), and then resetting the
mask upon reentry.</p>

<h2><code>init</code> and <code>wait</code></h2>

<p>I originally thought that <code>init</code> would <code>wait</code> on every orphan it
inherited, but of course, <code>wait</code> is blocking if nothing&#8217;s actually
terminated, so I think <code>init</code> actually checks the status of the
process and <code>wait</code>s only if it&#8217;s terminated. But if it inherits a
stopped process group, it won&#8217;t call wait. So you might have stopped
process groups that live on forever and no one ever terminates them.</p>

<p>Hence, upon orphaning, the kernel sends SIGHUP + SIGCONT to any
orphaning process groups that have at least one stopped process, and
these signals are sent to everyone. Of course, at some later
post-orphaning time, these orphaned processes might be stopped and would
need <em>something</em> to come along and resume or terminate them.</p>

<h2>nice values</h2>

<p>You can give processes (specific pids, groups&#8217;, users&#8217;) varying nice
values from -20 to 19, give or take. Lower means higher priority, high
means lower.</p>

<h2>The Complexity Balloon and other yehudaisms</h2>

<blockquote><p>&#8220;you can only squeeze the complexity ballooon&#8221;
- Yehuda Katz</p></blockquote>

<p>On XMLHttpRequest capitalization:</p>

<pre><code>btw: the rule for XHR is:
First acronym all caps
subsequent acronyms title-case
old Java rule
</code></pre>

<h2>Security book recommendations</h2>

<p>The art of software security assessment</p>

<p>The grey hat hackers handbook</p>

<h2>Scheduling</h2>

<p>CPUs have their own run queues, with items with different priorities.
Processes can be scheduled with RR or FIFO real-time policy.</p>

<p><code>RR</code> is round robin. Equal priority processes get a time slice and then
get thrown in back of queue at the end. They can be pre-empted by higher
order shits. How?</p>

<ul>
<li>higher order process blocked on syscall becomes unblocked (io
available, etc)</li>
<li>another process raised to higher level</li>
<li>current process raised to lower value than some other process</li>
</ul>


<p><code>RR</code> similar to standard RR <code>SCHED_OTHER</code>, difference being in the
strictness of the weighting algorithm. <code>SCHED_OTHER</code> uses nice values,
but a lower nice value than another isn&#8217;t a strict determiner of
scheduling order, but rather a weighted suggestion, where as <code>RR</code> is
brutal deterministic.</p>

<p>In <code>FIFO</code> there&#8217;s no timeslice. You have it til you&#8217;re preempted or give
up control.</p>

<p>You can lock up a system with <code>RR</code> or <code>FIFO</code>. To prevent:</p>

<ul>
<li>set low CPU limit, which causes default-terminating <code>SIGXCPU</code> to fire.</li>
<li>use <code>alarm()</code></li>
<li>use high priority watchdog process to watch others, adjust their
priorities.</li>
</ul>


<p>CPU Affinity just means the tendency for a process/thread/kernel
scheduling unit to run on the same CPU; switching CPUs involves a slow
context switch, cache invalidation, etc.</p>

<h2>Daemonizing</h2>

<ul>
<li>long-running, often started at boot</li>
<li>has no controlling terminal (hence never receives INT, TSTP, HUP,
etc); its excluded from job-control signals</li>
</ul>


<p>some examples</p>

<ul>
<li>cron</li>
<li>sshd: the ssh server that&#8217;s open for remote logins.</li>
<li>httpd: http server

<ul>
<li>ah so TCP isn&#8217;t a daemon, it&#8217;s a kernel-level IO protocol, but httpd
is a server. It&#8217;s apache, duerp.</li>
</ul>
</li>
<li>inetd: superserver daemon&#8230;? sounds like this doesn&#8217;t exist on mac.</li>
</ul>


<p>Some daemons run as kernel threads, w names bracketed.</p>

<p>To daemonize:</p>

<ul>
<li>fork: child process lives, master terminates.

<ul>
<li>returns control to terminal</li>
<li>child process lives on, and is no longer process group leader (it
inherits parent pgid which doesn&#8217;t match its new pid, so it can&#8217;t be
leader). this is needed for setsid (remember that setsid can&#8217;t be
called with process group leader, because other children processes
might be in that process group with a pgid pointing to a process
that lives in a different session, but process group members must
all live within the same session as a rule)</li>
</ul>
</li>
<li>setsid

<ul>
<li>become session leader

<ul>
<li>frees you from connected terminal</li>
<li>allows you to connect to another terminal (but&#8230; see below)</li>
</ul>
</li>
</ul>
</li>
<li>fork again

<ul>
<li>this prevents any future terminals you connect to from becoming
controlling terminal (TODO: why/when would a daemon connect to a
terminal?)</li>
<li>you don&#8217;t have to do this if you don&#8217;t open another terminal, or you
open terminals with <code>O_NOCTTY</code></li>
</ul>
</li>
<li>Clear umask (remember that umasks negate certain permissions on create
files&#8230; right? TODO: review this shit)</li>
<li>Change cwd to <code>/</code> so that in case the process was started with a cwd
on another file system that doesn&#8217;t contain <code>/</code>, that fs can be
unmounted

<ul>
<li>remember you can&#8217;t unmount &#8220;busy&#8221; FSs

<ul>
<li>files are open on it</li>
<li>processes have CWDs on it (how does it know? loop through the
processes?)</li>
</ul>
</li>
</ul>
</li>
<li>Close all file descriptors, 0, 1, 2, for similar busy FD unmount
reasons, also because you might get some TTOUs if you try and read
from stdin.</li>
<li><code>dup2</code> them to point to <code>/dev/null</code> so that lib functions and other
things don&#8217;t unexpectedly file, or you don&#8217;t open another file in
their place but some lib function things they&#8217;re std IO and then write
shit to them

<ul>
<li>reading dev null yields EOF. PRETTY EFFIN HANDY</li>
</ul>
</li>
</ul>


<p>Daemon shutdown consists of SIGTERM and a 5-second-layer SIGKILL if it
doesn&#8217;t clean up and shut down in that time (all processes concurrently
have 5 seconds to shutdown, not 5 seconds of CPU each; all SIGTERMS send
out at same time).</p>

<p>Memory leaks and fd leaks are a bigger deal for daemons since they&#8217;re so
long-lived.</p>

<p>Care must be taken to prevent multiple identical daemons from running;
Pidfiles help.</p>

<p>Logfiles can&#8217;t grow forever, and manually deleting a file if the daemon
doesn&#8217;t let go of it won&#8217;t prevent the resources from being freed until
the last handle is closed to the file. <code>logrotate()</code> can be used to aid
in this.</p>

<p>HUP is unused since daemons don&#8217;t have controlling terminals so people
classically use it to re-initialize or reload conf files.</p>

<p>Btw you can open other people&#8217;s TTYs. And it means you can write to
their screens.</p>

<p><code>syslog</code> and <code>syslogd</code> is a useful utility to global logging; write to
syslog unix domain datagram socket and blah dee blah dee blah it&#8217;ll
funnel out to wherever based on a shared conf FILE!</p>

<h2>Security</h2>

<p>Privilege via</p>

<ul>
<li>root started it</li>
<li>set-user-id or set-group-id + owned by root</li>
</ul>


<p>Guidelines:</p>

<ul>
<li>don&#8217;t use set-user/group-id unless you really need it; better to
use a child process

<ul>
<li>or if you need it, don&#8217;t give it root</li>
</ul>
</li>
<li>e.g. a process currently with set-user-id that allows unprivileged
users to write to a file they don&#8217;t have access to: much better to
set-group-id to a group specific to this process, and set group of
that file to that group. group. group. group.</li>
<li>if you&#8217;re set-user-id, only operate in that mode when you need it.</li>
<li>real id is whoever started the program</li>
<li>basically, shit is really hard and you should refer to this book every
time you need a refresher because this stuff megasucks.</li>
<li>don&#8217;t exec shells or other interpreters when you have privileges. Way
way way too open to abuse.</li>
<li>close file handlers; they&#8217;re just integers, not hard to reuse. recall
CLOEXEC</li>
</ul>


<h2>Clear out your memory</h2>

<p>Why? Because it might be paged out to a swap area that privileged
programs can read. So that seems pretty iScare. If that&#8217;s visible, why
not fuckin, fuckin, fuckin memory, man, why can&#8217;t you like open another
process and look at its memory maaaan, even without it having been paged
first.</p>

<p>Actually you can if you&#8217;re not careful. You can create special device
files that have direct access to RAM. That&#8217;s so fucking crazy. So even
<code>chroot</code> can&#8217;t even save you if you have a set-user-id-root program.
Crazy crazy crazy.</p>

<p>Also if you have a leftover open file handle to <code>/</code> then you can
<code>fchdir</code> into it and <code>chroot(".")</code> chroot back into that shiot.</p>

<h2>Use capabilities</h2>

<p>UNIX privileges are all-or-nothing; Linux adds the notion of
capabilities. Use em. They&#8217;re granular n shit.</p>

<h2>Use virtual kernels</h2>

<p>Totally isolated. They have no concept of the raw kernel. Can&#8217;t access
it. Can&#8217;t do shiot.</p>

<p>BSD <code>jail()</code> addresses lots of this stuff. SO MANY FUCKING LOOP HOLES OH
MY GOD.</p>

<h2>Time of check, time of use</h2>

<p><code>access()</code> lets you query access of user to file. If you&#8217;re
set-id-to-root and you check if some unprivileged user has access to
something, maybe a symlink, and then in between that check and whatever
you end up destructively doing, the symlink is swapped to elsewhere,
then you might clobber some shittles. Malicious user could go nutso and
fire off a bunch of <code>SIGSTOP</code>s and change runtime environment to fuck
with a privileged program.</p>

<h2>Bounds checking</h2>

<p>strcpy babeh</p>

<p>Linux now has stack address randomization which randomizes the location
of the stack in an 8 MB range in VM. Seems cool. That&#8217;s why if you print
the pointer of a var int main in a test C program, it&#8217;s different each
run. This feels similar to stretches in bcrypt and any other security
measure that makes certain operations slower to counteract brute force
attackers.</p>

<h2>DoS denial of service</h2>

<p>Local variants include fork bombing.</p>

<p>Remote DoS more common, combat w:</p>

<ul>
<li>load throttling, dropping requests when overloaded</li>
<li>timeouts</li>
<li>(throttled) logging of overloads</li>
<li>don&#8217;t crash from unexpected loads</li>
<li>avoid algorithmic complexity attacks wherein a structure known to
handle a particular series of input might get fucked and consume lots
of resources. Not insecure, necessarily, but might fuck the fuck.</li>
</ul>


<h2>Shared libs</h2>

<p>Compile w <code>-g</code> nowadays since RAM and disk are cheap. Apparently this
info doesn&#8217;t affect performance?</p>

<p>A shared lib is a <code>.a</code> file composed of <code>.o</code> files, constructed with
<code>ar</code>, as in &#8220;library archives&#8221;.</p>

<pre><code>$ ar tv /usr/lib/liby.a
rw-r--r--       0/0            40 Aug 24 21:45 2013 __.SYMDEF SORTED
rw-r--r--       0/0           920 Aug 24 21:45 2013 main.o
rw-r--r--       0/0           912 Aug 24 21:45 2013 yyerror.o
</code></pre>

<p>Variants of <code>gcc</code> and static libs</p>

<pre><code># generate wat.o
gcc -c wat.c

# generate a.out with wat.o lib
gcc lol.c wat.o otherlibarchive.a

# search standard lib directories (like /usr/lib)
# looks for /usr/lib/libwoot.a
gcc -c wat.c -lwoot

# Search a non-standard directory
gcc -c wat.c -lwoot -L/borflex/snaggletooth
</code></pre>

<p>All of the .a archive and .o object files is added to executable size.
Seems bad. Also when the processes are run, VM is increased by that
much, even though it&#8217;s all redundant read-only text shit.</p>

<p>Ah. Static libs. vs Shared libs. Shared libs are fuckin, fuckin,
dynamic, maaaan.</p>

<p>Ah note that static and global variables obviously aren&#8217;t shared between
shared libs; each process gets a copy.</p>

<p>Pros:</p>

<ul>
<li>Large shared libs between small processes mean quicker process startup
time (though the first time the shared lib is loaded into VM is
obviously slow)</li>
<li>With some limitations, you can swap out libs without relinking</li>
</ul>


<p>Cons:</p>

<ul>
<li>complexity</li>
<li>shared libs must use position-independent code

<ul>
<li>PIC is a way of compiling shared libs so that the location of
functions, statics, globals, string constants, etc, can vary, and I
don&#8217;t understand it.</li>
</ul>
</li>
</ul>


<p>Modern shared lib linking format is ELF: Executable and Linking Format.</p>

<p><code>.so</code> is shared object, shared lib, as opposed to just <code>.o</code>.</p>

<p><code>ar</code> lets you add/remove <code>.o</code>s from library archives, but not so with
<code>.so</code>s.</p>

<p>You can use <code>nm</code> (name list util, i.e. symbol table util) to list
symbols.</p>

<p>Interesting, so given the following <code>wat.c</code>:</p>

<pre><code>int WAT;
</code></pre>

<p>I see <code>_WAT</code> appear in the symbol table:</p>

<pre><code>$ gcc -c wat.c &amp;&amp; nm wat.o
0000000000000004 C _WAT
</code></pre>

<p>Note that it wouldn&#8217;t appear if I&#8217;d made it <code>static</code> or <code>extern</code>. Shit
is cool.</p>

<p>So PIC adds a global offset table to help the dynamic linking describe
where shit is.</p>

<p>Hmm what if I use <code>g++</code> on a cpp file?</p>

<pre><code>$ g++ -c wat.cpp &amp;&amp; nm wat.o
0000000000000000 S _WAT
</code></pre>

<p>What&#8217;s the difference b/w S and C? C apparently means &#8220;common&#8221; symbol,
and S means a generic &#8220;none of the above&#8221; in the <code>man nm</code>.</p>

<p>You can take a dynamic/shared lib and compile statically though, if you
want it:</p>

<ul>
<li>less complexity</li>
<li>safer against .so upgrades</li>
</ul>


<p>So what&#8217;s the difference between a .so and a .dylib? Is that a mac
thing?</p>

<h2>Dynamically loaded libraries</h2>

<p>Deferred loading whenever some plugin is loaded. As in your code does
it. Seems pretty rad. Use <code>dlopen</code>. Search a function by name, invoke
it.</p>

<p>You can use env var <code>LD_DEBUG</code> to print out some shit.</p>

<h2>IPC</h2>

<ul>
<li>byte streams: pipes, fifos, datagram sockets</li>
<li>message: message queues; can&#8217;t read them part way, all or nothing</li>
<li>pseudoterminals</li>
</ul>


<p>Different from shared mem:</p>

<ul>
<li>reads are destructive for byte streams (but yes in some cases you can
seek, multicast/broadcast)</li>
</ul>


<p>MQ (POSIX or SystemV) messages have priorities, and deliver in different
order.</p>

<p>Ah now it&#8217;s coming back to me:</p>

<ul>
<li>UNIX domain sockets

<ul>
<li>ruby: <code>Socket.pair</code></li>
<li>datagram (no need to worry about byte streams/delimiters)</li>
</ul>
</li>
<li>Pipe

<ul>
<li>ruby: <code>IO.pipe</code></li>
<li>stream</li>
<li>flow control handled by kernel</li>
</ul>
</li>
</ul>


<h2>Pipes and FIFOs</h2>

<p>Pipes are old as SHIT. Oldest method of IPC, since 3rd edition of UNIX
in early 1970s.</p>

<p>THAT&#8217;s what that dude meant. Pipes vs Sockets. We use pipes, not
sockets.</p>

<p>Pipes are constrained to related processes, FIFOs can talk between all
processes.</p>

<p>Pipes are unidirectional.</p>

<p>Can&#8217;t reorder data, can&#8217;t random access w lseek.</p>

<p>Writes up to <code>PIPE_BUF</code> are atomic, Linux has <code>PIPE_BUF</code> at 4096. If
larger, kernel might break into pieces. This means that if you have two
processes writing more than <code>PIPE_BUF</code>, the final stream might be
interleaved with both messages (both processes will still be blocked on
<code>write</code> until everything is flushed out).</p>

<p>Partial writes can occur if a write larger than <code>PIPE_BUF</code> is
interrupted by a signal handler, and call comes back with the number of
bytes written. Pretty cool. Makes sense.</p>

<p>Writes will block if kernel buffer is full.</p>

<p>Pipes only work b/w related processes, which mean they must have a
common fork ancestor. Apparently there&#8217;s another way to pass file
descriptors. But I guess it&#8217;d need translating? Because there are
descriptors and open file descriptions, and the descriptor ints are
different between shits.</p>

<p>SIGPIPE is ignored by default, but when you write to broken pipe you get
SIGPIPE and EPIPE. Such pipe.</p>

<p><code>popen</code> runs a shell command, letting you establish a single pipe,
either r or w.</p>

<p>FIFOs are like pipes except that they&#8217;re special files in th file
system. Opening a read-only FIFO blocks until someone writes, and vice
versa.</p>

<p><code>tee(1)</code> writes to stdio AND some other file, which could be a fifo. So
you can split a stream and send it to other things. Pretty cool.</p>

<p>UNRELATED: <code>bash -c "sleep 5"</code> execs sleep 5; it doesn&#8217;t create a bash
process and then fork again, it just straight up execs. Whereas when
you&#8217;re running interactive bash, all commands are forked and then
exec&#8217;d.</p>

<p>Trick with IPC w servers is that there needs to be some known file name,
which opens the door to exploitation if you&#8217;re not careful.
FIFOs (and pipes) are byte streams (rather than unix domain datagram
sockets) so you have to</p>

<ol>
<li>Use some EOM delimiter</li>
<li>Message length header</li>
<li>Fixed message size</li>
</ol>


<p>and on top of all of that everything needs to be less than the pipe
buffer size constant or else kernel might interleave messages.</p>

<p>Pipes provide synchronization by e.g. opening a pipe, forking, having
the parent blocked on a <code>read()</code> until child processes have all done
their shit and closed their end of the pipe.</p>

<p><code>popen</code> has the same considerations as <code>system</code>.</p>

<h2>System V</h2>

<p>http://en.wikipedia.org/wiki/UNIX_System_V</p>

<p>One of first commercial versions of UNIX, from 1983. Today&#8217;s descendants
are AIX, Solaris, and HP-UX.</p>

<p>System V IPC</p>

<ul>
<li>MQs

<ul>
<li>delivered in order, but each message has type, so can be selected
out of order</li>
</ul>
</li>
<li>Semaphores

<ul>
<li>kernel forbids it from going below 0, sync technique</li>
</ul>
</li>
<li>Shared mem</li>
</ul>


<p>w System V IPC you create objects (like files but unlike files). Objects
have ids, but unlike fd&#8217;s, these are system wide.</p>

<p>Semaphores don&#8217;t error when you subtract below zero; rather the kernel
will block if you try and subtract, and it&#8217;ll come back alive when
someone increments.</p>

<h2>Considered Harmful</h2>

<p>http://en.wikipedia.org/wiki/Considered_harmful</p>

<p>Popular phrase originating from &#8220;Go To Statement Considered Harmful&#8221;, a
Djikstra thing.</p>

<h2>mmap</h2>

<p>Memory mapping can either use</p>

<ul>
<li>real files</li>
<li>anonymous zero-d out files</li>
</ul>


<p>Both are shareable between processes. By:</p>

<ul>
<li>mmapping to the same region of the same file</li>
<li>forking with a previously established handle to a</li>
</ul>


<p>Mapping to same file can be configured:</p>

<ul>
<li>private: writes don&#8217;t go through to file, so process changes to the
mapping are isolated from each other. Implemented by copy-on-write.</li>
<li>shared: durp</li>
</ul>


<h2>dev zero</h2>

<p><code>/dev/zero</code> gives you null bytes. Forever!</p>

<h2>dev urandom</h2>

<p>Write seeds, read values.</p>

<p>This isn&#8217;t perfect but kinda works:</p>

<pre><code>ruby -e 'puts File.open("/dev/urandom").gets(4).unpack("l")'
</code></pre>

<p>Extra credit if you can figure out what that ain&#8217;t right</p>

<h2>Get off the aaaaaaair I&#8217;m in the STEREO</h2>

<p><code>mmap</code> can overcommit swap space due to lazy committal. Useful for
implementing things like sparse arrays (a large array might only access
bits and pieces, and if separate by a page.</p>

<pre><code>$ getconf PAGESIZE
4096
</code></pre>

<p>Daatz cool. So if you have a bajillion thingeroo and it&#8217;s allocated on a
shit, then woooop there it is.</p>

<p>Overcommitals can ran the system out of memory at which point the kernel
starts killin&#8217; shit. The kernel code that does this is the OOM
Out-of-Memory killer.</p>

<p>OOM kills with <code>SIGKILL</code>, you can look at your score with a special file
in procfs.</p>

<h2>dscacheutil</h2>

<p>Directory Service Cache Utility. Supercedes <code>lookupd</code>.</p>

<h2>VM operations</h2>

<ul>
<li>protect: set read/write protections on a VM page

<ul>
<li>applies to mmapped files, etc</li>
</ul>
</li>
<li>mlock and mlockall: keep memory in RAM; useful since an attack vector
would be to consume lots of RAM, forcing some processes to write to
disk, and then reading from the swap space.

<ul>
<li>then again, suspend mode in laptops/desktops copied ram to disk, so
you&#8217;re effed.</li>
</ul>
</li>
</ul>


<h2>traceroute UDP vs ICMP</h2>

<p>This doesn&#8217;t work</p>

<pre><code>traceroute machty.com
</code></pre>

<p>This does</p>

<pre><code>traceroute -I machty.com
</code></pre>

<p>because it uses ICMP ECHO rather than a UDP packet (which I guess gets
dropped somewhere along the way? tis a Rackspace github pages HTTP
server so UDP wouldn&#8217;t make sense anyway), and ICMP ECHOs I guess are
considered more sensible and friendly?</p>

<p>I realized this was the issue since <code>ping machty.com</code>, which uses ICMP
ECHO, works just fine.</p>

<h2>Power of Attorney</h2>

<p>Written authorized permission for one person to act on behalf of
another, even if the other disagrees. Relevant in the legal sense, as
well as health care decisions up to and including terminating care and
life support.</p>

<h2>Darwin, Mach, OS X</h2>

<p><a href="http://en.wikipedia.org/wiki/Darwin_(operating_system">Darwin wiki</a>)</p>

<p>Darwin is an an open source operating system released by Apple in 2000</p>

<ul>
<li>Composed of NeXSTEP, BSD, other freeware</li>
<li>Largely compatible with POSIX but not certified.</li>
<li>SUSv3-compatible</li>
<li>Kernel is XNU

<ul>
<li>&#8220;X is Not Unix&#8221; - stupidest naming scheme ever</li>
<li>Hybrid kernel

<ul>
<li>Combo of micro and monolithic: http://en.wikipedia.org/wiki/Hybrid_kernel</li>
<li>Micro kernels are often &lt; 10,000 lines of code, do the bare
minimum, put more things into user space (or at least a higher
privilege ring)</li>
<li>Linus thinks hybrid is just monolithic and that it&#8217;s all just
marketing</li>
</ul>
</li>
<li>Combo of Mach (microkernel) + aspects of BSD (monolithic kernel)</li>
</ul>
</li>
<li>Closed source Cocoa et al frameworks are missing, so it can&#8217;t run mac
applications</li>
</ul>


<p>http://en.wikipedia.org/wiki/Microkernel</p>

<p>So I guess OS X is Darwin + Cocoa and a bunch of other layers.</p>

<h2>POSIX IPC</h2>

<ul>
<li>Simular to System V</li>
<li>API closer to classic UNIX everything-is-a-file abstraction</li>
<li>Simpler API in general</li>
</ul>


<h2>Semaphores: portable?</h2>

<p>Does anyone use operating system semaphores in open source? I mostly see
sockets and forking and what not for IPC in server code; does anyone
use semaphores?</p>

<p>Answer: yes, libuv does (the async IO lib that Node uses). I&#8217;m sure
plenty of other people do too.</p>

<h2>Node copies in all dependencies</h2>

<p>The Node repo doesn&#8217;t use submodules or anything like that; literally
the entire codebase of a dependency, whether v8 or libuv, is copied into
the <code>/deps</code> folder.</p>

<h2>WATCHLISTS</h2>

<p>Something to Chromium devs use that mark certain portions of code as of
interest to some reviewer, presumably to prevent undesirables from
getting into the system.</p>

<p>https://github.com/joyent/node/blob/master/deps/v8/WATCHLISTS</p>

<h2>File locking</h2>

<p>Used for synchronization. Could use semaphores but the kernel already
has file locking so why not use that for files?</p>

<p>stdio lib might cause issues with buffers and locks, so either follow
some rules about immediately flushing, or just skip stdio and use <code>read</code>
and <code>write</code>, or disable the buffering.</p>

<p>Locks apply to open file descriptions (in the shared open file table in
the kernel), not descriptors, so if you dup the descriptor and
explicitly unlock it, it applies to all duplicates (it doesn&#8217;t maintain
a count or anything).</p>

<p>You can only hold a lock associated with an fd. So if all fds are
closed, the lock is unlocked.</p>

<p>If you fork a lock, then it only takes one unlock (parent or child) to
release the lock. Wacky shiznittletons. But this lends to the pattern of
&#8220;parent establishes lock, forks, and closes file descriptor so that only
the child has the lock and open fd&#8221;.</p>

<p>Locks are preserved across exec unless close-on-exec on the fd and the
fd was the last one associated with the description.</p>

<p><code>flock()</code> downsides:</p>

<ul>
<li>only whole files lockable, hamper concurrency if processes would be
otherwise able to write to the same file in separate sections</li>
<li>can only place advisory locks.

<ul>
<li>advisory locks mean the kernel doesn&#8217;t actually help prevent
reads/writes; processes could ignore advisory locks and perform IO
anyway. Mandatory locks on the other hand&#8230;</li>
</ul>
</li>
</ul>


<h2>Record locking with fcntl</h2>

<p><code>fcntl</code> allows record-locking: locking anywhere from a byte to whole
file. &#8220;record-locking&#8221; might be the wrong word since files are just byte
streams with no concept of &#8220;records&#8221; beyond what their consuming
processes decide.</p>

<p><code>fcntl</code> just stands for &#8220;file control&#8221;. I get it confused with <code>ioctl</code>.
<code>fcntl</code> is control over descriptors in a process. Basically <code>fcntl</code>
behaves almost like a kernel sys call in that it&#8217;s just setting an
integer of the command you want to perform followed by varying numbers
of arguments based on the command. So you can do arbtrary, extensible
stuff that might not already be neatly contained within some other
single purpose wrapper fn.</p>

<p>SUSv3 requires record locking for regular files and permits record
locking for other file types even if it doesn&#8217;t really make sense.</p>

<p>Write locks are exclusive (to both read and write locks). Read locks
are not (they can be shared). Nothing new here.</p>

<p><code>fcntl</code> locking works by passing <code>flock</code> structure. You can lock
relative to current file pointer.</p>

<p><code>BADF</code> if you try and read/write lock a file on a file not open for
reading/writing.</p>

<p><code>len</code> of 0 means lock from whence onward (even if bytes are added to the
file).</p>

<ul>
<li>Unlocking always immediately succeeds.</li>
<li>different sections can be locked with different types</li>
<li>locks can be split by e.g. placing a write lock in the middle of a
larger range of read locks (3 locked regions are produced)</li>
</ul>


<p>The kernel prevents deadlocks between processes. (Similar rules apply
with thread mutexes). Chooses one of the processes and unblocks fcntl
with errno <code>EDEADLK</code>. Even circular deadlocks are detected. Pretty cool.</p>

<p>fcntl locking semantics:</p>

<ul>
<li>locks not inherited cross fork()</li>
<li>locks are inherited</li>
<li>threads share record locks</li>
<li>Record locks are pid+inodenum, so, weirdly, if you close an fd, all of
its locks are released, even if they came from other fds. Kind of
crazy? (This is architectural weak sauce; should have been file
handler rather than inode, but it&#8217;s now standardized).</li>
</ul>


<h2>Mandatory Locking</h2>

<p>File system must be mounted with mandatory locking enabled. And it must
be enabled on a per-file basis by enabling set-group-id and disabling
group execute permission. This yields a capital S in <code>ls -l</code> if you&#8217;ve
done it right.</p>

<ul>
<li>most file systems support it, cept for things like VFAT which don&#8217;t
have the required permission bits</li>
<li>locked file can still be deleted</li>
<li>privileges processes can&#8217;t override a mandatory lock. A malicious user
holding on to a well known public file is a form of DOS attack.</li>
<li>mandatory locks has performance hit against IO</li>
</ul>


<p>Probably best avoided?</p>

<p>tmpfs <code>/proc/locks</code> is useful.</p>

<h2>Pidfile</h2>

<p>Create a file and place write lock on it. Any other instances will try
and do the same thing, fail, and terminate under the assumption that a
running process already has a lock on it. Alternate approaches for
networked apps use bound ports to make this same decision.</p>

<p>Often such things live in <code>/var/run</code>. Conventional to write pid to file
and use extension <code>.pid</code>.</p>

<p>You can CLOEXEC a pidfile since some servers reinitialize themselves by
<code>exec</code>ing themselves. Seems crazy?</p>

<h2>Sockets</h2>

<ul>
<li>exist in communication domain

<ul>
<li>determines how socket is identified (form of &#8220;address&#8221;)</li>
<li>range of communication (intra-computer, internet, etc)</li>
</ul>
</li>
<li>Multiple domains of sockets

<ul>
<li>UNIX domain: <code>AF_UNIX</code>. Communication b/w processes on same host
(all within the kernel)</li>
<li>IP (v4 and v6)</li>
</ul>
</li>
</ul>


<p><code>PF_UNIX</code> vs <code>AF_UNIX</code> constants: Protocol Family vs Address Family:
often synonomous, but different due to intent to support protocols
having multiple families of addresses, but this hasn&#8217;t happened.</p>

<p>Every socket impl can be stream or datagram oriented.</p>

<p>Stream socket
- &#8220;reliable&#8221;&#8230;? UNIX Domain streaming sockets? Curious to know what the overlap is with TCP.
- bi-directional, as if a pair of pipes had been established.</p>

<h3>socket()</h3>

<p>Create a socket with</p>

<ul>
<li>domain: UNIX, IPv4, IPv6</li>
<li>type: STREAM vs DATAGRAM</li>
<li>protocol (usually 0 unless you&#8217;re doing funky things with raw sockets</li>
</ul>


<h3>bind()</h3>

<ul>
<li>Binds to an address / port</li>
<li>is actually <em>optional</em>: if you don&#8217;t call <code>bind()</code> you&#8217;ll use an
ephemeral port chosen by the kernel. Though this means you&#8217;d need to
use some other mechanism for publishing.</li>
</ul>


<h3>stream sockets</h3>

<ul>
<li>socket() creates</li>
<li>server

<ul>
<li>bind()s to a specific port/address</li>
<li>listen()s, signalling the kernel that it&#8217;s ready to accept</li>
<li>accept()s to actually process a connection</li>
</ul>
</li>
<li>clients connects()</li>
<li>both can send(), recv(), write(), read(), etc</li>
</ul>


<p>Stream sockets can be active or passive</p>

<ul>
<li>active: can be used in a connect() call

<ul>
<li>usually clients</li>
</ul>
</li>
<li>passive: has been marked to <code>listen()</code> for connections

<ul>
<li>usually servers</li>
</ul>
</li>
</ul>


<h3>listen(int sockfd, int backlog)</h3>

<p>Tell the kernel to start listening for connections. <code>backlog</code> is the
number of connections you&#8217;re willing to have in a pending state before
<code>accept()</code> is called.</p>

<h3>accept()</h3>

<p>Blocks til connection arrives.</p>

<ul>
<li>creates a <em>new</em> socket, the one that you can actually perform IO on
that makes it to the peer socket.

<ul>
<li>so why are they both called sockets? one that&#8217;s used for a
establishing connections, and another that&#8217;s used within an
established connection?</li>
</ul>
</li>
</ul>


<h3>connect()</h3>

<ul>
<li>if it fails, close socket, create a new one, try again</li>
</ul>


<h3>Stream socket IO</h3>

<p>Sockets are bi-directional, which means kernel must internally maintain
two buffers, one for each direction.</p>

<p>Writing into already-closed UNIX domain socket yields SIGPIPE/EPIPE.</p>

<p>For UNIX-domain sockets, if a <code>close</code> fails to propagate or some other
shit goes down (eg a crash), then we have no way of knowing; should
build some sort of ACK into the system (or just use TCP?).</p>

<p>(then again with TCP, what&#8217;s the API for knowing that a specific write
failed? Usually you write and then move on, right? Or do all write&#8217;s
block? Seems weird brah)</p>

<h3>Datagram flow</h3>

<ul>
<li>create socket w socket()</li>
<li>bind() to known address</li>
<li>sendto() to send a datagram</li>
<li>recvfrom() to recv (the from implies that the source address will be
included in the thing)</li>
<li>close() when socket no longer needed</li>
</ul>


<p><code>recvfrom</code> takes a length, returns a single datagram, silently truncating
if less than <code>length</code>. <code>recvmsg</code> is a variant that sets <code>MSG_TRUNC</code> if
truncation occurred.</p>

<h3>Datagram <code>connect()</code></h3>

<p>Seemingly at oods with the known properties of datagram sockets, you can
actually use <code>connect</code> w dgram socks to yield a &#8220;connected datagram
socket&#8221;. This does a few things:</p>

<ul>
<li>allows you to use <code>write</code> and <code>read</code> (rather than having to pass the
address in to <code>sendto</code> and <code>recvfrom</code> all the live long day)</li>
<li>only messages from the socket peer can be <code>read</code></li>
</ul>


<h2>UNIX Domain Sockets</h2>

<p>For bidirectionality you always have to create a pair.</p>

<p>You can create a UNIX domain socket via other means by providing a file
name. You must have permissions to create this thing, and it&#8217;s a special
file of <code>stat</code> time <code>IFSOCK</code></p>

<p>Let&#8217;s do some ruby</p>

<pre><code>require 'socket'
socket = Socket.new(:UNIX, :DGRAM)

# recall that pack_sockaddr_in refers to internet, `un` refers to UNIX
# address becomes a null-packed string. The Ruby socket lib is
# actually pretty low level when it comes to this shit.
address = Socket.pack_sockaddr_un('./wat.unix.socket') 

# this will actually create a special file in the directory
socket.bind(address)
</code></pre>

<p>Verify it&#8217;s a special file (lf -F puts <code>/</code> at the end of directories and
<code>=</code> at the end of sockets). Recall that this requires directory search
permissions since it needs to read the contents of the inode rather than
just the name of the files.</p>

<pre><code>$ ls -F ./wat.unix.socket
./wat.unix.socket=
</code></pre>

<p>Note the starting &#8220;s&#8221;:</p>

<pre><code>$ ls -l ./wat.unix.socket
srwxr-xr-x  1 machty  staff  0 Oct 26 17:57 ./wat.unix.socket
</code></pre>

<p>Also you can&#8217;t open a socket like a normal file:</p>

<pre><code>f = File.open('./wat.unix.socket')
Errno::EOPNOTSUPP: Operation not supported on socket - ./wat.unix.socket
</code></pre>

<p>Note that if you tried to bind to this socket again, you&#8217;d get
EADDRINUSE. This is interesting since you always see this error in the
context of IP address/port collisions, but in this case it&#8217;s a file
pathname; that&#8217;s because address is a generic concept, the specifics of
which are dependent on which socket domain you&#8217;re using</p>

<ul>
<li>IPv4/IPv6 addresses are IP addresses</li>
<li>UNIX is pathnames</li>
</ul>


<p>Both are packed into that address struct so that sys calls can
use/expect the same struct blob.</p>

<p>STREAM sockets have active and passive. <code>passive</code> has had <code>listen()</code>
called on it.</p>

<p>I still am unclear about whether sockets are bi-directional. I think
they are. But I don&#8217;t understand how to stop blocking on <code>read()</code>. Like,
does it block until the buffer is full? I&#8217;ll figure it out later.</p>

<p>Datagrams are supposed to be unreliable, possibly delivered twice, etc,
but UNIX domain datagrams are reliable since it&#8217;s just the kernel
delivering shit (it&#8217;s only difficult to guarantee reliability over a
network). So UNIX domain datagrams are delivered in order and not
duplicated.</p>

<p>Linux allows large datagrams, but some UNIX buffers might only be 2048,
so if you&#8217;re going for portable, go for small.</p>

<p>AHHH fucking dummy, I was using the wrong ruby method. <code>IO#read</code> reads
until you&#8217;ve filled a buffer (or EOF). What you want is <code>read_nonblock</code>.
&#8220;But why do you still need to pass a max len&#8230; this is ruby it can
handle whatever&#8221; I don&#8217;t know, probably because it ultimately translates
to a syscall which needs the length? Yes I think I&#8217;m right about this
after consulting <code>io.c</code> in MRI.</p>

<h2>Socket pairs</h2>

<p><code>socketpair()</code> or <code>Socket.pair</code> returns a pair of connected sockets.
Communication is bi-directional. Benefits over manually creating this
pair include not having to have a public address. Useful for forky IPC.
Very similar to pipe approach to fork IPC cept that pipes are
unidirectional.</p>

<pre><code>require 'socket.rb'
a,b = Socket.pair(:UNIX, :DGRAM)

a.write("bullshit\n")
puts b.read_nonblock(100)
b.write("horseass\n")
puts a.read_nonblock(100)
</code></pre>

<p>Note that this example works also if we used <code>:STREAM</code>.</p>

<h2>Internet domain sockets</h2>

<p>Unlike UNIX domain datagram, internet domain datagrams (implemented on
UDP) are</p>

<ul>
<li>Unreliable, might be delivered twice or not at all.</li>
<li>Sending doesn&#8217;t block if client buffer full, just dropped silently.</li>
</ul>


<p>Network byte order is big-endian.</p>

<p>Marshalling is tricky, dealing with endianness and what not. Converting
to text is often the easiest way to make sense of things, can debug w
<code>telnet</code>, etc.</p>

<p>Clients generally don&#8217;t <code>bind()</code> when making connections / sending
datagrams, in which case the kernel provides an ephemeral port.</p>

<h2>DNS</h2>

<p>Types of requests:</p>

<ul>
<li>recursive: server handles entire task of resolution, including talking
with other DNS servers. I believe though that once you&#8217;ve made the
request, the server can make an iterative approach</li>
<li>iterative: ask <code>.</code> for <code>com.</code>, <code>com.</code> NS for <code>machty.com.</code>,
<code>machty.com.</code> NS for <code>www.machty.com.</code>.</li>
</ul>


<p>There&#8217;s a local DNS server (<code>named</code> for Linux) that you can ask for
names, and it&#8217;ll do iterative. You ask it for recursive and it does
iterative.</p>

<p>Root name servers found via <code>dig . NS</code>, e.g. &#8220;gimme all the Name Server
entries for the root domain <code>.</code>.</p>

<p><code>/etc/resolv.conf</code> configures the DNS resolver, defines how partial
domain names are resolved (they get concatted with the <code>domain</code> entry in
<code>resolve.conf</code>.</p>

<pre><code># assuming `domain home`
ssh machty # machty.home
ssh machty.home
</code></pre>

<p>Both work. But this is just a local DNS nicety, not the distributed DNS
whitchajigger.</p>

<h2>TLDs</h2>

<p>First layer of nodes immediately under the root <code>.</code> node. Two types:</p>

<ul>
<li>generic: com, edu, net, org:</li>
<li>country: co, de:</li>
</ul>


<h2>ports</h2>

<p><code>/etc/services</code> maintains known port names.</p>

<h2>getsockname</h2>

<p>This is useful when you&#8217;re using ephemeral ports (listen without
bind).</p>

<pre><code>require 'socket'
s = Socket.net(:INET, :STREAM)
s.listen(5)
s.puts s.local_address.ip_port
</code></pre>

<p><code>local_address</code> is a wrapper around <code>s.getsockname</code>, which is some null
padded garbage. For UNIX domain sockets it&#8217;ll contain the file pathname.</p>

<p>This is the difference between sockets bound at 127.0.0.1:45454 and
0.0.0.0:45455, which shows that both the local ip and port are
represented in getsockname.</p>

<pre><code>=&gt; "\x10\x02\xB1\x8E\x7F\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00"
=&gt; "\x10\x02\xB1\x8F\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
</code></pre>

<h2>UDP ephemeral port server</h2>

<p>So, <code>listen()</code> on a STREAM server will implicitly perform an ephemeral
port bind if you haven&#8217;t explicitly called <code>bind()</code> already; is it
possible to make an ephemeral UDP server, wherein the port is
ephemerally decided by the kernel? Well, yes, but you have to call bind;
the trick is to call it with port 0 to signify the kernel should pick
one for you. Why would you do this? I don&#8217;t know; probably if you wanted
some anonymous service that no attacker could guess the port of ahead of
time? But you&#8217;d still need to advertise your port somehow.</p>

<h2>UNIX v internet domain sockets</h2>

<ul>
<li>UNIX faster on some implementations</li>
<li>UNIX DGRAM delivery is reliable</li>
<li>UNIX lets you use file permissions for authentication</li>
<li>UNIX lets you pass open file descriptors when forking, etc</li>
</ul>


<p>But often internet sockets are the way to go since they work locally and
remotely.</p>

<h2>Load-balancing with DNS</h2>

<p>If you provide multiple IPs to the same DNS record, you get round-robin
resolution, babeh.</p>

<h2>inetd; inet daemon</h2>

<p>If you have infrequently used daemons that would hog a process table
entry and resources, why not give their sockets to inetd and inetd will
spin up your servers when they need them.</p>

<ul>
<li>number of processes reduced</li>
<li>inetd does the server-y stuff that its clients would otherwise have to
write.</li>
</ul>


<p>aka internet superserver.</p>

<h2>Who responds to ICMP messages?</h2>

<p>Just routers/gateways. Not apps, unless you&#8217;re opening raw sockets n shit.</p>

<p>For instance you can&#8217;t spin up a rails server on localhost:3000 and
expect <code>ping localhost:3000</code> to work, because it&#8217;s only listening to
TCP/UDP sockets. AHHHH I am saying so much ignorance: here&#8217;s the truth:</p>

<p>ICMP has no concept of port. Port is TCP/UDP concept. ALWAYS REMEMBER
THAT. ICMP is IP-only. Whatever responds to / notices an incoming ICMP
request must only have an IP address, and not expect to use a port in
any way. So gateways/hosts/routers will respond to ICMP. You can ping
your router. You can ping gateways. You can traceroute all the way to a
website. And you can ping localhost, because loopback is a gateway.</p>

<p>So how can you write a program that listens for ICMP requests? You need
a raw socket, which requires sudo:</p>

<pre><code>require 'socket'
require 'base64'

rsock = Socket.new(:INET, :RAW)

loop do
  s = rsock.recv(1024)
  enc = Base64.encode64(s)
  puts enc
end
</code></pre>

<p>Again, no concept of port; there&#8217;s no <code>bind</code> here nor does the kernel
assign an ephemeral port; it&#8217;s all raw sockets babeh.</p>

<p>From <code>ping(8)</code>:</p>

<pre><code>The ping utility uses the ICMP protocol's mandatory ECHO_REQUEST datagram to
elicit an ICMP ECHO_RESPONSE from a host or gateway.
</code></pre>

<p>So <code>ping</code> pings gateways/hosts, not servers.</p>

<h2>ECONNREFUSED</h2>

<p>This is caused by ICMP, if it decides it wants to send anything. Shit
gets dropped.</p>

<h2>MTU: Maximum Transmission Unit</h2>

<p>This is what causes IP packets to be sliced and diced.</p>

<p>http://en.wikipedia.org/wiki/Maximum_transmission_unit</p>

<p>The min MTU between two endpoints is the path MTU. The minimum allowable
MTU is well-defined, I forget what it is, but I think there&#8217;s one
guaranteed by IP.</p>

<p>You can find the path MTU (per TCP/UDP RFC) by setting do not fragment
flag and seeing if ICMP sends back a failure due to datagram size. That
said, lots of gateways silently drop ICMP to prevent DoS:</p>

<pre><code>http://en.wikipedia.org/wiki/Black_hole_(networking)
</code></pre>

<p>People might black hole to prevent pings; you can still send well formed
TCP/UDP requests but it won&#8217;t respond to ICMP <code>ECHO_REQUEST</code>s or
anything like that.</p>

<h2>Packet-switching</h2>

<blockquote><p>Packet switching is a digital networking communications method that groups all transmitted data – regardless of content, type, or structure – into suitably sized blocks, called packets.</p></blockquote>

<p>Switching I believe is how two endpoints of a physical link decide how
to send data between each other; they could either do circuit switching
and have a dedicated connection until the connection was over,
or you can packet switch, whereby you
break the communication into small packets that send all at once (and IP
might slice them to fit the link&#8217;s MTU).</p>

<h2>C Standard Library</h2>

<p>I was confused for a moment about where <code>write()</code> and <code>read()</code> and these
low level syscall wrappers lived&#8230; were they considered part of the C
standard library? Or were they in some bare-bones thing in some other
category of code that operating systems provided?</p>

<p>Naw, it&#8217;s all C Standard Library. It&#8217;s just that (I think) <code>write</code> and
<code>read</code> are so low level as to not be considered part of <code>stdio</code>, the IO
subset of the C standard lib.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-17T17:52:00-04:00" pubdate data-updated="true">Oct 17<span>th</span>, 2014</time></div>
	


	
</div></article>

<nav id="pagenavi">
    
        <a href="/blog/page/2/" class="prev">Prev</a>
    
    
        <a href="/blog/page/4/" class="next">Next</a>
    
    <div class="center"><a href="/archives">Blog Archives</a></div>
</nav></div>
	<footer id="footer" class="inner">Copyright &copy; 2015

    Alex Matchneer

<br>
Powered by Octopress.
</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'usefuldude';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-49928757-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>



</body>
</html>

