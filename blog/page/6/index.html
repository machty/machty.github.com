
<!DOCTYPE HTML>
<html>
<head>
	<script data-cfasync="false" type="text/javascript" src="//use.typekit.net/axj3cfp.js"></script>
	<script data-cfasync="false" type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<meta charset="utf-8">
	<title>Ember.js, random thoughts, journal  | machty's thoughtz</title>

<meta name="author" content="Alex Matchneer"> 

<meta name="description" content="I'm on Ember core and contribute to lots of stuff prefixed with "Em"."> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="machty's thoughtz" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script type="text/javascript" src="/javascripts/jquery.fancybox.pack.js"></script>

<script language="Javascript" type="text/javascript">
$(document).ready(
  function() {
    (function($) {
      $(".fancybox[data-content-id]").each(function() {
        this.href = $(this).data('content-id');
      });
      $(".fancybox").fancybox({
        beforeLoad: function() {
          var el, 
              id = $(this.element).data('title-id');

          if (id) {
            el = $('#' + id);

            if (el.length) {
              this.title = el.html();
            }
          }
          if ($(this).data('content')) {
            this.content = $(this).data('content');
          }
        },
        helpers: {
          title: {
            type: 'inside'
          }
        }
      });
    })(jQuery);
  }
);
</script>

	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">machty's thoughtz</a></h1>
<h4>Ember.js, random thoughts, journal</h4>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:machty.github.com">
			</form>
		</div>
	</div>
</nav>


</header>

	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/08/02/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>NPM is killing me</h2>

<p>Apparently this fixed everything.</p>

<pre><code>npm cache clear &amp;&amp; npm install
</code></pre>

<p>https://www.npmjs.org/doc/cli/npm-cache.html</p>

<p>npm caches everything in <code>npm config get cache</code>, which for me is:</p>

<pre><code>~/.npm
</code></pre>

<p>Folder structure is something like</p>

<pre><code>~/.npm/PACKAGE_NAME/VERSION/
</code></pre>

<p>which contains:</p>

<ul>
<li>.cache.json

<ul>
<li>lots of overlap w the project&#8217;s package.json, with additional
cache-specific things like</li>
<li>etag, shasum</li>
<li>deployment-specific data about the package</li>
</ul>
</li>
<li>package.tgz

<ul>
<li>the original tarball downloaded for this packaage</li>
</ul>
</li>
<li>package/

<ul>
<li>the unzipped tarball</li>
</ul>
</li>
</ul>


<p>In other words</p>

<blockquote><p>Additionally, whenever a registry request is made, a .cache.json file is placed at the corresponding URI, to store the ETag and the requested data. This is stored in {cache}/{hostname}/{path}/.cache.json.</p></blockquote>

<h2>Food Shit</h2>

<p>Pok Pok is a legit ass Thai place I need to check out.</p>

<pre><code>http://pokpokny.com/
</code></pre>

<h2><code>sed</code> to select lines</h2>

<pre><code>$ git branch
  cp-qp
* master
  new-doctitle
  setup-controller-qp
</code></pre>

<p>I wanted to switch to the fourth one without typing
<code>setup-controller-qp</code>. Here&#8217;s how you could do it by using the line
number</p>

<pre><code>$ git branch | sed -n '4p' | xargs git checkout
Switched to branch 'setup-controller-qp'
</code></pre>

<p>Obviously this is just a dumb exercise since it&#8217;s waaay more typing.
This is me practicing.</p>

<p>You can also display multiple lines using a syntax similiar to cut&#8217;s
<code>-f1,2</code> syntax:</p>

<pre><code>$ git branch | sed -n '3,4p' 
  new-doctitle
  setup-controller-qp
</code></pre>

<h2>commissary</h2>

<p>From Orange is the New Black</p>

<blockquote><p>commissary: a restaurant in a movie studio, military base, prison, or other institution.</p></blockquote>

<h2>HRT</h2>

<p><a href="http://en.wikipedia.org/wiki/Hormone_replacement_therapy">Hormone replacement therapy</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-08-02T21:24:00-04:00" pubdate data-updated="true">Aug 2<span>nd</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/29/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>tar</h2>

<p>Short for Tape Archives.</p>

<p>Had a tar.xz file, just needed to</p>

<pre><code>tar xf thefile.tar.xz
</code></pre>

<h2>Dexing</h2>

<p>Convert string names to numbers to be referenced within compiled Java
whilst packaging android apps.</p>

<h2>Good Food</h2>

<p>Prince St Cafe on Prince and Mott.</p>

<ul>
<li>Awesome burger</li>
<li>Awesome lamb thing</li>
</ul>


<h2>ls -l</h2>

<p>Was curious about an <code>@</code> sign I saw next to a .txt file, from <code>ls(1)</code>:</p>

<blockquote><p>The Long Format</p>

<pre><code>If the -l option is given, the following information is displayed for
each file: file mode, number of links, owner name, group name, number
of bytes in the file, abbreviated month, day-of-month file was last
modified, hour file last modified, minute file last modified, and the
pathname.  In addition, for each directory whose contents are dis-
played, the total number of 512-byte blocks used by the files in the
directory is displayed on a line by itself, immediately before the
information for the files in the directory.  If the file or directory
has extended attributes, the permissions field printed by the -l
option is followed by a '@' character.  Otherwise, if the file or
directory has extended security information (such as an access control
list), the permissions field printed by the -l option is followed by a
'+' character.
</code></pre></blockquote>

<ul>
<li><code>@</code> extended attributes</li>
<li><code>+</code> extended security info</li>
</ul>


<h2>Interrupted System Call</h2>

<p>http://infohost.nmt.edu/~eweiss/222_book/222_book/0201433079/ch10lev1sec5.html</p>

<p>I&#8217;m getting some shit about foreman and interrupted system calls. So
what is it.</p>

<h2>&#8220;data at the edge&#8221;</h2>

<p>Keeping secure data at the edge of your infrastructure, e.g. using
tokens instead of storing CC&#8217;s in your db.</p>

<h2>PAN (primary account number)</h2>

<p>Bank card number.</p>

<p>http://en.wikipedia.org/wiki/Primary_account_number</p>

<h2>CP (card present)</h2>

<p>e.g AuthorizeNetCP</p>

<p>Cheaper rates if you can prove card present (via CVV).</p>

<h2>TokenEx</h2>

<p>ProcessTransaction</p>

<p>ProcessTransactionWithPAN</p>

<ul>
<li>pass in all the CC data; no</li>
</ul>


<h2>Levenshtein Distance</h2>

<p>The minimum number of single-element operations (add, remove,
substitute) between two sequences. Often used for spell-checking
suggestions.</p>

<p>I was thinking of using it to do an array diffing for React-ish stuff.</p>

<pre><code>Array 1: B C D E F
Array 2: A B C D E
</code></pre>

<p>Clearly the answer to how to get from 1 to 2 is</p>

<pre><code>shift A
delete E
</code></pre>

<p>But how to programmatically detect that?</p>

<h2>Ruby String Substring Shorthand</h2>

<p>https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<p>I can&#8217;t believe I didn&#8217;t know this&#8230;</p>

<pre><code>s = "alex is quite maudlin"
s['quite'] = 'very'
s =&gt; "alex is very maudlin"
</code></pre>

<p>and if the substring isn&#8217;t in there, then</p>

<pre><code>IndexError: string not matched
</code></pre>

<p>http://www.ruby-doc.org/core-2.1.2/String.html#method-i-5B-5D-3D</p>

<h2>JRuby the Hard Parts</h2>

<p>Goal: understand this talk https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<h2>Learn about encodings</h2>

<p>I had to resort to this shit:</p>

<pre><code>line = line.force_encoding("iso-8859-1")
</code></pre>

<p>for a bigass file because I was running into</p>

<pre><code>http://stackoverflow.com/questions/15399530/ruby-match-invalid-byte-sequence-in-utf-8
</code></pre>

<p>Apparently you can open files as a certain encoding. Seems good.</p>

<h2>Auto-inline CSS with Roadie</h2>

<p>https://github.com/Mange/roadie</p>

<p>Useful for supporting a vast array of shitty email clients that require
inline CSS. This wouldn&#8217;t be a problem if web components.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-29T07:50:00-04:00" pubdate data-updated="true">Jul 29<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/28/daily-journal-2/">
		
			Daily Journal 2</a>
	</h2>
	<div class="entry-content">
		<h2>User and Kernel</h2>

<p>http://blog.codinghorror.com/understanding-user-and-kernel-mode/</p>

<p>Non-idle tasks.</p>

<p>The CPU graph is tasty. Red means kernel.</p>

<p>CPU hardware knows all about kernels n shit. It isn&#8217;t just a software
divide. CPU instructions and certain memory locations can only be
accessed by the kernel, enforced by hardware. User mode makes it so that
only the app crashes, not the entire system.</p>

<p>http://en.wikipedia.org/wiki/Ring_(computer_security)</p>

<p>Interesrserseting.</p>

<p>x86 CPU hardware:</p>

<ul>
<li>0 is kernel</li>
<li>3 is user</li>
</ul>


<p>1 and 2 are device drivers but they&#8217;re not often used. On Windows,
device drivers can be user or kernel mode, mostly to the user, but video
cards are often kernel level since they so perfy. In Vista+, the Windows
Driver Display Model is such that only kernel mode is used for executing
the GPU commands, but the translation from API to GPU now takes place in
userland.</p>

<p>Exceptions fire in kernel land I guess? Sometimes?</p>

<h2>Old Foreman Orphans Sidekiq</h2>

<p>After lots of starts/stops of foreman, I noticed lots of sidekiq
instances with ppid 1. They was orphans. I killed em.</p>

<h2>fspawn</h2>

<p>Refers to the fork+exec approach to spawning a process.</p>

<h2>Daemons</h2>

<p>https://github.com/ghazel/daemons</p>

<p>Library of fun little trinkets.</p>

<ul>
<li>given some-server.rb, let&#8217;s you write a some-server-control.rb</li>
<li>inline the server inside such a daemon (you can still run it
without forking via <code>run</code> command)</li>
<li>manage multiple daemons</li>
<li>Ability to take existing server and daemonize it; you do lose control
over the daemon unless you&#8217;re a <code>ps</code>/<code>kill</code> JOURNEYMAN.

<ul>
<li>this takes advantage of the <code>fork</code> <code>getsid</code></li>
</ul>
</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons.rb#L45-L53</p>

<pre><code># 1.  Forks a child (and exits the parent process, if needed)
# 2.  Becomes a session leader (which detaches the program from
#     the controlling terminal).
# 3.  Forks another child process and exits first child. This prevents
#     the potential of acquiring a controlling terminal.
# 4.  Changes the current working directory to "/".
# 5.  Clears the file creation mask (sets +umask+ to 0000).
# 6.  Closes file descriptors (reopens +STDOUT+ and +STDERR+ to point to a logfile if
#     possible).
</code></pre>

<p>Controlling terminal:</p>

<p>http://www.gnu.org/software/libc/manual/html_node/Controlling-Terminal.html</p>

<blockquote><p>An individual process disconnects from its controlling terminal when it calls setsid to become the leader of a new session.</p></blockquote>

<p>Ah I get it:</p>

<ul>
<li>first fork is to orphan the child, but it&#8217;s still connected to a
controlling terminal/session.</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L201</p>

<p>They actually loop through all known IO files to close file
descriptors using ObjectSpace:</p>

<p>http://www.ruby-doc.org/core-2.1.2/ObjectSpace.html</p>

<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L221</p>

<p>That&#8217;s pretty rad. I guess the GC uses it too.</p>

<h2>.pid file</h2>

<p>It&#8217;s a file in a well known location that contains only the pid of
some running process, usually a daemon. Useful because daemons are often
hard to detect, kinda look like forgotten orphan processes, and there
might be multiple similar ones. But pid files let you look up the pid of
the running process so that you can send it signals.</p>

<h2><code>$0</code> or <code>$PROGRAM_NAME</code></h2>

<p>If you run this script</p>

<pre><code>fork {
  $PROGRAM_NAME = "WAT"
  sleep
}
</code></pre>

<p>then <code>ps | grep WOOT</code> yields</p>

<pre><code>62724 ttys022    0:00.00 WOOT
</code></pre>

<p>Woot wat wat wotasoasdas lol.</p>

<h2><code>pidof</code></h2>

<pre><code>brew install pidof

$ pidof bash
754 1246 1748 2308 2498 5380 20397 23552 26224 26973 48454 79258 81847 5226 5346 5443 5851 10659 25008 26375 27009 52684 88768 88882 18853 19116 19246 20275 20476 21364 43211 52269 52390 52637 54869 54974 58037 58950 59080
</code></pre>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-28T20:43:00-04:00" pubdate data-updated="true">Jul 28<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/28/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Them processes</h2>

<p>Kernel</p>


		
		<a href="/blog/2014/07/28/daily-journal/" class="more-link">Read on &rarr;</a>
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-28T08:16:00-04:00" pubdate data-updated="true">Jul 28<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/26/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>top</h2>

<blockquote><p>display and update sorted information about processes</p></blockquote>

<p><code>top</code> will display a sampled, updating list of processes, ordered by pid
by default. Order by cpu:</p>

<pre><code>top -o cpu
</code></pre>

<p>Filter by a pid</p>

<pre><code>top -pid 12345
</code></pre>

<p>Show a single sample of the pid and thread number for a given pid</p>

<pre><code>top -l1 -pid 1234 -stats pid,th
</code></pre>

<h2>Spawn 50 ruby threads&#8230;</h2>

<p>and you wind up w 52: <code>Thread.main</code> + the 50 you created + Ruby
housekeeping thread (listening for OS signals and piping them
synchronously to main thread).</p>

<p>Ruby creates legit OS threads, vs <code>_____</code> threads, whatever the
terminology is for threads that live entirely in the code.</p>

<h2>Thread#join</h2>

<p>Yes, you have to call it on a spawned thread so that the main thread
will wait on it before prematurely exiting. But did you know that
exceptions thrown in a spawned thread get re-raised on the main thread
if you do <code>.join</code>?</p>

<p><code>Thread#value</code> joins and returns the last value of the thread.</p>

<p><code>Thread#status</code> returns status for live, dead, erroed, dying threads.</p>

<p><code>Thread.stop</code> puts the thread to sleep and it won&#8217;t wake up until
someone calls <code>wakeup</code> on it</p>

<p><code>Thread.pass</code> hints the OS to schedule another thread, but this may be
ignored by the scheduler.</p>

<p><code>Thread#raise</code> lets you externally fire exceptions within another thread
but should not be used because <code>ensure</code> is busted. <code>Thread#kill</code> does
what you expect but should also be aborted for the same reasons.</p>

<p>Multiple threads mean concurrency; they <em>might</em> mean parallelism. One
CPU switching b/w threads means concurrency but not parallelism;
multiple cores means paralleilism if they&#8217;re both executing.</p>

<p>Code can&#8217;t be parallel, only concurrent. The executation of concurrent
code can be parallel if the scheduler so chooses.</p>

<h2>golang concurrency vs parallelism</h2>

<p>http://concur.rspace.googlecode.com/hg/talk/concur.html#slide-2</p>

<p>Concurrency is defined as:</p>

<blockquote><p>Programming as the composition of independently executing processes</p></blockquote>

<p>not Linux processes, but rather the famously harder to define Process.</p>

<p>Parallelism is</p>

<blockquote><p>Programming as the simultaneous execution of (possibly related) computations.</p>

<p>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable</p></blockquote>

<p>Concurrency facilitates but doesn&#8217;t guarantee parallelism.</p>

<p>Goroutines aren&#8217;t threads; they&#8217;re similar but cheaper, won&#8217;t block
other goroutines, and multiplexed onto OS threads as necessary.</p>

<p>Synchronize via channels. I guess this is like Ruby Queue? Sounds like
you&#8217;d never do someGoroutine.value but rather use the channel primitive.</p>

<h2>ruby concurrency and you</h2>

<p>https://blog.engineyard.com/2011/ruby-concurrency-and-you</p>

<p>Green threads</p>

<ul>
<li>scheduled by VM, rather than underlying OS</li>
<li>pre 1.9 Ruby was this way (MRI)</li>
<li>managed in user space rather than kernel space</li>
</ul>


<p>Test: if i run Ruby 1.8.7 and do a top of new threads, I would expect
the thread count to be only whatever I started with.</p>

<p>BEHOLD, on 1.8.7:</p>

<pre><code>PID    #TH
84752  1
</code></pre>

<p>So old ruby didn&#8217;t even spawn another thread for housekeeping&#8230; I guess
maybe it wasn&#8217;t necessary because it didn&#8217;t have to coordinate the
signals landing at any random currently-active thread? Pretty cool.</p>

<p>I guess green threads are easy to implement in any interpreted language:
in the main loop of the interpreter you can just check if 100ms has gone
by and then move to another other known threads.</p>

<p>Early Java had green threads&#8230; I don&#8217;t know enough about Java to
comment here.</p>

<p>Ruby &lt;1.9 was smart enough to know when one of these threads was blocked
on external data so that it could &#8220;sleep&#8221; until the data arrived:</p>

<blockquote><p>MRI 1.8.7 is quite smart, and knows that when a Thread is waiting for some external event (such as a browser to send an HTTP request), the Thread can be put to sleep and be woken up when data is detected.</p></blockquote>

<p>1.9 uses native threads, but there&#8217;s still a GIL because the non-Ruby
parts of MRI 1.9 aren&#8217;t thread-safe.</p>

<p>MRI 1.9 uses the same technique as MRI 1.8 to improve the situation,
namely the GIL is released if a Thread is waiting on an external
event (normally IO) which improves responsiveness.</p>

<p>Great read:</p>

<p>http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/</p>

<p>Threads are hard, but requests are an extremely clean concurrency
primitive: controllers and the models loaded and views rendered, etc.,
are not shared between threads that are processing requests. It&#8217;s only
if you start using global state that problems arise, but why are you
doing that?</p>

<p>Why the Ruby/Rails thread FUD?</p>

<ul>
<li>Early Rails wasn&#8217;t threadsafe; essentially a mutex around each request</li>
<li>Mongrel explicitly mutexed around its Rails adapter, so even when
<code>threadsafe!</code> was added, you&#8217;d still have zero concurrency in mongrel.</li>
</ul>


<blockquote><p>For safety, Ruby does not allow a context switch while in C code unless the C code explicitly tells the VM that it’s ok to do so.</p></blockquote>

<p>And mysql was poorly written in this case. So mysql would block.</p>

<blockquote><p>A lot of people talk about the GIL (global interpreter lock) in Ruby 1.9 as a death knell for concurrency. For the uninitiated, the GIL disallows multiple CPU cores from running Ruby code simultaneously. That does mean that you’ll need one Ruby process (or thereabouts) per CPU core, but it also means that if your multithreaded code is running correctly, you should need only one process per CPU core. I’ve heard tales of six or more processes per core. Since it’s possible to fully utilize a CPU with a single process (even in Ruby 1.8), these applications could get a 4-6x improvement in RAM usage (depending on context-switching overhead) by switching to threadsafe mode and using modern drivers for blocking operations.</p></blockquote>

<p>Node vs Ruby Threading:</p>

<p>Yehuda: &#8220;the main difference is that a callback is smaller in size than a stack&#8221;</p>

<p>In other words, the context switch that happens when switching threads
includes copying over an entire stack of the thread you&#8217;re resuming and
some other details I don&#8217;t know of off the top of my head. But with
callbacks, the callbacks have no stack (is this true in Rubyland? maybe
there&#8217;s stack trace information but probably no stack. The only stack
starts from where the callback/block was created, and the same is true w
threads, but the point is that in a thread-per-request model, the stack
goes all the way up to when the request was first received, which can be
a pretty tall stack).</p>

<p>So what about Fibers? They&#8217;re cooperative, but why is their context
switch not a big deal? They have a stack size limit of 4kb. How can I
test this?</p>

<p>Here&#8217;s a nice article:</p>

<p>http://timetobleed.com/fixing-threads-in-ruby-18-a-2-10x-performance-boost/</p>

<p>Seems to suggest that the stack that needs to be copied when context
switching includes interpreter code, which has many local vars and
sometimes the stack is up to 4kb, which is cray cray.</p>

<p>Green threads: pre-emptible userland threads. userland = not kernel
land.</p>

<p>You can hack into the thread-yielding code of old Ruby to allocate
stacks on the heap so that all you have to do to context switch is
change what rsp (pointer to the bottom of the stack) points to. This
means the stack won&#8217;t grow (so you have to pick a sensible size).</p>

<p>Ruby 1.9 performs way better in the benchmarks than his hacks&#8230; why?
&#8220;Thanks. 1.9 uses pthreads which create stacks in a similar manner to
what I did.&#8221; Awesome.</p>

<p>pthreads = POSIX threads</p>

<p>http://timetobleed.com/threading-models-so-many-different-ways-to-get-stuff-done/</p>

<p>Threads models:</p>

<h3>1:1 (native threads)</h3>

<p>One kernel thread for every user thread.</p>

<p>Pros</p>

<ul>
<li>execute threads on different CPUs</li>
<li>threads don&#8217;t block each other</li>
<li>shared memory b/w threads</li>
</ul>


<p>Cons</p>

<ul>
<li>Setup overhead since creating a thread requires a system call (and
those are slow)</li>
<li>Low upper bound on the number of threads that can be created</li>
</ul>


<p><code>pthread_create</code> is the fn that makes the system call to create the
thread.</p>

<h3>1:N (green threads)</h3>

<p>&#8220;lightweight threads&#8221;</p>

<ul>
<li>thread creation, execution, cleanup are cheap</li>
<li>lots of threads can be created</li>
</ul>


<p>Cons</p>

<ul>
<li>kernel doesn&#8217;t know about it, so no parallel execution across CPUs</li>
<li>blocking IO can block all green threads</li>
</ul>


<p>Forking + threading and cross-process communication is one way around
limitations.</p>

<h3>M:N</h3>

<p>Hybrid of above</p>

<ul>
<li>Multi CPUs</li>
<li>Not all threads blocked by blocking system calls</li>
<li>Cheap</li>
</ul>


<p>Cons</p>

<ul>
<li>Really really hard to synchronize userland and kernel scheduler</li>
<li>Green threads will block within same kernel thread</li>
<li>Difficult to maintain</li>
</ul>


<p>1:1 has shown itself to be more performant, but in some cases M:N might
be the right choice.</p>

<p>TODO: read this http://www.akkadia.org/drepper/nptl-design.pdf</p>

<pre><code>b = nil

t = Thread.new do
  b = Fiber.new {
    puts "FIBER"
  }
end

while !b
  # just wait
end

b.resume
</code></pre>

<p>This results in</p>

<pre><code>fiberthread.rb:13:in `resume': fiber called across threads (FiberError)
        from fiberthread.rb:13:in `&lt;main&gt;'
</code></pre>

<p>Of course it would.</p>

<p>Use strace / dtruss to trace sys calls.</p>

<p>Spinlocks are locks that, rather than sleeping, actively busy-wait until
the lock is free. This only makes sense if the wait is expected to be
short, otherwise it might block other threads.</p>

<p>Interesting, from the wiki:</p>

<blockquote><p>Most operating systems (including Solaris, Mac OS X and FreeBSD) use a hybrid approach called &#8220;adaptive mutex&#8221;. The idea is to use a spinlock when trying to access a resource locked by a currently-running thread, but to sleep if the thread is not currently running. (The latter is always the case on single-processor systems.)</p></blockquote>

<p>The idea is that a lock by an active thread is likely to be finished
soon, and since spinlocks avoid the scheduling overhead of a context
switch, then hooray.</p>

<p>Busy-waiting in general means while-looping until some condition is
true. You can even do this in JS:</p>

<pre><code>var end = +new Date() + 1000;
while (+new Date() &lt; end) {}
</code></pre>

<p>So whether Node or EventMachine, the concept is the same: both run on
callbacks.</p>

<p>Realization: I was thinking that I could demonstrate the difference b/w
green threads and OS threads by seeing if a while(true) in a green
thread would yield to others, but the answer is:</p>

<ul>
<li>of course it would yield; each iteration of the while true is
an iteration of the interpreter loop that&#8217;s running commands, so its
timer would fire at that point.</li>
<li>the only time it&#8217;d block is if you called out to a C extension that
looped and didn&#8217;t yield back control.</li>
</ul>


<p>It seems a Fiber&#8217;s 4k stack begins at the point at which it is created.
Hmm. So does it or does it not include interpreter stuff? Well for one
it&#8217;s in the same thread as a requirement.</p>

<p>Reasons why Fibers are faster than threads:</p>

<ul>
<li>limited 4kb stack for quick context switching</li>
<li>no pre-emption means no aggressive/frequent context switching;
context-switch as infrequently as you&#8217;d like.</li>
</ul>


<p>https://github.com/eventmachine/eventmachine/blob/master/docs/old/LIGHTWEIGHT_CONCURRENCY</p>

<p>Lightweight Concurrency generally means</p>

<ul>
<li>putting thread scheduling under the control of your program</li>
</ul>


<blockquote><p>By &#8220;lighter,&#8221; we mean: less
resource-intensive in one or more dimensions, usually including memory and
CPU usage. In general, you turn to LC in the hope of improving the
performance and scalability of your programs.</p></blockquote>

<p>NOTE: race conditions can happen in concurrent environments, even if
parallelism isn&#8217;t there, e.g. preempting</p>

<p>Mac has a max 2048 thread limit.</p>

<p>&#8220;IO Bound&#8221; means your program is mostly bottlenecked by IO, such that
swapping for a faster IO would boost your program performance immensely.</p>

<p>In such a case, going multi-threaded is a no-brainer rather than
serially getting blocked on each slow thing. But if you over do it then
you might just be wasting memory/CPU resources from thread stacks and
context switching that it&#8217;s not justified.</p>

<p>&#8220;CPU bound&#8221; means doubling CPU would mean the job would get done that
much faster.</p>

<p>Quad-core with 4 threads on CPU bound means mega-wins for Rubinius but
obviously not GIL&#8217;d MRI. If you make it 5, then you get the
context-switching overhead.</p>

<p>Rails apps are combo of IO-bound and CPU-bound</p>

<p>IO:</p>

<ul>
<li>Database</li>
<li>Third party APIs</li>
<li>Files read</li>
</ul>


<p>CPU:</p>

<ul>
<li>Rendering templates</li>
<li>Rendering JSON</li>
</ul>


<p>Measure measure measure.</p>

<p>This is comically incorrect:</p>

<pre><code>Mutex.new.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>should be</p>

<pre><code>m = Mutex.new

# ...create thread...

m.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>&#8220;critical section&#8221; refers to the part of your concurrent code that
alters shared data.</p>

<p>Memory Models describe the guarantees made to threads when
reading-from/writing-to memory, which mostly become important to think
about in a multi-threaded settings. The memory model describes how
caching occurs in the registers before actually writing out to memory,
and it describes the scope of compiler/hardware optimizations that can
be made that lead to non-determinant order of memory operations which
can fuck your shit unless you use <code>volatile</code> in Java or explicit mutexes
in Ruby.  Ruby doesn&#8217;t have a memory model spec yet. Java and Go and
others do. I guess Rust nips this in the bud w ownership.</p>

<p>Mutex is a form of a memory barrier, and I think <code>volatile</code> is too.</p>

<p>Livelocking is when <code>try_lock</code>s repeatedly fail, so the threads are
still technically alive but stuck in the same loop.</p>

<p>Best solution is to declare mutex grabbing in the same order via a mutex
hierarchy.</p>

<h2>Signals in ruby</h2>

<p>Rubyz</p>

<pre><code>Signal.trap("USR1") do
  puts "lol handling your custom user handler"
end
puts Process.pid # =&gt; e.g. 12345
</code></pre>

<p>Shellz</p>

<pre><code>kill -s USR1 12345
</code></pre>

<p>So many ways to kill a program:</p>

<ul>
<li>Abort: often self-initiated by <code>abort</code></li>
</ul>


<h2>Difference b/w seg fault and bus error</h2>

<p>http://stackoverflow.com/questions/838540/bus-error-vs-segmentation-fault</p>

<p>On most architectures I&#8217;ve used, the distinction is that:</p>

<ul>
<li>a SEGV is caused when you access memory you&#8217;re not meant to
(e.g., outside of your address space).</li>
<li>a SIGBUS is caused due to alignment issues with the CPU
(e.g., trying to read a long from an address which isn&#8217;t a multiple of 4).</li>
</ul>


<h2>Signals in C</h2>

<p>This is just for fun, but you can set up signal masks and signal
handles and all that fun crap.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

static int gotSignal = 0;

void wat(int s) {
  printf("Got Signal %d", s);
  gotSignal = 1;
}

int main() {
  /* SIGUSR1 == 16 */
  signal(SIGUSR1, &amp;wat);

  pid_t pid = getpid();
  printf("The process id is %d", pid);

  // prevent signal from getting here
  sigset_t s;
  sigaddset(&amp;s, SIGUSR1);
  // uncomment to block the signal from arriving
  //sigprocmask(SIG_BLOCK, &amp;s, NULL);

  while(!gotSignal) {
    printf(".");
    fflush(stdout);
    sleep(1);
  }

  printf("\nDone!\n");
}
</code></pre>

<p>and you can send it usr1 via</p>

<pre><code>kill -s USR1 12345
</code></pre>

<h2>Signals in Node</h2>

<pre><code>var done = false;

process.on("SIGUSR1", function() {
  done = true;
});

console.log("pid: ", process.pid);

var timerId = setInterval(function() {
  if (done) {
    console.log("DONEZO");
    clearInterval(timerId);
  } else {
    process.stdout.write(".");
  }
}, 500);
</code></pre>

<p>Note that SIGUSR1 is reserved by node.js to start the debugger.
The above code will work but if the debugger&#8217;s enabled then that&#8217;ll also
cause it to start.</p>

<p>Seems that signals are often used to start a debugger, or some kind of
debugging operation. Interesting.</p>

<h2>Condition Variables</h2>

<p>A provider and consumer both use the same mutex. Provider locks when
providing an update. Consumer locks when trying to perform an operation,
but internally does a <code>condvar.wait(mutex)</code> with the locked <code>mutex</code> to
unlock until the <code>condvar</code> is <code>signal</code>ed by the provider.</p>

<p>So why wrap the consumer in a while loop rather than an if (see page 104
of storimer)? Because there could be multiple consumers.</p>

<p><code>ConditionVariable#signal</code> wakes up a single thread, <code>ConditionVariable#broadcast</code>
wakes up all threads.</p>

<h2><code>thread_safe</code> gem</h2>

<ul>
<li>ThreadSafe::Array</li>
<li>ThreadSafe::Hash</li>
<li>ThreadSafe::Cache

<ul>
<li>similar to Hash, but insertion order enumeration isn&#8217;t preserved,
which means it can be faster</li>
</ul>
</li>
</ul>


<h2>Immutable = threadsafe</h2>

<p>Read more about it.</p>

<h2>Globals</h2>

<p>The Ruby AST is a global (is it really an AST at that point? is
dynamically adding a method an example of modifying an AST? ASTs are for
parsing, not so much adding/removing methods from a class obj).</p>

<p>Anyway, Kaminari was bitten by this:</p>

<p>https://github.com/amatsuda/kaminari/issues/214</p>

<h2>Thread-locals</h2>

<p>Variables that are global to everything in the current thread but hidden
to everyone else. So you could do</p>

<pre><code>Thread.current[:some_service] = SomeService.new
</code></pre>

<p>which could open a new connection. Connections are nice concurrency
primitives, much like request objects in Rails. But if you have too many
threads, you might hit a max connection limit, so in that case, use
pools, lol.</p>

<p>Pools let you specify max concurrency, which is likely less than the
number of threads that might want to consume it, and then when
requesting access to a thing in a pool, it&#8217;ll block until a slot&#8217;s
available.</p>

<p>See: https://github.com/mperham/connection_pool</p>

<p>mperham is Mr Sidekiq. Mr. Concurrency in general I guess.</p>

<p>Question: is a connection pool the same as a thread pool? Probably not,
connection pool is just a resource pool that is thread-aware, but
doesn&#8217;t constitute individual threads.</p>

<h2>Rubinius Actor</h2>

<p>https://github.com/rubinius/rubinius-actor</p>

<p>Depends on core Rubinius class <code>Channel</code>. TODO: find out why <code>Channel</code>
doesn&#8217;t/can&#8217;t exist in MRI.</p>

<h2>Rubinius Ruby JITting</h2>

<p>Talking to IRC folk: one of the major reasons for Ruby all the way down
or at least Ruby most of the way down is that more of it can be JITted
rather than having the hard C/C++ boundary after which no more
optimizations can be made.</p>

<p>Also, in some benchmarks b/w Rubinius and JRuby and MRI, etc., one thing
that comes up a lot is the suggestion that the tests run for longer so
that the JIT is primed, all the optimizations have been made, etc etc
etc.</p>

<h2>Rails Batches</h2>

<p>http://api.rubyonrails.org/classes/ActiveRecord/Batches.html</p>

<pre><code>Article.find_each do |a|
  a.wat
end
</code></pre>

<p>this internally splits DB queries into batches of 1000 so that you&#8217;re
not instantiating potentially a billion Ruby objects for each row. In
the end you&#8217;ll still allocate the same amount of memory but it can be
GC&#8217;d along the way vs causing an insane spike and possibly crashing your
server.</p>

<h2>Server-sent events</h2>

<p>http://tenderlovemaking.com/2012/07/30/is-it-live.html</p>

<ol>
<li>A stream obj is added to Rails request object, quacks like IO obj.
You can write to it and close it, but it doesn&#8217;t actually stream live
to the client; it buffers, and then flushes.</li>
<li>With <code>ActionController::Live</code>, it&#8217;ll actually stream live.</li>
<li>Some WebServers, like WEBrick will thwart this by buffering the
response until it&#8217;s complete. Unicorn could work, but it&#8217;s meant for
fast responses; anything taking longer than 30s might get terminated.
Rainbows/Puma/Thin would work.</li>
</ol>


<h2>Celluloid</h2>

<p>Transforms method invocations into blocking messages. Precede w <code>async</code>
to prevent blocking (obviously still happens async);</p>

<pre><code>require 'celluloid'

class DoesStuff
  include Celluloid

  attr_accessor :i

  def foo
    # currently this displays
    # one item per second.
    # if you swap comments with
    # the line after it'll wait
    # until the very end to print them all
    # at once because the each at the end
    # will evaluate the "longest" future first
    sleep i
    #sleep (11 - i)
    i
  end
end


futures = []

10.times do |i|
  thing = DoesStuff.new
  thing.i = i

  futures &lt;&lt; thing.future.foo
end


futures.each do |f|
  puts "Completed: #{f.value.i}"
end

sleep
</code></pre>

<p>This is interesting: https://github.com/celluloid/celluloid/wiki/Frequently-Asked-Questions#q-can-i-do-blocking-io-inside-an-actor-or-do-i-have-to-use-celluloidio</p>

<p>It&#8217;s fine to have blocking IO such as waiting for a DB query to return,
or slow HTTP response, but you shouldn&#8217;t have it waiting on
<em>indefinite</em> IO; for that, use Celluloid::IO.</p>

<p>I believe that an actor can&#8217;t be handling multiple messages at the same
time. Wrong! That&#8217;s only if Erlang/Exclusive mode is on, and you have to
be careful about that because it means a higher risk of deadlock:</p>

<p>https://github.com/celluloid/celluloid/wiki/Exclusive</p>

<p>Sidekiq doesn&#8217;t make use of return values a whole lot; rather actors are
expected to send messages back to their &#8220;callers&#8221;.</p>

<p>Accessing localvars is faster than ivars: https://github.com/puma/puma/commit/fb4e23d628ad77c7978b67625d0da0e5b41fd124</p>

<h2>Compare and set (CAS)</h2>

<p>aka check-and-set</p>

<p>For platforms that support it, CAS is a mutex-free approach to
thread-safety</p>

<pre><code>a += 1
</code></pre>

<p>is not thread safe, but</p>

<pre><code>cur = a.value
new_value = cur + 1
if (!a.compare_and_set(cur, new_value)) 
  # try again
end
</code></pre>

<p>is.</p>

<p>Worth pointing out that Redis supports a form of this using WATCH.</p>

<pre><code>MULTI # begin transaction
SET foo lol
SET bar wat
EXEC # execute
</code></pre>

<p>so basically if you do</p>

<pre><code>WATCH someval
MULTI
set someval lol
EXEC
</code></pre>

<p>and someval changed after the MULTI then it will fail.</p>

<p>So why use CAS over a mutex?</p>

<blockquote><p>If the cost of retrying the operation is cheap, or rare, it may be much less expensive than using a lock.</p></blockquote>

<p>Logic checks out.</p>

<pre><code>require 'atomic'
v = Atomic.new(0)
v.update do |current|
  current + 1
end
</code></pre>

<p>This is the shorthand to the idempotent loop with CAS.</p>

<p>Lockless showed mega improvements relative to locking in Rubinius but
not JRuby for some reason.</p>

<p>Hamster is the immutability gem to check out.</p>

<h2>oni</h2>

<p>https://github.com/olery/oni</p>

<p>Uses SQS, look into it because i am such a nooblet.</p>

<h2>SQS</h2>

<p>Uses a visibility timeout after a consumer has started to receive a
message in which time it is hidden from other consumers, and in this
time it should be deleted.</p>

<ul>
<li>Supports GET/POST requests to public URLs, presuming you pass in a
valid signature

<ul>
<li>This means you could fire requests directly to SQS rather than
having to go to a server first&#8230; that is badass.</li>
</ul>
</li>
<li>Reports of scalability problems</li>
</ul>


<p><a href="http://nsono.net/amazon-sqs-vs-rabbitmq/">Alternative: RabbitMQ</a></p>

<ul>
<li>SQS: consumers must poll for messages, and SQS charges by the request,
even if the response is empty.</li>
<li>RabbitMQ supports push</li>
<li>is free and open source</li>
<li>based on erlang</li>
<li>adheres to AMQP (standard for high performance messages queues)</li>
<li>supports durable queues (crash-recoverable, written to disk)</li>
<li>delivered in order unless message requeued</li>
<li>more consistent (much less likely to deliver a message twice unless
the message actually failed)</li>
</ul>


<p>cons</p>

<ul>
<li>not necessarily highly available (because it&#8217;s a server that runs on
whatever instance you wanna put it on, so you have to manage failover,
redundancy, etc, whereas SQS is a system that handles all of that)</li>
<li>this is configurable, but the default is for RabbitMQ to drop messages
if there are no consumers; surprising to SQS folk.</li>
</ul>


<h2>Heartbeats</h2>

<p>https://www.rabbitmq.com/reliability.html</p>

<blockquote><p>In some types of network failure, packet loss can mean that disrupted TCP connections take some time to be detected by the operating system. AMQP offers a heartbeat feature to ensure that the application layer promptly finds out about disrupted connections (and also completely unresponsive peers). Heartbeats also defend against certain network equipment which may terminate &#8220;idle&#8221; TCP connections. In RabbitMQ versions 3.0 and higher, the broker will attempt to negotiate heartbeats by default (although the client can still veto them). Using earlier versions the client must be configured to request heartbeats.</p></blockquote>

<p>Re: &#8216;Heartbeats also defend against certain network equipment which may
terminate &#8220;idle&#8221; TCP connections.&#8217;: I bet that&#8217;s referring to NAT, which
manages a cache of IP translations and will go inactive if nothings been
sent to / received from an IP for a while.</p>

<p>YAY I WAS RIGHT http://stackoverflow.com/questions/865987/do-i-need-to-heartbeat-to-keep-a-tcp-connection-open#comment1713801_866003</p>

<p>So Heartbeats</p>

<ul>
<li>reassure you the connection is alive in some cases where the failure
conditions aren&#8217;t otherwise detectable</li>
<li>keep the NAT state tables warm for your IP</li>
</ul>


<h2>Celluloid::IO</h2>

<p>https://github.com/celluloid/celluloid-io</p>

<p>Provides a different class of Actor that&#8217;s heavier than normal Celluloid
actors, but contains a high performance reactor like EventMachine or
cool.io (todo: check out cool.io). So unlike EventMachine you can have
multiple loops, e.g. one in each actor (resources permitting). (Also,
does EM really force you to just have one?)</p>

<h2>Autoload</h2>

<p>Yes we know it&#8217;s not threadsafe in MRI. Recent JRuby versions make it
thread safe, but just eager load your shits before spawning threads.</p>

<h2>Requests as concurrency unit</h2>

<p>I guess in general you should always look for the concurrency unit; that
domain object that encapsulates all the data you need to get a job done
so that hopefully you&#8217;re not sharing data between threads. Each request
gets handled by its own thread.</p>

<h2>Queue</h2>

<p><code>Queue#pop</code> will suspend a thread until data is in the queue. Like a
mofuggin stream.</p>

<p>Queue is apparently the only thread-safe data structure that ships with
Ruby.</p>

<h2>JRuby</h2>

<p>Foreign function interface</p>

<p>http://en.wikipedia.org/wiki/Foreign_function_interface</p>

<p>Mechanism for languages to invoke routines from other languages.</p>

<p>Write your extension code in Ruby, FFI will call the write C / Java /
whatever stuff. It won&#8217;t even be compiled. I guess it just links into
dynamic libs?</p>

<p>JRuby obviously doesn&#8217;t support C extensions, but FFI extensions will
work.</p>

<p>JRuby</p>

<ul>
<li>has no fork(), since JVMs mostly can&#8217;t safely be forked
(<code>NotImplementedError: fork is not available on this platform</code>)</li>
<li>Fibers are native threads, rather than MRI green threads, which means
you are constrained to native thread overhead/limits.</li>
</ul>


<h2>Rubinius (rbx)</h2>

<ul>
<li>Designed for concurrency, speed.</li>
<li>Rubinius 2.0 has no GIL</li>
<li>All tools written in Ruby, including bytecode VM, compiler,
generational GC, JIT, etc</li>
<li>No continuations (because dependent on callcc, a C thing)</li>
<li>At some point, when dealing with locks and low level things, you&#8217;ll
find C++.</li>
</ul>


<p>http://rubini.us/2011/02/25/why-use-rubinius/</p>

<h2>Ruby Enterprise Edition</h2>

<p>By Phusion. No longer alive.</p>

<ul>
<li>Compatible w 1.8.7</li>
<li>End of Life since 2012</li>
<li>No more work being done, reasons being:

<ul>
<li>Rails 4 no longer supporting 1.8</li>
<li>COW patch accepted on Ruby 2.0</li>
<li>Many Ruby Enterprise Edition patches addressed in 1.9, 2.0</li>
</ul>
</li>
</ul>


<h2>MacRuby</h2>

<p>Implementation of 1.9 Ruby directly on top of Mac OS X core tech, e.g.</p>

<ul>
<li>Obj-C runtime and GC</li>
<li>LLVM compiler infrastructure</li>
</ul>


<h2>Reactive manifesto</h2>

<p>TODO: read this http://www.reactivemanifesto.org/</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-26T15:10:00-04:00" pubdate data-updated="true">Jul 26<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/19/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Crank</h2>

<p>Meth.</p>

<p>An eccentric person, esp. one who is obsessed by a particular subject or
theory: when he first started to air his views, they labeled him a
crank | [ as modifier ] : I am used to getting crank calls from
conspiracy theorists.</p>

<h2>Roko&#8217;s modern basilisk</h2>

<p>It&#8217;s happening.</p>

<h2>Transactional UIs</h2>

<p>People build forms. Ember gives you sweet syntax sugar for 2wb.
Not for transactional UI, anything that needs a buffer.</p>

<p>Old mindset: if you need 1wb, just&#8230; don&#8217;t set on the other side of a
2wb.</p>

<p>TODO: ask kris more about the async/sync cocoa observer binding
limitations.</p>

<ul>
<li>Most observers just do something and stop.</li>
<li>And they mostly want to know the last thing they cared about.</li>
</ul>


<p>Bubbling doesn&#8217;t describe actions; actions go wherever. Bubbling only in
route hierarchy.</p>

<p>Services:</p>

<ul>
<li>session/user</li>
<li>timer</li>
<li>websocket</li>
<li>analytics</li>
</ul>


<p>Idea: components provide services to the components the render. They
have a ServiceCertificate</p>

<p>Goal:</p>

<ul>
<li>Try and associate actions with objects.</li>
<li><code>actions</code> themselves can just be passed into the <code>actions</code></li>
</ul>


<h2>Non-dynamic routes</h2>

<pre><code>resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}

resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}
</code></pre>

<p>Initializers vs <code>applicationRoute#beforeModel</code>.</p>

<p>retcon for how to use controllers</p>

<p>asop to data binding</p>

<p>HTMLbars knows what parts of the template are dynamic vs static.</p>

<p>In React, if you have a conditional</p>

<h2>Skunkworks project</h2>

<blockquote><p>A skunkworks project is a project developed by a small and loosely
structured group of people who research and develop a project
primarily for the sake of radical innovation.[1] The terms
originated with Lockheed&#8217;s World War II Skunk Works project.</p></blockquote>

<p>http://en.wikipedia.org/wiki/Skunk_Works</p>

<blockquote><p>The designation &#8220;skunk works&#8221;, or &#8220;skunkworks&#8221;, is widely used
in business, engineering, and technical fields to describe a
group within an organization given a high degree of autonomy
and unhampered by bureaucracy, tasked with working on advanced
or secret projects.</p></blockquote>

<p>Lockheed Martin&#8217;s Skunk Works project made SR-71.</p>

<h2>Project Svelte</h2>

<p>http://www.trustedreviews.com/opinions/android-4-4-kitkat-s-project-svelte-what-it-is-and-why-you-should-care</p>

<blockquote><p>‘dogfooding’ – that is making its employees use and live with their own projects</p></blockquote>

<p>They dogfooded their employees by forcing them to dev on handicapped
phones. Android 4.4 was the result, apparently it was way more
performant.</p>

<h2>RACK_ENV vs RAILS_ENV</h2>

<p><code>Rails.env</code> is decided by <code>RAILS_ENV || RACK_ENV || "development"</code>. It&#8217;s
common to set <code>RACK_ENV</code> which will also set <code>RAILS_ENV</code>, but if you
have any rack middleware that behaves differently in different
environments, you might screw yourself if you&#8217;re using <code>RAILS_ENV</code>.</p>

<h2>wythoughts on blocks</h2>

<p>The reason <code>|i|</code> is ok is for the same reason you can&#8217;t do the following
in Ruby:</p>

<pre><code>a = { |it| wat }
</code></pre>

<p>You have to do</p>

<pre><code>a = proc { |it| wat }
</code></pre>

<p>Case in point you need an fn to save a block.</p>

<h2>mythoughts on mutability</h2>

<p>Can/should we swap POJOs when an observed property changes? Is there any
value to</p>

<pre><code>var pojo = {
  a: {
    b: 123
  }
};

var a = pojo.a;
Ember.set(pojo, 'a.b'
</code></pre>

<h2>ASI: automatic semicolon insertion</h2>

<p>Nuff said.</p>

<h2>old browser disagreements on ws</h2>

<pre><code>[ text ws text]
</code></pre>

<p>cloneNode produces:</p>

<ul>
<li>ie8: 1 node</li>
<li>ie9: 2 nodes</li>
<li>else: 3 nodes</li>
</ul>


<h2>NoScope</h2>

<p>http://www.thecssninja.com/javascript/noscope</p>

<p>tldr NoScope is an old IE categorization of nodes, and NoScope dictates
that innerHTML and cloneNode will strip these els.</p>

<h2>Ropes: DAG of string implementation for FF/Chrome</h2>

<p>http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=181EEF66EB411F4277C009A1D492CF75?doi=10.1.1.14.9450&amp;rep=rep1&amp;type=pdf</p>

<p>Look into this more. Too lazy to read / comment.</p>

<p>How to force Chrome to not use a rope:</p>

<ul>
<li>Less than 12 chars</li>
</ul>


<p>What does it mean to intern strings?</p>

<h2>CSP: Content Security Policy</h2>

<p>http://www.html5rocks.com/en/tutorials/security/content-security-policy/</p>

<h2>String interning</h2>

<pre><code>String.prototype.intern = (function() {
   "use strict";
   var o = {"- ": 0};
   delete o["- "];
   return function() {
       var str = this;
       o[str] = true;
       var ret = Object.keys(o)[0];
       delete o[str];
       return ret;
       try {} finally {}
   };
})();
</code></pre>

<h2>Component pinning</h2>

<p>Associating the re-render with the pre-existing fragment.</p>

<h2>localStorage on iOS Cordova webviews</h2>

<ol>
<li>Run dev, set <code>localStorage.wat = "lol"</code></li>
<li>Stop and re-run the app, and <code>localStorage.wat</code> still is &#8220;lol&#8221;</li>
<li>Delete the app, re-install, still dev, <code>localStorage.wat</code> is undefined</li>
</ol>


<p>I don&#8217;t even have to check&#8230; your app can&#8217;t run in both dev and prod.
You can&#8217;t share userSessions across dev and prod apps. Then again, our
servers could maintain keys for both APNS and APNS_SANDBOX.</p>

<h2>GCM project number vs project ID</h2>

<p>https://developers.google.com/compute/docs/faq#whatisthedifference</p>

<p>You pick project ID, they pick project number. Project number is the
Sender ID you use for GCM.</p>

<h2>Pointer comparisons for such perf</h2>

<pre><code>if (wat === false) {
}
</code></pre>

<p><code>false</code> can be implemented to just refer to a unique memory location,
such that all browsers need to comparison in the above code is <code>wat</code>&#8217;s
memory address against <code>false</code>&#8217;s.</p>

<p>Same goes with</p>

<pre><code>if (wat === undefined) {
}
</code></pre>

<p>just that the presence of <code>foo</code> in <code>cache.foo</code> is ambiguous without
testing <code>foo in cache</code>; might be easier to do <code>cache.foo = UNDEFINED</code>
where</p>

<pre><code>function UNDEFINED() {}
</code></pre>

<p>Sentinel as fuck.</p>

<h2>PushPlugin</h2>

<p>Only starts firing PNs after <code>register</code>. We need a user session to
register, right? Seems weird we can&#8217;t query it for information before
immediately registering&#8230; either way, works fine for us, at least we
killed Zalgo.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-19T11:30:00-04:00" pubdate data-updated="true">Jul 19<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/18/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Cookies</h2>

<p>What ends up in <code>document.cookie</code>?</p>

<p>Test: kill a previous localhost:5000 server, start a server for a
separate project. Reload the page. Request headers sent include
a transient cookie from the previous server. I bet it was due to
Turbolinks. I was right!</p>

<p>From http://tools.ietf.org/html/rfc6265#section-4.1.1</p>

<blockquote><p> Origin servers MAY send a Set-Cookie response header with any
 response.  User agents MAY ignore Set-Cookie headers contained in
 responses with 100-level status codes but MUST process Set-Cookie
 headers contained in other responses (including responses with 400-
 and 500-level status codes).  An origin server can include multiple
 Set-Cookie header fields in a single response.  The presence of a
 Cookie or a Set-Cookie header field does not preclude HTTP caches
 from storing and reusing a response.</p></blockquote>

<p>So you can send multiple headers with the same key. Makes sense, since
comma separation will conflict with the UTC date (e.g. <code>Aug 12, 2014</code>).</p>

<p>So how do you set multiple cookies in Rack?</p>

<p>Interesting: https://github.com/rack/rack/blob/master/lib/rack/utils.rb#L266</p>

<p>Anyway, split cookies with newlines and Rack will cause this to send two
<code>Set-Cookie</code> headers, which is totally fine.</p>

<p>You can also use <code>set_cookie</code> on <code>Rack::Response</code> if you&#8217;re into that
sort of thing..</p>

<p>I psyched myself out thinking cookies were overwriting each other by doing:</p>

<pre><code>"Set-Cookie" =&gt; "foo\nbar\nbaz"
</code></pre>

<p><code>document.cookie</code> was only revealing <code>baz</code>. But, I&#8217;m a dumb: cookies
need to be key-value pairs, which fixed it.</p>

<p>You can use <code>HttpOnly</code> to prevent JS (and other APIs?) access to the
cookie sent by the server. Makes sense; less likely that&#8217;ll break
something.</p>

<p>Getting <code>document.cookie</code> returns all the cookies available to JS.
Setting it will only set the cookie you provide.</p>

<blockquote><p>Notice that servers can delete cookies by sending the user agent a
new cookie with an Expires attribute with a value in the past.</p></blockquote>

<h2>JavaScript set focus</h2>

<p><code>focus()</code> is a method on input elements. So is <code>blur()</code>.</p>

<p><code>document.activeElement</code> in modern browsers points to the focused
element, which might also include scroll windows.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/document.activeElement</p>

<p>In older browsers, to <code>blur</code> the active element, you&#8217;d have to know what
that element was; there was no way to query. Might be wrong about this.</p>

<h2>React Nested Router</h2>

<p>http://www.youtube.com/watch?v=P6xTa3RRzfA</p>

<ul>
<li>State is just data</li>
<li>Your route is data, e.g. you could render a top-level App component
and tell it what its route is, and render everything a la React,
pretend like you&#8217;re redrawing the whole page.</li>
<li>Rather than switch-statement-based routing, the <code>activeRoute</code> just
gets passed in via <code>props</code> like any other property

<ul>
<li><code>router.match</code> handlers will create all the routes, and pass in a
single <code>activeRoute</code>; every route segment along the way just knows
about with its activeRoute child is, if one exists.</li>
<li>e.g. <code>contact/profile</code>, app.activeRoute = contact,
contact.activeRoute = profile</li>
</ul>
</li>
<li>API

<ul>
<li>Route component

<ul>
<li>handler = a React Class</li>
</ul>
</li>
</ul>
</li>
<li>Differences w Ember

<ul>
<li>No auto-gen &#8216;index&#8217; routes</li>
<li>paths don&#8217;t inherit parent paths

<ul>
<li>this means if you&#8217;re &#8220;overwriting&#8221; a parent dynamic segment, the
dynamic segment must appear <em>somewhere</em> in the child route so you
can actually load that data.

<ul>
<li>AH, the router will detect when children omit ids that their
parents have declared. That&#8217;s nice.</li>
<li>also yells at you if you use the same path in two places.</li>
</ul>
</li>
<li>nice that it lets you have <code>/profile</code> vs <code>/user</code></li>
</ul>
</li>
<li>Ember is less typing, but

<ul>
<li>React makes it easier to share handlers</li>
<li>Overwriting URL is nice when you need it, error checking is nice</li>
</ul>
</li>
</ul>
</li>
<li>So each non leaf handler gets <code>activeRoute</code>, all handlers get all
<code>params</code>.</li>
<li>Refactorability/decoupling:

<ul>
<li>Because route names and paths are fully specified and all params are provided to
each handler, changing the nesting of a route means you don&#8217;t have
to rewrite all your link-tos from &#8220;wat.foo&#8221; to &#8220;foo&#8221;. Then again
if you&#8217;re using resources you don&#8217;t have to do that either.</li>
</ul>
</li>
<li>Question: what about other <code>props</code> you&#8217;d want to pass into a
component?

<ul>
<li>Answer: Route components aren&#8217;t concerned with props other than how
to be a route handler.</li>
</ul>
</li>
</ul>


<p>http://jsbin.com/vukacule/6/edit</p>

<p>It is really cool that you can switch between rendering a route with App
as a handler vs just rendering App. The difference is that, when
route-driven, it gets passed props.</p>

<p>The <code>Route</code> components you use are obviously stateless; all state lives
on the Handlers.</p>

<p>Ah, in React <code>` syntax just means</code>{blah: &#8220;wat&#8221;}` inside
the normal single-curly.</p>

<p>How do Links work? They call transitionTo and there&#8217;s a single URLStore
singleton.</p>

<h2>TLS Replay?</h2>

<p>I had it in my head that man-in-the-middle wasn&#8217;t a problem for TLS but
maybe they could replay the messages? Turns out I am wrong; TLS includes
a sequence mechanism.</p>

<p>That being said, your app might send repeat messages, which demands its
own double checking / application-level sequencing or some other
prevention mechanism.</p>

<h2>chroot</h2>

<p>http://en.wikipedia.org/wiki/Chroot</p>

<p>Learned about this when speculating w Ember Core about how the front
page Rust evaluator works at http://www.rust-lang.org/</p>

<p>It runs a program with the assumption that <code>/</code> is somewhere else, and it
can&#8217;t access it.</p>

<p>Change</p>

<h2>process.nextTick</h2>

<p><code>process</code> doesn&#8217;t exist on the browser, so therefore neither does
<code>nextTick</code>, but you can hack it if you&#8217;re on a browser that has a native
<code>Promise</code> object, since the <a href="http://promisesaplus.com/">spec</a> mentions
that resolution callbacks must happen when the execution context
consists only of platform code.</p>

<blockquote><p>onFulfilled or onRejected must not be called until the execution
context stack contains only platform code. [3.1].</p></blockquote>

<p>So here&#8217;s how you could write nextTick, note that there&#8217;s no need to</p>

<pre><code>var p = Promise.resolve();
function nextTick(cb) {
  p.then(cb);
}
</code></pre>

<h2>Visibility API</h2>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/Guide/User_experience/Using_the_Page_Visibility_API">mdn</a></p>

<p>e.g.</p>

<ul>
<li>pause video when you tab-away</li>
<li>stop requestAnimationFrame</li>
</ul>


<h2>Closing over <code>let i</code></h2>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p>The above code has the gotcha that by the time the <code>fns</code> functions run,
they&#8217;ll all print out <code>10</code>, rather than the value of <code>i</code> when the
closing-over function was created. This is part of the reason why jshint
will yell at you for creating functions in a loop, e.g.</p>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(makeCallback(i));
}

function makeCallback(num) {
  return function() {
    console.log(num);
  }
}
</code></pre>

<p>Then <code>i</code> will be uniquely preserved for each callback.</p>

<p>The es6 <code>let</code> keyword gives you block scope, which includes everything
declared within the for loop. If you just use <code>let</code> in the original
code, you can do</p>

<pre><code>var fns = [];
for (let i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p><code>i</code> doesn&#8217;t get hoisted; rather, each iteration gets its own <code>i</code> value
that gets closed over.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-18T03:50:00-04:00" pubdate data-updated="true">Jul 18<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/16/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>WeakMap</h2>

<p>Use objects as keys. If you lose access to a key, it and its value will
eventually be removed by GC because references to keys are weak. This
also means WeakMaps are non enumerable since GC is non-deterministic and
a key that might exist pre GC might not exist after.</p>

<h2>ES6 Symbols</h2>

<p>They&#8217;re nothing like Ruby symbols.</p>

<p>They&#8217;re used to create unique, non-enumerable, keys that can&#8217;t be
determined publicly unless the symbol is exported. So you could prevent
tampering with a player&#8217;s score by storing the score on the player using
an unshared symbol as the key:</p>

<p>http://tc39wiki.calculist.org/es6/symbols/</p>

<h2>ES6 === Harmony === ES.next</h2>

<p>They&#8217;re all the same thing.</p>

<h2>JS 1.7 vs ES6, etc</h2>

<p><a href="http://ejohn.org/blog/versions-of-javascript/">jeresig clears this up a bit</a></p>

<p>All modern browsers support ECMAScript; JavaScript is a variant of it
that Mozilla&#8217;s largely been adding features to. ES3 === JS 1.5.</p>

<p>So I see <code>let</code> was added to JavaScript 1.7, so why is it now being
described as a new upcoming feature of ES6? Ah, because all browsers
track ECMAScript standards, even if they call their enhanced language in
the browser something else. Mozilla has been blazing ahead and trying
new shit, but other browsers won&#8217;t pick it up until it&#8217;s actually
standardized into ECMAScript.</p>

<p>Why would Microsoft follow ECMAScript? Well, for starters, it delivered
JScript to Ecma back in the day for standardization.</p>

<blockquote><p>The name &#8220;ECMAScript&#8221; was a compromise between the organizations involved in standardizing the language, especially Netscape and Microsoft, whose disputes dominated the early standards sessions.</p></blockquote>

<p>Interesting, and:</p>

<blockquote><p>While both JavaScript and JScript aim to be compatible with ECMAScript, they also provide additional features not described in the ECMA specifications</p></blockquote>

<p>Also, some reason I thought TC39 was part of Mozilla. I see that I am
obviously incorrect: http://www.ecma-international.org/memento/TC39.htm</p>

<p>It&#8217;s Ecma-TC39. The things I don&#8217;t know.</p>

<p>W3C Tag, Ecma-TC39. W3C Tag, Ecma-TC39.</p>

<h2><code>let</code></h2>

<p><code>let</code> behaves like C++ declarations; the obj is only available in the
curlies, or in for loops, or whatever, and there&#8217;s no hoisting. Outside
of the block, the variable is undefined.</p>

<h2>Cloudfront TTL</h2>

<p>TTL lets you specify a min time before CF checks the origin to see if it
has a new version of the file/response. You still need your origin
server&#8217;s Cache-Control headers setup correctly.</p>

<p><a href="http://stackoverflow.com/questions/10621099/what-is-a-ttl-0-in-cloudfront-useful-for">TTL can be 0</a>.
Why? TTL 0 means that it delegates Cache-Control entirely to the origin.
This means CF will always make a GET request w <code>If-Modified-Since</code>
header to let the server return <code>304 Not Modified</code>.</p>

<h2>Drag and Drop</h2>

<p>Draggable elements need to be marked as <code>draggable="true"</code>.</p>

<p>Then listen to the <code>ondragstart</code> event, e.g.
<code>ondragstart="drag(event)"</code>.</p>

<p>And then say what data is associated with the dragged el&#8230;</p>

<pre><code>ev.dataTransfer.setData("Text", ev.target.id);
</code></pre>

<p>This seems strange.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/DataTransfer</p>

<p>It really is a class associated only w drag and drop.</p>

<p>Should probably be reading this rather than fucking w3schools. Why do I
still do that?
https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Drag_and_drop</p>

<p>Ah I get it, you use dataTransfer as part of the mechanism for
dynamically determining drop targets. You have to prevent bubbling
(return false or preventDefault) on droppable targets, and in that fn
they have the option of looking up the data transfer to see if they want
to accept the data from that drag drop.</p>

<p>You can also configure drag drag visual details to indicate copying,
moving, etc. LOL such drag and drop.</p>

<p>Oof apparently it&#8217;s a fucking disaster: http://www.quirksmode.org/blog/archives/2009/09/the_html5_drag.html</p>

<p>Criticisms:</p>

<ul>
<li>7 fucking events, such API surface</li>
<li>&#8220;For the drop event to fire at all, you have to cancel the defaults of both the dragover and the dragenter event.&#8221;</li>
</ul>


<h2>Cordova events: sticky != buffered</h2>

<p>Sticky events (e.g. deviceready) just mean that once fired, they stay in
a fired state. This means you can&#8217;t have multiple events fire if it&#8217;s a
sticky event. I was originally thinking sticky meant all the events were
cached until the first handler was registered.</p>

<p>Ended up making this: https://gist.github.com/machty/e1cc485060f2951aeb6c</p>

<h2>Why <code>-print0</code> in <code>find</code>?</h2>

<p>Often you pipe the results of <code>find</code> into <code>xargs</code> to pass the results of
a <code>find</code> so that some utility can operate on each file found. GOOD
ENGRISH, MATCHNEER.</p>

<p>But since <code>xargs</code> splits based on whitespace by default, this will break
for files with newlines or or spaces in them, so <code>-print0</code> separates
files w null bytes, and <code>-0</code> tells xargs to split via null bytes as
well. Win win win. No difference if you have no files with spaces in
them.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-16T00:40:00-04:00" pubdate data-updated="true">Jul 16<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/15/forgotten-things/">
		
			Forgotten Things</a>
	</h2>
	<div class="entry-content">
		<p>Here&#8217;s a progressively-updated list of things I forget throughout the
day. This is different from the list of things I&#8217;ve learned; that
approach is useful for packing the things into my brain, hopefully; the
purpose of this list is to pack things back in when I forget. And for
now it&#8217;ll just be one giant progressively-updated blog.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-15T12:18:00-04:00" pubdate data-updated="true">Jul 15<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/14/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Website Push != Push Notifications</h2>

<p>So when you&#8217;re rummaging through the Apple Dev Portal, don&#8217;t confuse the
two and generate the wrong certs. K?</p>

<h2>WWDC 2011 video on UIViewController Containment</h2>

<pre><code>https://developer.apple.com/videos/wwdc/2011/
</code></pre>

<p>First off, WWDC stands for the Apple World-Wide Developer Conference.</p>

<h2>Why view controllers</h2>

<ul>
<li>Make it easy to make high quality apps</li>
<li>Reusable</li>
</ul>


<p>A View Controller just a Controller. Mediates model data with many
views. View controllers maintain entire hierarchies of views. They&#8217;re
heavyweight, meant to manage a &#8220;screenful of content&#8221;. Often packaged
with a model, e.g.</p>

<ul>
<li>TweetViewController</li>
<li>ImagePickerController</li>
</ul>


<p>View Controllers are social, meant to connect to each other. They push
and pop each other, etc. They talk to each other a lot.</p>

<p>The &#8220;manage a screenful of content&#8221;:</p>

<p>View Controllers anticipate being presented in different ways. More
accurately: they should maintain a unit of content. Only
<code>rootViewController</code> manages a &#8220;screenful of content&#8221;, specifically the
<code>rootViewController</code> property of the window object. Knows how to forward
rotation events, decides overall layout.</p>

<p>How to use View Controllers</p>

<ul>
<li>subclass UIViewController</li>
<li>associate VC w view hierarchy</li>
<li>override callbacks</li>
</ul>


<p>Apperance callbacks: viewWillAppear, viewDidAppear, etc
Rotation callbacks: viewWillRotate, etc</p>

<p>ViewControllers manage an entire view hierarchy. Not just one to one
with a view.</p>

<p>View Controller Containers, a tale of Two Hierarchies: view hierarchies
and view controller hierarchies.</p>

<p>Container controllers</p>

<ul>
<li>responsible for parent child relationships

<ul>
<li>API like <code>initWithRootViewController</code> implies parent-child in nav
controller</li>
<li>split view controllers lets you set view controller children.</li>
</ul>
</li>
</ul>


<p>Controller container api</p>

<ul>
<li>addChildViewController

<ul>
<li>not meant to be called by anyone but its own implementation; don&#8217;t
call it on other controllers, basically</li>
</ul>
</li>
<li>remoteFromParentViewController

<ul>
<li>^^ ditto</li>
</ul>
</li>
<li>childViewControllers array</li>
<li>callbacks

<ul>
<li>willMoveToParentViewController</li>
<li>didMoveToParentViewController</li>
</ul>
</li>
</ul>


<p>Shouldn&#8217;t be able to walk up view hierarchy and totally skip over a
parent view controller: UIViewControllerHierarchyInconsistencyException,
prevents you from manually adding views into the wrong view controller
hierarchy.</p>

<p>When are appearance callbacks called?</p>

<p>viewWillAppear etc has nothing to do w addChildViewController, which has
nothing to do w view appearance.</p>

<p>viewWillAppear just means it&#8217;s in the window view hiearchy, but doesn&#8217;t
mean it&#8217;s actually visible (same w viewDidAppear).</p>

<p>TODO: what is view layoutSubviews?</p>

<p>viewDidAppear after the view added to viewHierarchy. Called after
layoutSubviews.</p>

<p>When implementing transitions, you have to implement
didTransitionToBlahBlah, one of the options is <code>animations</code> lambda.</p>

<p>VS Layout callbacks:</p>

<ul>
<li>viewWillLayoutSubviews&#8230;</li>
</ul>


<p>Presentation and Dismissal of VCs</p>

<p>set presentation style and then do presentViewController</p>

<p>Can also present VCs by direct subview manipulation.</p>

<pre><code>[root.someView addSubview: vc.view]
</code></pre>

<p>But this is bad form; better to make the VC a child of the root VC. VC
knows where subviews should go rather than the ass backwards way.</p>

<p>When to create a custom view controller container?</p>

<ul>
<li>Hopefully you don&#8217;t need to, so think twice first</li>
<li>Aesthetics</li>
<li>Custom app flows</li>
<li>Your app manipulates view hiearchy directly</li>
</ul>


<p>Use case: make split view show up in both landscape and portrait: no
need to make custom VC because now there&#8217;s API to just better configure
split view.</p>

<p>View controllers know themselves if they&#8217;re moving to or from parent
view controllers within viewWillAppear and viewDidAppear by checking:</p>

<pre><code>// used in viewDid/WillAppear
- (BOOL)isMovingToParentViewController;

// used in viewDid/WillDisappear
- (BOOL)isMovingFromParentViewController;

- isBeingPresented;
- isBeingDismissed;
</code></pre>

<p>Lol:</p>

<pre><code>- (BOOL) automaticallyForwardAppearanceAndRotationMethodsToChildViewControllers;
</code></pre>

<h2>RFC</h2>

<p>RFC&#8217;s (Request for Comments):</p>

<blockquote><p>Memos in the Requests for Comments (RFC) document series contain technical and organizational notes about the Internet</p></blockquote>

<p>http://www.ietf.org/about/</p>

<p>So many standards organizations. How am I supposed to keep this separate
from IEEE?</p>

<p>Anyway, RFCs are docs produced by IETF. I don&#8217;t think anyone else
(notable) produces docs called RFCs.</p>

<h2>Push Notifications</h2>

<p>Two levels of trust involved in publishing a push notifications:</p>

<h3>Connection Trust</h3>

<ul>
<li>Provider-side: provider proves it is an authorized provider that
Apple&#8217;s agreed to publish notifications for</li>
<li>Device-side: APNs must validate the connection is a with a legit
device</li>
</ul>


<h3>Token Trust</h3>

<p>Establishes certainty that messages are routed correctly; a provider
shouldn&#8217;t be able to send messages to random iPhones.</p>

<ul>
<li>APNs gives device a token</li>
<li>Devices gives it to provider</li>
<li>Provider uses it when publishing to APNs</li>
<li>APNs uses it to route back to device</li>
</ul>


<p>A <code>device token</code> is not a device <code>UDID</code>; aside from being a totally
different string, it is conceptually different in that it identifies not
only the unique device, but the application the Push Notification is
delivered to.</p>

<p>Maybe that&#8217;s what&#8217;s confusing: don&#8217;t call it a <code>device token</code>, call
it&#8230; an app-token? I get confused by the easiest things.</p>

<h3>Providers must maintain persistent connection</h3>

<p>If you want to send a notification through APNS (and GCM),
you must maintain a persistent connection to the server. In other words,
you can&#8217;t just connect-sendmessage-disconnect a la HTTP, which makes
push notifications inconvenient for Rails-y architectures without
using Sidekiq/Resque to reuse a persistent connection.</p>

<p>I both:</p>

<ol>
<li>failed to realize that this was a requirement for a while and</li>
<li>failed to understand why</li>
</ol>


<p>The best justification for this architecture that I can determine from
the docs and people I&#8217;ve talked to is that constantly
connecting/disconnecting to what is a high-performance, low-latency,
distributed system would be a colossal waste of resources and a latency
hit. An app capable of notifications is essentially a stream that APNS
consumes, and might be sending thousands of messages, so either way
they&#8217;d at least need to support a persistent connection for performance
reasons, and if they&#8217;re going to support that, why bother supporting
an obviously deficient connect/disconnect-based server interaction.</p>

<p>How many other services can be considered consumers of your stream?</p>

<h3>Service-to-Device Connection Trust</h3>

<p>Device identity is established via TLS peer-to-peer auth (internally;
iOS devs don&#8217;t need to implement this).</p>

<ul>
<li>Device TLS auths w APNs</li>
<li>APNs returns certificate, which it validates</li>
<li>Device sends device certificate to APNs</li>
<li>APNs valiates device certificate</li>
</ul>


<p>So I guess this prevents:</p>

<ul>
<li>an iPhone mimicker pretending to be something it&#8217;s not</li>
<li>an APNs ripoff pretending to be something it&#8217;s not</li>
</ul>


<h3>Provider-to-APNS connection trust</h3>

<p>Same process as above, just w provider (your server) and APNS.</p>

<p>A connection to APNs can only serve a single application, identified by
the topic (bundle ID) specified in the certificate, presumably the
one you generate in the online dev console. Also, APNs has a certificate
revocation list; if a provider is on that list, it&#8217;s connection will be
refused/closed. I think this would happen if you didn&#8217;t implement a
persistent connection to APNs but rather treated it like HTTP and kept
closing/opening the connection.</p>

<h3>Token Generation and Dispersal / token trust</h3>

<p>Jesus christ why don&#8217;t I just RTFM? It solves all the problems. Ah yes,
arm-chair ADD.</p>

<ul>
<li>Application asks system to register</li>
<li>System (iOS) forwards this to APNs</li>
<li>APNs generates device token using info in the certficate (presumably
the one established as described above) and encrypts it, and sends
back the encrypted token</li>
<li>App gets the encrypted key as an <code>NSData</code>, and must send it to the
provider in hexidecimal format</li>
</ul>


<p>This guarantees that only APNs generated the token used for routing
(since it&#8217;s encrypted by some private key within APNs). This token can
only be used for the device that originally connected to receive
notifications.</p>

<h3>Trust components</h3>

<p>e.g. keys/certificates you need to create/provide to APNs for all of
this shit to work:</p>

<ul>
<li><p>Provider</p>

<ul>
<li>unique provider certificate and private key for validating
connection to APNs</li>
<li>certificate identifies a topic that the provide can publish to (the
app&#8217;s bundle id).</li>
<li>Provider provides device token.</li>
<li>Provider can additionally validate that it&#8217;s talking to APNs using
the public server certificate provide&#8230; at connection time?</li>
</ul>
</li>
<li><p>Device</p>

<ul>
<li>obvious stuff already covered</li>
</ul>
</li>
</ul>


<p>Note: &#8220;topic&#8221; today is literally the bundle ID of the app. A certificate
identifies which apps it&#8217;s allowed to broadcast notifications to via
this topic. Maybe in the future, topics can refer to multiple apps?
Right now it&#8217;s coupled to bundle ID, in the future, this could be a
configurable thing&#8230; multiple apps could subscribe to the same topic?
This is all bullshit atm but what I think based on their terminology.
It&#8217;s really just a really constrained pub-sub, where apps can&#8217;t
subscribe to message channels other than the one that uniquely
identifies their app+device tuple.</p>

<h3>Coalescing</h3>

<p>APNs is last-write wins in that that in the case of multiple
notifications, only the last one will be stored-forwarded to the app.
This isn&#8217;t to say they coalesce within your device (validated by the
fact that you&#8217;ll see multiple messages from IRCCloud rather than a
single one saying &#8220;new messages available&#8221;), but specifically refers to
the storage of messages undeliverable because the client app&#8217;s turned
off. GCM gives you more fine-grained control over this.</p>

<h3>Summary</h3>

<p>So, given that I&#8217;ve been fighting this bullshit, realizations:</p>

<p>I need to stop revoking/re-creating the APNs app certificate generated
in the Apple Dev console. It&#8217;s not like it&#8217;s tied to some private/public
key or anything.</p>

<h2>Difference b/w .pem and .cer, etc</h2>

<p>I had to run this to convert .cer to .pem</p>

<pre><code>openssl x509 -in aps_development.cer -inform DER -out aps_development.pem
</code></pre>

<h3>X.509</h3>

<pre><code>http://en.wikipedia.org/wiki/X.509
</code></pre>

<p>X.509 is an ITU-T (Telecommunication Standardization Sector)
standard that describes certificate generation, revocation, and other
utilities. <code>openssl</code> just happens to support x509 certificate
generation.</p>

<p>Remember: x509 means one thing: certificates. If you see x509 in the
wild, it&#8217;s probably talking about certificates. x509 certificates.
Certificates.</p>

<p>x509 is unlike PGP in that it maintains a hierarchical chain of
certificate signers, each validated by the previous, with a root CA
(Certificate Authority) starting the chain. PGP relies (or at least
originally relied on) a Web of Trust.</p>

<h3>PEM</h3>

<p><code>---BEGIN CERTIFICATE---</code> and <code>---END CERTIFICATE---</code>.</p>

<p>Can contain multiple certificate and even the prviate key. &#8220;The private
key&#8221;? Which private key? Answer: the one that&#8217;s automatically generated
by Keychain Access and similar utilities when you create a Certificate
Signing Request (CSR).</p>

<p><a href="http://stackoverflow.com/a/7947362/914123">See here</a></p>

<p>TODO: can you even use an existing public/private key? Probably, but
possibly less secure:</p>

<p><a href="http://en.wikipedia.org/wiki/Certificate_signing_request">Read the wiki, you dingus</a></p>

<h2>PKCS</h2>

<p>(public key cryptography standards) created by RSA Security in the 90s.
It&#8217;s a family of standards relating to cryptography.</p>

<p>PCKS 1 is a standard, PCKS 9 is a standard, PCKS 12 is a standard.</p>

<p>Exporting multiple cryptography shits in a single file falls under the
PKCS 12 standard. PKCS 12 also handles bundling all the members of a
CHAIN OF TRUST.</p>

<blockquote><p>It is commonly used to bundle a private key with its X.509 certificate or to bundle all the members of a chain of trust.</p></blockquote>

<p>Makes sense, must be a common thing. Apple obviously does that. AWS SNS
expects you to upload a <code>.p12</code> that it splits into a cert and priv key.</p>

<p>File name extension is <code>.p12</code> (which I&#8217;ve seen) or <code>.pfx</code> which I&#8217;ve
not.</p>

<p><a href="http://en.wikipedia.org/wiki/PKCS_12">Wiki</a></p>

<p>So if I understand correctly, the purpose of certificate is so that you
can encrypt data, and anyone who wants to validate that you are who you
say you are can look up the certificate chain.</p>

<p>You create a pub/priv key pair, create a CSR with it, and then the
approving authority gives you a certificate that you can hand to other
people. The certificate can be used to validate that whatever you
encrypted with your (still unshared and totally) private key, can be
guaranteed to have originated from you. Without certification, you&#8217;re
just some entity with a pub/priv key pair&#8230; and&#8230; I don&#8217;t know, need
to read up more on the implications of this. Amazing how hard this stuff
is.</p>

<p>Anyway, <code>pkcs12</code> is the <code>openssl</code> file utility for creating/parsing
pkcs12 file.</p>

<h2><code>man</code> page sections</h2>

<p>Valid:</p>

<pre><code>man crontab
man 1 crontab # equiv to above
man -s 1 crontab # equiv to above
man 5 crontab 
man -s 5 crontab # equiv to above
</code></pre>

<p>Invalid:</p>

<pre><code>man 2 crontab # No entry for crontab in section 2 of the manual
man 3 crontab # ditto
man 4 crontab # ditto
</code></pre>

<p>Why would it have pages 1 and 5 but not 2-4?</p>

<p><a href="http://en.wikipedia.org/wiki/Man_page">Ahhhh!</a></p>

<p>Turns out there are sections (that vary by platform):</p>

<pre><code>1   General commands
2   System calls
3   Library functions, covering in particular the C standard library
4   Special files (usually devices, those found in /dev) and drivers
5   File formats and conventions
6   Games and screensavers
7   Miscellanea
8   System administration commands and daemons
</code></pre>

<p><code>crontab</code> has no system calls, lib fns, special files, but it does have
general commands and file formats.</p>

<p><code>man</code> isn&#8217;t just unix commands, but also lib, system calls, C functions,
etc.</p>

<p>These sections also handle cases when unrelated concepts have the same
name&#8230; there might be an <code>exit</code> C fn (there is) and an <code>exit</code> terminal
command.</p>

<p>This explains the wording here:</p>

<pre><code>No entry for printf in section 4 of the manual
</code></pre>

<p>You don&#8217;t look up the <code>printf</code> page, and then its section 4
subsection&#8230; rather, you look up entries in a section of <code>man</code>.</p>

<p>That&#8217;s the same reason it&#8217;s <code>man 3 printf</code> rather than <code>man printf 3</code></p>

<p>God, such an obvious thing I never understood/remembered.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-14T09:33:00-04:00" pubdate data-updated="true">Jul 14<span>th</span>, 2014</time></div>
	


	
</div></article>

<nav id="pagenavi">
    
        <a href="/blog/page/5/" class="prev">Prev</a>
    
    
        <a href="/blog/page/7/" class="next">Next</a>
    
    <div class="center"><a href="/archives">Blog Archives</a></div>
</nav></div>
	<footer id="footer" class="inner">Copyright &copy; 2017

    Alex Matchneer

<br>
Powered by Octopress.
</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'usefuldude';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-49928757-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>



</body>
</html>

