<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[machty's thoughtz]]></title>
  <link href="http://machty.github.com/atom.xml" rel="self"/>
  <link href="http://machty.github.com/"/>
  <updated>2014-10-29T23:45:06-04:00</updated>
  <id>http://machty.github.com/</id>
  <author>
    <name><![CDATA[Alex Matchneer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Gnomons all up on this journal]]></title>
    <link href="http://machty.github.com/blog/2014/10/17/gnomons-all-up-on-this-journal/"/>
    <updated>2014-10-17T17:52:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/10/17/gnomons-all-up-on-this-journal</id>
    <content type="html"><![CDATA[<h2>timerfd</h2>

<p>Just like any other api that inverts signal-handling API into something
file handle-y, Linux has such an API for expiring timers, which means
you can use these file handles w functions like <code>select</code>, <code>poll</code>, and
<code>epoll</code>.</p>

<h2>CLOEXEC reminder</h2>

<p>I&#8217;ve already kinda learned this but I FORGET. The CLOEXEC flag is
something that appears in <code>open</code> and other APIs that create a file
handle; it means that if <code>exec</code> is ever called on a process with a
CLOEXEC handle, the handle will close rather than leak to a process that
can&#8217;t even really access that file handle.</p>

<h2>spawn = fork + exec</h2>

<p>Allows for greater degree of flexibility in what happens between those
two steps. Node only has spawn because it&#8217;s trying to be cross platform.
There&#8217;s no fork. There&#8217;s no spoon.</p>

<p><code>posix_spawn</code> exists to more directly spawn a process when <code>fork</code> is not
supported.</p>

<h2>Embedded System</h2>

<p>http://en.wikipedia.org/wiki/Embedded_system</p>

<p>Usually means you&#8217;re running software on some piece of hardware with a
dedicated purpose, limited resources, and real-time requirements. It&#8217;s a
computer system embedded into some larger mechanical whole.</p>

<h2>fork</h2>

<p>No guarantee of where parent or child is scheduled to run so don&#8217;t run
into conditions.</p>

<p><code>fork</code>ing can be wasteful especially if immediately <code>exec</code>ing, cept for
the fact that</p>

<ul>
<li>program text is marked read only and often shares the same page
mapping as parent</li>
<li>copy-on-write</li>
</ul>


<p>You can execute code in a single-purpose forked child process without
changing the resource/memory footprint of the parent. Useful if the code
in question is unspeakably/unstoppably leaky or prone to memory fragmentation.</p>

<p>Mmm mmm mmm using pipes.</p>

<pre><code>r,w = IO.pipe

if fork
  w.close
  answer = r.read
  Process.wait
  puts $?.exitstatus
  puts answer
else
  r.close
  w.write("SOME BULLSHIT")
  exit(123)
end
</code></pre>

<p>Useful for when the single byte/octet return code (<code>$?.exitstatus</code>)
won&#8217;t cut it. Insane Posse Clown.</p>

<p>BSD used to have a shit wasteful fork back in the day, then added vfork,
and then everyone else made efficient COW <code>fork</code>s, but still most people
provide an implementation of vfork which:</p>

<ul>
<li>performs zero duplication, even of VM pages (which all forks due, even
if no writes have happened yet under a COW system). Parent memory
shared until <code>exec</code> or <code>_exit</code>.</li>
<li>Parent execution suspended til then</li>
</ul>


<p>This is risky as fuck because:</p>

<ul>
<li>simply returning from a function will impact parent process&#8217;s memory.
It&#8217;s almost like a step-through longjmp, cept, no this totally breaks.
It&#8217;s not like the parent will pick up from wherever the child process
leaves off; the process counters are different between processes, so
if you return from a function in a child, you&#8217;ll fuck with the stack
frame, probably cause some SEGVs, and bite the big one.</li>
</ul>


<p>You can on the other handle futz with file handles in this time
(apparently these are duplicated? just not VM pages?)</p>

<pre><code>vfork -- spawn new process in a virtual memory efficient way
</code></pre>

<p><code>_exit</code> must be used because <code>exit</code> would flush stdio and thus fuck the
parent.</p>

<p>But don&#8217;t use vfork. It sucks. It&#8217;s obsolete. It&#8217;s not even in SUSv4.
It&#8217;s garbage shit-kicker nonsense. <code>fork</code> is pretty much just as fast
when COW exists.</p>

<p>You can actually control whether parent or child runs first via
<code>proc/sys/kernel/sched_child_runs_first</code> (or the sysctl equiv).</p>

<p>The argument for parent-first is that the TLB cache is warm with parent
stuff, so memory lookups are faster yadda yadaa I can&#8217;t imagine this
actually makes a difference unless you&#8217;re forking like a motherforker.</p>

<p>Hehehehe:</p>

<pre><code>3.times { fork }
puts "wat"
</code></pre>

<p>Results in</p>

<pre><code>wat
wat
wat
wat
wat
wat
wat
wat
</code></pre>

<p><code>atexit</code> handlers are shared w <code>fork</code>.</p>

<h2>Process rehash, new learnings</h2>

<p>Even if a parent kills a child, it has to wait or else it remains a
zombie.</p>

<p>There&#8217;s no such thing as a zombie orphan; well actually there are
transient zombie orphans; <code>init</code> will adopt them and immediately <code>wait</code>
on them, and then they&#8217;ll be collected.</p>

<p>Prediction: it gets messy to call <code>wait</code> in a SIGCHLD handler since
signals might coalesce; two SIGCHLDs might coalesce into one, and the
foolish programmer might only wait once. I bet if I looked at unicorn
I&#8217;d find a loop.</p>

<h2>KGIO</h2>

<p>http://bogomips.org/kgio/</p>

<p>Ruby gem w C extensions for Kinder, Gentler IO.</p>

<ul>
<li>Avoids expensive EAGAIN / EINPROGRESS exceptions

<ul>
<li>EAGAIN: non-blocking IO when there&#8217;s no data, so try <em>again</em> later</li>
<li>EINPROGRESS: (less common), similar to EAGAIN but distinguished for
things like <code>connect</code> in mid 3-way handshake</li>
</ul>
</li>
<li>other niceties</li>
</ul>


<p>Used in Unicorn and related Rainbows!. Can&#8217;t use in JRuby obviously but
then again no forking server model is supported in JRuby.</p>

<h2>JRuby Servers</h2>

<p>https://github.com/jruby/jruby/wiki/Servers</p>

<p>Can&#8217;t use unicorn but you can use things like Puma, or Trinidad, which
wraps rack/rails within a Tomcat container. So many things I do not
know!</p>

<h2>Isomorphic Code</h2>

<p>Can run on server or client. Not sure of the roots, but sounds like it
started in 2011, at least as way of describing JS code that runs between
both? React-router is &#8220;isomorphic&#8221;.</p>

<h2>ELF format</h2>

<p>Executable and Linking Format.</p>

<h2>Built-ins</h2>

<p>Sometimes no forking occurs because it&#8217;s quick and efficient, or because
there are desirable side effects that should make it into the current
shell process. Like <code>cd</code> (can&#8217;t change the cwd of the current process
if you&#8217;re forking). Or <code>export</code>.</p>

<h2>Why keep fd&#8217;s open on <code>exec</code>?</h2>

<p>If you&#8217;re exec&#8217;ing, shouldn&#8217;t you lose access to file handles? Not
necessarily; stream redirection via the shell is a good example where
you preserve what 0 1 2 point to.</p>

<h2>Auto-reap zombie child processes</h2>

<p>If you set the signal mask to ignore <code>SIG_CHLD</code>, potential zombie child
processes will be automatically reaped. So no need to <code>wait</code> in that
case.</p>

<p>Also, it&#8217;s implementation-defined (according to SUS) whether <code>exec</code>
resets the <code>SIG_CHLD</code> disposition after an exec (Linux preserves,
Solaris resets to default, etc).</p>

<h2><code>exec</code> clears sig handlers</h2>

<p>Of course, since sig handlers live in the text and text is replaced, so
must handled signals be reset. Everything else about signals is
preserved (cept that <code>SIG_CHLD</code> ignores may not
get reset to <code>DFL</code> depending on the implementation), but since most
processes expect to start with a clean slate, if you didn&#8217;t write the
process, you should reset everything yourself before an exec.</p>

<h2><code>system</code></h2>

<p>Runs a shell command, with all the processing/substitutions of the
command string that you would expect.</p>

<p>Inefficient; fork+execs twice, one for the shell, and one for the
process you intend to run.</p>

<p>set-user-id and set-group-id programs should never use <code>system</code>
since it opens the door to setting weird ENV vars to get unintended
programs to run, and they&#8217;ll inherit the effective user id. The
canonical example is setting IFS to <code>a</code>, and then <code>shar</code> runs and is
interpreted as <code>sh r</code>, and <code>r</code> is some script/executable that is no
running with admin privileges to do whatever it wants. Evil shit!</p>

<p>Note that modern shells reset IFS now as a rule.</p>

<h2><code>clone</code></h2>

<p>A Linux-specific sister of <code>fork</code>; it creates a new process, but starts
at the beginning of a provided function called w a provided arg. The
child process terminates if this function returns (or the exit variants
are called).</p>

<ul>
<li>you can specify termination signal (rather than always CHLD)</li>
<li>flags let you meticulously control a variety of info about what is
actually shared with the new child process: file handles, signal
dispositions, etc.</li>
</ul>


<p>So basically it&#8217;s threads&#8230; but separate processes? Is there a name for
these kinds of threads? LinuxThreads I guess.</p>

<p>Threads/processes are just kernel scheduling entities with differing
degrees of shared attributes. Processes are just, like, organizational
distinctions. Schedule wise, the scheduler doesn&#8217;t care whether it&#8217;s a
thread or a process. Blueskying of course.</p>

<h2>Mode 7</h2>

<p>http://en.wikipedia.org/wiki/Mode_7</p>

<p>The special background layer mode that enabled perspective-y effects, as
well as zooming and other cool things. F-zero relied on it, the map in
Link to Past relied on it. Any zoomy crazy shit that wasn&#8217;t a sprite
relied on it.</p>

<h2>Dyson Sphere</h2>

<p>Shell around the sun.</p>

<p>http://www.islandone.org/LEOBiblio/SETI1.HTM</p>

<p>Other lifeforms smashed apart their planets to build a dyson sphere to
capture energy, support population growth.</p>

<p>We could knock apart Jupiter, use its mass to create a sphere around sun
with a diameter twice that of Earth&#8217;s orbit. The shell would be 10 feet
thick, and make&#8230; something&#8230; habitable?</p>

<h2>Fermi Paradox</h2>

<p>http://waitbutwhy.com/2014/05/fermi-paradox.html</p>

<p>http://en.wikipedia.org/wiki/Fermi_paradox</p>

<p>The apparent contradiction between the high probability of alien life
and the fact that no one has contacted us yet.</p>

<p>Explanation 1: They don&#8217;t exist</p>

<p>Possibly due to a Great Filter; at some point in development, something
wipes them out, or there&#8217;s some point of evolution that&#8217;s reaaaally
really hard to get beyond that filters out people who made it beyond the
previous step.</p>

<p>So where does that leave <em>us</em>?</p>

<p>We&#8217;re</p>

<ul>
<li><p>rare</p>

<ul>
<li>other rare survivors might be reaaaally far away</li>
<li>the filter is behind us</li>
</ul>
</li>
<li><p>first: no one else to communicate with yet</p></li>
<li>fucked: we&#8217;re about to hit our wall like everyone else has</li>
</ul>


<p>Ah I love the potentialy reason for why intelligent life wouldn&#8217;t
broadcast data: there are potential harmful civilizations that would
destroy anyone they could find, and most advanced civilizations are
smart enough not to give away their locations to these fuckers. That&#8217;s
why we only have SETI today, and not METI (messaging to ETs), which most
scientists agree is a profoundly unwise idea.</p>

<p>Eesh, or there&#8217;s only one superpredator species, like humans on Earth,
that would wipe out another species before it got too intelligent.
Nipping the universe in the bud. Fuuuck that.</p>

<p>Or we&#8217;re not using the right technologies to communicate, or even if we
did, other minds might work much faster or slower than ours; it could
take years for them to say hello. Hahaha.</p>

<p>Or we are receiving communications but the gov is hiding it.</p>

<p>Or other civilizations see us, but we&#8217;re a look-don&#8217;t-touch zoo.</p>

<p>Or the higher civilizations are here, but we couldn&#8217;t begin to
understand them, they&#8217;re just so advanced.</p>

<p>Or we&#8217;re just so fundamentally incorrect about reality.</p>

<p>Types of civilization</p>

<ul>
<li>I: ability to use all the energy on the planet (Sagan says we&#8217;re a
0.7; just under the legal limit)</li>
<li>II: ability to harness all power of a star (e.g. Dyson sphere)</li>
<li>III: ability to harness all power of a whole galaxy</li>
</ul>


<p>http://waitbutwhy.com/ seems pretty awesome in general. Three thumbs up.</p>

<h2>fork v vfork</h2>

<p>I&#8217;ve already written about this but followup: vfork is faster, but
considering how slow the followup <code>exec</code> is, this is probably
neglibibilgigible.</p>

<h2><code>time</code> and forking</h2>

<p>Are child process CPU times included?</p>

<pre><code>N = 20000000

def slow_thing
  inc = N / 5
  N.times do |i|
    puts "." if i % inc == 0
  end
end

do_fork = true
if do_fork
  fork do
    slow_thing
  end

  Process.wait
else
  slow_thing
end
</code></pre>

<p>With forking:</p>

<pre><code>real    0m1.565s
user    0m1.544s
sys     0m0.013s
</code></pre>

<p>Without forking:</p>

<pre><code>real    0m1.480s
user    0m1.464s
sys     0m0.011s
</code></pre>

<p>Seems that yes they are (there&#8217;s no difference with the above).
Actually, quick aside: it seems that <code>time</code> is a bash builtin. Not sure
why, but if I use <code>/usr/bin/time</code> as well, not much changes</p>

<pre><code>1.42 real         1.41 user         0.00 sys
1.49 real         1.47 user         0.01 sys
</code></pre>

<p>Ah, <code>time</code> will add together all forked processes. And apparently if you
have two active processes, you might wind up with a CPU time greater
than real time. LET US FIND THE FUCK OUT.</p>

<pre><code>N = 20000000

def slow_thing
  inc = N / 5
  N.times do |i|
    puts "." if i % inc == 0
  end
end

num_forks = 2

num_forks.times do
  fork do
    slow_thing
  end
end

num_forks.times { Process.wait }
</code></pre>

<p>BOO YA</p>

<pre><code>real    0m1.636s
user    0m3.199s
sys     0m0.021s
</code></pre>

<p>How awesome is it when things start clickin.</p>

<p>So how does time actually do it?</p>

<h2>curl + tar</h2>

<pre><code>curl http://mirror.anl.gov/pub/gnu/time/time-1.7.tar.gz | tar -x
</code></pre>

<p>I guess you&#8217;re also supposed to use <code>-z</code> as well, but in my manpages:</p>

<pre><code> -z      (c mode only) Compress the resulting archive with gzip(1).  In extract
         or list modes, this option is ignored.  _Note that, unlike other tar
         implementations, this implementation recognizes gzip compression auto-
         matically when reading archives._
</code></pre>

<p>That&#8217;s so nice of them. And ridiculous that it wouldn&#8217;t always work that
way. Maybe not.</p>

<h2>Threads</h2>

<p>Every process has at least one thread.</p>

<p>Concurrency via processes has some limitations:</p>

<ul>
<li>nothing is shared so communication is limited to IPC, pipes and what
not</li>
<li>expensive due to page table duplication and file descriptor table dups
and all the things that happen during <code>fork</code></li>
</ul>


<p>Most process attributes are shared between threads. Here&#8217;s some stuff
that&#8217;s not:</p>

<ul>
<li>thread ID</li>
<li>signal mask</li>
<li>thread-specific data</li>
<li>alternate signal stack</li>
<li><code>errno</code></li>
<li>floating-point env</li>
<li>scheduling priority/policy</li>
<li>CPU affinity</li>
<li>capabilities</li>
<li>stack</li>
</ul>


<p>Of course you could share stack vars between threads but this runs the
risk of data invalidation once a function returns etc etc etc.</p>

<p>How does errno work if it&#8217;s a variable? Trick question, it&#8217;s a macro
that evals to an lvalue (so you can still manually set it yourself).</p>

<p><code>join</code> is like <code>wait</code>, it seems to free up that thread, and you wouldn&#8217;t
want to call it twice, lest terrible things happen. You must detach or
join. (Seems like the equiv in processland for detach is to set
<code>SIG_CHLD</code> to ignore).</p>

<p>Unlike processes, threads are created as peers. If A spawns B spawns C,
then A can join C. They&#8217;re all siblings in the same process cult.
There&#8217;s no concept of generic <code>Process.wait</code> to join with any ol thread.
This makes sense since some lib function could spawn a thread and you
might clobber its operation and steal its return value.</p>

<p>Once you detach a thread, you can&#8217;t join it. Again keep in mind that
threads can&#8217;t escape the fact that they live in a process; if the
process dies, so do the threads.</p>

<p>Threads can&#8217;t use the full virtual memory address space; they have to
share with all the other threads. Probably not a big deal unless you&#8217;re
doing insane shit, but still.</p>

<p>Mutexes in Linux are implemented in user spaces using futexes (fast user
space mutexes). They only cause system calls when multiple threads lock.</p>

<h2>Pitchblende</h2>

<p>Old school word for Uraninite. Basically ore ready for uranium
processing.</p>

<h2>Javascryptonomicomicon</h2>

<p>http://matasano.com/articles/javascript-cryptography/</p>

<h2>ffs ssl</h2>

<p>http://wingolog.org/archives/2014/10/17/ffs-ssl</p>

<blockquote><p>WTF their price is 49 dollars for a stupid certificate? Your domain name was only 10 dollars, and domain name resolution is an actual ongoing service, unlike certificate issuance that just happens one time.</p></blockquote>

<p>Hmm clearly I need to better understand how this all works&#8230; being a
CA, root or no, definitely requires constant service</p>

<p>Wow this is sneaky: http://thejh.net/misc/website-terminal-copy-paste</p>

<p>Never copy and paste secure stuff from a webpage. I&#8217;m so sad.</p>

<p>Lol &#8220;Well now I have to live with this confidence-inspiring dialog,
because I left off the organization&#8221;</p>

<p>TIL Organization is the name you choose that you want to pop up when
inspecting certifications.</p>

<p>Wow, googlebot still doesn&#8217;t use TLS 1.2.</p>

<h2>Condition variables</h2>

<p>Didn&#8217;t I write about this already? So forgetful!</p>

<pre><code>Loop
  Lock around shared structure
    If shared structure "empty"/unusable, wait on condition variable


(other thread):
Lock around shared structure
  Put data into it
  Signal Condition variable
</code></pre>

<p>If you didn&#8217;t do this, you&#8217;d have some wasteful CPU-hog loop that
constantly locked and unlocked the mutex to check if the shared
structure had data ready.</p>

<ul>
<li>Always re-check the condvar predicate; some other thread might have
invalidated it in the meantime.</li>
<li>Also, a looseness of predicates lends to some flexibility; a producer
doesn&#8217;t need to know the exactly logic that consumer cond var depends
on; producer can just say &#8220;hey interested people, this shared
structure changed, so chiggity check yourselves&#8221;</li>
<li>Some implementations, particularly multi-core, might wake up a cond
var for fucks sake (explicitly allowed by SUSv3</li>
</ul>


<h2>Reentrant revisited</h2>

<p>We already knew thread-safe functions aren&#8217;t necessarily reentrant (e.g.
a signal handler that locks a mutex might be reentered and deadlock the
same mutex on the same thread). A reentrant function is one that doesn&#8217;t
access globals, mutexes included (what if a shared structure, possibly a
mutex is passed on to the function? Deadlock could still occur&#8230; I
guess the answer is that a function might be itself reentrant, but a
caller might not be reentrant so the chain of calls it makes with
whatever global data it&#8217;s using isn&#8217;t going to be reentrant).</p>

<p>Not every function can be reentrant. malloc can&#8217;t be: it <em>must</em> access
global data. A <code>_r</code> suffix implies reentrancy.</p>

<h2><code>pthread_once</code></h2>

<p>The pthreads library provides facilities for ensuring that some kind of
initialization (that occurs in the function you provide it) only happens
once.</p>

<h2>Thread-specific data</h2>

<p>I guess it&#8217;s a thread-local storage, but TLS is an overlay API that&#8217;s
friendlier to program in. In C at least you use the <code>__thread</code> keyword
when declaring a variable and voila you get everything for freeee.</p>

<h2>Thread cancellation</h2>

<p>Threads can be cancelled at cancellation points, SUS-specified
lib/syscall functions, or if you&#8217;re a moron (or you have a 0.001% use
case) you can set cancelability to be async, which means it might
interrupt at any ol machine instruction.</p>

<h2>ncurses</h2>

<p>New curses. Used for writing terminal apps. Cross-terminal. Optimizes
refreshes for our remotely connected friends.</p>

<h2>Thread stacks</h2>

<p>Main thread has mucho size, thread stacks are smaller but configurable
in size.</p>

<h2>Signals and threads</h2>

<p>Horrible combination, avoid when possible. Reason being: signals existed
long before threads and never expected to integrate with them.</p>

<ul>
<li>signal dispositions are process wide (you can&#8217;t have one thread ignore
a signal and another use a specific handler, etc)</li>
<li>signals might be directed to thread or process. Thread directed if

<ul>
<li>signal is result of hardware instruction (SEGV, etc&#8230; same
reason that signals are sometimes synchronous)</li>
<li>SIGPIPE</li>
<li><code>pthread_kill</code> or <code>pthread_sigqueue</code></li>
</ul>
</li>
<li>all others are process wide</li>
<li>kernel selects arbitrary thread to handle signal (as opposed to
multiple threads handling a single sig)</li>
</ul>


<p>Shit. What the fuck is a difference between signal disposition and
signal mask?</p>

<p>Disposition: per-process structure that controls whether a signal
is a) is ignored, b) runs a custom handler, or c) invokes the default
action.</p>

<p>Mask: data structure that knows when signals are temporarily blocked,
the idea being that they should be later unblocked and the signal will
fire.</p>

<p>OK so dispositions are process-wide, but masks are thread-local; so as
one time slice begins, the kernel will look up the mask for that thread
and decide whether a pending signal should fire upon it, and if not,
wait til later. You might have some threads that block all signal
handlers.</p>

<p>Ahhhhhhh SO FUCKING FORGETFUL. Didn&#8217;t I just cover this a few days ago?
Basically I tried writign a ruby program to set the mask, but you don&#8217;t
have access to the mask in Ruby because Ruby uses it internally and is
trying to layer a nice signal API on top of it. I was trying to set up
something where a main thread had a custom handler but all the threads
it spawned blocked SIGINT so that it must be handled by the main thread.</p>

<p>But if I weren&#8217;t too lazy to write the test in C:</p>

<blockquote><p>By manipulating the per-thread signal masks, an application can control which thread(s) may handle a signal that is directed to the whole process.</p></blockquote>

<p>I mostly just wanna know how the kernel selects the thread to wake up.
Does it just loop through each of the sleeping threads and find the one
whose signal mask will allow it?</p>

<p>None of the pthread lib has async-signal-safe functions, so what&#8217;s
recommended:</p>

<ul>
<li>main thread blocks everything, all spawned threads inherit signal mask</li>
<li>single thread deblocks and is responsible for dispatching signals.</li>
</ul>


<p>Reminder: difference b/w reentrant and async-signal-safe:
async-signal-safe is a function you can call in a signal handler because
it as either a) reentrant or b) not interruptible by a signal handler.</p>

<p>So why &#8220;async&#8221;-signal-safe? There are sync signals and async signals
depending on whether hardware issued the signal, whether it&#8217;s a signal
sent to yourself, etc. I think the answer is that async-signal-safe is a
concept that exists even outside of the context of a currently running
signal handler. In other words, if you know <code>foo</code> is NOT async signal
safe, it means <code>foo</code> might be interrupted by an async signal, and if
itself were called, hell might break loose.</p>

<p>So that&#8217;s a useful concept on its own, but when applied to what you&#8217;re
allowed to call within a signal handler, the rule is &#8220;don&#8217;t call non
async-signal-safe functions&#8221; because, within a handler or no, you might
be interrupted by <em>another</em> signal handler and fuck yourself.</p>

<p>So you should always write signal handlers that are themselves reentrant
and only call async-signal-safe functions.</p>

<p>Remember, these async-signal-safe functions might not be reentrant on
their own, but because they block signal handlers from interrupting
them, they are async-signal-safe.</p>

<p><code>exec</code> wipes out all other threads entirely. Gone. No termination /
cancel handlers called.</p>

<p><code>fork</code> kills all other threads than the caller, but mutexes and
conditional variables live on in whatever state. (What about
<code>thread_t</code>s? Probably persist but point to dead threads?). Memory leaks
can happen since the killed threads don&#8217;t have an opportunity to clean
up after themselves.</p>

<p>LOVE.</p>

<p>But you can defined atfork handlers. Otherwise you probably shouldn&#8217;t
fork unless you&#8217;re also <code>exec</code>-ing.</p>

<h2>NPTL</h2>

<p>Native POSIX Threading Lib</p>

<p>The software feature in linux kernel that enabled POSIX-compliant
threads. Red Hat 9 added it first, either as a kernel module or patch to
the OSS kernel.</p>

<h2>Social Engineering</h2>

<pre><code>http://en.wikipedia.org/wiki/Social_engineering_(security)
</code></pre>

<p>It just means sneakily manipulating people into giving away their shit.
Phishing and what not.</p>

<h2>M:N</h2>

<p>aka number of threads map to number of Kernel Scheduling Entities
(processes, threads, etc, schedulable executable things).</p>

<h3>M:1</h3>

<p>Multiple threads to a single KSE. User-level threads aka green threads.
Kernel doesn&#8217;t know about these threads.  Fast context switching, but</p>

<ul>
<li>other slow syscalls block all other threads, e.g. <code>read</code>, since
control is passed from user-spacing threading lib to kernel</li>
<li>kernel can&#8217;t schedule, which means no multi-processor green threads.</li>
</ul>


<p>I&#8217;m guessing the way scheduling worked was to set interval timers and
pre-empty threads. Seems correct.</p>

<h3>1:1</h3>

<p>Kernel-level threads. Pthreads.</p>

<p>Thread creation, context switching, etc, are slower since it requires a
syscall, but it means the kernel can efficiently schedule, put them on
separate cores.</p>

<h3>M:N</h3>

<p>Some kernel, some green.</p>

<p>Keep in mind that this whole <code>M:N</code> nomenclature also applies to
processes vs threads. err, does it? Processes and green threads? I could
be bullsharting right now.</p>

<p>M:N is complex, perhaps not worth it. It was originally the suggested
implementation for NPTL.</p>

<h2>Process Group / Session</h2>

<ul>
<li>Process group

<ul>
<li>Process group leader

<ul>
<li>Process that creates the group, whose PID becomes the process group
ID</li>
</ul>
</li>
<li>New process inherits its parent&#8217;s pgid</li>
<li>Lifetime: from process group creation to when last process leaves
group id</li>
<li>premature question: can a new process take the id of a now-dead
process that used to be pg leader?</li>
<li>processes can leave by terminating or joining another group</li>
<li>pg leader can leave before others, no biggie.</li>
</ul>
</li>
<li>Session

<ul>
<li>collection of PGs</li>
<li>Session leader

<ul>
<li>Process that creates the session, whose PID becomes the session ID</li>
</ul>
</li>
<li>New process inherits its parent&#8217;s pgid</li>
<li>all processes in session share terminal</li>
</ul>
</li>
</ul>


<p>SIGHUP is sent to PG leader when terminal disconnects.</p>

<p>Login:</p>

<ul>
<li>Shell becomes session leader AND process group leader

<ul>
<li>every command it runs, it makes it process group leader (but shell
remains session leader)</li>
<li>any command forks have same process group id (the command&#8217;s pid),
and session id is shell.</li>
<li>shell can create many process groups (commands) and can foreground
one and the rest are background</li>
</ul>
</li>
</ul>


<p>You can only change process group of yourself or your children, else
ESRCH. You can only move a process between groups within the same
session. You can&#8217;t change the process group of the session leader.
You can&#8217;t child the process group of a child if it&#8217;s already called
<code>exec</code> (you might confuse the poor child); I guess this means shells
will fork and then the parent will call setpgid on the child&#8230;? Why
doesn&#8217;t the child just do it itself?</p>

<p>Answer (and I love this book for this shit: go buy the Linux Programming
Interface right now): the parent process needs to be able to send job
control signals to the newly created child (to the new process group
ID it&#8217;ll have), and the child needs to set the new pgid before it
<code>exec</code>s or else all is lost, so how do you guarantee that the new process
group on the child has been set before either the parent or child
proceed? Answer: do it on both and ignore errors on the parent.</p>

<p><code>setsid</code> establishes a process as group and session leader and
disconnects it from any controlling terminal. You can&#8217;t <code>setsid</code> if
you&#8217;re process group leader (EPERM), so you need to <code>fork</code> first to get around
that. This restriction is in place because any other process group
children will still have a pgid that points to this same process group
leader process even if it has a new session id; the only way to ensure
the numbers don&#8217;t point to the same place is to distribute new numbers,
e.g. new process ids, e.g by forking.</p>

<pre><code>if fork
  Process.wait
  puts "done"
else
  # if you hadn't forked, setsid would fail because
  # this process would be PG leader
  Process.setsid
  puts gets
end
</code></pre>

<p>The above code doesn&#8217;t error out like I thought it would&#8230; it still has
access to the terminal, but, it, umm, couldn&#8217;t open the terminal if it
wanted to?</p>

<p>When session leader opens a controlling terminal, it becomes the
controlling process for a terminal. They are LINKED. If a process
has a controlling terminal, it can open special file <code>/dev/tty</code>.</p>

<p>Ah ok so to make the above snippet break, I should have actually done</p>

<pre><code>fork do
  Process.setsid
  File.open('/dev/tty')
end
Process.wait
</code></pre>

<p>which yields</p>

<pre><code>setsid.rb:3:in `initialize': Device not configured - /dev/tty (Errno::ENXIO)
</code></pre>

<p>You open <code>/dev/tty</code> if the shell (or someone else) already redirected
your output (by <code>dup2</code>ing 0 1 2 file descriptors) and you want to get
back in touch with your <code>tty</code>. Call your <code>tty</code>. She&#8217;s your controlling
terminal.</p>

<p>AH HA this is how you can take a program with redirected input and get,
say, the users password from the terminal. Fuckin badass. Let&#8217;s try it.</p>

<pre><code>$ echo "wat" | ruby getpass.rb
here's some stuff from stdin
wat
now type something in: borflex
You wrote borflex
</code></pre>

<p>So many cool shits!</p>

<p>Note that you can also open <code>/dev/tty</code> without it becoming the
controlling terminal.</p>

<p>TTY captures special characters, converts into signals sent to members
of the foreground process group.</p>

<p>This demonstrates how a signal is delivered to literally everyone in the
foreground process group (5 &#8220;omg&#8221;s are printed).</p>

<pre><code>N = 5
N.times do
  fork do
    trap(:INT) do
      puts "omg\n"
      exit
    end
    sleep
  end
end

trap(:INT) do
  puts "main\n"
end

N.times do
  Process.wait
end
</code></pre>

<p>It&#8217;s possible for no one to be the foreground process, but rare, and not
when there&#8217;s a shell that&#8217;s monitoring for foreground process to quit
(via wait or some other signal handle).</p>

<p><code>tcgetpgrp</code> gets the foreground process group of a provided terminal fd.
<code>bash</code> and other shells make use of this when passing the terminal
around to child processes.</p>

<h2>SIGHUP</h2>

<p>This is sent when terminal connection is severed (also sends SIGCONT to
make sure the process is alive). Happens when:</p>

<ul>
<li>terminal driver detects disconnect of one form or another</li>
<li>the last pseudoterminal file handle has been closed (i don&#8217;t
understand this)</li>
</ul>


<p>You can ignore / handle SIGHUP but future reads yield EOF. (What about
output? Same thang?).</p>

<p>SIGHUP is often used to tell a daemon process to reload a config file.
Why SIGHUP? Because daemons have no controlling terminal so the single
is otherwise useless; why not put it to work in some useful way? nginx
and others do this.</p>

<p>When terminal disconnects, the controlling process (the shell) gets a
SIGHUP. Shells will terminate, but before doing that they&#8217;ll send a
SIGHUP to each of the process groups.</p>

<p><code>nohup</code> just forks, sets disposition to ignore HUP, and then <code>exec</code>s.
Easy peasy.</p>

<p>Note that shells won&#8217;t send SIGHUP to any process groups it didn&#8217;t
create.</p>

<pre><code>echo $$
</code></pre>

<p>This is like the thing that trolled me before w <code>ruby -e</code>&#8230; <code>$$</code> in a
shell command is the shell&#8217;s pid.</p>

<p>Background tasks don&#8217;t get sighup&#8217;d when you exit a terminal. SIGHUP
only gets sent to foreground processes. That seems cray cray.</p>

<h2>$$ in Ruby</h2>

<p>Everywhere I look it says it is the id of the running process. As in,
you know, the pid. But if I do</p>

<pre><code>ruby -e "puts Process.pid; puts $$"
</code></pre>

<p>I get two different numbers.</p>

<p>You know why?</p>

<p>Because, of course, <code>$$</code> means something to shells! Before the command
even runs, <code>$$</code> will be substituted with the pid of the shell! If I
change double quotes to single quotes, I get the same numbers, of
course!</p>

<pre><code>ruby -e 'puts Process.pid; puts $$'
</code></pre>

<p>This is why I started going crazy and thinking that the internet was
just wrong and that <code>$$</code> means the session id. Wrong!</p>

<h2>terminfo / termcap</h2>

<p>These are packages that some programs like vi and less make use of for
gracefully switching in and out of screen-controlling modes; vi and less
take over the screen but when you quit, you see the terminal lines from
before you ran them. This uses terminfo, which is a terminal database
which provides facilities such as that.</p>

<h2>sigtstp</h2>

<p>You can catch a suspend ^Z via sigtstp and then signal sigstop to
actually stop the process, but any parent processes listening in will
think you were stopped by sigstop rather than sigtstp, so you can do the
more complicated thing of setting disposition to default, unblocking,
raising tstp (so that it suspends this time), and then resetting the
mask upon reentry.</p>

<h2><code>init</code> and <code>wait</code></h2>

<p>I originally thought that <code>init</code> would <code>wait</code> on every orphan it
inherited, but of course, <code>wait</code> is blocking if nothing&#8217;s actually
terminated, so I think <code>init</code> actually checks the status of the
process and <code>wait</code>s only if it&#8217;s terminated. But if it inherits a
stopped process group, it won&#8217;t call wait. So you might have stopped
process groups that live on forever and no one ever terminates them.</p>

<p>Hence, upon orphaning, the kernel sends SIGHUP + SIGCONT to any
orphaning process groups that have at least one stopped process, and
these signals are sent to everyone. Of course, at some later
post-orphaning time, these orphaned processes might be stopped and would
need <em>something</em> to come along and resume or terminate them.</p>

<h2>nice values</h2>

<p>You can give processes (specific pids, groups&#8217;, users&#8217;) varying nice
values from -20 to 19, give or take. Lower means higher priority, high
means lower.</p>

<h2>The Complexity Balloon and other yehudaisms</h2>

<blockquote><p>&#8220;you can only squeeze the complexity ballooon&#8221;
- Yehuda Katz</p></blockquote>

<p>On XMLHttpRequest capitalization:</p>

<pre><code>btw: the rule for XHR is:
First acronym all caps
subsequent acronyms title-case
old Java rule
</code></pre>

<h2>Security book recommendations</h2>

<p>The art of software security assessment</p>

<p>The grey hat hackers handbook</p>

<h2>Scheduling</h2>

<p>CPUs have their own run queues, with items with different priorities.
Processes can be scheduled with RR or FIFO real-time policy.</p>

<p><code>RR</code> is round robin. Equal priority processes get a time slice and then
get thrown in back of queue at the end. They can be pre-empted by higher
order shits. How?</p>

<ul>
<li>higher order process blocked on syscall becomes unblocked (io
available, etc)</li>
<li>another process raised to higher level</li>
<li>current process raised to lower value than some other process</li>
</ul>


<p><code>RR</code> similar to standard RR <code>SCHED_OTHER</code>, difference being in the
strictness of the weighting algorithm. <code>SCHED_OTHER</code> uses nice values,
but a lower nice value than another isn&#8217;t a strict determiner of
scheduling order, but rather a weighted suggestion, where as <code>RR</code> is
brutal deterministic.</p>

<p>In <code>FIFO</code> there&#8217;s no timeslice. You have it til you&#8217;re preempted or give
up control.</p>

<p>You can lock up a system with <code>RR</code> or <code>FIFO</code>. To prevent:</p>

<ul>
<li>set low CPU limit, which causes default-terminating <code>SIGXCPU</code> to fire.</li>
<li>use <code>alarm()</code></li>
<li>use high priority watchdog process to watch others, adjust their
priorities.</li>
</ul>


<p>CPU Affinity just means the tendency for a process/thread/kernel
scheduling unit to run on the same CPU; switching CPUs involves a slow
context switch, cache invalidation, etc.</p>

<h2>Daemonizing</h2>

<ul>
<li>long-running, often started at boot</li>
<li>has no controlling terminal (hence never receives INT, TSTP, HUP,
etc); its excluded from job-control signals</li>
</ul>


<p>some examples</p>

<ul>
<li>cron</li>
<li>sshd: the ssh server that&#8217;s open for remote logins.</li>
<li>httpd: http server

<ul>
<li>ah so TCP isn&#8217;t a daemon, it&#8217;s a kernel-level IO protocol, but httpd
is a server. It&#8217;s apache, duerp.</li>
</ul>
</li>
<li>inetd: superserver daemon&#8230;? sounds like this doesn&#8217;t exist on mac.</li>
</ul>


<p>Some daemons run as kernel threads, w names bracketed.</p>

<p>To daemonize:</p>

<ul>
<li>fork: child process lives, master terminates.

<ul>
<li>returns control to terminal</li>
<li>child process lives on, and is no longer process group leader (it
inherits parent pgid which doesn&#8217;t match its new pid, so it can&#8217;t be
leader). this is needed for setsid (remember that setsid can&#8217;t be
called with process group leader, because other children processes
might be in that process group with a pgid pointing to a process
that lives in a different session, but process group members must
all live within the same session as a rule)</li>
</ul>
</li>
<li>setsid

<ul>
<li>become session leader

<ul>
<li>frees you from connected terminal</li>
<li>allows you to connect to another terminal (but&#8230; see below)</li>
</ul>
</li>
</ul>
</li>
<li>fork again

<ul>
<li>this prevents any future terminals you connect to from becoming
controlling terminal (TODO: why/when would a daemon connect to a
terminal?)</li>
<li>you don&#8217;t have to do this if you don&#8217;t open another terminal, or you
open terminals with <code>O_NOCTTY</code></li>
</ul>
</li>
<li>Clear umask (remember that umasks negate certain permissions on create
files&#8230; right? TODO: review this shit)</li>
<li>Change cwd to <code>/</code> so that in case the process was started with a cwd
on another file system that doesn&#8217;t contain <code>/</code>, that fs can be
unmounted

<ul>
<li>remember you can&#8217;t unmount &#8220;busy&#8221; FSs

<ul>
<li>files are open on it</li>
<li>processes have CWDs on it (how does it know? loop through the
processes?)</li>
</ul>
</li>
</ul>
</li>
<li>Close all file descriptors, 0, 1, 2, for similar busy FD unmount
reasons, also because you might get some TTOUs if you try and read
from stdin.</li>
<li><code>dup2</code> them to point to <code>/dev/null</code> so that lib functions and other
things don&#8217;t unexpectedly file, or you don&#8217;t open another file in
their place but some lib function things they&#8217;re std IO and then write
shit to them

<ul>
<li>reading dev null yields EOF. PRETTY EFFIN HANDY</li>
</ul>
</li>
</ul>


<p>Daemon shutdown consists of SIGTERM and a 5-second-layer SIGKILL if it
doesn&#8217;t clean up and shut down in that time (all processes concurrently
have 5 seconds to shutdown, not 5 seconds of CPU each; all SIGTERMS send
out at same time).</p>

<p>Memory leaks and fd leaks are a bigger deal for daemons since they&#8217;re so
long-lived.</p>

<p>Care must be taken to prevent multiple identical daemons from running;
Pidfiles help.</p>

<p>Logfiles can&#8217;t grow forever, and manually deleting a file if the daemon
doesn&#8217;t let go of it won&#8217;t prevent the resources from being freed until
the last handle is closed to the file. <code>logrotate()</code> can be used to aid
in this.</p>

<p>HUP is unused since daemons don&#8217;t have controlling terminals so people
classically use it to re-initialize or reload conf files.</p>

<p>Btw you can open other people&#8217;s TTYs. And it means you can write to
their screens.</p>

<p><code>syslog</code> and <code>syslogd</code> is a useful utility to global logging; write to
syslog unix domain datagram socket and blah dee blah dee blah it&#8217;ll
funnel out to wherever based on a shared conf FILE!</p>

<h2>Security</h2>

<p>Privilege via</p>

<ul>
<li>root started it</li>
<li>set-user-id or set-group-id + owned by root</li>
</ul>


<p>Guidelines:</p>

<ul>
<li>don&#8217;t use set-user/group-id unless you really need it; better to
use a child process

<ul>
<li>or if you need it, don&#8217;t give it root</li>
</ul>
</li>
<li>e.g. a process currently with set-user-id that allows unprivileged
users to write to a file they don&#8217;t have access to: much better to
set-group-id to a group specific to this process, and set group of
that file to that group. group. group. group.</li>
<li>if you&#8217;re set-user-id, only operate in that mode when you need it.</li>
<li>real id is whoever started the program</li>
<li>basically, shit is really hard and you should refer to this book every
time you need a refresher because this stuff megasucks.</li>
<li>don&#8217;t exec shells or other interpreters when you have privileges. Way
way way too open to abuse.</li>
<li>close file handlers; they&#8217;re just integers, not hard to reuse. recall
CLOEXEC</li>
</ul>


<h2>Clear out your memory</h2>

<p>Why? Because it might be paged out to a swap area that privileged
programs can read. So that seems pretty iScare. If that&#8217;s visible, why
not fuckin, fuckin, fuckin memory, man, why can&#8217;t you like open another
process and look at its memory maaaan, even without it having been paged
first.</p>

<p>Actually you can if you&#8217;re not careful. You can create special device
files that have direct access to RAM. That&#8217;s so fucking crazy. So even
<code>chroot</code> can&#8217;t even save you if you have a set-user-id-root program.
Crazy crazy crazy.</p>

<p>Also if you have a leftover open file handle to <code>/</code> then you can
<code>fchdir</code> into it and <code>chroot(".")</code> chroot back into that shiot.</p>

<h2>Use capabilities</h2>

<p>UNIX privileges are all-or-nothing; Linux adds the notion of
capabilities. Use em. They&#8217;re granular n shit.</p>

<h2>Use virtual kernels</h2>

<p>Totally isolated. They have no concept of the raw kernel. Can&#8217;t access
it. Can&#8217;t do shiot.</p>

<p>BSD <code>jail()</code> addresses lots of this stuff. SO MANY FUCKING LOOP HOLES OH
MY GOD.</p>

<h2>Time of check, time of use</h2>

<p><code>access()</code> lets you query access of user to file. If you&#8217;re
set-id-to-root and you check if some unprivileged user has access to
something, maybe a symlink, and then in between that check and whatever
you end up destructively doing, the symlink is swapped to elsewhere,
then you might clobber some shittles. Malicious user could go nutso and
fire off a bunch of <code>SIGSTOP</code>s and change runtime environment to fuck
with a privileged program.</p>

<h2>Bounds checking</h2>

<p>strcpy babeh</p>

<p>Linux now has stack address randomization which randomizes the location
of the stack in an 8 MB range in VM. Seems cool. That&#8217;s why if you print
the pointer of a var int main in a test C program, it&#8217;s different each
run. This feels similar to stretches in bcrypt and any other security
measure that makes certain operations slower to counteract brute force
attackers.</p>

<h2>DoS denial of service</h2>

<p>Local variants include fork bombing.</p>

<p>Remote DoS more common, combat w:</p>

<ul>
<li>load throttling, dropping requests when overloaded</li>
<li>timeouts</li>
<li>(throttled) logging of overloads</li>
<li>don&#8217;t crash from unexpected loads</li>
<li>avoid algorithmic complexity attacks wherein a structure known to
handle a particular series of input might get fucked and consume lots
of resources. Not insecure, necessarily, but might fuck the fuck.</li>
</ul>


<h2>Shared libs</h2>

<p>Compile w <code>-g</code> nowadays since RAM and disk are cheap. Apparently this
info doesn&#8217;t affect performance?</p>

<p>A shared lib is a <code>.a</code> file composed of <code>.o</code> files, constructed with
<code>ar</code>, as in &#8220;library archives&#8221;.</p>

<pre><code>$ ar tv /usr/lib/liby.a
rw-r--r--       0/0            40 Aug 24 21:45 2013 __.SYMDEF SORTED
rw-r--r--       0/0           920 Aug 24 21:45 2013 main.o
rw-r--r--       0/0           912 Aug 24 21:45 2013 yyerror.o
</code></pre>

<p>Variants of <code>gcc</code> and static libs</p>

<pre><code># generate wat.o
gcc -c wat.c

# generate a.out with wat.o lib
gcc lol.c wat.o otherlibarchive.a

# search standard lib directories (like /usr/lib)
# looks for /usr/lib/libwoot.a
gcc -c wat.c -lwoot

# Search a non-standard directory
gcc -c wat.c -lwoot -L/borflex/snaggletooth
</code></pre>

<p>All of the .a archive and .o object files is added to executable size.
Seems bad. Also when the processes are run, VM is increased by that
much, even though it&#8217;s all redundant read-only text shit.</p>

<p>Ah. Static libs. vs Shared libs. Shared libs are fuckin, fuckin,
dynamic, maaaan.</p>

<p>Ah note that static and global variables obviously aren&#8217;t shared between
shared libs; each process gets a copy.</p>

<p>Pros:</p>

<ul>
<li>Large shared libs between small processes mean quicker process startup
time (though the first time the shared lib is loaded into VM is
obviously slow)</li>
<li>With some limitations, you can swap out libs without relinking</li>
</ul>


<p>Cons:</p>

<ul>
<li>complexity</li>
<li>shared libs must use position-independent code

<ul>
<li>PIC is a way of compiling shared libs so that the location of
functions, statics, globals, string constants, etc, can vary, and I
don&#8217;t understand it.</li>
</ul>
</li>
</ul>


<p>Modern shared lib linking format is ELF: Executable and Linking Format.</p>

<p><code>.so</code> is shared object, shared lib, as opposed to just <code>.o</code>.</p>

<p><code>ar</code> lets you add/remove <code>.o</code>s from library archives, but not so with
<code>.so</code>s.</p>

<p>You can use <code>nm</code> (name list util, i.e. symbol table util) to list
symbols.</p>

<p>Interesting, so given the following <code>wat.c</code>:</p>

<pre><code>int WAT;
</code></pre>

<p>I see <code>_WAT</code> appear in the symbol table:</p>

<pre><code>$ gcc -c wat.c &amp;&amp; nm wat.o
0000000000000004 C _WAT
</code></pre>

<p>Note that it wouldn&#8217;t appear if I&#8217;d made it <code>static</code> or <code>extern</code>. Shit
is cool.</p>

<p>So PIC adds a global offset table to help the dynamic linking describe
where shit is.</p>

<p>Hmm what if I use <code>g++</code> on a cpp file?</p>

<pre><code>$ g++ -c wat.cpp &amp;&amp; nm wat.o
0000000000000000 S _WAT
</code></pre>

<p>What&#8217;s the difference b/w S and C? C apparently means &#8220;common&#8221; symbol,
and S means a generic &#8220;none of the above&#8221; in the <code>man nm</code>.</p>

<p>You can take a dynamic/shared lib and compile statically though, if you
want it:</p>

<ul>
<li>less complexity</li>
<li>safer against .so upgrades</li>
</ul>


<p>So what&#8217;s the difference between a .so and a .dylib? Is that a mac
thing?</p>

<h2>Dynamically loaded libraries</h2>

<p>Deferred loading whenever some plugin is loaded. As in your code does
it. Seems pretty rad. Use <code>dlopen</code>. Search a function by name, invoke
it.</p>

<p>You can use env var <code>LD_DEBUG</code> to print out some shit.</p>

<h2>IPC</h2>

<ul>
<li>byte streams: pipes, fifos, datagram sockets</li>
<li>message: message queues; can&#8217;t read them part way, all or nothing</li>
<li>pseudoterminals</li>
</ul>


<p>Different from shared mem:</p>

<ul>
<li>reads are destructive for byte streams (but yes in some cases you can
seek, multicast/broadcast)</li>
</ul>


<p>MQ (POSIX or SystemV) messages have priorities, and deliver in different
order.</p>

<p>Ah now it&#8217;s coming back to me:</p>

<ul>
<li>UNIX domain sockets

<ul>
<li>ruby: <code>Socket.pair</code></li>
<li>datagram (no need to worry about byte streams/delimiters)</li>
</ul>
</li>
<li>Pipe

<ul>
<li>ruby: <code>IO.pipe</code></li>
<li>stream</li>
<li>flow control handled by kernel</li>
</ul>
</li>
</ul>


<h2>Pipes and FIFOs</h2>

<p>Pipes are old as SHIT. Oldest method of IPC, since 3rd edition of UNIX
in early 1970s.</p>

<p>THAT&#8217;s what that dude meant. Pipes vs Sockets. We use pipes, not
sockets.</p>

<p>Pipes are constrained to related processes, FIFOs can talk between all
processes.</p>

<p>Pipes are unidirectional.</p>

<p>Can&#8217;t reorder data, can&#8217;t random access w lseek.</p>

<p>Writes up to <code>PIPE_BUF</code> are atomic, Linux has <code>PIPE_BUF</code> at 4096. If
larger, kernel might break into pieces. This means that if you have two
processes writing more than <code>PIPE_BUF</code>, the final stream might be
interleaved with both messages (both processes will still be blocked on
<code>write</code> until everything is flushed out).</p>

<p>Partial writes can occur if a write larger than <code>PIPE_BUF</code> is
interrupted by a signal handler, and call comes back with the number of
bytes written. Pretty cool. Makes sense.</p>

<p>Writes will block if kernel buffer is full.</p>

<p>Pipes only work b/w related processes, which mean they must have a
common fork ancestor. Apparently there&#8217;s another way to pass file
descriptors. But I guess it&#8217;d need translating? Because there are
descriptors and open file descriptions, and the descriptor ints are
different between shits.</p>

<p>SIGPIPE is ignored by default, but when you write to broken pipe you get
SIGPIPE and EPIPE. Such pipe.</p>

<p><code>popen</code> runs a shell command, letting you establish a single pipe,
either r or w.</p>

<p>FIFOs are like pipes except that they&#8217;re special files in th file
system. Opening a read-only FIFO blocks until someone writes, and vice
versa.</p>

<p><code>tee(1)</code> writes to stdio AND some other file, which could be a fifo. So
you can split a stream and send it to other things. Pretty cool.</p>

<p>UNRELATED: <code>bash -c "sleep 5"</code> execs sleep 5; it doesn&#8217;t create a bash
process and then fork again, it just straight up execs. Whereas when
you&#8217;re running interactive bash, all commands are forked and then
exec&#8217;d.</p>

<p>Trick with IPC w servers is that there needs to be some known file name,
which opens the door to exploitation if you&#8217;re not careful.
FIFOs (and pipes) are byte streams (rather than unix domain datagram
sockets) so you have to</p>

<ol>
<li>Use some EOM delimiter</li>
<li>Message length header</li>
<li>Fixed message size</li>
</ol>


<p>and on top of all of that everything needs to be less than the pipe
buffer size constant or else kernel might interleave messages.</p>

<p>Pipes provide synchronization by e.g. opening a pipe, forking, having
the parent blocked on a <code>read()</code> until child processes have all done
their shit and closed their end of the pipe.</p>

<p><code>popen</code> has the same considerations as <code>system</code>.</p>

<h2>System V</h2>

<p>http://en.wikipedia.org/wiki/UNIX_System_V</p>

<p>One of first commercial versions of UNIX, from 1983. Today&#8217;s descendants
are AIX, Solaris, and HP-UX.</p>

<p>System V IPC</p>

<ul>
<li>MQs

<ul>
<li>delivered in order, but each message has type, so can be selected
out of order</li>
</ul>
</li>
<li>Semaphores

<ul>
<li>kernel forbids it from going below 0, sync technique</li>
</ul>
</li>
<li>Shared mem</li>
</ul>


<p>w System V IPC you create objects (like files but unlike files). Objects
have ids, but unlike fd&#8217;s, these are system wide.</p>

<p>Semaphores don&#8217;t error when you subtract below zero; rather the kernel
will block if you try and subtract, and it&#8217;ll come back alive when
someone increments.</p>

<h2>Considered Harmful</h2>

<p>http://en.wikipedia.org/wiki/Considered_harmful</p>

<p>Popular phrase originating from &#8220;Go To Statement Considered Harmful&#8221;, a
Djikstra thing.</p>

<h2>mmap</h2>

<p>Memory mapping can either use</p>

<ul>
<li>real files</li>
<li>anonymous zero-d out files</li>
</ul>


<p>Both are shareable between processes. By:</p>

<ul>
<li>mmapping to the same region of the same file</li>
<li>forking with a previously established handle to a</li>
</ul>


<p>Mapping to same file can be configured:</p>

<ul>
<li>private: writes don&#8217;t go through to file, so process changes to the
mapping are isolated from each other. Implemented by copy-on-write.</li>
<li>shared: durp</li>
</ul>


<h2>dev zero</h2>

<p><code>/dev/zero</code> gives you null bytes. Forever!</p>

<h2>dev urandom</h2>

<p>Write seeds, read values.</p>

<p>This isn&#8217;t perfect but kinda works:</p>

<pre><code>ruby -e 'puts File.open("/dev/urandom").gets(4).unpack("l")'
</code></pre>

<p>Extra credit if you can figure out what that ain&#8217;t right</p>

<h2>Get off the aaaaaaair I&#8217;m in the STEREO</h2>

<p><code>mmap</code> can overcommit swap space due to lazy committal. Useful for
implementing things like sparse arrays (a large array might only access
bits and pieces, and if separate by a page.</p>

<pre><code>$ getconf PAGESIZE
4096
</code></pre>

<p>Daatz cool. So if you have a bajillion thingeroo and it&#8217;s allocated on a
shit, then woooop there it is.</p>

<p>Overcommitals can ran the system out of memory at which point the kernel
starts killin&#8217; shit. The kernel code that does this is the OOM
Out-of-Memory killer.</p>

<p>OOM kills with <code>SIGKILL</code>, you can look at your score with a special file
in procfs.</p>

<h2>dscacheutil</h2>

<p>Directory Service Cache Utility. Supercedes <code>lookupd</code>.</p>

<h2>VM operations</h2>

<ul>
<li>protect: set read/write protections on a VM page

<ul>
<li>applies to mmapped files, etc</li>
</ul>
</li>
<li>mlock and mlockall: keep memory in RAM; useful since an attack vector
would be to consume lots of RAM, forcing some processes to write to
disk, and then reading from the swap space.

<ul>
<li>then again, suspend mode in laptops/desktops copied ram to disk, so
you&#8217;re effed.</li>
</ul>
</li>
</ul>


<h2>traceroute UDP vs ICMP</h2>

<p>This doesn&#8217;t work</p>

<pre><code>traceroute machty.com
</code></pre>

<p>This does</p>

<pre><code>traceroute -I machty.com
</code></pre>

<p>because it uses ICMP ECHO rather than a UDP packet (which I guess gets
dropped somewhere along the way? tis a Rackspace github pages HTTP
server so UDP wouldn&#8217;t make sense anyway), and ICMP ECHOs I guess are
considered more sensible and friendly?</p>

<p>I realized this was the issue since <code>ping machty.com</code>, which uses ICMP
ECHO, works just fine.</p>

<h2>Power of Attorney</h2>

<p>Written authorized permission for one person to act on behalf of
another, even if the other disagrees. Relevant in the legal sense, as
well as health care decisions up to and including terminating care and
life support.</p>

<h2>Darwin, Mach, OS X</h2>

<p><a href="http://en.wikipedia.org/wiki/Darwin_(operating_system">Darwin wiki</a>)</p>

<p>Darwin is an an open source operating system released by Apple in 2000</p>

<ul>
<li>Composed of NeXSTEP, BSD, other freeware</li>
<li>Largely compatible with POSIX but not certified.</li>
<li>SUSv3-compatible</li>
<li>Kernel is XNU

<ul>
<li>&#8220;X is Not Unix&#8221; - stupidest naming scheme ever</li>
<li>Hybrid kernel

<ul>
<li>Combo of micro and monolithic: http://en.wikipedia.org/wiki/Hybrid_kernel</li>
<li>Micro kernels are often &lt; 10,000 lines of code, do the bare
minimum, put more things into user space (or at least a higher
privilege ring)</li>
<li>Linus thinks hybrid is just monolithic and that it&#8217;s all just
marketing</li>
</ul>
</li>
<li>Combo of Mach (microkernel) + aspects of BSD (monolithic kernel)</li>
</ul>
</li>
<li>Closed source Cocoa et al frameworks are missing, so it can&#8217;t run mac
applications</li>
</ul>


<p>http://en.wikipedia.org/wiki/Microkernel</p>

<p>So I guess OS X is Darwin + Cocoa and a bunch of other layers.</p>

<h2>POSIX IPC</h2>

<ul>
<li>Simular to System V</li>
<li>API closer to classic UNIX everything-is-a-file abstraction</li>
<li>Simpler API in general</li>
</ul>


<h2>Semaphores: portable?</h2>

<p>Does anyone use operating system semaphores in open source? I mostly see
sockets and forking and what not for IPC in server code; does anyone
use semaphores?</p>

<p>Answer: yes, libuv does (the async IO lib that Node uses). I&#8217;m sure
plenty of other people do too.</p>

<h2>Node copies in all dependencies</h2>

<p>The Node repo doesn&#8217;t use submodules or anything like that; literally
the entire codebase of a dependency, whether v8 or libuv, is copied into
the <code>/deps</code> folder.</p>

<h2>WATCHLISTS</h2>

<p>Something to Chromium devs use that mark certain portions of code as of
interest to some reviewer, presumably to prevent undesirables from
getting into the system.</p>

<p>https://github.com/joyent/node/blob/master/deps/v8/WATCHLISTS</p>

<h2>File locking</h2>

<p>Used for synchronization. Could use semaphores but the kernel already
has file locking so why not use that for files?</p>

<p>stdio lib might cause issues with buffers and locks, so either follow
some rules about immediately flushing, or just skip stdio and use <code>read</code>
and <code>write</code>, or disable the buffering.</p>

<p>Locks apply to open file descriptions (in the shared open file table in
the kernel), not descriptors, so if you dup the descriptor and
explicitly unlock it, it applies to all duplicates (it doesn&#8217;t maintain
a count or anything).</p>

<p>You can only hold a lock associated with an fd. So if all fds are
closed, the lock is unlocked.</p>

<p>If you fork a lock, then it only takes one unlock (parent or child) to
release the lock. Wacky shiznittletons. But this lends to the pattern of
&#8220;parent establishes lock, forks, and closes file descriptor so that only
the child has the lock and open fd&#8221;.</p>

<p>Locks are preserved across exec unless close-on-exec on the fd and the
fd was the last one associated with the description.</p>

<p><code>flock()</code> downsides:</p>

<ul>
<li>only whole files lockable, hamper concurrency if processes would be
otherwise able to write to the same file in separate sections</li>
<li>can only place advisory locks.

<ul>
<li>advisory locks mean the kernel doesn&#8217;t actually help prevent
reads/writes; processes could ignore advisory locks and perform IO
anyway. Mandatory locks on the other hand&#8230;</li>
</ul>
</li>
</ul>


<h2>Record locking with fcntl</h2>

<p><code>fcntl</code> allows record-locking: locking anywhere from a byte to whole
file. &#8220;record-locking&#8221; might be the wrong word since files are just byte
streams with no concept of &#8220;records&#8221; beyond what their consuming
processes decide.</p>

<p><code>fcntl</code> just stands for &#8220;file control&#8221;. I get it confused with <code>ioctl</code>.
<code>fcntl</code> is control over descriptors in a process. Basically <code>fcntl</code>
behaves almost like a kernel sys call in that it&#8217;s just setting an
integer of the command you want to perform followed by varying numbers
of arguments based on the command. So you can do arbtrary, extensible
stuff that might not already be neatly contained within some other
single purpose wrapper fn.</p>

<p>SUSv3 requires record locking for regular files and permits record
locking for other file types even if it doesn&#8217;t really make sense.</p>

<p>Write locks are exclusive (to both read and write locks). Read locks
are not (they can be shared). Nothing new here.</p>

<p><code>fcntl</code> locking works by passing <code>flock</code> structure. You can lock
relative to current file pointer.</p>

<p><code>BADF</code> if you try and read/write lock a file on a file not open for
reading/writing.</p>

<p><code>len</code> of 0 means lock from whence onward (even if bytes are added to the
file).</p>

<ul>
<li>Unlocking always immediately succeeds.</li>
<li>different sections can be locked with different types</li>
<li>locks can be split by e.g. placing a write lock in the middle of a
larger range of read locks (3 locked regions are produced)</li>
</ul>


<p>The kernel prevents deadlocks between processes. (Similar rules apply
with thread mutexes). Chooses one of the processes and unblocks fcntl
with errno <code>EDEADLK</code>. Even circular deadlocks are detected. Pretty cool.</p>

<p>fcntl locking semantics:</p>

<ul>
<li>locks not inherited cross fork()</li>
<li>locks are inherited</li>
<li>threads share record locks</li>
<li>Record locks are pid+inodenum, so, weirdly, if you close an fd, all of
its locks are released, even if they came from other fds. Kind of
crazy? (This is architectural weak sauce; should have been file
handler rather than inode, but it&#8217;s now standardized).</li>
</ul>


<h2>Mandatory Locking</h2>

<p>File system must be mounted with mandatory locking enabled. And it must
be enabled on a per-file basis by enabling set-group-id and disabling
group execute permission. This yields a capital S in <code>ls -l</code> if you&#8217;ve
done it right.</p>

<ul>
<li>most file systems support it, cept for things like VFAT which don&#8217;t
have the required permission bits</li>
<li>locked file can still be deleted</li>
<li>privileges processes can&#8217;t override a mandatory lock. A malicious user
holding on to a well known public file is a form of DOS attack.</li>
<li>mandatory locks has performance hit against IO</li>
</ul>


<p>Probably best avoided?</p>

<p>tmpfs <code>/proc/locks</code> is useful.</p>

<h2>Pidfile</h2>

<p>Create a file and place write lock on it. Any other instances will try
and do the same thing, fail, and terminate under the assumption that a
running process already has a lock on it. Alternate approaches for
networked apps use bound ports to make this same decision.</p>

<p>Often such things live in <code>/var/run</code>. Conventional to write pid to file
and use extension <code>.pid</code>.</p>

<p>You can CLOEXEC a pidfile since some servers reinitialize themselves by
<code>exec</code>ing themselves. Seems crazy?</p>

<h2>Sockets</h2>

<ul>
<li>exist in communication domain

<ul>
<li>determines how socket is identified (form of &#8220;address&#8221;)</li>
<li>range of communication (intra-computer, internet, etc)</li>
</ul>
</li>
<li>Multiple domains of sockets

<ul>
<li>UNIX domain: <code>AF_UNIX</code>. Communication b/w processes on same host
(all within the kernel)</li>
<li>IP (v4 and v6)</li>
</ul>
</li>
</ul>


<p><code>PF_UNIX</code> vs <code>AF_UNIX</code> constants: Protocol Family vs Address Family:
often synonomous, but different due to intent to support protocols
having multiple families of addresses, but this hasn&#8217;t happened.</p>

<p>Every socket impl can be stream or datagram oriented.</p>

<p>Stream socket
- &#8220;reliable&#8221;&#8230;? UNIX Domain streaming sockets? Curious to know what the overlap is with TCP.
- bi-directional, as if a pair of pipes had been established.</p>

<h3>socket()</h3>

<p>Create a socket with</p>

<ul>
<li>domain: UNIX, IPv4, IPv6</li>
<li>type: STREAM vs DATAGRAM</li>
<li>protocol (usually 0 unless you&#8217;re doing funky things with raw sockets</li>
</ul>


<h3>bind()</h3>

<ul>
<li>Binds to an address / port</li>
<li>is actually <em>optional</em>: if you don&#8217;t call <code>bind()</code> you&#8217;ll use an
ephemeral port chosen by the kernel. Though this means you&#8217;d need to
use some other mechanism for publishing.</li>
</ul>


<h3>stream sockets</h3>

<ul>
<li>socket() creates</li>
<li>server

<ul>
<li>bind()s to a specific port/address</li>
<li>listen()s, signalling the kernel that it&#8217;s ready to accept</li>
<li>accept()s to actually process a connection</li>
</ul>
</li>
<li>clients connects()</li>
<li>both can send(), recv(), write(), read(), etc</li>
</ul>


<p>Stream sockets can be active or passive</p>

<ul>
<li>active: can be used in a connect() call

<ul>
<li>usually clients</li>
</ul>
</li>
<li>passive: has been marked to <code>listen()</code> for connections

<ul>
<li>usually servers</li>
</ul>
</li>
</ul>


<h3>listen(int sockfd, int backlog)</h3>

<p>Tell the kernel to start listening for connections. <code>backlog</code> is the
number of connections you&#8217;re willing to have in a pending state before
<code>accept()</code> is called.</p>

<h3>accept()</h3>

<p>Blocks til connection arrives.</p>

<ul>
<li>creates a <em>new</em> socket, the one that you can actually perform IO on
that makes it to the peer socket.

<ul>
<li>so why are they both called sockets? one that&#8217;s used for a
establishing connections, and another that&#8217;s used within an
established connection?</li>
</ul>
</li>
</ul>


<h3>connect()</h3>

<ul>
<li>if it fails, close socket, create a new one, try again</li>
</ul>


<h3>Stream socket IO</h3>

<p>Sockets are bi-directional, which means kernel must internally maintain
two buffers, one for each direction.</p>

<p>Writing into already-closed UNIX domain socket yields SIGPIPE/EPIPE.</p>

<p>For UNIX-domain sockets, if a <code>close</code> fails to propagate or some other
shit goes down (eg a crash), then we have no way of knowing; should
build some sort of ACK into the system (or just use TCP?).</p>

<p>(then again with TCP, what&#8217;s the API for knowing that a specific write
failed? Usually you write and then move on, right? Or do all write&#8217;s
block? Seems weird brah)</p>

<h3>Datagram flow</h3>

<ul>
<li>create socket w socket()</li>
<li>bind() to known address</li>
<li>sendto() to send a datagram</li>
<li>recvfrom() to recv (the from implies that the source address will be
included in the thing)</li>
<li>close() when socket no longer needed</li>
</ul>


<p><code>recvfrom</code> takes a length, returns a single datagram, silently truncating
if less than <code>length</code>. <code>recvmsg</code> is a variant that sets <code>MSG_TRUNC</code> if
truncation occurred.</p>

<h3>Datagram <code>connect()</code></h3>

<p>Seemingly at oods with the known properties of datagram sockets, you can
actually use <code>connect</code> w dgram socks to yield a &#8220;connected datagram
socket&#8221;. This does a few things:</p>

<ul>
<li>allows you to use <code>write</code> and <code>read</code> (rather than having to pass the
address in to <code>sendto</code> and <code>recvfrom</code> all the live long day)</li>
<li>only messages from the socket peer can be <code>read</code></li>
</ul>


<h2>UNIX Domain Sockets</h2>

<p>For bidirectionality you always have to create a pair.</p>

<p>You can create a UNIX domain socket via other means by providing a file
name. You must have permissions to create this thing, and it&#8217;s a special
file of <code>stat</code> time <code>IFSOCK</code></p>

<p>Let&#8217;s do some ruby</p>

<pre><code>require 'socket'
socket = Socket.new(:UNIX, :DGRAM)

# recall that pack_sockaddr_in refers to internet, `un` refers to UNIX
# address becomes a null-packed string. The Ruby socket lib is
# actually pretty low level when it comes to this shit.
address = Socket.pack_sockaddr_un('./wat.unix.socket') 

# this will actually create a special file in the directory
socket.bind(address)
</code></pre>

<p>Verify it&#8217;s a special file (lf -F puts <code>/</code> at the end of directories and
<code>=</code> at the end of sockets). Recall that this requires directory search
permissions since it needs to read the contents of the inode rather than
just the name of the files.</p>

<pre><code>$ ls -F ./wat.unix.socket
./wat.unix.socket=
</code></pre>

<p>Note the starting &#8220;s&#8221;:</p>

<pre><code>$ ls -l ./wat.unix.socket
srwxr-xr-x  1 machty  staff  0 Oct 26 17:57 ./wat.unix.socket
</code></pre>

<p>Also you can&#8217;t open a socket like a normal file:</p>

<pre><code>f = File.open('./wat.unix.socket')
Errno::EOPNOTSUPP: Operation not supported on socket - ./wat.unix.socket
</code></pre>

<p>Note that if you tried to bind to this socket again, you&#8217;d get
EADDRINUSE. This is interesting since you always see this error in the
context of IP address/port collisions, but in this case it&#8217;s a file
pathname; that&#8217;s because address is a generic concept, the specifics of
which are dependent on which socket domain you&#8217;re using</p>

<ul>
<li>IPv4/IPv6 addresses are IP addresses</li>
<li>UNIX is pathnames</li>
</ul>


<p>Both are packed into that address struct so that sys calls can
use/expect the same struct blob.</p>

<p>STREAM sockets have active and passive. <code>passive</code> has had <code>listen()</code>
called on it.</p>

<p>I still am unclear about whether sockets are bi-directional. I think
they are. But I don&#8217;t understand how to stop blocking on <code>read()</code>. Like,
does it block until the buffer is full? I&#8217;ll figure it out later.</p>

<p>Datagrams are supposed to be unreliable, possibly delivered twice, etc,
but UNIX domain datagrams are reliable since it&#8217;s just the kernel
delivering shit (it&#8217;s only difficult to guarantee reliability over a
network). So UNIX domain datagrams are delivered in order and not
duplicated.</p>

<p>Linux allows large datagrams, but some UNIX buffers might only be 2048,
so if you&#8217;re going for portable, go for small.</p>

<p>AHHH fucking dummy, I was using the wrong ruby method. <code>IO#read</code> reads
until you&#8217;ve filled a buffer (or EOF). What you want is <code>read_nonblock</code>.
&#8220;But why do you still need to pass a max len&#8230; this is ruby it can
handle whatever&#8221; I don&#8217;t know, probably because it ultimately translates
to a syscall which needs the length? Yes I think I&#8217;m right about this
after consulting <code>io.c</code> in MRI.</p>

<h2>Socket pairs</h2>

<p><code>socketpair()</code> or <code>Socket.pair</code> returns a pair of connected sockets.
Communication is bi-directional. Benefits over manually creating this
pair include not having to have a public address. Useful for forky IPC.
Very similar to pipe approach to fork IPC cept that pipes are
unidirectional.</p>

<pre><code>require 'socket.rb'
a,b = Socket.pair(:UNIX, :DGRAM)

a.write("bullshit\n")
puts b.read_nonblock(100)
b.write("horseass\n")
puts a.read_nonblock(100)
</code></pre>

<p>Note that this example works also if we used <code>:STREAM</code>.</p>

<h2>Internet domain sockets</h2>

<p>Unlike UNIX domain datagram, internet domain datagrams (implemented on
UDP) are</p>

<ul>
<li>Unreliable, might be delivered twice or not at all.</li>
<li>Sending doesn&#8217;t block if client buffer full, just dropped silently.</li>
</ul>


<p>Network byte order is big-endian.</p>

<p>Marshalling is tricky, dealing with endianness and what not. Converting
to text is often the easiest way to make sense of things, can debug w
<code>telnet</code>, etc.</p>

<p>Clients generally don&#8217;t <code>bind()</code> when making connections / sending
datagrams, in which case the kernel provides an ephemeral port.</p>

<h2>DNS</h2>

<p>Types of requests:</p>

<ul>
<li>recursive: server handles entire task of resolution, including talking
with other DNS servers. I believe though that once you&#8217;ve made the
request, the server can make an iterative approach</li>
<li>iterative: ask <code>.</code> for <code>com.</code>, <code>com.</code> NS for <code>machty.com.</code>,
<code>machty.com.</code> NS for <code>www.machty.com.</code>.</li>
</ul>


<p>There&#8217;s a local DNS server (<code>named</code> for Linux) that you can ask for
names, and it&#8217;ll do iterative. You ask it for recursive and it does
iterative.</p>

<p>Root name servers found via <code>dig . NS</code>, e.g. &#8220;gimme all the Name Server
entries for the root domain <code>.</code>.</p>

<p><code>/etc/resolv.conf</code> configures the DNS resolver, defines how partial
domain names are resolved (they get concatted with the <code>domain</code> entry in
<code>resolve.conf</code>.</p>

<pre><code># assuming `domain home`
ssh machty # machty.home
ssh machty.home
</code></pre>

<p>Both work. But this is just a local DNS nicety, not the distributed DNS
whitchajigger.</p>

<h2>TLDs</h2>

<p>First layer of nodes immediately under the root <code>.</code> node. Two types:</p>

<ul>
<li>generic: com, edu, net, org:</li>
<li>country: co, de:</li>
</ul>


<h2>ports</h2>

<p><code>/etc/services</code> maintains known port names.</p>

<h2>getsockname</h2>

<p>This is useful when you&#8217;re using ephemeral ports (listen without
bind).</p>

<pre><code>require 'socket'
s = Socket.net(:INET, :STREAM)
s.listen(5)
s.puts s.local_address.ip_port
</code></pre>

<p><code>local_address</code> is a wrapper around <code>s.getsockname</code>, which is some null
padded garbage. For UNIX domain sockets it&#8217;ll contain the file pathname.</p>

<p>This is the difference between sockets bound at 127.0.0.1:45454 and
0.0.0.0:45455, which shows that both the local ip and port are
represented in getsockname.</p>

<pre><code>=&gt; "\x10\x02\xB1\x8E\x7F\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00"
=&gt; "\x10\x02\xB1\x8F\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
</code></pre>

<h2>UDP ephemeral port server</h2>

<p>So, <code>listen()</code> on a STREAM server will implicitly perform an ephemeral
port bind if you haven&#8217;t explicitly called <code>bind()</code> already; is it
possible to make an ephemeral UDP server, wherein the port is
ephemerally decided by the kernel? Well, yes, but you have to call bind;
the trick is to call it with port 0 to signify the kernel should pick
one for you. Why would you do this? I don&#8217;t know; probably if you wanted
some anonymous service that no attacker could guess the port of ahead of
time? But you&#8217;d still need to advertise your port somehow.</p>

<h2>UNIX v internet domain sockets</h2>

<ul>
<li>UNIX faster on some implementations</li>
<li>UNIX DGRAM delivery is reliable</li>
<li>UNIX lets you use file permissions for authentication</li>
<li>UNIX lets you pass open file descriptors when forking, etc</li>
</ul>


<p>But often internet sockets are the way to go since they work locally and
remotely.</p>

<h2>Load-balancing with DNS</h2>

<p>If you provide multiple IPs to the same DNS record, you get round-robin
resolution, babeh.</p>

<h2>inetd; inet daemon</h2>

<p>If you have infrequently used daemons that would hog a process table
entry and resources, why not give their sockets to inetd and inetd will
spin up your servers when they need them.</p>

<ul>
<li>number of processes reduced</li>
<li>inetd does the server-y stuff that its clients would otherwise have to
write.</li>
</ul>


<p>aka internet superserver.</p>

<h2>Who responds to ICMP messages?</h2>

<p>Just routers/gateways. Not apps, unless you&#8217;re opening raw sockets n shit.</p>

<p>For instance you can&#8217;t spin up a rails server on localhost:3000 and
expect <code>ping localhost:3000</code> to work, because it&#8217;s only listening to
TCP/UDP sockets. AHHHH I am saying so much ignorance: here&#8217;s the truth:</p>

<p>ICMP has no concept of port. Port is TCP/UDP concept. ALWAYS REMEMBER
THAT. ICMP is IP-only. Whatever responds to / notices an incoming ICMP
request must only have an IP address, and not expect to use a port in
any way. So gateways/hosts/routers will respond to ICMP. You can ping
your router. You can ping gateways. You can traceroute all the way to a
website. And you can ping localhost, because loopback is a gateway.</p>

<p>So how can you write a program that listens for ICMP requests? You need
a raw socket, which requires sudo:</p>

<pre><code>require 'socket'
require 'base64'

rsock = Socket.new(:INET, :RAW)

loop do
  s = rsock.recv(1024)
  enc = Base64.encode64(s)
  puts enc
end
</code></pre>

<p>Again, no concept of port; there&#8217;s no <code>bind</code> here nor does the kernel
assign an ephemeral port; it&#8217;s all raw sockets babeh.</p>

<p>From <code>ping(8)</code>:</p>

<pre><code>The ping utility uses the ICMP protocol's mandatory ECHO_REQUEST datagram to
elicit an ICMP ECHO_RESPONSE from a host or gateway.
</code></pre>

<p>So <code>ping</code> pings gateways/hosts, not servers.</p>

<h2>ECONNREFUSED</h2>

<p>This is caused by ICMP, if it decides it wants to send anything. Shit
gets dropped.</p>

<h2>MTU: Maximum Transmission Unit</h2>

<p>This is what causes IP packets to be sliced and diced.</p>

<p>http://en.wikipedia.org/wiki/Maximum_transmission_unit</p>

<p>The min MTU between two endpoints is the path MTU. The minimum allowable
MTU is well-defined, I forget what it is, but I think there&#8217;s one
guaranteed by IP.</p>

<p>You can find the path MTU (per TCP/UDP RFC) by setting do not fragment
flag and seeing if ICMP sends back a failure due to datagram size. That
said, lots of gateways silently drop ICMP to prevent DoS:</p>

<pre><code>http://en.wikipedia.org/wiki/Black_hole_(networking)
</code></pre>

<p>People might black hole to prevent pings; you can still send well formed
TCP/UDP requests but it won&#8217;t respond to ICMP <code>ECHO_REQUEST</code>s or
anything like that.</p>

<h2>Packet-switching</h2>

<blockquote><p>Packet switching is a digital networking communications method that groups all transmitted data – regardless of content, type, or structure – into suitably sized blocks, called packets.</p></blockquote>

<p>Switching I believe is how two endpoints of a physical link decide how
to send data between each other; they could either do circuit switching
and have a dedicated connection until the connection was over,
or you can packet switch, whereby you
break the communication into small packets that send all at once (and IP
might slice them to fit the link&#8217;s MTU).</p>

<h2>C Standard Library</h2>

<p>I was confused for a moment about where <code>write()</code> and <code>read()</code> and these
low level syscall wrappers lived&#8230; were they considered part of the C
standard library? Or were they in some bare-bones thing in some other
category of code that operating systems provided?</p>

<p>Naw, it&#8217;s all C Standard Library. It&#8217;s just that (I think) <code>write</code> and
<code>read</code> are so low level as to not be considered part of <code>stdio</code>, the IO
subset of the C standard lib.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Faily Burnhole]]></title>
    <link href="http://machty.github.com/blog/2014/10/10/faily-burnhole/"/>
    <updated>2014-10-10T10:24:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/10/10/faily-burnhole</id>
    <content type="html"><![CDATA[<h2>(postgres) Transactions</h2>

<p>http://www.postgresql.org/docs/8.3/static/tutorial-transactions.html</p>

<ul>
<li>group sequence of SQL into atomic (all-or-nothing) operations</li>
<li>useful for preventing invalid state of a crash occurs in the middle of
a sequence of queries</li>
<li>also, transactions are isolated from each other; one in-progress
transaction won&#8217;t see the partially complete transaction process of
another</li>
<li>postgres implicitly wraps every statement in a transaction block if
you haven&#8217;t.</li>
<li>transaction is <code>BEGIN</code> followed by <code>COMMIT</code> or <code>ROLLBACK</code>.</li>
<li>savepoints allow for finer granularity:

<ul>
<li><code>BEGIN</code></li>
<li><code>UPDATE ...</code></li>
<li><code>SAVEPOINT wat</code></li>
<li><code>UPDATE ...</code></li>
<li><code>ROLLBACK TO wat</code></li>
<li><code>UPDATE ...</code></li>
<li><code>COMMIT</code></li>
</ul>
</li>
</ul>


<p>So how can I use this for nested world environments&#8230;</p>

<h2>Sharing raised error with <code>ensure</code> block</h2>

<p>Saw a Ruby thing I hadn&#8217;t seen before at
https://github.com/rails/rails/blob/master/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb#L186-L205</p>

<p>Basically, a <code>rescue</code> must precede an optional <code>ensure</code> block, but whats
cool is that the error caught be the rescue block is available to the
<code>ensure</code> block. Stripped down, the basic construct is</p>

<pre><code>def wat
  do_something_that_might_fail
  rescue Exception =&gt; e
    # do some error handling
  ensure
    # do generic stuff
    if e
      # continue to do some error handling
    end
end
</code></pre>

<h2>ramdisk + ember-cli</h2>

<p>tmpfs is a form of ramdisk. ramdisk is just a general purpose term for
when a virtual file system is provided but the data just lives on memory
rather than hard disk.</p>

<p>Some questions I need to answer:</p>

<ul>
<li>are there different rules about paging when you create a ramdisk? Does
it prevent its own memory from paging to disk any more than other
processes&#8217; virtual memory?</li>
<li>can you control paging in general? (other than going out of your way
to regularly read memory)</li>
</ul>


<p>My ember-cli builds for a decently complex project are about 2s, which
is waaaay better than the 20s they were a month ago. But I can get my 2s
down to 1s my mounting a ramdisk and symlinking my tmp folder to it:</p>

<pre><code>diskutil erasevolume HFS+ 'RAM Disk' `hdiutil attach -nomount ram://8388608`
rm -rf tmp
mkdir /Volumes/RAM\ Disk/tmp
ln -s /Volumes/RAM\ Disk/tmp tmp
</code></pre>

<h2>Photoshop and tmpfs</h2>

<p>http://www.tekrevue.com/tip/how-to-create-a-4gbs-ram-disk-in-mac-os-x/#comment-904649071</p>

<p>This comment speaks of the diminishing returns of using a ramdisk as
scratch space for Photoshop now that Photoshop is 64bit.</p>

<p>If your system is 32bit, it means running processes can only access
virtual mem addresses from 0 to 2<sup>32-1</sup> (0xFFFFFFFF or 4294967293).
On 64 bit systems, that max address is doubled to 0xFFFFFFFFFFFFFFFF, or
1.84 * 10<sup>19.</sup> If you had more than 4gig of RAM on a 32bit system, each
process would still be limited to a max of 4gig memory usage simply due
to the fact that it can&#8217;t reference memory addresses higher than 4gig.
But Photoshop often needs more than 4gig, so what&#8217;s the solution?
Scratch disks.</p>

<p>Scratch disks are like virtual memory implemented in user space. If you
need to store more temporary data than you can put into memory, just
throw it on scratch disk. The problem is that scratch disks</p>

<p>I could totally be bullshitting right now. I could be wrong. But seems
right? Less wrong?</p>

<h2>ln</h2>

<p>I never remember the argument order for <code>ln</code>.</p>

<p>It is FUCKING LEFTWARD. The thing you create on the right points to the
thing on the left.</p>

<pre><code>ln EXISTING_THING LINK

&lt;-------------
</code></pre>

<p>The thing that confused me was that i kept thinking <code>-s</code> was an option
that accepted an argument. It is not! It&#8217;s just an argless option. <code>ln</code>
always has the format of new thing on right points to left. NEVER
FORGOT.</p>

<h2>Dockyard&#8217;s fixtory</h2>

<p>https://github.com/dockyard/fixtory</p>

<p>Convenient way to populate groups of fixtures, maintain references to
the created instances, etc.</p>

<h2>Execute/search permission</h2>

<p>http://content.hccfl.edu/pollock/AUnix1/FilePermissions.htm</p>

<p>Directories have different levels of &#8220;readability&#8221; based on their read /
execute flags. A file record within a directory has a name and an inode.</p>

<p>You can read names of files in a directory (<code>ls</code>) if you have read
permissions on that directory, and permissions denied if not.</p>

<pre><code>$ ls wat
lol
$ chmod -r wat
$ ls wat
ls: wat: Permission denied
</code></pre>

<p>If you want to access the inode in any way, like to read file
attributes (permissions et al), or to read its contents, you&#8217;ll need
execute (search) permissions on the directory.</p>

<pre><code>$ chmod +r wat
$ chmod -x wat
$ ls wat
lol
$ ls -l wat
ls: wat: Permission denied
$ ls -i wat
ls: wat: Permission denied
$ cat wat/lol
cat: wat/lol: Permission denied
$ chmod +x wat
$ ls wat
lol
</code></pre>

<p>Then of course you need file read permissions to access the contents.</p>

<p>So if you&#8217;re using absolute file paths, every directory along the way
needs execute (search) permissions. But in the unusual case that you&#8217;re
able to <code>cd</code> into a directory (thus setting the process&#8217;s current
working directory, something the kernel tracks to control where relative
file lookups occur from) before a parent directory&#8217;s read permissions
are revoked, you&#8217;re grandfathered in if you&#8217;re using relative file perms
from that point on, unless of course the path you provide steps out and
in again.</p>

<pre><code>$ chmod -x ..
$ cat ../inner/woot
../inner/woot: Permission denied
$ chmod +x ..
$ cat ../inner/woot
lol
</code></pre>

<p>Basically, there&#8217;s no concept of deeper and deeper folders, just
following pointers (<code>..</code> and <code>.</code> included), and pointers have permissions
that must be adhered to in order to traverse them.</p>

<h2>dev id and inode</h2>

<p>Device id + inode uniquely identify a file across all file systems.</p>

<p>If the file itself is a special device file, the inode for that file
contains the major/minor id of the device.</p>

<h2><code>utimes(2)</code> for manually changing access/modify timestamps</h2>

<p>You can change the last modified time and last accessed time of a file.
One use case is how <code>tar</code> and <code>unzip</code> preserve the original timestamps
of archived files when they are unarchived.</p>

<p><code>ctime</code> is changed to now when you run <code>utimes</code>.</p>

<h2>group ID of newly created files</h2>

<p>This is governed by 1. how you&#8217;ve configured the file system and 2.
whether set-group-id is set on parent directory.</p>

<p>I think this is one of the rare cases where set-group-id is meaningfully
used on files rather than directories.</p>

<h2>File deletion doesn&#8217;t require file permissions</h2>

<p>You can delete a file without having any permissions on it, since all
you&#8217;re doing is modifying a parent directory.</p>

<h2>Why not have slashes for directories by default?</h2>

<pre><code>$ ls
inner   lol
$ ls -F
inner/  lol
</code></pre>

<p>Wouldn&#8217;t that slash on <code>inner/</code> be convenient to always display?
Why isn&#8217;t that a default?</p>

<p>Answer: because knowing whether a file is a normal file or a directory
requires execute/search permissions on the directory that file lives in.
You can list file/directory names with next to no permissions, but once
you start looking at inode information (such as whether a file is a
normal file or a directory), you&#8217;ll need search/execute perms, and the
default behavior of <code>ls</code> is much less likely to get permission denied
errors.</p>

<p>So thinketh I. Could be wrong.</p>

<h2>Accessing files w/o read perms</h2>

<p>Even if a directory has no read permissions, if it has execute
permissions, then files inside can still be accessed, but their names
must be known ahead of time since you won&#8217;t be able to list the file
names in that directory.</p>

<p>Seems crazy, but useful for when you have a public directory and don&#8217;t
want to list all the contents.</p>

<p>I guess this also means it&#8217;s not possible to hide a single
file/directory within a directory that has read permissions; i.e. if you
can list one file in a directory, you can list them all.</p>

<p>Neat tidbit: there is (was?) a process accounting flag ASU that&#8217;s set if
the process made use of superuser privileges, and the kernel will only
check superuser permissions last in case it can&#8217;t get privileges any
other way than so that it can avoid unnecessarily setting ASU.</p>

<p>It&#8217;s possible to wind up in a situation where an owner has less access
than a group s/he belongs to, due to the fact that the kernel
permissions algorithm will stop once it finds a matching user or group;
it won&#8217;t try to find read (etc) permissions in all matching permission
bits, it&#8217;ll just check the first set of bits it matches.</p>

<p>ACLs (Access Control Lists) allow for per-user and per-group file permissions.</p>

<h2>Sticky bit</h2>

<p>Used to be a signal for a process to stay in swap, now it&#8217;s a signal
set on directories that, when set, prevents non owners and non write
accessors from being able to delete files they don&#8217;t own.</p>

<h2>umask</h2>

<p>A mask, attached to a process, that negates certain permissions.</p>

<h2>EA: extended attrs</h2>

<p>User EAs can only be applied to files and folders, because</p>

<ul>
<li>symlinks have no meaningful permissions, which means anyone in the
world could clutter symlink w EAs if it were possible</li>
</ul>


<h2>executable permissions</h2>

<p>If no one has executable permissions on a file, then not even <code>sudo</code> can
get it to run as such.</p>

<pre><code>$ chmod -x exe
$ ./exe
-bash: ./exe: Permission denied
$ sudo ./exe
sudo: ./exe: command not found
$ chmod o+x ./exe
$ sudo ./exe
wat
</code></pre>

<p>I guess another way of thinking about it is that a file isn&#8217;t an
executable if no one has permissions to it.</p>

<h2>Processes, cwd, directories, etc</h2>

<p>Kernel tracks two attributes on running processes:</p>

<ul>
<li>root: the point from which absolute paths are looked up. Most
processes have <code>/</code></li>
<li>cwd: the directory from which relative paths are looked up</li>
</ul>


<p>(you can use <code>chroot</code> to change the root directory for a process)</p>

<p>A directory is different from a file in that 1) it is specially marked
as a directory in its inode attrs (remember this is why <code>ls -F</code>
requires execute permissions on the parent directory), and 2)
its contents are a table of filenames (read perms) and inodes
(execute/search perms).</p>

<p>You can&#8217;t use <code>read</code> on a directory, you must use other system calls,
hence <code>cat: wat: Is a directory</code>. Basically, the kernel restricts you to
certain syscalls to modify the directory; you can&#8217;t <code>read</code> / <code>write</code> it
the way you would a normal file. The error that gets thrown is <code>EISDIR</code>.</p>

<h2>inode table</h2>

<p>A filesystem has a root inode table that inode entries in directories
will refer to. The root inode table has the following features:</p>

<ul>
<li>index 0 is unused since a 0 is how directory inodes signal that an
entry is unused</li>
<li>index 1 tracks bad blocks on the disk</li>
<li><p>index 2 is <code>/</code></p>

<p>  $ ls -di /
  2 /</p></li>
</ul>


<p>Woot woot! This stuff is so awesome.</p>

<p>So it&#8217;s in this shared inode table that perms are stored. So if you hard
link, any changes to the permissions of one link affects the other:</p>

<pre><code>permstest :: touch shit1 &amp;&amp; ln shit1 shit2
permstest :: ls -l shit*
-rw-r--r--  2 machty  staff  0 Oct 14 10:40 shit1
-rw-r--r--  2 machty  staff  0 Oct 14 10:40 shit2
permstest :: chmod -rwx shit1
permstest :: ls -l shit*
----------  2 machty  staff  0 Oct 14 10:40 shit1
----------  2 machty  staff  0 Oct 14 10:40 shit2
</code></pre>

<p>TODO: Is this the same w ACLs permissions?</p>

<p>Hardlinks not supported by MS VFAT, but yes to NTFS.</p>

<p>inodes don&#8217;t have filenames&#8230; that&#8217;s only in the directory&#8217;s table;
remember that gzip and gunzip (and some other utilities) share the same
inode, and depending on <code>argv[0]</code>, do different things:</p>

<pre><code>$ ls -i `which gunzip` `which gzip`
343041 /usr/bin/gunzip  343041 /usr/bin/gzip
</code></pre>

<p>The <code>rm</code> algorithm is simple: decrement the inode counter, and if 0,
then deallocate. Reference counting, bitchez.</p>

<p>Based on the above layout, you can&#8217;t (easily) get the filename of an
open file, because multiple files might point to that inode, not to
mention that even if you wanted to loop through the file system&#8217;s inode
table, you still wouldn&#8217;t have the file name, just a matching inode
number.</p>

<p>Hardlinks can&#8217;t be created cross-file-system (since they&#8217;re just inode
numbers. symlinks can handle this though).</p>

<p>Hardlinks can&#8217;t (cept Mac due to Time Machine shit) link to directories
due to circular dependencies (e.g. a nested folder hardlinking to an
ancestor folder).</p>

<p>Symlinks can be displayed with trailing <code>@</code> via <code>ls -F</code>. They don&#8217;t bump
the inode counter. They can be created to point to nothing, or can have
their target files deleted (dangling). Like all the other extra data
displayed by <code>ls -F</code>, search perms are needed on the parent directory.
Symlinks have a symlink file type stored in the inode.</p>

<p>Tools are smart enough to avoid cirular dependencies when symlinks link
to directories, because they actually can know they&#8217;re dealing with a
symlink; a multi-hardlink doesn&#8217;t look any different than anything else.</p>

<pre><code>$ ln -s ./circle ./circle
$ ./circle
-bash: ./circle: Too many levels of symbolic links
</code></pre>

<p>For long ass symlinks (> 60 bytes), a data block (where file data is
normally stored) is used to store the target link. But lots of file
systems (<code>ext2</code>+ et al) have an optimization where if the target is less
than 60 bytes, the target is written right into the inode structure
where the data block pointers are usually kept. I tried reproducing this
with a test case of a bunch of <code>stat</code> syscalls on a small-target symlink
and a 60+ byte symlink and it didn&#8217;t make a difference, but that could
just be due to disk cache on behalf of the kernel; the kernel kept the
inode data in RAM so it was just as fast, but if the cache was cold then
symlink lookups should be a lot faster.</p>

<h2>unlinks don&#8217;t complete while files are open</h2>

<p>If there are open file descriptors, an unlinked file won&#8217;t be totally
deleted. Hence the common practice to create and unlink a temporary file
so that you&#8217;re guaranteed when the handle closes, the file will be
totally deleted. This also makes it possible to happily unlink a file
and not worry whether someone else is using it&#8230; but don&#8217;t we sometimes
get file-in-use errors, like &#8220;can&#8217;t delete this file since it&#8217;s being
used be process X&#8221; stuff? Ah, you can delete a file out from under
someone else. They might still save it if they&#8217;ve buffered the data
(think Vim&#8217;s OMG THE FILE NO LONGER EXISTS warning).</p>

<h2>NTFS vs FAT32</h2>

<p>Windows 7 prefers NTFS. Earlier versions prefer FAT. FAT doesn&#8217;t have
security-related features (I&#8217;m guessing permissions?). FAT was
originally designed for floppies, and then used on hard drives. It&#8217;s
still often used for thumb drives.</p>

<h2>Transducers</h2>

<p>http://blog.cognitect.com/blog/2014/8/6/transducers-are-coming</p>

<p>http://jlongster.com/Transducers.js&#8211;A-JavaScript-Library-for-Transformation-of-Data</p>

<p>God damn it. Guess I have to learn a new thing.</p>

<h2>Reentrant</h2>

<p><a href="wiki">http://en.wikipedia.org/wiki/Reentrancy_(computing)</a></p>

<p>Reentrancy means the function can be interrupted and re-entered without
harm. Actually I think more accurately it means it can be re-entered,
even within the same thread, without causing issue. A function can be
threadsafe and not re-entrant. e.g.</p>

<pre><code>trap :INT do
  puts "int"
end
Process.kill :INT, Process.pid
puts "boom"
</code></pre>

<p>This yields a <code>deadlock; recursive locking (ThreadError)</code> every time,
the same that would happen if you tried to double lock a mutex within
the same thread. The reason is that <code>puts</code> calls <code>write</code>, and <code>write</code>
mutexes around Ruby&#8217;s IO buffer. The signal handler doesn&#8217;t get called
synchronously at <code>Process.kill</code>, but for whatever reason, the kernel
decides to fire the signal handler during <code>write</code> in <code>puts "boom"</code>,
after the write mutex has already been locked. Then the signal handler
runs, tries to the do the same lock, and BOOM. Weird shit. But proof
that <code>puts</code> and <code>write</code> aren&#8217;t re-entrant even though they&#8217;re thread
safe. If you did <code>$stdout.sync = true</code>, they would be reentrant though
and the above error would go away.</p>

<h2>Process cwd</h2>

<p>Hmmm a process&#8217;s cwd does contain a pathname to the cwd; I thought it&#8217;d
just be some kind of inode pointer and not know the name? That said, the
beginning of the path is truncated if there&#8217;s not enough space, though
this is probably rare. That said, you can <code>readlink</code> the symlink at
<code>/proc/PID/cwd</code> (this doesn&#8217;t exist on Mac though).</p>

<h2><code>chroot</code> jail</h2>

<ul>
<li>FTP uses this so that anonymous users can&#8217;t just browse the whole
system</li>
<li>Linux doesn&#8217;t have hard-linked directories, but some UNIX varieties
do, and a hardlink outside of a <code>chroot</code> jail will compromise the jail</li>
<li>Most programs can&#8217;t run in <code>chroot</code> jail because they rely on
dynamically linked libraries, and the link targets are often absolute
and expect <code>/usr</code> to live.</li>
</ul>


<h2>Symlink perfs</h2>

<p>I was enouraged by the fact that on ext2+, symlinks whose targets are
less than 60 chars long get written into the inode rather than into a
separate data block (it&#8217;s basically written where the data block
pointers are usually saved, which amounts to ~60 bytes). Sooo I did a
quick benchmark to see if ember-cli would benefit, and alas (and go
figure?) 60 char perfs that apply to ext2 (and 3 and 4) don&#8217;t apply to
OS X&#8217;s HFS+.</p>

<p>I ran a test creating 100,000 symlinks, one where each symlink target
was 59 chars, and another with 60, and the difference is dramatic:</p>

<pre><code>Linux, ext4, 60 char symlink, 100,000

real    0m19.642s
user    0m0.468s
sys     0m3.988s

Linux, ext4, 59 char symlink, 100,000

real    0m2.005s
user    0m0.360s
sys     0m1.436s
</code></pre>

<p>I&#8217;m sad, because most ember-cli / broccoli symlinks are above the 60
limit, and this would have brought us some insane perfs, but alas alas
alas, most people do ember-cli work on OS X, not Linux. Oh god damn
well.</p>

<h2>ARS Technica on why HFS+ blows</h2>

<p>http://arstechnica.com/apple/2011/07/mac-os-x-10-7/12/#file-system</p>

<ul>
<li>HFS is from 1985</li>
<li>HFS+ (aka Mac OS Extended) released in 1998.</li>
<li>OS X (2001) unfortunately kept HFS+ around even though it sucks</li>
</ul>


<p>So yusuck:</p>

<ul>
<li>16 bit processing resolution in Mac&#8217;s implementation (Motorola 68000
hangover). Not really sure what this means, not sure why if the data
is 32+ bit why 16 is the resolution? So many things I don&#8217;t know.</li>
<li>Time resolution of HFS+ is only a second, shitty for file timing logic
in <code>make</code>, et al. Most modern fs&#8217;s have nanosecond resolution.</li>
<li>Global file lock on metadata; only one process can write to a file at a time. NOPE
that&#8217;s obviously incorrect. It means only one process can update the
file system at a time&#8230; I don&#8217;t understand? Can&#8217;t add multiple files to
a directory at the same time? Metadata?</li>
<li><p>No sparse files. The following ruby code will instantly eat a gig on
HFS+. On ext2 you could still use that gig space for other files, and
intermediate blocks would only be allocated as needed:</p>

<p>  File.open(&#8216;bigassfile_DELETE_ME&#8217;, &#8216;w&#8217;) do |f|</p>

<pre><code>f.seek(1000000000)
f.puts('l')
</code></pre>

<p>  end</p></li>
</ul>


<p>Result: Finder reports -=1gig of freespace, as expected (if there are no
sparse files). Weird though: <code>ls -l</code> reports only 87 block usage; I
would have expected a lot more give the fact that the file system is
allegedly allocating a bunch of zeroes? ANSWER: I think it&#8217;s because OS
X uses a VFS that pretends to support sparse files over HFS+, which
doesn&#8217;t, but I need to confirm this.</p>

<ul>
<li>Hard links to directories is supported, which is kinda weird.
Internally it works by hiding them in hidden a hidden directory (my
guess is to avoid cycles?)</li>
<li>No concern about data integrity. Easy for meta data to get corrupted.
Report showed that ~30% of HFS+ systems had mismatched checksum. Data
loss likely.</li>
</ul>


<h2>Endianness</h2>

<p>Not to be confused with &#8220;bit-endianness&#8221;, the atomic unit Endianness
as people normally talk about it is the byte, rather than the order of
bits. Endianness is concerned with the byte order in a &#8220;word&#8221; (the unit
of a CPU processing, e.g. 32 bit machine vs 64 bit machine refers to the
word size and has implications on the size limits of integers, memory
addresses, etc.). Whether the most significant bits appear at the
beginning or end of a word is the endianness, big-endian or
little-endian. You have to care about this stuff if you&#8217;re manually
converting bytestreams between different systems with different
endianness. Some processors are bi-endian.</p>

<h2>POODLE attack</h2>

<p>https://tools.ietf.org/html/draft-ietf-tls-downgrade-scsv-00</p>

<p>SSL 3.0 preceded TLS 1.0 and has vulnerabilities that allow an attacker
to see plaintext communication. Some clients go beyond the TLS handshake
specifications and will fall back to SSL 3.0 if a TLS handshake fails in
order to support the case where they&#8217;re talking to a legacy ass server
that runs SSL 3.0. A man in the middle can fuck with a handshake,
causing it to fail, and causing the TLS client to try communication with
SSL 3.0, and many servers supporting legacy SSL 3.0 will just happily
fall back to that, exposing the connection to SSL 3.0&#8217;s weaknesses.</p>

<p>The solution is for clients falling back to SSL 3.0 to send a backwards
compatible cipher suggestion that newer patched servers will look out
for and will treat as a signal that &#8220;this SSL 3.0 connection attempt is
only a fallback, and you shouldn&#8217;t accept this and start speaking in
3.0&#8221;. Legacy servers will just see it as a suggested cipher that they
don&#8217;t understand and will just choose another cipher that they do, and
continue communicating in their legacy 3.0 way. Case in point: upgrade
your servers.</p>

<p>The name for the patch is the TLS Signaling Cipher Suite Value (SCSV).</p>

<h2>inotify config</h2>

<p>On Linux you can configure aspects of <code>inotify</code> by writing values in to
various files in <code>/proc/sys/fs/inotify</code>. Question: why this format of
config? Why a single value in each? Why not <code>sysctl</code>?</p>

<h2>ssh escape char</h2>

<p><code>~</code> at the beginning of a line is an ssh escape char; if your connection
is hung, you can do <code>~.</code> (at the beginning of a line; you can force this
by pressing enter) and that&#8217;ll disconnect.</p>

<pre><code>Supported escape sequences:
 ~.   - terminate connection (and any multiplexed sessions)
 ~B   - send a BREAK to the remote system
 ~C   - open a command line
 ~R   - request rekey
 ~V/v - decrease/increase verbosity (LogLevel)
 ~^Z  - suspend ssh
 ~#   - list forwarded connections
 ~&amp;   - background ssh (when waiting for connections to terminate)
 ~?   - this message
 ~~   - send the escape character by typing it twice
</code></pre>

<p>Mmmm command line, this seems interesting if you&#8217;re using ssh for
proxying:</p>

<pre><code> ~C      Open command line.  Currently this allows the addition of port for-
         wardings using the -L, -R and -D options (see above).  It also
         allows the cancellation of existing port-forwardings with
         -KL[bind_address:]port for local, -KR[bind_address:]port for remote
         and -KD[bind_address:]port for dynamic port-forwardings.  !command
         allows the user to execute a local command if the PermitLocalCommand
         option is enabled in ssh_config(5).  Basic help is available, using
         the -h option.
</code></pre>

<h2>Signals</h2>

<p>Signals are sync; between generation and delivery, they are pending.
Most often sent immediately if running, or once it&#8217;s next scheduled to
run. Signals can be temporarily blocked by signal masks til the process
is ready to handle them (to prevent rude interruptions). Signals can
yield the following reponse from processes:</p>

<ul>
<li>ignore: kernel never tells process about it</li>
<li>terminate: &#8220;abnormal&#8221; (non <code>exit</code>) termination</li>
<li>core dump and terminate: core dump is image of virtual memory</li>
<li>stop execution (suspend)</li>
<li>resume execution</li>
</ul>


<p>I guess the thing I&#8217;ve learned here is that by setting signal masks,
you&#8217;re telling the kernel ahead of time what should happen when signals
are sent to this process, rather than setting some process-level
handlers that server as callbacks when these signals arrive;
particularly ignore &#8211; I thought it&#8217;d still make it to some low level
library in the process, but sounds like it&#8217;s rather just the kernel
knowing ahead of time not to even send it.</p>

<p>You can&#8217;t tell a signal that doesn&#8217;t by default terminate/core dump to
terminate/core dump, but you can install a signal handler and then call
<code>abort()</code> or whatever to send yourself a signal that <em>will</em> cause such a
thing to happen.</p>

<p>On Linux you can look up a process&#8217;s signal mask via <code>/proc/PID/status</code>.
You can also use <code>ps -p $$ -o sigmask,sig</code> to get info about signal
masks.</p>

<p><code>SEGV</code> means segmentation violation.</p>

<p><code>SIGBUS</code> is like <code>SIGSEGV</code> but in very particular situations, such as
reading past the end of a memory mapped file. BUS is hipster SEGV.</p>

<p>Send signals with <code>kill</code> (whose name is a hangover from a time in which
most if not all signals terminated a process). Different <code>pid</code> values do
different things:</p>

<ul>
<li>positive: send signal to pid</li>
<li><code>0</code>: send signal to processing group of calling process, including
calling process</li>
<li><code>&lt; -1</code>: send signal to process group dilineated by the absolute value of
the supplied pid</li>
<li><code>-1</code>: send to all processes you have permission to send to, excluding
<code>init</code>/<code>launchd</code> (pid 1) and the calling process. AKA broadcast
signals.</li>
</ul>


<p><code>init</code>/<code>launchd</code> can only be sent signals for which it has signal
handlers, to prevent accidental killing of this precious process.</p>

<p><code>CAP_KILL</code> is the privilege that allows a process to send a signal to
whatever.</p>

<p><code>SIG_CONT</code> is special in that it can be sent by unprivileged processes
to any process in the same session to allow for job-control shells to
restart stopped jobs that have changed their user IDs.</p>

<p>Null signal 0 can be used to test if a process exists and we can send a
signal to it. Of course you might troll yourself given that pids are
recycled.</p>

<p>Plain ol (non-realtime) signals don&#8217;t queue; they just internally set a
bit in the kernel and fire next time that process runs. This is why
multiple signals fired very quickly might get coalesced into one</p>

<h2>How to check if process is still running</h2>

<ul>
<li>(for child processes) <code>wait</code></li>
<li>semaphores and exclusive file locks; if you know a process locks a
file, and you can acquire the lock or semaphore, you know it must be
dead. I&#8217;m guessing pidfiles work this way?</li>
<li><code>stat</code> <code>/proc/PID</code>.</li>
<li>IPC sockets go dead, etc</li>
</ul>


<h2>async-signal-safe</h2>

<p>A function is async-signal-safe if</p>

<ol>
<li>it&#8217;s reentrant</li>
<li>it can&#8217;t be interrupted by signal handler</li>
</ol>


<p>Signal handlers should ideally only call async-signal-safe functions.
Note that if you have a signal handler installed for multiple signals,
or if you have <code>SA_NODEFER</code>, a handler function might get simultaneously
and might not be reentrant relative to itself if it mucks with globals,
even if the main app code doesn&#8217;t touch those globals.</p>

<p>In C-land (and Java) you can use the volatile keyword to prevent
variables from living in registers, or at least guaranteeing that a
write to a variable goes all the way to memory, which is an important
guarantee for when threads share and write to a global variable.</p>

<p>In JRuby, the Atomic gem is useful as a lock-free test-and-set way of
performing an update to a value, and detecting/retrying if someone else
interrupted your operation.</p>

<p>http://moonbase.rydia.net/mental/blog/programming/atomic-operations-in-ruby.html</p>

<p>Parallelism is moronically hard.</p>

<h2>Signal handler recovery</h2>

<p>You can do <code>setjmp</code> and <code>longjmp</code>&#8230; cray crqy.</p>

<p>When the kernel runs a handler, it adds a bit to the <code>sa_mask</code> and then
removes it when handler returns, so if you <code>longjmp</code>, you need to make
sure to unset it. (Presumably NODEFER prevents this bit from being set,
allowing the handler to be called multiple times?)</p>

<h2>Signal Stack</h2>

<p>Processes have a signal stack separate from the regular stack for
running signal handlers. You can use <code>sigaltstack</code> to change it to some
preallocated region, useful for when you want to catch SIGSEGV on a
stack overflow (which means there&#8217;s no more room on the process stack
for a signal frame/stack).</p>

<h2>Interrupted syscalls</h2>

<p>Blocking reads are syscalls, and if a signal hits an app during such a
syscall, when the signal handler returns and normal process flow
continues, that syscall will yield an <code>EINTR</code>. In Ruby this results in a
<code>Interrupt &lt; SignalException &lt; Exception</code> being raised. So you have to
jump through some hoops, put things in loops, to handle/ignore <code>EINTR</code>
on blocking syscalls. Orrr you can use <code>SA_RESTART</code> when establishing
signal handlers w <code>sigaction</code> so that the kernel automatically restarts
interrupted syscalls post signal handler.</p>

<p>Just realized something: on Ruby, if you don&#8217;t trap a (non-terminating)
signal handle, it&#8217;ll fire as an exception that you can caught. That&#8217;s
crazy. This must mean Ruby internally traps all trappable signals and
then checks them against any registered trap handlers in Rubyland.</p>

<h2>Framework blackboxing</h2>

<p>Exceptions in blackboxed frameworks don&#8217;t pause. So you can add
blackboxed frameworks in Chrome inspector options to ignore a framework
that keeps throwing shit. Probably other thins too; TODO: research!</p>

<h2>Cryptonomicomicon</h2>

<p>Page 17.</p>

<p>lambent: glowing, gleaming, or flickering with a soft radiance</p>

<p>gnomon: the projecting piece on a sundial that shows the time by the
position of its shadow.</p>

<h2>Why <code>sysctl</code>?</h2>

<p>In my Linux learnings I was curious as to why some settings seemed to be
stored in files while others seemed to be stored via separate utilities
like <code>sysctl</code>. Turns out <code>sysctl</code> is just a wrapper around <code>/proc/sys</code>,
and the setting variable names e.g. <code>a.b.c.d</code> would map to
<code>/proc/sys/a/b/c/d</code> and the setting would be the contents of that file.</p>

<p>So as far as global structures go, I know about:</p>

<ul>
<li>Environment variables</li>
<li>Shell variables (basically non-exported env vars, don&#8217;t get shared
with child processes).</li>
<li>Shell settings (e.g. ulimit, a per-shell set of defaults used when
invoking child processes <em>from that shell</em>; it&#8217;s not like you&#8217;re
setting system-wide settings when you set <code>ulimit</code>)</li>
<li><code>procfs</code></li>
<li>Probably lots more file based stuff I&#8217;m not thinking of. If it&#8217;s
really system-wide global stuff, it must live in a file somewhere,
right? Everything is a file?</li>
</ul>


<h2><code>TASK_UNINTERRUPTIBLE</code></h2>

<p>A risky process state, usually for operations that are quick to
complete, like waiting for a syscall to finish flushing data to disk,
but if there&#8217;s some issue, NFS or kernel bug, it might result in a hung
task that cannot be killed without a system restart. Another state,
<code>TASK_KILLABLE</code>, was added to prevent this, and it was first applied to
hung NFS.</p>

<h2>Hardware signals</h2>

<p>Linux force-delivers hardware signals even if they&#8217;re set to ignore.
Returning from a signal handler means undefined behavior because likely
the machine instruction that caused the interrupt is going to be
retried, likely causing an infinite loop. You need to <code>_exit</code> (because
<code>exit</code> flushes stdio buffers which might be locked and cause problems,
not to mention that <code>exit</code> fires <code>onexit</code> hooks) or do a <code>siglongjmp</code> to
guarantee that you&#8217;re skipping over the broke ass machine instruction.</p>

<h2>Timers</h2>

<p>3 types of timers per process: real (wall clock), virtual (user CPU),
and profile (user+kernel).</p>

<p>You can set timers on read operations by omitting <code>SA_RESTART</code> from the
<code>SIGALRM</code> registration.</p>

<h2><code>sleep</code></h2>

<p>This could be implemented otherwise with <code>sigsuspend()</code> (which allows
you to specify a temporary signal mask and block until a signal arrives
to wake it up).</p>

<p>You can use <code>sleep</code>, or <code>nanosleep</code>. <code>nanosleep</code> is limited by
resolution of software clock which uses units of time called jiffies&#8230;?
Jiffies are the amount of time the kernel lets a process execute, in HZ.
For a long time it was 100 HZ. So a jiffy was 1% of a second, or 10ms.
That seems crazy big! Maybe not? But if video games wanna run at 60 fps,
and they have to share the CPU with other things, they&#8217;re gonna need
larger jiffy. Because if the video game is alternating with only a
single other process (and in real life it should be many other
processes), then it couldn&#8217;t achieve more than 50 fps. Soooo sounds like
there&#8217;s something I don&#8217;t understand. The Jiffies did get smaller.</p>

<h2>SSLMate</h2>

<p>Buy SSL certs from your terminal. Why the fuck not?</p>

<p>https://sslmate.com/</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crowley Journal]]></title>
    <link href="http://machty.github.com/blog/2014/10/06/crowley-journal/"/>
    <updated>2014-10-06T21:15:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/10/06/crowley-journal</id>
    <content type="html"><![CDATA[<h2>Comptroller</h2>

<p>Basically the CFO of public institutions. In charge of audits,
accountability, etc.</p>

<h2>Fetch remote branch</h2>

<p>http://stackoverflow.com/questions/945654/git-checkout-on-a-remote-branch-does-not-work</p>

<p>I was burned by this.</p>

<p>Basically, I had <code>origin</code> in the <code>+fetch</code> section when I wanted the new
branch in there</p>

<pre><code>fetch = +refs/heads/*:refs/remotes/origin/*
</code></pre>

<p>TODO: understand this fetch crap. I still don&#8217;t grok it.</p>

<h2>Amazon SES</h2>

<p>http://aws.amazon.com/ses/</p>

<p>Simple Email Service.</p>

<h2>Bash run last command substitute</h2>

<pre><code>$ ls lol
ls: wat: No such file or directory
$ ^wat^lol
ls lol
ls: lol: No such file or directory
</code></pre>

<h2>Harp. What is it?</h2>

<p>I don&#8217;t know. You tell me.</p>

<p>http://harpjs.com/</p>

<p>Static web server with built in preprocessing.</p>

<p>https://github.com/silentrob/harp-editor</p>

<h2>Candy kid</h2>

<p><img src="http://kandipatterns.com/images/kandikids.jpg" alt="" /></p>

<h2>Lissajous curve</h2>

<p>http://en.wikipedia.org/wiki/Lissajous_curve</p>

<pre><code>x=A\sin(at+\delta),\quad y=B\sin(bt),
</code></pre>

<p>Family of curves that seem bounded by a (-1,-1)x(1,1) box. What am I
doing with my life.</p>

<p>Source: cryptonomicon, bumble bee doing Lissajous across the ceiling.</p>

<h2>CSS history theft</h2>

<p>http://lcamtuf.coredump.cx/css_calc/?utm_source=html5weekly&amp;utm_medium=email</p>

<ul>
<li>Til mid 2010, a crappy site could use the <code>:visited</code> pseudo class to
render a bunch of URLs and then check the url to see if the <code>:visited</code>
styles were applied.</li>
<li>this loophole was closed by only letting specify color attributes, and
prevent color lookup via <code>getComputedStyle</code>.</li>
<li>loophole remains open for clicking a single URL, which doesn&#8217;t scale
too well.</li>
</ul>


<h2>Milquetoast</h2>

<p>Based on comic cartoon character Caspar Milquetoast, a timid, weak-willed old man,
whose namesake is breakfast comfort food consisting of toast and a white
milk-based sauce.</p>

<p>Millhouse is milqtoast, kinda, but more dweeby. Edward Norton in Fight
Club is milquetoast.</p>

<h2>Gone Girl</h2>

<p>I should see it. Once book, now David Fincher movie that makes people
not want to get married.</p>

<h2>504 Gateway Timeout</h2>

<p>Never knew what this meant, but this can be returned by an intermediary
or proxy server that doesn&#8217;t get a timely response from a backend server
it&#8217;s talking to in order to prepare a response to the client. DOS&#8217;d
servers might see this, wherein their nginx/whatever reverse proxy can
handle the load just fine, but the backend server is inundated and can&#8217;t
keep up with the load.</p>

<h2>Cairns</h2>

<p>City in far north of Queensland, Australia. Scuba.</p>

<h2>FastCGI</h2>

<p>http://en.wikipedia.org/wiki/FastCGI</p>

<p>CGI applications are processes spun up by a web server to handle an
incoming request. Unscalable since spinning up processes all the time
takes a toll on the OS, not to mention that there&#8217;s no way to do
resource sharing (DB connection sharing, in-memory caching (because
the process dies at the end of request)).</p>

<p>With FastCGI, there&#8217;s a persisting FastCGI server that owns all of the
CGI programs, and webservers interact with FastCGI via a binary protocol
(over a socket (local) or TCP connection (remote)).</p>

<p>This decoupling also allows smaller components to be restarted (rather
than having to restart the entire web server).</p>

<p><code>mod_php</code> is another answer to this problem, which takes the approach to
embedding the PHP interpreter inside Apache itself. But each Apache
child then needs to load the interpreter. FastCGI is better on memory
and not constrained to Apache (nginx implements it).</p>

<p>TODO: reverse proxy rails configuration vs Rails attached to FastCGI.</p>

<h2>Copy as curl</h2>

<p>You can copy a resource request made by Chrome as a curl command.</p>

<h2>HAR format</h2>

<p>You can save network requests (request data/headers and response etc) as
a HAR files from the Chrome debugger.</p>

<p>Stands for &#8220;HTTP ARchive&#8221;:
http://www.softwareishard.com/blog/har-12-spec/</p>

<p>HARs are JSON documents containing</p>

<h2>bcrypt stretches</h2>

<p><code>Devise.stretches</code> controls the internal bcrypt stretching amount for
bcrypt password hashing. When <code>RACK_ENV=test</code>, <code>Devise.stretches</code> is 1,
else it is 10 (or some higher number).</p>

<p>Increasing stretches drastically increases the CPU time required for
hashing passwords, which seems like an obvious anti-perf except for the
nice fact that if you&#8217;re server&#8217;s being bombed by a dictionary attack,
which sequentially tries to hash many passwords, the attack will be
thwarted by just how long the server takes to hash the password.</p>

<p>http://en.wikipedia.org/wiki/Key_stretching</p>

<h2>ActiveRecord connection pooling</h2>

<p>http://blog.plataformatec.com.br/2011/12/three-tips-to-improve-the-performance-of-your-test-suite/</p>

<p>Connection pools allow for connection reuse (rather than, say, the
shitty alternative of opening/closing a connection for every query).
The ActiveRecord connection pool has the additional stipulation that
connections are not shared between threads. This makes sense, since
otherwise if you had a multithreaded Rails application and connections
were shared between threads, then only one thread at a time could be
querying the database, and locking would occur, making shit slow.</p>

<p>So by letting each thread have its own connection to a shared resource,
threads won&#8217;t get blocked on each other. Happy fucking day.</p>

<h2>Rails dbconsole</h2>

<p>http://guides.rubyonrails.org/command_line.html#rails-dbconsole</p>

<pre><code>rails dbconsole
# or
rails db
</code></pre>

<h2>dRuby</h2>

<p>COBRA for Ruby basically.</p>

<p>http://www.ruby-doc.org/stdlib-1.9.3/libdoc/drb/rdoc/DRb.html</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Smelly Journal]]></title>
    <link href="http://machty.github.com/blog/2014/10/01/smelly-journal/"/>
    <updated>2014-10-01T08:29:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/10/01/smelly-journal</id>
    <content type="html"><![CDATA[<h2>TCP/UDP/Sockets/wat</h2>

<p>What&#8217;s a socket?  Depends on who you ask.</p>

<p>The <a href="file:///Users/machty/code/machty.github.com/rfc793.html">TCP RFC</a>
defines a &#8220;socket&#8221; as an IP address (supplied in IP packet) combined
with a port (supplied in the TCP packet). So a &#8220;socket&#8221; is
(IP,PORT). Socket + Socket = Connection. Hence, in this sense, you can
use the same socket for multiple connections.</p>

<blockquote><p>To allow for many processes within a single Host to use TCP
communication facilities simultaneously, the TCP provides a set of
addresses or ports within each host.  Concatenated with the network
and host addresses from the internet communication layer, this forms
a socket.  A pair of sockets uniquely identifies each connection.
That is, a socket may be simultaneously used in multiple
connections.</p></blockquote>

<ul>
<li>Socket: an operating system abstraction referring to a communication
endpoint. You can read from it. You can write to it.</li>
<li>Note that raw sockets don&#8217;t have ports (ports are a UDP/TCP concept).</li>
</ul>


<h2>Built-ins aren&#8217;t sudo-able</h2>

<pre><code>sudo: cd: command not found
</code></pre>

<p>:). Makes sense. You either need to use absolute paths or <code>sudo bash</code>.</p>

<h2>Switch into another user</h2>

<pre><code>sudo su - machty
</code></pre>

<h2>socket bind vs listen vs accept</h2>

<p>Why so many steps? What does each one do?</p>

<h3>Bind</h3>

<p>Registers a socket with the kernel. Even if you do nothing with that
socket, once you bind, anyone else who tries will get an EADDRINUSE.
This code gets an EADDRINUSE every time.</p>

<pre><code>require 'socket'
def wat
  socket = Socket.new(:INET, :STREAM)
  addr = Socket.pack_sockaddr_in(4485, '0.0.0.0')

  socket.bind(addr)
end

fork { wat }
wat
Process.wait
</code></pre>

<p>If the socket had been created, then a new file descriptor pointing to
the same socket could be used by the forked child process, but you can&#8217;t
just create a totally separate one that points to the same already-bound
port.</p>

<h3>Listen</h3>

<p><code>listen()</code> indicates a &#8220;willingness to accept incoming connections&#8221;.
You provide <code>listen</code> with a <code>backlog</code> integer referring to the max
number of queued connections allowed before you ECONNREFUSED.</p>

<p>It&#8217;s separate from <code>bind</code> because maybe you want to grab a port right at
application start, but you still need to do some thing before you know
a) whether to actually start listening or b) how big the queue size
should be.</p>

<p>It&#8217;s separate from <code>accept</code> because <code>accept</code> kind of a dead end as far
as application initialization goes; once you start <code>accept</code>ing, you must
be all set up and fine with the fact that you&#8217;ll be blocked on IO.</p>

<p>SOMAXCONN is the max backlog number. Probably best to just set
<code>listen</code>&#8217;s backlog to that number. If you&#8217;ve got people queued up for
connections, you should probably be fixing whatever&#8217;s causing the wait.</p>

<h3>Accept</h3>

<p><code>accept</code> will block.</p>

<p>So basically here&#8217;s what happens if you try to connect to a server
that&#8217;s ran through the following steps (followed by a sleep unless
<code>accept</code> is called):</p>

<ul>
<li>no <code>bind</code>: ECONNREFUSED</li>
<li><code>bind</code>: client blocks. If you kill the server, ECONNREFUSED</li>
<li><code>listen</code>: client blocks, reports a successful connection (which means
that <code>listen</code> makes the kernel start accepting connections even if no
one&#8217;s accepting&#8230; this makes sense since at this point we&#8217;ve provided
the kernel a max queue size)</li>
</ul>


<p>If a connection comes in, the kernel will do the handshake, but the
connection will remain in the queue and future connection attempts won&#8217;t
get the handshake until the first one is <code>accept</code>ed.</p>

<p>Does that make sense? The alternative would be the kernel not responding
to the handshake until <code>accept</code>, which seems like a major performance
hit.</p>

<h2>Elastic Beanstalk</h2>

<p>Tries to do what Heroku does. Apparently a clunkier CLI. But neato
features.</p>

<h2>Kernel buffers</h2>

<p>C and Ruby provide buffering on top of a kernel buffers. Why not just
have one buffer? Because the kernel definitely needs to provide
buffering in general so that you can get the perfs for free. But
application specific stuff can benefit from buffering on top of the
kernel&#8217;s defaults, but unfortunately the system calls are megaslow.</p>

<p>Kernel maintains a kernel thread that makes sure that nothing remains
unflushed for more than 30 seconds and will flush things.</p>

<p>You can <code>fadvise</code> the kernel about how reads/writes are likely to
occur so that it can select the best strategy for what you&#8217;re doing.</p>

<p>There&#8217;s an <code>madvise</code> memory equivalent. Wouldn&#8217;t you just write your own
allocator at that point? Guess I should probably learn my shit.</p>

<p>Different types of strategies:</p>

<ul>
<li>NORMAL: no special patterns to report, default kernel behavior.
Read-ahead buffer set to 128k.</li>
<li>SEQUENTIAL: you&#8217;re gonna be reading from lower to higher offsets.
Large files, streaming large music files, blah blah blah, etc., on
linux this yields read-ahead window size 2x the default.</li>
<li>RANDOM: scattershot reads, hence read-ahead is likely a waste, hence
it is disabled.</li>
<li>WILLNEED: notify kernel that you&#8217;ll need a segment of memory soon, so
kernel loads it into the buffer cache (redundant much?). Memory
presurre from other processes might eject these buffers from the
cache, so it&#8217;s good to make sure you <code>read</code> soonish after this
fadvise.</li>
<li>WONTNEED: flush a region if possible</li>
<li>NOREUSE: WILLNEED + WONTNEED, basically. You only expect to read the
region once.</li>
</ul>


<h2>Unzip a curled tar</h2>

<pre><code>curl https://opensource.apple.com/tarballs/bash/bash-92.tar.gz | tar zxf -
</code></pre>

<p>Pretty amazing.</p>

<h2><code>O_DIRECT</code>: bypass the buffer cache</h2>

<p>Often this means slower performance, but if you reaaaally know what
you&#8217;re doing, you can use it. If you use <code>O_DIRECT</code>, here&#8217;s what you
lose:</p>

<ul>
<li>sensible read-aheads</li>
<li>sharing buffers between processes using the same files</li>
<li>other things</li>
</ul>


<p>Database software probably wants <code>O_DIRECT</code> because databases have
unique IO requirements, maintain their own caches, etc.</p>

<p>You have to start paying attention to things like alignment
restrictions. The databuffer must begin on a memory boundary that is a
multiple of block size. I guess that means you have to shift things in
memory before writing to disk. File offset must also be multiple of
block size. Length of data transferred must also be multiple. Else
<code>EINVAL</code>.</p>

<h2>Write-ahead log</h2>

<p>http://en.wikipedia.org/wiki/Write-ahead_logging</p>

<p>Postgres et al use this to provide atomicity / durability. With WAL, all
modifications are written to a log before applied. Redo/undo information
is written to the log.</p>

<p>http://en.wikipedia.org/wiki/Point-in-time_recovery</p>

<p>Restore a previous state in time. Time Machine is OS X is an example of
this (also why they allow directory hard-linking).</p>

<h2>Virtual devices and device files</h2>

<p>Expose universal IO API.</p>

<p>There are character devices like TTYs which can handle a character at a
time, and there are block devices, which can handle IO in (often 512b)
blocks.</p>

<p>Use <code>mknod</code> for making device files. Used to be used for other things,
now it&#8217;s just device files.</p>

<p><code>ls -l</code> displays major or minor number of special device fields in place
of the size (from <code>man ls</code>)</p>

<pre><code> If the file is a character special or block special file, the major and
 minor device numbers for the file are displayed in the size field. 
</code></pre>

<h2>Cryptonomicomicon</h2>

<p>Words.</p>

<p><a href="http://en.wikipedia.org/wiki/Coolie">Coolie</a>: a laborer from Southern
China, Indian subcontinent, Phillipines or Indonesia. Nowadays a
racial slur for people of Asian descent (mostly in South African
vernacular). Etymology not agreed upon, could be from an Urdu word for
&#8220;slave&#8221; or in reference to the Koli, or a Tamil word that meant payment
for work. Coolie trade pretty much was like slave trade, with indentured
servitude, etc. In Crypto they&#8217;re the workers who trade various Shanghai
banks silver-backed paper money in for silver, transporting large boxes
of currency hanging from bamboo sticks.</p>

<p><a href="http://en.wikipedia.org/wiki/Claque">Claque</a>: people paid to applaud
(or heckle) a performance. Basically, real-time proto-laugh tracks,
originating from France. There were laughers (Rieurs), criers
(Pleureurs), ticklers (Chatouilleurs, who kept the audience in high
spirits), and encore-ers (bisseurs). North Korea&#8217;s got lots of claquers.
Entrenched claque-masters also extorted money from performers in
exchange for not booing their performance. Fucking dickweeds.</p>

<p>Swabbie: &#8220;a member of the navy, typically one who is of low rank.&#8221;</p>

<p>Estuary (esturial): the tidal mouth of a large river, where the tide
meets the stream.</p>

<h2>Number authorities</h2>

<p>Kinda like the IANA and port numbers, there&#8217;s a Linux
http://www.lanana.org for controlling things like major version numbers
for device files.</p>

<h2>Silicon Valley</h2>

<p>Turns out I never knew where it was: it&#8217;s the southern portion of the
San Francisco bay area.</p>

<h2>Disk Partitions</h2>

<p>Hard disks have platters, platters have tracks of data, split into
sectors, split into physical blocks.</p>

<p>Platters > data > sectors > blocks.</p>

<p>Blocks are the smallest unit of data a driver can read/write. They&#8217;re
usually 512 bytes.</p>

<p>Disk partitions are treated by the kernel as separate devices in
<code>/dev</code>.</p>

<p>Partitions might consist of</p>

<ul>
<li>a file system</li>
<li>totally raw data (some databases do this)</li>
<li>swap area used by kernel for VM</li>
</ul>


<p>File system on disk is composed of</p>

<ul>
<li>Boot block: how to boot the OS</li>
<li>Superblock: single block saying:

<ul>
<li>size of inode table</li>
<li>logical block size (always a multiple of physical block)</li>
<li>size of the system in logical blocks</li>
</ul>
</li>
<li>inode table / ilist</li>
<li>data blocks</li>
</ul>


<p><code>ext2</code> is special in that it breaks down data blocks into block groups
and prepends a copy of the super block to each to minimize seeks.</p>

<p><code>ls -li</code> shows inode number in first column. inodes contain:</p>

<ul>
<li>file type</li>
<li>owner</li>
<li>group</li>
<li>access perms</li>
<li>timestamps

<ul>
<li>last access</li>
<li>last mod</li>
<li>last status change</li>
<li>(but not a created at? WEIRD. must be a linux thing; mac has this)</li>
</ul>
</li>
<li>number of hardlinks</li>
<li>size of file in bytes</li>
<li>number of blocks allocated (might be less than expected due to holes)</li>
<li>pointers to blocks</li>
</ul>


<p>Note that there is a tradeoff between fragmenting freespace into small
chunks that are too small to use vs fragmenting data blocks so that all
free small chunks can be used.</p>

<p>ext2 has 15 pointers, 12 of which are data block pointers, the next
which points to a block of pointers, the next which points to a an array
of block pointers, and then a tertiary one for large fucking files.</p>

<p>This (using blocks for inode indirection) allows for fixed size
of inode table.</p>

<h2>TLDP</h2>

<p>The Linux Documentation Project</p>

<blockquote><p>LDP is a loosely knit team of volunteers who provide documentation for many aspects of Linux. There are several forms of documentation: Guides, HOWTOs, man pages, and FAQs.</p></blockquote>

<p>That&#8217;s nice.</p>

<h2>McRouter</h2>

<p>https://www.youtube.com/watch?v=EYhcumt8YyI</p>

<p>A &#8220;memcache protocol router, for scaling memcache deployments&#8221;.</p>

<p>Two forms of caching at facebook:</p>

<ul>
<li>demand-filled cache

<ul>
<li>fetch from memcache with key. if not there, fetch from db, then set
memcache w key. all of this logic on webserver</li>
</ul>
</li>
<li>read-through / write-through cache

<ul>
<li>TAO system; query TAO, and if it&#8217;s not there, <em>it</em> fetches from DB
on your behalf</li>
</ul>
</li>
</ul>


<p>Both share the following in common: two orders of magnitude more reads
than writes.</p>

<p>Cache becomes bottleneck, extremely crucial or whole site fails.</p>

<p>Having inconsistent implementations of memcache libs might result in
data loss. So, anyway, McRouter to the rescue. It:</p>

<ul>
<li>is a proxy between memcache client and server (adheres to same ol API,
makes for good drop-in replacement)</li>
<li>also an embedded mode for low latency</li>
<li>a load balancer</li>
<li><a href="http://en.wikipedia.org/wiki/Consistent_hashing">consistent hashing</a>
(where hash table resizes minimize the amount of remapping:

<ul>
<li>Consistent hashing maps objects to the same cache machine, as
far as possible. It means when a cache machine is added,
it takes its share of objects from all the other cache
machines and when it is removed, its objects are shared
between the remaining machines.</li>
</ul>
</li>
<li>connection pooling (presumably this means connections are maintained
by mcrouter to the memcache instances and loaned out when mcrouter
clients make queries, rather than slowly reopening connections each
time)</li>
<li>Server pools&#8230; I guess this means multiple instances of McRouter?</li>
<li>Automatic failover</li>
<li>Cold cache warmup</li>
<li>Broadcast operations</li>
<li>Replicated Data Sets</li>
</ul>


<p>Connection Pooling:</p>

<p>Application threads share McRouter&#8217;s N connections to the memcache
instances, rather then each thread creating N connections resulting in
<code>N*T</code> total connections.</p>

<p>Heterogeneous workloads:</p>

<p>Prefixed keys get routed to specific memcache instances, I guess, rather
than having them all on the same things getting clobbered by others.</p>

<p>Automatic failover:</p>

<p>Normal server, fail over to backup when error returned, timeout,
ECONNREFUSED, etc, with probing to see when it can be reconnected.</p>

<p>Twitter <code>twemproxy</code> is similar to McRouter.</p>

<h4>Reddit infrastructure</h4>

<ul>
<li>AWS</li>
<li>170-300 servers daily (scales in peak hours)</li>
<li>73 cache nodes with 1TB memory</li>
<li>App code fragile-y uses memcache</li>
</ul>


<h4>Reddit Scaling Issues</h4>

<p>AWS constantly releases lovely new instance types, but Reddit can&#8217;t just
hop onto them without testing them out.</p>

<h2>NTFS</h2>

<p>New Technology File System, as in, Windows NT.</p>

<h2>VFS</h2>

<p>Virtual File System: the unified kernel abstraction, providing familiar
things like <code>read()</code>, <code>write()</code>, etc.</p>

<h2>Journaling</h2>

<p>If an OS running ext2 crashes, you need to run <code>fsck</code> (filesystem check)
to make sure inode entries point to real things, etc., else you run the
risk of breaking more shiznittletons.</p>

<p>Journaling FS&#8217;s imply basic database transactions. All intended metadata
writes are written to a journal file first before they&#8217;re performed, and
if the operation is interrupted by a crash, recovery is quick. Actually,
could just be metadata or full on everything data.</p>

<h2>OS X</h2>

<p>Macs use something called HFS Plus, or Mac OS Extended.</p>

<ul>
<li>lots of metadata</li>
<li><p>case-preserving though case-insensitive</p>

<p>  machty.github.com :: cat woot
  lol
  machty.github.com :: cat WOOT
  lol</p></li>
<li><p>journaling</p></li>
</ul>


<h2>mount</h2>

<p><code>mount</code> and <code>unmount</code> will attach a file system to a specified
directory.</p>

<p>KEEP IN MIND DINGUS this &#8220;mount&#8221; concept is all over the place. Mount
routes. Mount external thing blah.</p>

<p><code>unmount2</code> is <code>unmount</code> with flags.</p>

<p>You can mount in multiple mount points.</p>

<pre><code>mount /dev/sdva123 /dumbness
</code></pre>

<p>A device is not accessible as a file system until you mount it. You
couldn&#8217;t just do <code>cd /dev/sdva123</code>. You have to mount it first.</p>

<p>Just realized something: the EBS provided to your EC2 instance could be
formatted into any file system. FUCK IT let&#8217;s do ext4.</p>

<p>mounts can be stacked on top of the same mount point. This makes it
possible to migrate off of an old mount; old processes maintain their
file handles on the old mount, new processes use the new fs, and
eventually you can retire the old mounted fs that&#8217;s not at the top of
the stack. Kinda nifty, weird as it sounds.</p>

<h2>Basic <code>cat</code> shit</h2>

<p>If you want to type some random shit into a new file, do</p>

<pre><code>cat &gt; lolz
</code></pre>

<p>and then you can type into cat&#8217;s STDIN and then Control D to signal EOF.</p>

<h2>kitchen sink of disk utils</h2>

<p>What&#8217;s the difference between all these shits?</p>

<ul>
<li>fdisk: manipulate disk partition table</li>
<li>df: report file system disk space usage</li>
<li>mkfs: build a linux filesystem</li>
</ul>


<h2>tmpfs</h2>

<p>Virtual memory file system. But the thing about virtual memory is that
unused portions might get paged to a swap file on the disk&#8230; so it&#8217;s
not just strictly memory.</p>

<pre><code>sudo mkdir ./wat
sudo mount -t tmpfs StupidName ./wat
</code></pre>

<p><code>tmpfs</code> doesn&#8217;t exist on Mac OS X though some other form probably does.</p>

<p>It&#8217;s used to speed up applications like compilers that make heavy use of
<code>/tmp</code>.</p>

<p><code>tmpfs</code> has also had other use cases, such as implementing shared
memory (System V) and the <code>glibc</code> implementation of POSIX shared memory
and POSIX semaphores.</p>

<h2>Ableton Live</h2>

<ul>
<li>Opt-shift-B: hide Browser</li>
</ul>


<p>Arrangement view is the classic multi track view. You can disable
portions of the mixer that you don&#8217;t care about.</p>

<ul>
<li>IO (opt + command + i): input/output for this track

<ul>
<li>Input type (device, e.g. M-Audio Whatchufuck)</li>
<li>Input channel (devices often have multiple)</li>
<li>Monitoring (radio button basically)

<ul>
<li>In (enable monitoring of input)</li>
<li>Auto (only enable when track is armed - not just when actively
recording)</li>
<li>Off</li>
</ul>
</li>
</ul>
</li>
<li>Delay (no shortcut)

<ul>
<li>delay/predelay to compensate for device/hardware/whatever latency</li>
</ul>
</li>
<li>Mixer (opt + command + m)

<ul>
<li>Activate/deactivate (mute) the track</li>
</ul>
</li>
<li>Return tracks

<ul>
<li>Note that if you tab into clip view (?) then the R button splits
into S and R.</li>
</ul>
</li>
</ul>


<p>Note the master track at the bottom. The Preview/Cue volume controls the
metrononme. Not sure what else Cue refers to&#8230;</p>

<p>Count-in is attached to the metronome menu.</p>

<p>Opt+unfold (triangle button) to unfold all them shits.</p>

<p>You can arm multiple tracks with command+click.</p>

<p>Impulse is an Ableton instrument. Instrument Racks are combinations of
the Impulse instrument with certain pre-saved audio effects.</p>

<h3>Quantize</h3>

<p>This doesn&#8217;t seem to refer to individual notes in a midi recording but
rather for playback between clips; when you press the play button by a
clip, it doesn&#8217;t immediately play unless you have it turned off (which
can result in crazy timing issues). Also, even if you Command-0 to turn
it off and get shit out of sync, if you Command-9 back to one bar and
play a new track, it&#8217;ll make sure it starts in sync with the metronome
(what else could it be? clips don&#8217;t have meter, just a length).</p>

<p>Ah but if you do want per note quantization you can do it a) while
recording, by going to Edit > Record Quantization.</p>

<p>Then if you already recorded something unquantized, you can Command-U.</p>

<h3>Recording clips</h3>

<p>If you create an empty clip, that clip has a size, as all do, so you&#8217;ll
be recording within a loop.</p>

<p>Whereas if you pressed the slot&#8217;s record button, there would be no fixed
length until you stopped recording. The Notes menu associated with that
clip (which has length info) doesn&#8217;t even appear until after the new
recording is finished. How grand!</p>

<h3>Looping</h3>

<ul>
<li>One-indexing: the quickly set things to the beginning of a clip, you
do 1 tab 1 tab 1, not 0 tab 0 tab 0 which&#8217;ll normalize to -1. But
lengths can have zero. 2 0 0 means two measures.</li>
<li>Known trick: 0 0 16 will normalize into 1. If it&#8217;s more convenient to
think in terms of odd meters, this could be useful&#8230; INSTANT
MESHUGGAH.</li>
<li>When loop enabled, normal end is meaningless. When loop disabled, all
loop info is useless. (Though these details still seem to be
displayed.</li>
</ul>


<p>Place insert markers just by clicking the grid.</p>

<p>You can manually copy and paste or you could DuplLoop. DuplLoop also
conveniently works such that if you duplicate into notes you&#8217;ve already
written, they&#8217;re overwritten, rather than dubbed or something cray cray.</p>

<h3>Hotswapping</h3>

<p>Constrasted with double-clicking a new instrument in the Browser,
hotswapping seems to:</p>

<ul>
<li>preserve the rest of the devices you might have attached to the
instrument you&#8217;re hotswapping.</li>
<li>open the browser to the current devices folder; relevant for quickly
finding the thing you want to switch out.</li>
</ul>


<p>Weird that they make such a big deal out of it (do they, or am i just
saying).</p>

<h2>SHIT IS EBS BACKED, DUMMY</h2>

<p>Root device type: ebs</p>

<p>Root device: <code>/dev/xvda</code></p>

<p><code>#NotAllEC2InstancesStartOffWithEphemeralStorage</code></p>

<h2>Helicopter parent</h2>

<p>http://en.wikipedia.org/wiki/Helicopter_parent</p>

<p>A hovery overbearing parent who&#8217;s still around even when kids have gone
to college.</p>

<p>Thought it might mean when you&#8217;re a parent who drops in every so often,
or drops in on other kids. Nope.</p>

<h2>Geocoder can&#8217;t have radiuses be stored on the row</h2>

<p>The bounding box is calculated before the SQL is fired&#8230; then again
there&#8217;s all sorts of sin/cos shit going on, but all to translate into
something that can be compared against that box.</p>

<h2>College</h2>

<p>http://www.nytimes.com/2014/05/18/magazine/who-gets-to-graduate.html</p>

<p>Community College:</p>

<p>Means different things depending on the country, but in America it
usually means a two-year public institution, often granting certificates
and associate&#8217;s degrees (two-year degrees).</p>

<p>Dropout rate is apparently 40%, and if you include community college
dropouts, we&#8217;re the worst other than Hungary.</p>

<p>Rich kids are more likely to graduate (90% of the upper quartile of
income), whereas 25% of the lower half will expect to graduate by 24.</p>

<p>College students who scored the same on standardized tests still have
educational outcomes (graduation rates) that correlate with family
wealth.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Shnurgle]]></title>
    <link href="http://machty.github.com/blog/2014/09/27/daily-shnurgle/"/>
    <updated>2014-09-27T09:29:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/27/daily-shnurgle</id>
    <content type="html"><![CDATA[<h2>lseek</h2>

<p>&#8220;long&#8221; (int) seek. There used to just be a <code>seek</code> that took a smaller
int.</p>

<p>You can seek past EOF and the kernel will be fine with it; reads yield 0
and set EOF flag, but writing will cause a &#8220;file hole&#8221; to exist, wherein
null bytes are returned but aren&#8217;t actually written to disk until
someone writes into the hole.</p>

<pre><code>File.open("seektestfile", "r+") do |f|
  f.write("begin")
  f.seek(10, IO::SEEK_SET)
  f.write("end")
end
</code></pre>

<p>Then open <code>seektestfile</code> in vim to see the null bytes. Pretty rad. But
again keep in mind that those null bytes aren&#8217;t actually there on disk
(well actually I guess it&#8217;s up to the kernel to figure out whether the
hole is large enough to warrant the overhead of splitting into a
different block; some file systems don&#8217;t offer file holes at all).</p>

<p>A file is just a collection of allocated disk blocks. No guarantee their
in the same order. But you could use <code>posix_fallocate</code> to reserve
multiple blocks even if you&#8217;re writing to different places in it to make
sure that future writes will succeed rather than risk some other
application filling a hole and blah.</p>

<p>How many bytes in a block/sector in OS X? <code>diskutil info /</code> reveals
(among other things):</p>

<pre><code>Device Block Size:        512 Bytes
</code></pre>

<p>That&#8217;s the hardware block size, which can be different than the file system
block size (the fs block size must of course be >= device block size).</p>

<p>The <code>stat</code> command tells you information about files, like their size n
shit. It has a format option which is like printf. You could be like
<code>stat -f "hello world"</code> and &#8220;hello world&#8221; would be the output, having
run <code>lstat</code> on STDIN and printing out no actual information about it.</p>

<p><code>ioctl</code> is useful for special-cased IO scenarios, like controlling a
terminal device special file. You pass it an op code which determines
what the remaining parameters are.</p>

<h2>syscalls and atomicity</h2>

<p>Examples of system calls that accept flags to ease race condition pain:</p>

<ol>
<li><code>O_EXCL</code> when opening a file throws an error if it already exists;
otherwise you&#8217;d have to try and open it (to see if it exists), and
then try to create it if it doesn&#8217;t, in which time another process
could have come in and created it. <code>O_EXCL</code> guarantees that if the
open succeeds, that process is the owner of the new file.</li>
<li><code>O_APPEND</code> opens a file AND moves its pointer to the end in one shot,
otherwise two processes trying to append might clobber each other
between their <code>seek</code> and <code>write</code>s. Some systems like NFS don&#8217;t
support it and are prone to this race condition. WRONG. I wrote the
wrong thing. <code>O_APPEND</code> actually works by opening the file, flagging
it in such a way that all writes also atomically include an EOF seek.
If <code>O_APPEND</code> worked the way I first described (an <code>open</code> + a
<code>seek</code>), the race condition described could still happen.</li>
</ol>


<h2>File descriptors vs open files</h2>

<p>You can have multiple file descriptors point to the same open file. This
for example happens automatically every time you fork a program (its FDs
get dup&#8217;d).</p>

<p>The kernel maintains</p>

<ul>
<li>a per-process table of descriptors

<ul>
<li>close-on-exec flag</li>
<li>reference to the system-wide open file description</li>
</ul>
</li>
<li>a system-wide table of open file descriptions (the open file table)

<ul>
<li>current file offset (from reads/writes/seeks)</li>
<li>status flags from when the file was open()ed (read-only, etc)</li>
<li>reference to the i-node</li>
</ul>
</li>
<li>file system i-node table</li>
</ul>


<p>Note that there&#8217;s an on-disk i-node and an in-memory i-node that has a
lot more information about locks and other kernel-specific things that only make sense
to open files rather than just static files living on a disk somewhere.</p>

<p><code>fork</code>ing and UNIX domain sockets are two (of many? maybe?) ways for two
processes to have a file descriptor that points to the same system wide
descriptions.</p>

<p>I originally thought the file offset was stored per descriptor, but
apparently it lives in the shared description record? Only one way to
find out:</p>

<pre><code>File.open('shareddesctest.txt', 'w') do |f|
  if fork
    # parent
    f.seek(1, IO::SEEK_SET)
    Process.wait
  else
    # child
    sleep 1
    f.write "wat"
  end
end
</code></pre>

<p>If I open vim, I see <code>^@wat</code>, which means in fact the offset is shared:
parent seeks to offset 1, child waits for this to happen, and then
writes to a file descriptor it hasn&#8217;t touched yet, and it starts writing
at where the parent <code>seek</code>ed to. So indeed offsets are stored in the
shared system-level open file description.</p>

<h2>Redirection and dup2</h2>

<p><code>./a.out &gt; wat 2&gt;&amp;1</code> will pipe both STDOUT and STDERR into the <code>wat</code>
file, using a single system-level file description. How does this work?
Pretty hilariously-jankly.</p>

<ul>
<li>File descriptors are just integers (stdout=1, stderr=2)</li>
<li>To redirect stderr to stdout, you have to duplicate stdout&#8217;s file
descriptor but make sure that that final descriptor has a value of 2,
so that code that writes to stderr (2) is unaffected and will
successfully keeping writing to the newly redirected stream.</li>
<li>File descriptor integers are reused; the various syscalls that
allocate file descriptors always choose the smallest unused file
descriptor int.</li>
<li>So you could 1. close stderr and 2. dup stdout, and this would work,
but not if stdin (0) had already been closed, since the new handle
would take the lower value 0. LOL.</li>
<li>So you have to use <code>dup2</code>, which lets you specify the number of the
file descriptor you&#8217;d like to allocate. Which is what shells with
stream redirection support. :)</li>
</ul>


<p>Duping FDs can also be done w <code>fcntl</code> and <code>F_DUPFD</code>.</p>

<h2>IO at specific offset</h2>

<p>Good for concurrent processes in some cases, you can use <code>pread</code> and
<code>pwrite</code> to perform IO at a specific offset without modifying the file
pointer.</p>

<p>A single syscall is way more performant than multiple ones, hence the
value in <code>pread</code> and friends. You also sidestep certain race conditions.
Then again the time to do IO often dwarfs syscall overhead.</p>

<h2>Scatter IO</h2>

<p><code>readv</code> reads a contiguous chunk of data from a file descriptor and
distributes into multiple buffers supplied to the syscall. <code>writev</code>
writes a contiguous chunk of data to the file.</p>

<p>This avoids certain race conditions, allows you to combine multiple
reads/writes.</p>

<h2><code>/dev/fd</code></h2>

<p>Virtual directory of file descriptors, e.g. 0, 1, 2 (stdin, stdout,
stderr, and some others). Useful for passing a command line utility a
filename when you really want it to read from stdin, e.g.</p>

<pre><code>echo 'wat' | diff /dev/fd/0 olderwat
</code></pre>

<p>Note that you could also do process substitution:</p>

<pre><code>diff &lt;(echo 'wat') olderwat
</code></pre>

<p>which has the same effect but creates a new descriptor rather than
reusing the stdin descriptor.</p>

<p>Note that these process subsitution file handles also live in <code>/dev/fd</code>:</p>

<pre><code>echo &lt;(echo wat) 
# /dev/fd/63
</code></pre>

<h2>&#8220;Header Search Paths&#8221; vs &#8220;User Header Search Paths&#8221;</h2>

<p>User: <code>#include "wat.h"</code>
Non-user: <code>#include &lt;wat.h&gt;</code></p>

<h2>Process vs Program</h2>

<p>A Process is an instance of a Program. A Program is a description of how
to construct a Process.</p>

<p>Program consists of:</p>

<ul>
<li>Binary format ID: describes the format of the executable.</li>
<li>Machine code</li>
<li>Program entry point address; address to <code>int main</code>, or something that
quickly calls <code>int main</code>.</li>
<li>data (constants, default starting values)</li>
<li>symbol/relocation tables: locations and names of functions, for
debugging purposes but also dynamic linking</li>
<li>shared libs: list of dynamic libs for run time linking</li>
</ul>


<p>A process has an initialized data segment and uninitialized data
segment. The former contains all starting values for a program, hence
it&#8217;s stored in disk space, whereas uninitialized data gets initialized
at process start up through a more dynamic process and hence the space
it occupies doesn&#8217;t need to be stored on disk. Uninitialized data gets
zeroed out.</p>

<ul>
<li>Program break: the &#8220;top&#8221; of the heap</li>
</ul>


<p>Application Binary Interface (ABI) set of rules for what registers are
set, etc., when interacting with some low-level service, like the
kernel. SUSv3 standardizes this API so that you&#8217;re using a higher level
than some ultra low level API.</p>

<h2>Locality of reference</h2>

<p>In regards to memory access and optimizations based thereupon.</p>

<ul>
<li>spatial locality: tendency for memory accesses to be near recent
memory accesses (e.g. traversing a data structure, sequential
execution of code)</li>
<li>temporal locality: tendency to access a recently accessed location
(e.g. a loop)</li>
</ul>


<p>This is part of what makes virtual memory possible; it&#8217;s largely pretty
rare to suddenly need to access a non-resident page.</p>

<p>Each process has a page table, which maps pages to their physical RAM
locations. If you access a page that&#8217;s not in RAM, then page fault
occurs (kernel takes over).</p>

<p>Not all virtual memory address regions have a corresponding page, in
which case, SIGSEGV.</p>

<p>The range of valid virtual addresses changes as the stack grows and more
stuff is allocated on the heap (malloc). Also when you run <code>mmap</code>.</p>

<p>Virtual memory requires hardware support, specifically a Paged Memory
Management Unit, which needs to be smart enough to do address
translating but also notify the kernel of page faults.</p>

<p>VM keeps memory isolated between processes unless you really really want
to share: <code>shmget</code> and <code>mmap</code> let you do this as a means of
Inter-Process Communication. It works by having page table entries point
to the same region of RAM, allowing for the different process page table
entries to have different permissions, e.g. one process might have read
access but other has write access to the same page frame in physical
memory.</p>

<p>There&#8217;s a per-process kernel stack which maps to kernel RAM and is
therefore inaccessible when not in kernel mode. This is used for syscall
stacks. I need to read more about this; why can&#8217;t there be a system-wide
kernel stack shared between processes? Isn&#8217;t only one process going to
be in kernel mode at any given time? Maybe not&#8230; if multiple processes
are blocked on IO, does that mean they&#8217;re all in kernel mode? TODO: come
back to dis shiz.</p>

<h2>argv argc</h2>

<p><code>argv[0]</code> is the process name which can be used to switch the behavior
of multiple commands that all point to the same executable.
<code>gzip/gunzip/etc</code> is an example of this. <code>ls -lai</code> yields:</p>

<pre><code>343041 -rwxr-xr-x  4 root  wheel  43200 Oct 31  2013 /usr/bin/gzip
343041 -rwxr-xr-x  4 root  wheel  43200 Oct 31  2013 /usr/bin/gunzip
</code></pre>

<p>Same inode 343041. Here&#8217;s all of em (<code>find /usr/bin -inum 343041</code>):</p>

<pre><code>/usr/bin/gunzip
/usr/bin/gzcat
/usr/bin/gzip
/usr/bin/zcat
</code></pre>

<p>Apparently there&#8217;s no easy way to find all the files that link to an
inode (the above was simple only because they all happened to be in the
same directory).</p>

<p>Note that you can&#8217;t hard-link directories.</p>

<p>Short of stashing global vars, you can&#8217;t access argv and argc (Ruby
facilitates this for you though), unless you&#8217;re willing to do some
non-portable stuff.</p>

<pre><code>kernel
argv,environ
stack
...
heap
uninitialized data
initialized data
text (program code)
...?
</code></pre>

<p><code>argv</code> lives right above the stack.</p>

<h2>env vars</h2>

<p>If you just do</p>

<pre><code>wat=lol
</code></pre>

<p>that sets a shell variable, not strictly an env var tied to the shell
process that gets with children. Functionally, it&#8217;s an environment var
that doesn&#8217;t get passed to children when forked.</p>

<p>You could then put it into the process env via</p>

<pre><code>export wat
</code></pre>

<p>or in one shot</p>

<pre><code>export wat=lol
</code></pre>

<p>You can set a child processes env var (without polluting parent shell
variable list or environment vars) via</p>

<pre><code>wat=lol somecommand
</code></pre>

<p>in which case ARGC for somecommand will be 0. If you did</p>

<pre><code>somecommand wat=lol
</code></pre>

<p>ARGC would be 1, and ARGV[1] would be &#8220;wat=lol&#8221; rather than an env var.</p>

<p>Order of env vars is implementation specific; you don&#8217;t want to rely on
this shiznittletons.</p>

<h2>Streams and LazyValue</h2>

<p>LazyValue is coming to Ember along with HTMLbars. LazyValues are a kind
of / relative of Observables, with the unique feature that they avoid
the back pressure of pushing values into the stream by merely replacing
the current value and notifying an end consumer that the stream has been
invalidated, letting the final consumer decide when it should consume
and actually flush the lazy value through all of its transformations.</p>

<p>I was wondering what the technical term for a stream that doesn&#8217;t mind
&#8220;dropping&#8221; &#8220;samples&#8221; before it has a chance to consume the latest value.
Apparently the word for that is a &#8220;signal&#8221;&#8230;?</p>

<h2>brk and sbrk</h2>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;

int main() {
  void *curBrk;

  for (int i = 0; i &lt; 1; ++i) {
    curBrk = sbrk(0);
    printf("brk is %p\n", curBrk);
  }

  return 0;
}
</code></pre>

<p>brk sets the brk lowest address of a process&#8217;s data segment
(uninitialized) to addr.</p>

<p>These are mad deprecated. Use malloc. Malloc will grow the heap for you
rather than making you set the break. <code>free</code> won&#8217;t shrink the break but
rather just return a chunk to the free list. Why?</p>

<ul>
<li>most frees are in the middle of the heap (as opposed to the edge,
where shrinking the break makes sense)</li>
<li>syscalls are expensive</li>
</ul>


<p>Mac OS X specifics: just from a few experiments I can verify that the
stack grows downward, the break is really small, but malloc seems to be
producing pointer values much closer to the stack than the break. What
gives? No idea.</p>

<p><code>free(NULL)</code> is a noop. <code>malloc(NULL)</code> might return a small piece of
memory that can be freed.</p>

<p><code>malloc</code> scans the free list for something >= the required amount. If >
than the required amount, the free block is split. Different
implementations might be first-fit or best-fit. If nothing found, <code>sbrk</code>
is called to increase it, by some multiple of the virtual memory page
size.</p>

<p><code>free</code> knows the size of the block to free because malloc sneakishly
inserts the length at the beginning of a chunk of allocated memory.</p>

<p>Wow, the algorithm for free and malloc is pretty awesome.</p>

<p>Let&#8217;s see nothing&#8217;s been allocated on the heap. Your free list is a
single element doubly-link list</p>

<pre><code>|Length of Block|prevBlock*|nextBlock*|empty space|
</code></pre>

<p>Then you <code>malloc(4)</code>. It&#8217;ll start at the beginning of that list, see
that <code>4</code> is less than the length of the block, and then it&#8217;ll split that
block. Hmm, so the pointer to the free list needs to remain the same&#8230;
so either malloc&#8217;d block could get put at the end, length of block is
decremented. Yeah that&#8217;s probably how it works.</p>

<p>TL;DR: the free list is a doubly-linked list whose nodes are stored in
the same chunk of memory that&#8217;ll be distributed when mallocs occur. I
always wondered where the &#8220;free list&#8221; lived&#8230; it seemed like one of
those problems where it&#8217;d be mallocs all the way down, but this is
a pretty elegant solution, but it also explains how quickly shit can go
haywire if you accidentally futz with freed values.</p>

<p>The specific algorithm can vary; glibc uses a boundary tag approach,
wherein an allocated chunk includes size of previous chunk, size of
current chunk, and then user space, then size of chunk.</p>

<p>So how are SIGSEGVs detected on double-frees?</p>

<p>http://www.opensource.apple.com/source/Libc/Libc-594.1.4/gen/malloc.c</p>

<p>I think Apple&#8217;s version of malloc tracks allocated blocks (rather than
just a free list). So it&#8217;ll loop through that list and make sure it&#8217;s
actually in there. I think glibc see does something else, where it loops
through the free list to see if it&#8217;s already in there? Or some other
efficient thing using the boundaries stored in adjacent blocks? Unsure.</p>

<p><code>alloca</code> lets you dynamically allocate on the stack by moving the stack
frame pointer downward. It gets &#8220;collected&#8221; one you return from the
function. Not standardized but most systems have it? It&#8217;s useful if
you&#8217;re actually writing a program that necessitates <code>longjump</code> since
heap-allocated memory in the stack frames you&#8217;re skipping over can&#8217;t
possibly be freed, but you get the &#8220;free&#8221; for free if it was allocated
via <code>alloca</code>. That being said, you probably shouldn&#8217;t use it. :)</p>

<h2>Users and Groups</h2>

<p>You can have multiple usernames/passwords map to the same UID. This
means multiple users can be granted the exact same privileges by nature
of them literally being distinguishable by username but not UID.</p>

<p><code>wheel</code> comes from the phrase &#8220;big wheel&#8221; (&#8220;she&#8217;s a big wheel at
Microsoft&#8221;), it refers to a group with admin privileges. <code>admin</code> is
also one such group. <code>root</code> is a member of both:</p>

<pre><code>wheel:*:0:root
admin:*:80:root
</code></pre>

<p>On Mac OpenDirectory is used instead; you can see all of the
<code>/etc/group</code> groups in Directory Utility. <code>wheel</code> is System Group,
<code>admin</code> is Administrators, and there&#8217;s a bunch of other ones specific to
applications, which seem to be prefixed via underscore blah blah blah
who cares.</p>

<h2>groups, permissions</h2>

<p>A process with effective user ID of 0 is a <em>privileged process</em>.</p>

<p>A process starts off with a real user and group ID and can change its
effective user and group ID.</p>

<p>Processes that don&#8217;t start off with the privileges they need can be
granted the ability to set their effective user and group ids, but only
to the owner or group, e.g. I, user <code>peon</code>, can execute <code>a.out</code> (if it
has <code>a+x</code> perms) and have <code>a.out</code> grant itself the permissions that its
owner has.</p>

<pre><code>machty.github.com :: ls -la wat
-rw-r--r--  1 machty  staff  0 Sep 28 09:23 wat
machty.github.com :: chmod u+s wat
machty.github.com :: ls -la wat
-rwSr--r--  1 machty  staff  0 Sep 28 09:23 wat
</code></pre>

<p>The capital <code>S</code> means set-user-id-able but non-executable (this is rare
and maybe useless?). If I do <code>chmod u+x wat</code> it becomes:</p>

<pre><code>-rwsr--r--  1 machty  staff  0 Sep 28 09:23 wat
</code></pre>

<p>If I set group, it&#8217;d be the next column of bits.</p>

<p>Note that there&#8217;s no setUID call that the process has to make to enter
this mode; rather, the bit causes the kernel to set the effective user
or group ID once the process begins to run.</p>

<p>Here&#8217;s all the <code>/usr/bin</code>s that have set-user-id</p>

<pre><code>machty.github.com :: ls -la /usr/bin | grep '^...[Ss]'
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 at
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 atq
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 atrm
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 batch
-rwsr-xr-x     1 root   wheel     35136 Oct 31  2013 crontab
-rws--x--x     1 root   wheel     23008 Oct 31  2013 ipcs
-r-sr-xr-x     1 root   wheel     68240 Mar 10  2014 login
-r-sr-xr-x     1 root   wheel     44416 Mar 10  2014 newgrp
-r-sr-xr-x     1 root   wheel     19664 Oct 31  2013 quota
-r-sr-xr-x     1 root   wheel     20720 Mar 10  2014 rlogin
-r-sr-xr-x     1 root   wheel     19856 Mar 10  2014 rsh
-rwsr-xr-x     1 root   wheel     21488 Oct 31  2013 su
-r-s--x--x     1 root   wheel    164896 Oct 31  2013 sudo
-r-sr-xr-x     1 root   wheel     83856 Oct 31  2013 top
</code></pre>

<p>and all the set-group-ids</p>

<pre><code>machty.github.com :: ls -la /usr/bin | grep '^......[Ss]'
-rwxr-sr-x     1 root   mail      24640 Oct 31  2013 lockfile
-rwxr-sr-x     1 root   mail      84656 Oct 31  2013 procmail
-r-xr-sr-x     1 root   tty       20832 Mar 10  2014 wall
-r-xr-sr-x     1 root   tty       19920 Oct 31  2013 write
</code></pre>

<p><code>wall</code> writes some nonsense to everyone&#8217;s terminal: <code>echo wat | wall</code>.</p>

<p>Processes have the ability to switch in and out of their set-uids and
set-group ids. In other words, a program might have its set-uid enabled
(and its owner is root), but it&#8217;s bad/unsafe practice to let a program
just run in root mode the whole time; rather, it should only switch into
root mode when doing stuff that requires privileges, and then switch
back.</p>

<p>In Linux there&#8217;s also the concept of file-system IDs and groupd IDs,
which follow effective ID/group except when <code>setfsuid</code> and <code>setfsfid</code>
are called. But they&#8217;re seldom used. They only exist to cover use cases
of <code>NFS</code>.</p>

<h2>Ruby Base64</h2>

<pre><code>require 'base64'
Base64.encode64("borf") # =&gt; "Ym9yZg==\n"
Base64.strict_encode64("borf") # =&gt; "Ym9yZg=="
</code></pre>

<ul>
<li><code>encode64</code> implements the base64 referenced in
<a href="https://www.ietf.org/rfc/rfc2045.txt">IETF 2045</a>,
the RFC on Multipurpose Internet Mail Extensions (MIME).</li>
<li><code>strict_encode64</code> implements the base64 specified
in <a href="http://tools.ietf.org/html/rfc4648">IETF 4648</a>, which
goes into more detail, gets rid of the newlines</li>
</ul>


<p>I used to have to do <code>gsub(/\n/, "")</code> after encoding to get Ruby&#8217;s
<code>encode64</code> to be compatible with some other that was more picky about
Base64.</p>

<p>Also, I was wondering why the <code>==</code> exist. Base64 converts any bytestream
to a 64 bit alphabet. In other words, 2<sup>6</sup> characters. Consider the
following random 3 byte stream:</p>

<pre><code>01011010 00001111 10101111
</code></pre>

<p>We&#8217;re used to thinking of them split by 8 bits, but a base64 character
can only account for 6 bits, so you&#8217;d actually think of it like:</p>

<pre><code>010110 100000 111110 101111
</code></pre>

<p>This explains why encoding as base 64 has a 4/3 size overhead, an
important consideration before willy nilly encoding a bunch of giant
assets at base 64.</p>

<p>It also explains why encoding strings whose lengths aren&#8217;t a multiple of
3 end up adding <code>=</code> padding (&#8220;borf&#8221; => &#8220;Ym9yZg==\n&#8221;).</p>

<h2><code>ls -d</code></h2>

<p>e.g. <code>ls -ld somedir</code> to show the directory entry rather than expanding
it and listing all of its files.</p>

<h2>Y2K for epoch 32 bit = year 2038</h2>

<p>The epoch + 32 bit signed int max = year 2038.</p>

<h2>Service Workers</h2>

<p>http://www.w3.org/TR/service-workers/#motivations</p>

<p>https://github.com/slightlyoff/ServiceWorker/blob/master/explainer.md</p>

<p>Alex Russell&#8217;s been working on this. It&#8217;s a huge improvement over the
declarative app cache. A ServiceWorker is a WebWorker that can get
installed on page load, and then once installed, is consulted on future
page loads, even if there isn&#8217;t any internet.</p>

<blockquote><p>Documents live out their whole lives using the ServiceWorker they start with.</p></blockquote>

<p>This means if no service worker existed at initial doc download, then
installing a ServiceWorker on the first load means the ServiceWorker
will have to completely sit out for the lifetime of that page. It&#8217;s only
on feature reload where it might get consulted. This slightly off
behavior results in:</p>

<ul>
<li>better fallback for unsupporting browsers</li>
<li>makes sure that people write good URLs whether using ServiceWorkers
or not</li>
<li>Zalgo issues with pages suddenly switching in and out of being managed
by a ServiceWorker</li>
</ul>


<p>Other things of note:</p>

<ul>
<li>ServiceWorkers can die, be aborted, be restarted</li>
<li>So don&#8217;t write them to be stateful.</li>
<li>Or if so, use IndexedDB. (If ServiceWorkers are available, IndexedDB
is available)</li>
</ul>


<h2><code>od</code>: octal decimal dumps</h2>

<pre><code>echo "a" | od

0000000    005141
0000002
</code></pre>

<p>I&#8217;d expect just one stupid byte, why are there multiples?</p>

<p>Oh duh because <code>echo</code> includes a newline.</p>

<pre><code>echo -n "a" | od 

0000000    000141
0000001
</code></pre>

<p>Wat.</p>

<pre><code>echo -n "aa" | od
0000000    060541
0000002
</code></pre>

<p>Oh right, this is an octal dump. Here&#8217;s binary</p>

<pre><code>echo -n "aa" | od -b
0000000   141 141
0000002
</code></pre>

<p>Makes more sense. The leftmost column is just a row indicator.
At some point it&#8217;ll wrap, and you always look at the last one for an
indicator of the length thus far.</p>

<pre><code>echo -n "big ass set of bytes" | od -b
0000000   142 151 147 040 141 163 163 040 163 145 164 040 157 146 040 142
0000020   171 164 145 163
0000024
</code></pre>

<p>See? It wraps automagically.</p>

<h2>cwd</h2>

<p>Processes have <code>cwd</code>s. They&#8217;re the starting point for filename lookups.
A shell&#8217;s current directory is that shell&#8217;s <code>cwd</code>. You can use
<code>getcwd(3)</code> to get the current one.</p>

<p>What&#8217;s the difference between <code>pwd</code> and <code>cwd</code>? <code>pwd</code> is a command that
stands for Print Working Directory. It prints the <code>cwd</code>. But it does so
with the <code>PWD</code></p>

<p><code>$PWD</code> is an env var you can check. <code>$OLDPWD</code> is set when you <code>cd</code> and
<code>cd -</code> uses it.</p>

<p>Soooo I believe the answer to everything is this: the kernel knows about
<code>cwd</code>, but doesn&#8217;t track the absolute path to it in string form; it&#8217;s
just a pointer, which is all it needs in conjunction with relative file
paths to locate and open/create/unlink files, etc.</p>

<p>Shells on the other hand provide a convenience built-in <code>pwd</code> and
expose/manage the <code>$PWD</code> var (et al) to provide a string.</p>

<h2>Hard-linking directories.</h2>

<p>Forbidden in most things, allowed in Mac OS X; twas responsible for
the data loss bug in Broccoli, since <code>rm -rf</code> ing a directory would
follow that link and kill shit.</p>

<p>Why does Mac allow it? Apparently it&#8217;s used in Time Machine. If a
directory hasn&#8217;t changed, a new snapshot can just point to the same
directory inode without duplicating it.</p>

<p>Great explanation: http://stackoverflow.com/a/4707231/914123</p>

<p>By the way <code>ln</code> and <code>link</code> are the same executable:</p>

<pre><code>$ ls -lai `which link`
11551 -rwxr-xr-x  2 root  wheel  14976 Oct 31  2013 /bin/link
$ ls -lai `which ln`
11551 -rwxr-xr-x  2 root  wheel  14976 Oct 31  2013 /bin/ln
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Snaggletooth]]></title>
    <link href="http://machty.github.com/blog/2014/09/23/daily-snaggletooth/"/>
    <updated>2014-09-23T11:18:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/23/daily-snaggletooth</id>
    <content type="html"><![CDATA[<h2>Nginx Heroku Buildpack</h2>

<p>https://github.com/ryandotsmith/nginx-buildpack</p>

<blockquote><p>Some application servers (e.g. Ruby&#8217;s Unicorn) halt progress when
dealing with network I/O.</p></blockquote>

<p>This was confusing at first but I think it just means that since
Heroku&#8217;s router only buffers headers and not the entire request, it&#8217;s
possible that a slow client with a large payload will hog a unicorn
worker due to a slow blocking <code>read()</code>, in which time that worker isn&#8217;t
available to process other requests.</p>

<p>The proposed nginx buildpack solution is to put nginx in front of an
IO-bound (and poorly designed/optimized) server and buffer the entire
request and not engage the app server until all the data is there, and
then it can barf the entire request into the app server in one shot,
minimizing blocking IO.</p>

<p>In general though Unicorn is non-ideal in the following cases:</p>

<ul>
<li>Slow client and/or large payload</li>
<li>The app server is internally IO-bound and makes, say, lots of long
slow 3rd party API requests, because in that time it&#8217;s blocking
requests that otherwise could have been handled in a less IO-bound
setting</li>
</ul>


<h2>TTL: Time to Live</h2>

<p>http://en.wikipedia.org/wiki/Time_to_live#IP_packets</p>

<p>Some reason I always pronounced &#8220;live&#8221; as a-live. Rather than the verb
&#8220;live&#8221;. Why? I don&#8217;t know. Time to Live (verb) makes way more sense. How
much time it has to live, rather than, how much time until it is live.
Ridiculous.</p>

<ul>
<li>IP: a per-gateway decrementing value (as opposed to a unit of time).
In other words: IP TTL is max hop.</li>
<li>DNS: time in seconds that a DNS record can be cached. Low values tax
authoritative name servers. Higher values risk staleness. 86400 (24
hours) is common. Before a DNS change, DNS admins might change to a
lower number in advance. QUESTION: why would I, selfish DNS admin, not
just choose a TTL of 1 all the time? Presumable answer: DNS is another
roundtrip unless cached; I might be making my application slower.
Additionally, if DNS goes down (probably rare?), my clients can
still use
<code>#networking</code> validates my presumable answer.</li>
</ul>


<h2>HTTPSAP</h2>

<p>HTTPS Ain&#8217;t a Protocol. It&#8217;s just HTTP layered over TLS, an encrypted
transport layer.</p>

<h2>Resetting Wifi of Remote Mac server</h2>

<p>Heh, this worked</p>

<pre><code>#!/bin/bash

networksetup -setairportpower en1 off
sleep 10
networksetup -setairportpower en1 on
</code></pre>

<p>Run via <code>nohup ./thisdumbscript &amp;</code>.</p>

<p>SSH will be unresponsive for 10+ seconds and then recover. The Magic of
the INTERNET!</p>

<h2>WebSockets and proxy servers</h2>

<p>http://www.infoq.com/articles/Web-Sockets-Proxy-Servers</p>

<p>Websockets work on port 80 and 443:</p>

<blockquote><p>HTML5 Web Sockets do not require new hardware to be installed, or new ports to be opened on corporate networks&#8211;two things that would stop the adoption of any new protocol dead in its tracks.</p></blockquote>

<p>Transparent proxy server: let&#8217;s stuff through, might manipulate content?</p>

<h2>BOSH: Bidirectional-streams Over Synchronous HTTP</h2>

<p>http://en.wikipedia.org/wiki/BOSH</p>

<p>Isn&#8217;t this just long polling? It&#8217;s long polling with the assurance that
immediately after receiving a &#8220;push&#8221;, the client makes a new long-lived
request on the same keep-alive connection. And it can make no more than
one connection whenever it needs to send data. Why does this have its
own stupid name?</p>

<h2>SSH Tunneling</h2>

<p>First off, you can just execute commands like</p>

<pre><code>ssh machty@whatever.com ls
</code></pre>

<p>and assuming I&#8217;ve already done the keygen stuff, that&#8217;ll log in, run
<code>ls</code>, and output the result of that.</p>

<p>But you can use <code>ssh</code> to spin up a local server that makes your SSH
connection act as a proxy to some other IP/port, map that to a local
port, and then connect other things through to that local port.</p>

<p>If I did</p>

<pre><code>ssh machty@wat.com -L 8080:somesite.com:80
</code></pre>

<p>Then I could do</p>

<pre><code>curl localhost:8080
</code></pre>

<p>and then see the contents of somesite.com as a request originating from
the wat.com server I &#8220;logged&#8221; into. (Except that most sites don&#8217;t
respond the way you&#8217;d like if <code>Host</code> and other headers are incorrect).</p>

<h2>What is my public IP?</h2>

<p>You need some third party to tell your your public IP after all the NAT
traversals. You shouldn&#8217;t use this for super sensitive stuff (it&#8217;s
possible the 3rd party server was compromised and maaaaybe there&#8217;s some
exploit if you use this fake IP for some internal thing?).</p>

<p>But this worked for me:</p>

<pre><code>curl icanhazip.com
</code></pre>

<p>Someone on SO suggested this: http://www.moanmyip.com/</p>

<p>I can&#8217;t believe that exists.</p>

<h2>SOCKS proxy</h2>

<p>https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-tunneling-on-a-vps</p>

<p>http://en.wikipedia.org/wiki/SOCKS</p>

<p>With a SOCKS proxy</p>

<h2>tcptraceroute</h2>

<p>Instead of ICMP ECHO packets, which often get filtered out at some point
by some asshole proxy along the way to the destination, tcptraceroute
uses TCP SYN packets instead. What&#8217;s that you say? Don&#8217;t we still need
the incrementing TTL that ICMP uses? TRICK QUESTION: TTL is an octet in
the IP packet, which wraps TCP/UDP/ICMP. So <code>tcptraceroute</code> still uses
TTL. It&#8217;s also nice enough to send a TCP RST (reset) package if the the
destination responds with a SYN|ACK so that you don&#8217;t leave it in a
connection-half-opened state (normally you&#8217;re supposed to send an ACK
and then start sending application data).</p>

<p>Interesting: you need root privileges to run tcptraceroute. Why? Because
the custom SYN packets it creates requires root privileges, probably to
prevent non-privileged users from doing malicious things with packets.
I&#8217;d be curious to know exactly where that takes place though.</p>

<h2>IP packets have no port</h2>

<p>Why? Because ports map to applications, a concept which IP packets don&#8217;t
care about; they&#8217;re all about getting messages to an address. Leave it
to the UDP/TCP packets to provide a source and destination</p>

<p>So hmmm how does ICMP traceroute work? How do the ECHO&#8217;d packets know to
come back to that specific traceroute command?</p>

<h2>ICMP</h2>

<ul>
<li>No port</li>
</ul>


<p>There&#8217;s a single ICMP socket apparently?</p>

<p>https://www.cs.utah.edu/~swalton/listings/sockets/programs/part4/chap18/ping.c</p>

<pre><code>/*
 * pr_pack --
 *  Print out the packet, if it came from us.  This logic is necessary
 * because ALL readers of the ICMP socket get a copy of ALL ICMP packets
 * which arrive ('tis only fair).  This permits multiple copies of this
 * program to be run without having intermingled output (or statistics!).
 */
</code></pre>

<ul>
<li>ident = getpid() &amp; 0xFFFF;

<ul>
<li>this is how a pong that returns is identified as originating from a
pong.</li>
</ul>
</li>
</ul>


<p>Anyway here&#8217;s a little Ruby program you can run with <code>sudo</code>
that&#8217;ll open a raw socket and print a Base64&#8217;d ping packet if you
<code>ping localhost</code>.</p>

<pre><code>require 'socket'
require 'base64'

rsock = Socket.open(:INET, :RAW)

loop do
  s = rsock.recv(1024)
  enc = Base64.encode64(s)
  puts enc
end
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Juggernaut]]></title>
    <link href="http://machty.github.com/blog/2014/09/20/daily-juggernaut/"/>
    <updated>2014-09-20T12:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/20/daily-juggernaut</id>
    <content type="html"><![CDATA[<h2>Rust is a &#8220;Systems&#8221; programming language</h2>

<p>Seems vague. You can use it for games (<code>#rust-gamedev</code> or
<code>/r/rust_gamedev</code>). What does systems mean?</p>

<p><code>#rust</code> tells me more vague stuff, but basically:</p>

<ul>
<li>Rust doesn&#8217;t impose garbage collection, so you maintain fine-grained
control over memory in that regard</li>
<li>Rust integrates nicely with C</li>
</ul>


<p>These features are often compared with Go. Go has GC. Go apparently
doesn&#8217;t integrate as nicely with C (not sure how true this is, need to
dig in). Apparently Go used to advertise itself as systems, then they
stopped, and Rust adopted that term to make it clear how it is different
from the oft-compared Go.</p>

<h2><code>source</code> and <code>export</code></h2>

<p>I always knew the <code>source</code> command as the command you use when you want
to run a script with a bunch of <code>export</code> definitions, but all it really
means is that <code>source</code> doesn&#8217;t actually make new process but just runs
the code in the source file as shell commands. As such, it means that
any environment vars set in the sourced command don&#8217;t get set in a
separate child process that dies and forgets set vars.</p>

<p><code>export</code> makes sure that an env var gets passed to child processes. Just
setting an env var without <code>export</code> won&#8217;t mark it to be shared with
child processes.</p>

<p>You can verify all of this by <code>source</code>ing a script with a long <code>sleep</code>
and then checking <code>ps</code> to verify that <code>sleep</code> is a direct child of
<code>bash</code>; there&#8217;s no intermediate process running that execution.</p>

<h2>prey project</h2>

<p>Protect your devices from theft:</p>

<p>https://preyproject.com/</p>

<p>TODO: look into this shit.</p>

<h2>awesome cheese</h2>

<p>Stompetoren Grand Cru. With Effie&#8217;s Homemade Oatcakes.</p>

<p>So fucking good.</p>

<p>http://bedfordcheeseshop.com/products/stompetoren-gouda-grand-cru</p>

<h2>Why is CORS disabled for XHR but not a 3rd party post?</h2>

<p>CSRF is still a thing, but falls outside of CORS because CORS intends to
make JavaScript-initiated requests safe. Then again didn&#8217;t
Chrome/Mozilla just make fonts CORS-y?</p>

<h2>Access-Control-Allow-Origin</h2>

<p>I&#8217;d get this error in devtools console whenever my Rails code errored
out during an XHR request:</p>

<pre><code>XMLHttpRequest cannot load http://localhost:5000/wat
No 'Access-Control-Allow-Origin' header is present on the requested resource.
Origin 'http://localhost:4200' is therefore not allowed access. 
</code></pre>

<p>It&#8217;s misleading since I have CORS set up correctly, but apparently not
for erroring requests? Basically, using XMLHTTPRequest (ajax) is going
to set the <code>Origin</code> request header, which flags the server to send back
CORS headers. If the browser doesn&#8217;t see those CORS headers, or the
provided ones don&#8217;t match / grant proper permissions, then the XHR
request will fail.</p>

<p>So basically I have an error in my server code I need to fix. Maybe it&#8217;s
good that CORS fails upon error? Because if not, then I might be opening
up some third party door that&#8217;s sniffing my site due via erroneous
requets? I can&#8217;t really see it but maybe.</p>

<h2>Why won&#8217;t my dumbass server work?</h2>

<p>Scenario: I have a remote Minecraft server. It runs from a persistent
tmux session so that I can log in and run server commands on it. I can
ping it successfully but when I try to join, it fails to connect with
authentication servers. There&#8217;s lots of reported issues online with
authentication servers but I think in my case no outbound requests are
succeeding. <code>curl google.com</code> yields no response, and neither do pings.</p>

<p>Whoops. I just remotely turned off the server&#8217;s wifi and got
disconnected. I figured I&#8217;d turn it off and on again to see if that
&#8220;rebooted&#8221; things. But, uh, kinda need internet through that whole
process. Dumbest moment of 2014.</p>

<h2>Do shells fork to start new processes?</h2>

<p>Yes. Bash will fork itself and then calls execve to transform itself
into a new process.</p>

<p>There&#8217;s also an <code>exec</code> built-in command that will replace your bash
instance with whatever you wanna run, which means when the new command
terminates, your bash terminal will close, e.g.:</p>

<pre><code>exec sleep 1
</code></pre>

<p>An &#8220;Environment list&#8221; maintains the key value pairs of env vars. When
you exec a new process, it either inherits the env of its parent or gets
a new one. In C-land, the <code>char ** environ</code> variable is exposed contain
all env vars, testable via:</p>

<pre><code>#include &lt;stdio.h&gt;
extern char **environ;
int main() {
  printf("%s\n", environ[0]);
  return 0;
}
</code></pre>

<h2>mmap</h2>

<p>Virtual memory mapping. It&#8217;s a syscall to map a region of virtual memory
to a file, or to create an anonymous mapping that doesn&#8217;t write to a
file.</p>

<h2>CGI / Rack limitations</h2>

<p><a href="http://en.wikipedia.org/wiki/Common_Gateway_Interface">Common Gateway Interface</a></p>

<p>http://blog.plataformatec.com.br/2012/06/why-your-web-framework-should-not-adopt-rack-api/</p>

<p>Shortcoming: middlewares that allocate/release resources</p>

<h2>Mac Desktop Shell Scripts</h2>

<p>Save this with <code>+x</code> chmod permissions as <code>~/Desktop/wat.command</code>.</p>

<pre><code>#!/bin/bash
echo "wat"
</code></pre>

<h2>htop</h2>

<p><code>brew install htop</code></p>

<p>It&#8217;s top but way way more bitchin. OMG, it even has a tree mode.</p>

<h2>man vs info</h2>

<p>Just discovered that there&#8217;s both <code>man bash</code> and <code>info bash</code>. <code>info</code> was
added in the 90s by GNU, who felt <code>man</code> was too crappy a manual system for
sophisticated software.</p>

<h2>Job control / monitor mode</h2>

<p>Bash (et al, but apparently not Bourne?) implement job control, the
ability to suspend resume jobs (process groups) via an interactive
shell. Job control is enabled when &#8220;monitor mode&#8221; is on. In bash, this
is enabled by default. To disable: <code>set +m</code>. To enable: <code>set -m</code>. When
disabled, you&#8217;ll see things like:</p>

<pre><code>$ fg
-bash: fg: no job control
</code></pre>

<p>You also won&#8217;t be able to ^Z out of a running process (a SIGTSTP still
fires but bash ignores it). <code>ruby -e "Process.kill(:TSTP,0)"</code> runs to
completion when monitor mode is disabled.</p>

<p>Actually hmm, interesting, if you disable monitor mode and run</p>

<pre><code>ruby -e "Process.kill(:STOP, 0); puts 'done'"
</code></pre>

<p>then it just runs to completion? How is that possible?
My guess is that the process stops, and then is immediately resumed
because there&#8217;s nothing to take its place? Seems SIGSTOP is ignored even
when you sent it from another terminal to a terminal with -m.</p>

<p>Also, you can display all the shell options via <code>echo $-</code></p>

<pre><code>himBH
hiBH # monitor mode disabled
</code></pre>

<h2>Dollar signs</h2>

<p>http://stackoverflow.com/a/5163260/914123</p>

<pre><code> 1. Positional parameters `$1,$2,$3…` and their corresponding array representation, count and IFS expansion `$@`, `$#`, and `$*`.
 2. `$-` current options set for the shell.
 3. `$$` pid of the current shell (not subshell)
 4. `$_` most recent parameter (or the abs path of the command to start the current shell immediately after startup)
 5. `$IFS` the (input) field separator
 6. `$?` most recent foreground pipeline exit status
 7. `$!` PID of the most recent background command
 8. `$0` name of the shell or shell script
</code></pre>

<h2>syscalls</h2>

<p>Example: <a href="http://www.opensource.apple.com/source/tcl/tcl-5/tcl/compat/waitpid.c">waitpid</a></p>

<p>Wrapper C functions stash args in registers, stash syscall id in <code>%eax</code>,
and then runs a <code>trap</code> machine instruction, which tells the processor to
switch into kernel mode. (Recent hardware uses <code>sysenter</code> instead of
slower <code>trap</code>, which incurred interrupt overhead&#8230; TODO: learn about
interrupts!). The rest is obvious enough.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journeaux]]></title>
    <link href="http://machty.github.com/blog/2014/09/17/daily-journeaux/"/>
    <updated>2014-09-17T08:08:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/17/daily-journeaux</id>
    <content type="html"><![CDATA[<h2>nginx book</h2>

<p>This is nice: http://aosabook.org/en/nginx.html</p>

<p>Some random notes:</p>

<p>For CPU-bound loads, number of nginx workers should equal the number of
cores (&#8220;TCP/IP, doing SSL, or compression&#8221;). For IO-bound stuff
(&#8220;serving different sets of content from storage, or heavy proxying&#8221; &#8211;
presumably teh &#8220;different sets&#8221; is important because if it were
the same stuff, it&#8217;d probably be cached which I guess means the IO would
be negligible? unsure) &#8211; you might want 1.5-2 times the number of
cores.</p>

<h2>SSL/TLS random questions:</h2>

<p>I have so many misconceptions? For anyone who reads this, this is stream
of thought as I try to answer my own questions before looking shit up.</p>

<p>How come domains are signed and not IPs?</p>

<p>Reasoned guess: first off, everyone can encrypt data. It&#8217;s just that the
key thing that TLS brings in is certification of a sending. It&#8217;s not
enough to say &#8220;yo here&#8217;s my public key&#8221;, you still have to answer the
question &#8220;uh ok yes but who are you?&#8221;. Certificate authority to the
rescue.</p>

<p>So what if CA&#8217;s certified IPs, rather than domain names (maybe they do,
I don&#8217;t actually know at this point)? Some ideas come to mind:</p>

<ul>
<li>DNS can map to multiple IPs, and a single IP might load balance to
many different servers, all of which should be able to (de)/encrypt
incoming traffic.</li>
</ul>


<p>That&#8217;s actually probably the only reason. I was originally thinking
that since IPs can change, you might certify server A and then the next
day the IP changes to server B, and that that would mean the CA is
giving a stamp of approval to the wrong server, but then, duh, it&#8217;s key
pairs that are being validated, and server B wouldn&#8217;t have these keys
and wouldn&#8217;t know how to do the handshake. I think this is close to
correct, it&#8217;s just I&#8217;m forgetting everything that happens internally
within the handshake.</p>

<p>http://en.wikipedia.org/wiki/Transport_Layer_Security</p>

<h2>Symmetric Key</h2>

<p>A single key encrypts plaintext and decrypts the ciphertext generated
from the encryption.</p>

<p>Example: AES.</p>

<h2>Cipher suite</h2>

<p>https://www.iana.org/assignments/tls-parameters/tls-parameters.xhtml#tls-parameters-4</p>

<p>A triple of</p>

<ul>
<li>authentication</li>
<li>encryption</li>
<li>and message authentication c</li>
</ul>


<h2>SSL / TLS</h2>

<p>Lots of people use them interchaangeably, but SSL was originally created
at Netscape and used to be implemented at the application layer, living
on top of TCP. When it was IETF standardized, it was renamed TLS and
moved out of the application layer.</p>

<p>TLS provides:</p>

<ul>
<li>encryption

<ul>
<li>obfuscate data transmitted from one computer to another</li>
<li>example: plaintext means zero encryption and easily breakable
ciphertext means shitty encryption</li>
</ul>
</li>
<li>authentication</li>
<li>verify that you&#8217;re talking to who you think you&#8217;re talking to</li>
<li>example: the CA validates the certificate that a server sends you</li>
<li>integrity

<ul>
<li>detect message forgery or tampering</li>
<li>example:</li>
</ul>
</li>
</ul>


<h2>Beware the intermediaries</h2>

<p>Intermediaries are caching servers, gateways, web accelerators, content
filters, blah blah blah, all the stuff that&#8217;s come out to aid and extend
HTTP. They&#8217;re often transparent to the end user, but they come with the
limitation that if you start wanting to deviate from HTTP on port 80 in some
application specific way, you&#8217;re boned. And it&#8217;s kinda rare to find
other ports that are open: 80 and 443 (HTTPS) are usually open but
everything else is often closed. These intermediaries might improperly
try to apply their logic to the non HTTP, etc, there&#8217;s no easy way to
detect when or when not to apply.</p>

<p>Solution: HTTPS tunnel all the things. All data is obfuscated from
intermediaries and intermediaries have no way of known whether the
encrypted data is HTTP or some custom proprietary crazy thing.</p>

<h2>Self-signed certificates</h2>

<p>http://www.akadia.com/services/ssh_test_certificate.html</p>

<p>Things learned:</p>

<ul>
<li>&#8220;If the private key is no longer encrypted, it is critical that this file only be readable by the root user!&#8221;</li>
<li>You can remove the DES from the private key so that you don&#8217;t have to
type in the password all the god damn time when your server starts.
(Verified this with a node app)</li>
</ul>


<p>Turns out you could also just run the following:</p>

<pre><code>openssl req -new 
</code></pre>

<p>So why is DES required at all? I&#8217;m guessing it&#8217;s possible to generate a
CSR without it, right?</p>

<h2>ALPN: Application-Layer Protocol Negotiation</h2>

<p>Note to dummy: there&#8217;s no TLS 3 way handshake. You&#8217;re thinking of TCP
ACK SYN SYNACK that has to happen before app data is exchanged.</p>

<p>ALPN takes place during the</p>

<h2>SNI: Server Name Indication</h2>

<p><a href="https://www.ietf.org/rfc/rfc3546.txt">rfc, page 8</a></p>

<p>If you have a server that you want to host multiple sites with their own
respective TLS certificates,</p>

<h2>self-signed-certificate</h2>

<p>Useful for testing SSL before you go ahead and buy a certificate for 3rd
party validation.</p>

<h2>AES vs RSA</h2>

<p>AES is symmetric, and generally speaking symmetric encryption/decryption
is a lot faster than assymetric, hence AES is used for the
encryption/decryption of data.</p>

<h2>Sprite gotchas</h2>

<p>I used to think sprites were bitchin; save HTTP requests, combine all
your images into one. Obviously, these are lame application-level
optimizations/hacks to cover the ass of the transport layer&#8217;s (HTTP&#8217;s)
shortcomings (addressed in SPDY / HTTP 2.0).</p>

<p>Downsides of sprites:</p>

<ul>
<li>all the application-layer crap you have to do to handle it</li>
<li>change a single pixel of a single image and you&#8217;ve busted a massive
cached of all the other images in the sprite</li>
<li>memory intensive; you might not be using each image but you have to
load all of it in memory, might be too much for mobile clients</li>
</ul>


<h2>Octet</h2>

<p>It means byte. Saw it all over the place in the
<a href="https://datatracker.ietf.org/doc/draft-ietf-httpbis-http2/?include_text=1">HTTP 2 spec draft</a></p>

<h2>nginx</h2>

<p>After <code>brew install nginx</code></p>

<pre><code>Docroot is: /usr/local/var/www

The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that
nginx can run without sudo.

To have launchd start nginx at login:
    ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
Then to load nginx now:
    launchctl load ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist
Or, if you don't want/need launchctl, you can just run:
    nginx

WARNING: launchctl will fail when run under tmux.
</code></pre>

<p>What is docroot?</p>

<ul>
<li>It&#8217;s a file&#8230; not a directory?</li>
<li>But you can delete it and replace with a directory and put an
index.html in there and it works</li>
<li>So I guess there&#8217;s some default configuration of nginx that just hosts
static files from this doc root directory</li>
</ul>


<p>What do them commands does?</p>

<pre><code>ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
</code></pre>

<p>What are launchd and launchctl?</p>

<p><code>launchd</code> is a daemon (conventions dictate that daemons end in a <code>d</code>).
<code>launchctl</code> is what you use to control that daemon. So if you want to
schedule something to start</p>

<p>What&#8217;s the <code>mxcl</code> in <code>homebrew.mxcl.redis.plist</code>?</p>

<p>It refers to <code>mxcl</code>, maintainer of Homebrew. Just normal reverse domain
name notation. So does that mean any homebrew-installed domains get
prefixed like that? I&#8217;m guessing <code>mxcl</code> also made the Redis recipe.
Or maybe every homebrew daemon gets prefixed like that? Not sure, who
cares.</p>

<pre><code> In the launchd lexicon, a "daemon" is, by definition, a system-wide service of
 which there is one instance for all clients. An "agent" is a service that runs
 on a per-user basis. Daemons should not attempt to display UI or interact
 directly with a user's login session. Any and all work that involves interacting
 with a user should be done through agents.
</code></pre>

<p><a href="https://developer.apple.com/library/mac/technotes/tn2083/_index.html">TN2083 - Daemons and Agents</a></p>

<p>Wow, &#8220;Daemonomicon&#8221; is an awesome word: &#8220;formal definition of the types
of bg programs you can write&#8221;.</p>

<ul>
<li>bootstrap server: launchd</li>
<li>root session: first and last session. Boot-time processes and daemons
live here. User-independent. e.g. <code>mDNSResponder</code></li>
<li>login session: proceses launched by or for a user live in login
session. Login sessions are associated w authenticated users. Each
user</li>
</ul>


<p>If I</p>

<h2>Origins of TTY</h2>

<p>http://www.linusakesson.net/programming/tty/</p>

<ul>
<li>stock tickers, then ASCII teletype within a network called Telex.</li>
<li>Telex was a network that used level of current to respresent different
characters, vs different voltages used by analog telephone shit</li>
<li>Telex existed before integration w computers</li>
<li>When command lines became the norm, teletypes were used as input and
output since they were readily available on the market</li>
<li>Lots of different models, needed to standardize in some way; UNIX
philosophy dictated letting kernel handle low level word length, baud
rate, flow control, etc., later things like color output, cursor
movement, etc, was left to application (not kernel)</li>
<li>Line editing is managed by OS-provided line discipline. Default is
cooked/canonical mode. raw mode disables things like editing,
backspace, and generally disables any IO processing within the line
discipline.</li>
</ul>


<p>Skipping ahead, you can force your terminal into stty raw mode via</p>

<pre><code>stty raw #enable
stty -raw #disable
</code></pre>

<p>Now I know how to write a Ruby impl of Press Any Key</p>

<pre><code>print "Press any key... "

begin
  system("stty raw -echo")
  c = STDIN.getc
ensure
  # re-enable
  system("stty -raw echo")
end

puts "Thanks!"
</code></pre>

<p>Note that it&#8217;ll consume CTRL-C as well rather than signalling an
interrupt (hence CTRL-C prints &#8220;Thanks!&#8221; rather than terminating
immediately).</p>

<p>This is also how any text editor functions.</p>

<p>This must be what&#8217;s happening when I kill some script when it doesn&#8217;t
expect it and then my terminals fucked. Typing in <code>stty -raw</code> even
though I can&#8217;t see it probably would fix it&#8230; need to try.</p>

<p>Back to the thing:</p>

<ul>
<li>Kernel provides many line disciplines, only one attached to serial
device at a time. Default is <code>n_tty</code>. I guess that&#8217;s what we&#8217;re
configuring when we futz w <code>stty</code></li>
<li>Other disciplines are for things like packet switched data</li>
<li><a href="http://www.cs.fsu.edu/~baker/devices/lxr/http/source/linux/drivers/char/n_tty.c">tty C source code</a></li>
<li>UART (Universal Async Receiver and Transmitter): converts teletype
signal into bytes that the OS can process. OS has a UART driver.</li>
<li>TTY driver: allows user to kill/suspend an infinite looped program,
bg processes can process til they try to write to terminal (at which
point they suspend), and user input to fg process only.
(implemented in <code>tty_io.c</code>)</li>
<li>TTY Device: triplet of UART driver, line discipline, and TTY driver.</li>
<li>TTY devices live in <code>/dev</code> w file mode <code>c</code> for &#8220;Character special
file&#8221;. To manipulate one, you need ownership of the device file
(e.g. via <code>login</code>).</li>
<li>TTYs are just objects. Not alive. Other things plug into it. Those
other things have execution contexts.</li>
<li>pty = pseudoterminal, as opposed to TTY.</li>
</ul>


<p><code>ps -o stat</code> prints out <code>Ss</code> <code>Ss+</code>, etc&#8230; here&#8217;s what the capital
letters mean:</p>

<pre><code>R   Running or runnable (on run queue)
D   Uninterruptible sleep (waiting for some event)
S   Interruptible sleep (waiting for some event or signal)
T   Stopped, either by a job control signal or because it is being traced by a debugger.
Z   Zombie process, terminated but not yet reaped by its parent.
</code></pre>

<p>Most things are in <code>S</code>. An example of <code>R</code>:</p>

<pre><code>ruby -e 'loop {}'
</code></pre>

<p><code>s</code> means session group leader. <code>+</code> means process is part of foreground
process group.</p>

<ul>
<li>Ctrl Z suspends a process, puts it in <code>T</code> state.</li>
</ul>


<p>Jobs, e.g. <code>fg</code> and <code>bg</code> are just process groups. Consider</p>

<pre><code>ruby -e 'loop {}'  | grep a | grep a | grep a
</code></pre>

<p>This causes as CPU-intensive loop and will be in R state.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R+   s045    7:03.43 ruby -e loop {}
machty 45755 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>and when I suspend:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 T    s045    7:29.05 ruby -e loop {}
machty 45755 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 T    s045    0:00.00 grep a
</code></pre>

<p>Everything below it suspends.</p>

<p><code>jobs</code> are tied to session leaders, and terminals are session leaders.
If I go to another tmux pane and type <code>jobs</code>, the suspended job <em>won&#8217;t</em>
show up; I have to be in the same terminal that started it. TODO: can I
change session IDs?</p>

<p>If I <code>bg 1</code>, the following happens:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R    s045    7:39.63 ruby -e loop {}
machty 45755 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S    s045    0:00.00 grep a
</code></pre>

<p>Note how it&#8217;s back to running, but note the missing foreground <code>+</code>. <code>fg 1</code>
would bring it back.</p>

<p>Note that we could turn one of those greps into <code>R</code> if it was actively
processing data, e.g.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 46054 45014 46054      0    4 R+   s045    0:37.84 ruby -e loop { puts "a" }
machty 46055 45014 46054      0    4 R+   s045    0:45.56 grep a
machty 46056 45014 46054      0    4 R+   s045    0:27.01 grep b
machty 46057 45014 46054      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>(Actually, the first 3 R&#8217;s might be S&#8217;s if you re-run this command;
there&#8217;s a race condition as to whether the CPU is actually running code
or whether it&#8217;s blocked on an IO syscall waiting for piped data to come
in, but the last grep is always S+ because it never gets output from the
<code>grep b</code>).</p>

<p>A Job is a Processs Group.</p>

<p>If you&#8217;re just starting/stopping/piping processes, all those child
processes with have a parent process ID of <code>bash</code>&#8217;s pid.</p>

<p>What constitutes a job/process group? Piped commands for one.
Let&#8217;s see about Process Subsitution. Answer: process substitution
doesn&#8217;t consider it as a pipe. It considers it as a shit of epic
fartitude. In other words, process substitution ends up being miserably
old and mortal and definitely going to die. In other words, process
substitution is not in the same process group. It&#8217;s its own process
group. If you do <code>echo &lt;(some long living thing)</code>, the long living thing
will survive as a sibling process, in its own process GROUP WHO CARES.</p>

<p>You can only read from  / write to TTY if you&#8217;re foreground. If you&#8217;re
not <code>fg</code> and you try and write to TTY, kernel will suspend your ass.</p>

<ul>
<li><code>ioctl</code> is the UNIX swiss army knife; manipulates special files like
terminals.</li>
<li><code>ioctl</code> requests must be initated from processes, so the kernel can&#8217;t
asyncly communicate w an application unless the app asked for it.</li>
<li>Signals are how kernel communicates asyncly w a process. Messy and
error prone they are.</li>
</ul>


<p>Question: nohup detaches into its own session id to prevent closing on
SIGHUP&#8230; why does it have to do that? Why can&#8217;t it just ignore that
signal? Let&#8217;s see.</p>

<pre><code>Signal.trap(:HUP) do
  puts "I WILL NOT"
end
sleep
</code></pre>

<p>If I ssh localhost and run that in background (with <code>&amp;</code>) and then
logout, it stays running, PPID changes to 1 (root). So how is that
different than nohup? TODO: find out. Something with setsid, etc.</p>

<p>SIGINT&#8217;s originate from the terminal&#8230; is it correct to say they
originate from TTY? I think it is based on the <code>n_tty.c</code> code.
Also, in raw mode it doesn&#8217;t even fire. COOL.</p>

<ul>
<li>SIGPIPE isn&#8217;t just an error but also a way to know whoever was
listening to you has stopped listening to you, e.g. <code>yes | head</code>.</li>
<li>SIGSTOP is to SIGTSTP as SIGKILL is to SIGQUIT.</li>
<li>SIGCONT can be sent to a ^Z-suspended process. It behaves as if you
started the process with <code>&amp;</code>. It&#8217;s running, but it&#8217;s bg. In other
words, if you have a suspended process 12345, <code>bg 1</code> or
<code>kill -CONT 12345</code> would do the same thing; it&#8217;d start running in the
background, spitting out output</li>
<li>You can break shit with
<code>ruby -e 'Signal.trap(:TTIN) { puts "wat" }; sleep 1; gets' &amp;</code>
(recursive SIGTTIN). You try and write to TTY in the background and
then keep ignoring the signal that it&#8217;s failing. I don&#8217;t know what
causes the deadlock though, but <em>something</em> screwing up sounds right.</li>
<li>If you press ^Z, that sends a message to the foreground process group.
The line discipline sends <code>SIGTSTP</code> to the foreground process group.
This will suspend the whole process group, whatever the main</li>
</ul>


<p>Question: if you use pipes combined with <code>&amp;</code>, what gets put into the
background? All tasks? Answer (I think): <code>&amp;</code> ultimately results in a
process group getting put into the background, and a process group
contains any pipes, child processes, etc, so it <em>must</em> apply to all of
the different processes as a whole, and there&#8217;s no way to say that only
one of the pipe segments runs in the background.</p>

<p>Fun fact: you can reimplement the default ^Z behavior as follows:</p>

<pre><code>has_ignored = false
Signal.trap(:TSTP) do
  if has_ignored
    Process.kill(:STOP, Process.getpgrp)
  else
    has_ignored = true
    puts "ignoring"
  end
end

sleep
</code></pre>

<p>TL;DR the default SIGTSTP ^Z handler fires a STOP. You can catch TSTP
and immediately do the same for the same effect.</p>

<p>Vim&#8217;s source code (and probably everyone&#8217;s) does some variant of</p>

<pre><code>settmode(TMODE_COOK);
kill(0, SIGTSTP);       /* send ourselves a STOP signal */
</code></pre>

<p>So, you return TTY mode to cook mode.</p>

<ul>
<li>If you run something like <code>echo "wat" | less &amp;</code>, you&#8217;ll immediately
see <code>[2]+  Stopped   echo "wat" | less</code> because <code>less</code> is always going
to try and write to TTY in a raw manner&#8230;?</li>
<li>If you suspend, say, vim, vim will catch the SIGTSTP, move the cursor
to the last line of the screen w control signals (it&#8217;s still attached
to TTY) and then fires a SIGSTOP.</li>
<li>Once stopped, a SIGCHLD is sent to the session leader with the pid of
the suspended process. When all processes in fg have been suspended
(T&#8217;d), the current TTY config is stashed for later restoration
(<code>stty -g</code> is one way of doing this).</li>
</ul>


<p>So why doesn&#8217;t ^Z suspend bash?</p>

<p>Ahh, so here&#8217;s how you get TTOU to fire (and cause a process to suspend)</p>

<pre><code>ruby -r "io/console" -e "IO.console.raw { puts 'wat' }" &amp;
</code></pre>

<p>Note that if we hadn&#8217;t used <code>.raw</code> to put TTY in raw mode, it would have
just printed &#8220;wat&#8221; into the same terminal even though the process is
running in the background, but if you grab full control of the TTY with
<code>raw</code>, it&#8217;ll cause a TTOU.</p>

<p>You can go in and configure another TTY to update its rows/cols. I can
fuck w the vim in another tmux pane, tell it its skinnier/wider than it
is, but once i resized a tmux pane then BOOM it fires its own tty
commands, and tty fires a SIGWINCH, and then that causes vim to query
the tty for the current width and repaint.</p>

<p>Ah: realization: the ultimate decider in whether TTOU fires is whether
topstop</p>

<h2><code>read</code></h2>

<pre><code>read words &lt; &lt;(echo "wat")
echo $words
</code></pre>

<h2>resetting the keyboard when things go crazy</h2>

<p><code>reset</code>, or typing Escape and c.</p>

<pre><code>stty raw
reset
</code></pre>

<p>and we&#8217;re back. It resets your TTY driver, I guess.</p>

<h2><code>yes</code></h2>

<p>Repeatedly enter <code>y</code> for saying yes to everything. Like the dropper bird
from the simpsons when homer gets fat. You can also do <code>yes no</code> to say
other things.</p>

<h2>Ack</h2>

<p>is written in Perl.</p>

<h2>100 Continue status</h2>

<p>An HTTP 1.1 mechanism.</p>

<p>http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html</p>

<p>In some cases, a server knows just by looking at request headers that it
won&#8217;t process the request, making it potentially wasteful for the client to send a
giant doomed-to-fail payload. In these cases, the client can decide not
the send the full payload unless the server has told it &#8220;based on your
headers, you should Continue sending this full payload because I don&#8217;t
see any reason why it should fail, just by looking at the headers.&#8221;</p>

<p>To opt into this, the client must provide the following header:</p>

<pre><code>Expect: 100-continue
</code></pre>

<p>The server will see this, decide if the request will succeed, and if so,
it send back 100 Continue and keeps reading from the input stream.
Client then sends the whole payload.</p>

<p>Proxies can reject if it knows the next-hop server is HTTP 1.0 or less
with a 417 Expectation Failed.</p>

<h2>IOS8 breaks file uploads in Safari</h2>

<p>http://blog.fineuploader.com/2014/09/10/ios8-presents-serious-issues-that-prevent-file-uploading/</p>

<p>Jesus. No workaround? Apple, you suck.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/09/15/daily-journal/"/>
    <updated>2014-09-15T19:57:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/15/daily-journal</id>
    <content type="html"><![CDATA[<h2>FTP</h2>

<p>Plaintext, unless you&#8217;re using SFTP or some variant.</p>

<p>FTP uses multiple connections: 1 control connection for sending
commands and tracking current directory, etc, and a connection for
actually streaming the file data.</p>

<p>How the second connection (data) is established depends on active vs
passive mode: in active mode, the server will try to connect back to the
client at PORT+1, and in most modern cases, this will fail due to NATs
and firewalls, hence passive mode (via PASV) command is meant to get
around this. In passive mode, the client requests an IP and port from
the server (via the control connection), and then the client makes the
second connection to whatever the server returns. This works as clients can
generally connect to servers without NAT/firewall issues.</p>

<p>Note that active connections are rare. The man page for <code>ftp</code> is
telling:</p>

<pre><code>-A          Force active mode ftp.  By default, ftp will try to use passive mode
            ftp and fall back to active mode if passive is not supported by the
            server.  This option causes ftp to always use an active connection.
            It is only useful for connecting to very old servers that do not
            implement passive mode properly.
</code></pre>

<h2>Application-level gateway</h2>

<p>http://en.wikipedia.org/wiki/Application-level_gateway</p>

<p>TODO: learn more.</p>

<h2>Process per connection</h2>

<p>One way of handling a new connection is to fork and let the forked
process handle that connection. Makes sense for the parent instance to
use Ruby&#8217;s <code>Process.detach</code>, which doesn&#8217;t have a native kernel
equivalent but is just a Ruby convenience that spins up a thread that
calls <code>wait()</code> on the forked process to prevent it from becoming a
zombie if the parent process exits before the forked one.</p>

<p>Remember that forking isn&#8217;t available on Windows or JRuby.</p>

<p><code>shotgun</code> is a Ruby server that forks per connection. Why? Isn&#8217;t this
wasteful (relative to pre-forking solutions like Unicorn)? Yes, but it
has specific purpose: assuming it&#8217;s not painfully expensive to spin up
your server (like Rails), and that you don&#8217;t have a mechanism for
reloading after code changes (like Rails), <code>shotgun</code> will fork per
connection and entirely reload / spin up the rack server, less reloading
the latest version of any Ruby code, thus not requiring you to manually
restart your server.</p>

<h2>Thread per connection</h2>

<p>Typical state-sharing caveats apply when working with threads, hence
it&#8217;s useful to thing about the simple unit of concurrency that will keep
your threads isolate and minimize their access to shared data. That unit
would be a connection; each thread should get its own connection object.
Create a connection object, immediately create a new thread, and let
that connection object fall out of scope in the creator thread so that
only the newly spawned thread has access to it. Simple enough.</p>

<h2>How to verify your code is on multiple cores</h2>

<p>You have to dig in a little bit to verify that Ruby code you&#8217;re writing
is actually being processed on multiple CPU cores. There are many
variables:</p>

<ol>
<li>Does your system even have more than one core? (try <code>system_profiler | grep 'Total Number of Cores'</code> to find out, probably some other ways too)</li>
<li>Does your Ruby have a GIL? (MRI does, Rubinius and JRuby don&#8217;t)</li>
<li>Some third thing to pad my arbitrary list of bullshit.</li>
</ol>


<p>Anyway, one easy way is to run the following code:</p>

<pre><code>NUM_CORES = 2

threads = []
NUM_CORES.times do |t|
  threads &lt;&lt; Thread.new do
    log_every = 1000000
    i = 0
    loop do
      i += 1
      if i == log_every
        i = 0
        putc t.to_s
      end
    end
  end
end

threads.each(&amp;:join)
</code></pre>

<p>Running this on MRI Ruby results in 100% CPU usage. Running in JRuby
yields 200%, which means two cores are operating at 100%. Pretty rad,
yes?</p>

<p>CPU usage reported by activity monitor or <code>top -o cpu</code>.</p>

<h2>Preforking</h2>

<p>e.g Unicorn</p>

<p>What&#8217;s nice is that the kernel will handle load-balancing for us: when
there are no incoming requests, you have N forked instances blocked on
<code>accept</code>, and the kernel will choose which instance gets the next
incoming request. If all forked instances are busy, the kernel will just
queue up the request internally. If the queue gets full, you&#8217;ll get an
ECONNREFUSED. Easy peazy.</p>

<p>Unicorn (and probably Rainbows) does some extra tracking on child
processes to make sure it&#8217;s not getting stuck on long requests, etc.</p>

<p>Main disadvantage is memory usage. By the time you fork, if the parent
process is 100 mb, then 4 forks and you&#8217;re at 500 mb&#8230; unless 1) your
OS has COW and 2) you don&#8217;t write to it all that much.</p>

<h2>Reactor</h2>

<p>e.g. Node.js, Twisted, EventMachine</p>

<p>High levels of concurrency (not necessarily parallelism) achievable,
relative to threading/forking models, which hit their RAM limit much
faster (Reactor patterns mean that everything is just heap allocations
on the same thread).</p>

<p>Impacts on programming model:</p>

<ul>
<li>No processes/threads, so no shared memory, synchronization, etc, to
have to worry about</li>
<li>Don&#8217;t block the single Reactor thread (because nothing else will be able to
run). You wouldn&#8217;t have to worry about this in thread/processland.
This is why if you&#8217;re using EventMachine, your gems must be
event-machine aware, otherwise they&#8217;ll block (which would be fine in a
threading/forking environment).</li>
</ul>


<h2>Node cluster</h2>

<p>http://nodejs.org/api/cluster.html</p>

<p>Based on the fact that you can use child process forking to split heavy
duty work into process that can each live on a different core, if that&#8217;s
what you&#8217;re about.</p>

<p>Note that there&#8217;s no C-like or Ruby-like fork in Node; you can&#8217;t just
call fork and then have both the parent and newly forked child process
continue execution from that <code>fork()</code> invocation&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/09/06/daily-journal/"/>
    <updated>2014-09-06T14:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/06/daily-journal</id>
    <content type="html"><![CDATA[<h2>netcat (nc)</h2>

<p>Utility to spinning up arbitrary tcp servers for testing, sending
packets, etc.</p>

<pre><code>Socket.new(Socket::AF_INET, Socket::SOCK_STREAM)
or symbols:
Socket.new(:INET6, :STREAM)
</code></pre>

<p>INET = internet, specifically IPv4, <code>SOCK_STREAM</code> means a TCP stream
will be set up, as opposed to <code>DGRAM</code>, which would set up UDP.</p>

<p>Set up bullshit listener:</p>

<pre><code>nc -l localhost 4481
</code></pre>

<h2>Loopback</h2>

<p><code>localhost</code> is a loopback, which is a virtual interface where any data
sent to the loopback is immediately received. <code>127.0.0.1</code> is the IP.</p>

<p>Check dat <code>/etc/hosts</code> file:</p>

<pre><code>##
# Host Database
#
# localhost is used to configure the loopback interface
# when the system is booting.  Do not change this entry.
##
</code></pre>

<p>Funny how I never notice stuff like that until someone officially
defines it for me.</p>

<h2>&#8220;well-known&#8221; ports</h2>

<p>Hosted by IANA.org, the Internet Assigned Numbers Authority.</p>

<h2>Gerrymandering</h2>

<blockquote><p>manipulate the boundaries of (an electoral constituency) so as to favor one party or class.</p></blockquote>

<p>Knew what this was, forgot the word for it.</p>

<h2>AWS Spot Instances</h2>

<p>Running interruption-tolerant applications on EC2 unused capacity, where
you can bid on price per hour and maximum bid price.</p>

<h2>Chekhov&#8217;s Gun</h2>

<p>http://en.wikipedia.org/wiki/Chekhov&#8217;s_gun</p>

<blockquote><p>Remove everything that has no relevance to the story. If you say in the first chapter that there is a rifle hanging on the wall, in the second or third chapter it absolutely must go off. If it&#8217;s not going to be fired, it shouldn&#8217;t be hanging there.</p></blockquote>

<p>Anton Chekhov is considered to be among the greatest writers of short
stories in history. Guess I should start reading.</p>

<h2>Binding to an interface</h2>

<p>You can bind to a single interface, or ALL interfaces, lol!</p>

<p><code>0.0.0.0</code> means all interfaces. I guess that means that requests to
localhost, and potentially some other external facing interface, will
route requests to this socket. So what if someone has already bound
specifically to localhost:12345 and you try to bind to <code>0.0.0.0:12345</code>?</p>

<p>Answer: I don&#8217;t know&#8230; need to learn about what other interfaces are
available</p>

<p>REVISED ANSWER: I can use the IP provided by my router.</p>

<pre><code>ruby -run -e httpd . --port=4124 --bind-address=192.168.1.3
</code></pre>

<p>Then if I type <code>localhost:4124</code> in the browser, it don&#8217;t work, but if I
type <code>192.168.1.3:4124</code> in the browser, IT WORKS. :)</p>

<p>But to the original question, it turns out you can run ALL THREE of
these:</p>

<pre><code>ruby -run -e httpd . --port=4123 --bind-address=0.0.0.0
ruby -run -e httpd . --port=4123 --bind-address=192.168.1.3
ruby -run -e httpd . --port=4123 --bind-address=localhost
</code></pre>

<p>So the first and 3rd of these should be able to respond to</p>

<pre><code>curl localhost:4123 &gt; /dev/null
</code></pre>

<p>It seems that the third (localhost) always wins. Makes sense. What about</p>

<pre><code>curl 192.168.1.3:4123 &gt; /dev/null
</code></pre>

<p>And the more specific second one always wins. So I guess the OS will
look for a match of interface+port before falling back to 0.0.0.0.
Makes sense.</p>

<h2>listen queue size</h2>

<pre><code>socket.listen(10)
</code></pre>

<p>This means your socket will buffer up to 10 connections before
<code>ECONNREFUSED</code> is return to the shits on the other side.</p>

<p>If you&#8217;re getting a lot of ECONNREFUSED, it probably means users are
already experiencing some some queue-based lag, and you should rethink
your architecture, spin up more server instances, etc. But you can also
just set to the max size via</p>

<pre><code>server.listen(Socket::SOMAXCONN)
</code></pre>

<h2>A connection is a socket</h2>

<p>When you accept() after binding, you&#8217;ll get a connection object, which
is just a Socket, but different from your server socket; it&#8217;s just a
file wrapper for that particular connection that you can write shit to.</p>

<h2>quadruple of remote/ip/port must be unique</h2>

<p>You can&#8217;t have more than one connection where</p>

<pre><code>local addr, local port, remote addr, and remote port
</code></pre>

<p>are not totally unique. Hmmm, so where is this prevented? TODO</p>

<h2>Close socket file descriptors</h2>

<p>Why, doesn&#8217;t this happen automatically on exit/GC?</p>

<ol>
<li>GC might not clean up for you fast enough;</li>
<li>Might hit file descriptor limit</li>
</ol>


<p>Wat wat wat wat in the boot.</p>

<p>You can close the read side, or close the write side, or both. This make
use of <code>shutdown</code>, and shutdown will close a side of a connection even
if you&#8217;re dup&#8217;d file descriptors (explicitly or via fork). <code>close</code>
wouldn&#8217;t actually close unless there were no other file descriptors
holding on to that socket.</p>

<h2>Keybase</h2>

<p>Uses social media accounts to prove crypto identity.</p>

<h2>Clients don&#8217;t need to bind</h2>

<p>to a port when connecting to a server. For obvious reasons. Namely that
a server needs to have a known/consistent port in order for clients to
reach it, but a client can just send from any ol po,]rt.</p>

<h2>Long ass timeouts</h2>

<pre><code>require 'socket'
socket = Socket.new(:INET, :STREAM)
remote_addr = Socket.pack_sockaddr_in(666, 'machty.com')
socket.connect(remote_addr)
</code></pre>

<p>This won&#8217;t fail any time soon. (Note if i&#8217;d given a BS DNS then it would: SocketError
exception from getaddrinfo). Only after a long ass time do you get a
ETIMEDOUT.</p>

<p>getaddrinfo seems cool. I guess it&#8217;s the C function that does a DNS
lookup? Nevermind, man <code>getaddrinfo</code> makes me cry.</p>

<p>So when does ECONNREFUSED happen vs just a long ass timeout? I guess it
means you&#8217;ve hit a server but a) no app is bound to the requested port
or b) the queue is full, and probably c) some other reason. No that&#8217;s
not valid; google.com:70 hangs for a while rather than ECONNREFUSED.</p>

<p>Maybe localhost knows what&#8217;s connected or not? I have NO IDEA.</p>

<h2><code>TIME_WAIT</code></h2>

<p>If you close a socket with pending outbound data, it won&#8217;t discard that
data but rather finish sending (and wait for ack) before totally closing
the socket. This is the <code>TIME_WAIT</code> state. Unless you&#8217;ve enabled
<code>REUSEADDR</code>, you&#8217;ll get an <code>EADDRINUSE</code> if you try to bind to a socket
that&#8217;s still in <code>TIME_WAIT</code> state.</p>

<h2><code>EAGAIN</code></h2>

<p>Commonly seen in non-blocking IO operations when there&#8217;s no data
available to read. Reading nonblockingly from a socket that hasn&#8217;t had EOF set yet but
doesn&#8217;t have data at the moment would cause that.</p>

<p>Non blocking reads will find any data in Ruby buffers, followed by
kernel buffers. If there&#8217;s nothing in there, then blocking read is
necessary.</p>

<h2>Ruby IO.write</h2>

<p><code>IO.write_nonblock</code> behavior maps to sys call <code>write()</code>, in that it can
fail to write all the data you provided it. Ruby&#8217;s <code>IO.write</code> tries to
be helpful and might internally call <code>write()</code> many times.</p>

<p>A saturated <code>write()</code> followed immediately by <code>write()</code> will cause an
<code>EAGAIN</code> because you haven&#8217;t given the kernel/network enough time to
flush the data you gave it. This is when you&#8217;d use <code>IO.select</code> to let
you know when a socket is available for writing/reading again.</p>

<p>Wat wat wat. In the BOOT.</p>

<p><code>select</code> returns an array of descriptors that are ready to be written
to. I guess it blocks?</p>

<p>Writes are blocked by TCP congestion prevention algo requirements
(cwnd, rwnd, etc).</p>

<p>There&#8217;s also <code>accept_nonblock</code> which <code>EAGAIN</code>s if there are no pending
connection on dat queue.</p>

<p><code>connect_nonblock</code> is sp</p>

<h2>TPC Resets</h2>

<p>http://en.wikipedia.org/wiki/TCP_reset_attack</p>

<p>There&#8217;s a usually-0 flag in a packet that can be set to 1 that tells the
receiver to stop using this TCP connection. Useful, for instance, when a
computer&#8217;s crashed, gets a packet it has no context for, so it tells the
sender to stop it, so that it might make a new connection and start from
there.</p>

<h2>Edge Device</h2>

<p>http://en.wikipedia.org/wiki/Edge_device</p>

<p>Basically, all the stuff that separates the public network (internet)
from your private network.</p>

<ul>
<li>routers</li>
<li>routing switches</li>
</ul>


<h2>traceroute</h2>

<p>I&#8217;ve already written about this before, but traceroute is useful for
tracing all the gateways your packet goes through to get to its
destination.</p>

<p>A gateway is any node that might forward packets along to some other
destination. Could be a router, switch, etc. Could also be a protocol
converter. Gateways could be software too.</p>

<p>Anyway, traceroute makes use of ICMP <code>TIME_EXCEEDED</code> response.</p>

<p><a href="http://en.wikipedia.org/wiki/Internet_Control_Message_Protocol">What is ICMP?</a></p>

<p>One of the many protocols that can be communicated via packets. Packets
have an 8 bit protocol field. The protocol values are decided by the
IANA (just like common/reserved ports&#8230; MIND BLOWN).</p>

<p>The list is here: http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml</p>

<h2><code>host google.com</code></h2>

<p>I noticed that the DNS lookup results via <code>host google.com</code> differed
almost each time I ran it.</p>

<pre><code>google.com has address 74.125.226.72
google.com has address 74.125.226.65
google.com has address 74.125.226.68
google.com has address 74.125.226.67
google.com has address 74.125.226.64
google.com has address 74.125.226.70
google.com has address 74.125.226.78
google.com has address 74.125.226.69
google.com has address 74.125.226.73
google.com has address 74.125.226.71
google.com has address 74.125.226.66
...
</code></pre>

<p>and then</p>

<pre><code>google.com has address 74.125.226.2
google.com has address 74.125.226.5
google.com has address 74.125.226.8
google.com has address 74.125.226.9
google.com has address 74.125.226.6
google.com has address 74.125.226.4
google.com has address 74.125.226.3
google.com has address 74.125.226.14
google.com has address 74.125.226.7
google.com has address 74.125.226.0
google.com has address 74.125.226.1
...
</code></pre>

<p>I&#8217;m asking the friendly folk at <code>##networking</code>. They turned me on to
<code>dig</code>. <code>dig</code> is the most raw and flexible DNS lookup tool. <code>host</code> is
apparently for chumps (i.e. it&#8217;s useful/quick/easy but not as much
functionality).</p>

<pre><code>dig google.com @ns1.google.com +short | sort | md5
</code></pre>

<p>This queries a specific name server&#8230;</p>

<p>OK i have a bunch of questions:</p>

<p>Why do DNS records contain
<a href="http://en.wikipedia.org/wiki/Fully_qualified_domain_name">Fully Qualified Domain Names</a>
as references to name servers? That seems to make no sense&#8230; you have
to turn something like <code>ns1.google.com</code> into an IP by querying&#8230; the
DNS system?</p>

<p>Answer: http://en.wikipedia.org/wiki/Domain_Name_System#Circular_dependencies_and_glue_records</p>

<ul>
<li>GET www.example.com /

<ul>
<li>Look up record, find its NS records</li>
<li>NS ns1.example.com</li>
<li>Need to get IP of ns1.example.com (we need to issue another DNS
request)</li>
<li>&#8230; circular dependency: you have to look up a name server&#8217;s IP
using that name server. Need some way to break dependency</li>
<li><p>Dependency broken by <code>AUTHORITY SECTION</code>, e.g.</p>

<p>;; AUTHORITY SECTION:
google.com.             60      IN      SOA     ns1.google.com. dns-admin.google.com. 1566886 7200 1800 1209600 300</p></li>
</ul>
</li>
</ul>


<p>This is called the &#8220;glue&#8221;. It&#8217;s either in Authority or Additional
section? (I should find this out.)</p>

<p>Related: http://support.dnsimple.com/articles/vanity-nameservers/</p>

<p>DNSimple allows &#8220;vanity&#8221; name servers, which lets you pretend like
you&#8217;re a bigass enough company to own/maintain your own name servers,
and anyone looking at your DNS records will see your fake name servers,
like ns1.machty.com, but these servers obviously don&#8217;t actually exist;
DNSimple provides this service by sending &#8220;glue&#8221; that maps your fake
name servers to the IP addresses of their actual name servers.</p>

<p>Top-level domains live under root (.).</p>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<p>That&#8217;s why sometimes you&#8217;ll see stuff ending in a period, like
<code>ns1.dnsimple.com.</code>.</p>

<pre><code>;; ANSWER SECTION:
dnssimple.com.          597     IN      A       184.168.221.96
</code></pre>

<p>The dot is important! You know how you can just put <code>www</code> is the record
value? You could also do a fully qualified shit e.g. <code>www.machty.com.</code>
(note the period at the end).</p>

<p>So my question is: when does the glue record get sent?</p>

<p>Gimme the NS records for www.machty.com</p>

<pre><code>$ dig machty.com NS
...
;; ANSWER SECTION:
machty.com.             3481    IN      NS      ns1.dnsimple.com.
machty.com.             3481    IN      NS      ns1a.dnsimple.com.
machty.com.             3481    IN      NS      ns2.dnsimple.com.
machty.com.             3481    IN      NS      ns2a.dnsimple.com.
machty.com.             3481    IN      NS      ns3.dnsimple.com.
machty.com.             3481    IN      NS      ns3a.dnsimple.com.
machty.com.             3481    IN      NS      ns4.dnsimple.com.
machty.com.             3481    IN      NS      ns4a.dnsimple.com.
</code></pre>

<p>Cool, so internally it&#8217;d need to look up ns1.dnsimple.com, so something
like:</p>

<pre><code>$ dig @ns1.dnsimple.com. www.machty.com
</code></pre>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<blockquote><p>+norec means that dig is asking non-recursive questions so that we get to do the recursion ourselves. The other options are to reduce the amount of dig produces so this won&#8217;t go on for too many pages:</p></blockquote>

<pre><code>a.root-servers.net. 518400  IN  A   198.41.0.4
a.root-servers.net. 518400  IN  AAAA    2001:503:ba3e:0:0:0:2:30
</code></pre>

<p>AAAA records serve the same purpose as A records, just that they are
IPv6.</p>

<p>WebPageTest.org: breaks your requests down into blah blah blah why is
this different than Network tab in devtools? Ah because it does it from
many different browsers.</p>

<p>162.212.105.24</p>

<h2>Turntable.fm</h2>

<p>Me: &#8220;there should be an app where multiple people have a playlist, but
there&#8217;s a single player that alternates between different people&#8217;s
playlists.&#8221;</p>

<p>Person next to me: &#8220;yes, that&#8217;s turntable.fm&#8221;</p>

<p>Should probably check that out.</p>

<h2>non-blocking connect</h2>

<p>http://stackoverflow.com/questions/8277970/what-are-possible-reason-for-socket-error-einprogress-in-solaris</p>

<p>There are two error codes for &#8220;shit is underway&#8221; when doing a
non-blocking connect/accept:</p>

<pre><code> [EALREADY]         The socket is non-blocking and a previous connection attempt
                    has not yet been completed.

 [EINPROGRESS]      The socket is non-blocking and the connection cannot be com-
                    pleted immediately.  It is possible to select(2) for comple-
                    tion by selecting the socket for writing.
</code></pre>

<p>Nice docs yo. The difference is that <code>EINPROGRESS</code> is the error that
gets returned if the operation has started but hasn&#8217;t finished (as
opposed to not yet being able to start because it can&#8217;t allocate the
resources it needs, file handlers, sockets, etc.). Most likely, the 3
way handshake packets have been sent, but SYN-ACK hasn&#8217;t been sent.</p>

<h2>Inversion of Control / DI</h2>

<p>Matthew Beale and I were discussing whether the proposed
<code>Ember.service()</code> violated the inversion of control that dependency
injection is meant to provide, e.g.:</p>

<pre><code>export default Controller.extend({
  foo: Ember.service() // request that 'service:foo' be injected
});
</code></pre>

<p>The fact that the consumer is requesting a specific thing to be injected
into it seems like it might be an IOC violation, but to me, all that&#8217;s
happening is that you&#8217;re specifying a provider, and it&#8217;s still up to the
outside world to decide what it&#8217;ll specifically inject into you. Also,
regardless of whether it&#8217;s explicit or not, if you use whatever is
injected into you, you are implicitly specifying a duck-typed provider
interface by the consumer; in other words, if we do things the classic
way and use <code>app.inject('controller:article', 'articleLookup', 'service:article-lookup')</code>,
this may seem like we&#8217;re moving all &#8220;control&#8221; to the injector, but
still, the article controller is going access <code>articleLookup</code>&#8217;s
properties and methods in a very specific way, which is the most
powerful / crucial way that you could specify a dependency (by
describing / using the duck type interface).</p>

<p>So, tl;dr, your consumer is always going to be specifying its
dependency, whether explicitly (<code>Ember.service()</code>) or implicitly (by
whatever methods/properties it uses from <code>this.injectedThing</code>), and it&#8217;s
therefore not a violation for a consumer to specify a Provider of the
dependency, so long as it&#8217;s still possible for the injector to disregard
the specifically-requested provider and substitute another one (e.g. a
stub) in its place.</p>

<p>This is what Angular&#8217;s <a href="https://github.com/angular/di.js">di.js</a> does
and I think it&#8217;s correct. I want it.</p>

<h2>Password-less SSH</h2>

<p>I&#8217;ve done this a bunch of times before but always forget, now I&#8217;m
writing about it:</p>

<p>The remote server you&#8217;re SSHing into needs to have your public key if
you want to be able to skip providing a password every time you ssh in.
I wanted to use a different public rsa key, so I made a new one:</p>

<pre><code>ssh-keygen
</code></pre>

<p>The optional passphrase you&#8217;re asked to supply is NOT the same password
you would have otherwise needed to use to log into SSH (which we&#8217;re
trying to avoid). Rather, it&#8217;s an additional security measure that&#8217;s
required every time you want to use your private RSA key to try and
decrypt data. I guess: if private RSA keys are a kind of password, the
passphrase is a password for your password. It means that someone who
steals your private key also needs to know your passphrase in order to
use it.</p>

<p>Anyway, let&#8217;s say I save the newly generated key pair to
<code>~/.ssh/shortcut_rsa</code> and <code>~/.ssh/shortcut_rsa.pub</code>, now I want to make
it possible to just type <code>ssh shortcut</code> and have it never ask me for a
password again. This means I need a few things:</p>

<ol>
<li><code>ssh shortcut</code> should translate into the IP I&#8217;m connecting to
(because I&#8217;d rather not type the IP every time and <code>shortcut</code> is not
a domain name that&#8217;d do the translating for me)</li>
<li><code>ssh shortcut</code> should supply the user name that the remote machine
expects (so that I don&#8217;t have to do <code>ssh remote_user_name@shortcut</code>).</li>
<li><code>ssh shortcut</code> should use the key pair I just generated w
<code>ssh-keygen</code>.</li>
</ol>


<p>To do all of these things, I need to append the following to
<code>~/.ssh/config</code>.</p>

<pre><code>Host shortcut
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>Pretty self explanatory and does the job. Note that you&#8217;ll be prompted
for the passphrase you provided for your RSA private key, but that&#8217;ll be
cached for a little while, and if you want, you can just save it to your
Apple keychain if you feel safe doing that.</p>

<p>The SSH config file also allows for wildcards, so you could literally do</p>

<pre><code>Host *
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>and then this would cause <code>ssh somerandombullshit</code> to connect to the
same remote machine. Obviously that use case is a little nuts, but it&#8217;s
useful if you wanna say &#8220;every remote machine I connect to should use
this same RSA key pair&#8221;.</p>

<h2>say+say+say = choir</h2>

<p>I devised the most badass script.</p>

<pre><code>#!/usr/bin/env sh

# use/uncomment this instead to weed out the annoying singing voices
#voices=`say -v ? | grep en_US | grep -v Cellos | grep -v Good | grep -v Hysterical | grep -v Bad | grep -v Pipe | grep -v Bells | cut -f1 -d ' '`
voices=`say -v ? | grep en_US | cut -f1 -d ' '`
num=`echo $voices | wc -w`
echo $voices | xargs -n 1 -P $num say $* -v
</code></pre>

<h2>How many segments are sent per SSH character?</h2>

<p>http://blog.hyfather.com/blog/2013/04/18/ssh-uses-four-tcp-segments-for-each-character/</p>

<p>Answer: 4</p>

<ol>
<li>You: Hey SSH server, user pressed &#8216;b&#8217;</li>
<li>SSH: cool, got it (ack)</li>
<li>SSH: hey btw, this is what <code>bash</code> (or whatever shell) ended up doing
with that character you type (description of screen update)</li>
<li>You: cool, got it (ack)</li>
</ol>


<p>What&#8217;s the difference between a segment and a packet?</p>

<ul>
<li>Segment: TCP header + application data</li>
<li>Packet: wraps segment w IP header information; a packet is a routable
piece of data</li>
</ul>


<p>This seems like the best answer: http://superuser.com/a/505134</p>

<p>A TCP segment is not enough information to know where to route data
within a network; you need IP headers for that, and where do those shits
live? In packets.</p>

<p>Take a packet and rip off its IP head: voila, a packet. Take a packet
and rip off its TCP (or UDP) head: voila, application data.</p>

<p>Don&#8217;t forget &#8220;frames&#8221;: frames wrap packets. If you wanna send your shit
over an ethernet, you need to wrap in a frame, whether wired or
wireless. Frames have MAC addresses. MAC addresses are generally
hard-wired into some hardware and are never expected to collide, lest
undefined behavior.</p>

<p>Now my question is: does TCP ever have access to IP headers? I guess it
must get forwarded along in some way&#8230; then again I dunno.</p>

<h2>RFC3439: Some Internet Architectural Guidelines and Philosophy</h2>

<p>http://tools.ietf.org/html/rfc3439</p>

<p>Clearly I need to read this.</p>

<h2>Nagle&#8217;s Algo</h2>

<p>When sending data:</p>

<ol>
<li>If there&#8217;s enough data in local packet buffer to comprise a whole TCP
packet, send that shit.</li>
<li>If no pending data in buffers and no pending acks, send immediately.</li>
<li>If there&#8217;s a pending ack, and not enough data to fill a packet, put
data in local buffer.</li>
</ol>


<p>This prevents protocols like telnet from saturating with
one-packet-per-char traffic. For telnet, if you type a bunch of chars in
a row, you could expect that the first char would send immediately and
the following ones would buffer and then send once the first char&#8217;s ack
came back.</p>

<p>All Ruby servers disable this since Ruby does its own internal buffering
in the socket lib. You disable by sending with NODELAY.</p>

<h2>URG flag</h2>

<p>Apparently you can break the FIFO-ness of TCP with Urgent data.</p>

<p><code>Socket#send</code> is the same as <code>write</code> except that you can pass flags to
<code>send</code>, e.g.</p>

<pre><code>socket.send 'urgent data', Socket::MSG_OOB
</code></pre>

<p>OOB stands for out of band. Note that the receiver must use the same
flag w <code>recv</code> to read the OOB data or else it won&#8217;t notice it.</p>

<p>OOB is rarely used because:</p>

<ul>
<li>only one byte of urgent data can be sent</li>
<li>there are issues w <code>select</code> wherein consumed urgent data continues to
be reported as unread, requires additional state tracking to get
right, etc.</li>
</ul>


<p>You could also use OOBINLINE flag to stick in an urgent byte amidst
normal queued data, and <code>read</code> will stop once it hits an urgent thing.</p>

<p>I&#8217;m guessing OOB is only a TCP thing since in UDP there&#8217;s no concept of
connection and &#8220;in order&#8221;.</p>

<h2>Datagram</h2>

<p>Data + telegram. From RFC 1594:</p>

<blockquote><p>“A self-contained, independent entity of data carrying sufficient information to be routed from the source to the destination computer without reliance on earlier exchanges between this source and destination computer and the transporting network.”</p>

<p>The term datagram is often considered synonymous to packet but there are some nuances. The term datagram is generally reserved for packets of an unreliable service, which cannot notify the sender if delivery fails, while the term packet applies to any packet, reliable or not. Datagrams are the IP packets that provide a quick and unreliable service like UDP, and all IP packets are datagrams;[4] however, at the TCP layer what is termed a TCP segment is the sometimes necessary IP fragmentation of a datagram,[5] but those are referred to as &#8220;packets&#8221;.</p></blockquote>

<p>So, datagrams imply unreliability of delivery, whereas packet could
refer to reliable or unreliable packets. I guess a TCP segment is a
packet. But you can&#8217;t call it a datagram, since the protocol makes it
its business to be a shit.</p>

<h2>Bill Burr</h2>

<p>How&#8217;s your danish?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/28/daily-journal/"/>
    <updated>2014-08-28T13:10:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/28/daily-journal</id>
    <content type="html"><![CDATA[<h2>Why can&#8217;t React render() return multiple elements?</h2>

<p>you can&#8217;t do</p>

<pre><code>return &lt;div/&gt;&lt;div/&gt;
</code></pre>

<p>Pete Hunt tells me it&#8217;s because of how <code>ref</code>s work; it&#8217;s a common
pattern to do <code>this.refs.x.getDOMNode()</code>, but if the component returns
multiple DOM nodes, which one do you return?</p>

<p>It&#8217;s an admitted shortcoming but not a major major push to fix any time
soon.</p>

<h2>Ruby Fixnum vs Bignum</h2>

<pre><code>2.0.0-p353 :004 &gt; (100).class
 =&gt; Fixnum
2.0.0-p353 :005 &gt; (100234234234234234234).class
 =&gt; Bignum
</code></pre>

<h2>Postgres indexing</h2>

<p>I need to optimize. Most of the queries in my app are very specific
&#8220;SELECT WHERE bleh = wat, lol = yeah, foo = bar&#8221;. By default Rails
creates a btree index, which handles many common indexing use cases, but
there&#8217;s also a &#8220;hash&#8221; index, which Postgres only considers for usage for
<code>bleh = bleh</code> queries (you can&#8217;t use it for ordering, sorting,
whatever), so it seemed ideal for me:</p>

<blockquote><p>Hash indexes can only handle simple equality comparisons. The query planner will consider using a hash index whenever an indexed column is involved in a comparison using the = operator.</p></blockquote>

<p>But then I&#8217;d like it to match multiple columns, not just a single one,
so I&#8217;d like to consider a multi-column index, but then:</p>

<blockquote><p>Currently, only the B-tree, GiST and GIN index types support multicolumn indexes. Up to 32 columns can be specified. (This limit can be altered when building PostgreSQL; see the file pg_config_manual.h.)</p></blockquote>

<p>So I guess Hash is out of the question. So the final thing I need to
figure out is: does it make sense for me to use a multi-column index if
I have three columns that need to be <code>=</code> matched?</p>

<p>Partial indexes: http://www.postgresql.org/docs/8.2/static/indexes-partial.html</p>

<p>Useful for when you&#8217;d like to exclude common values from consideration
in an index (because indexes lose value the more duplicates there are in
a database).</p>

<h2>V8 optimizes based on AST size</h2>

<p>&#8230;and comments are part of the AST:</p>

<p>https://github.com/broccolijs/broccoli-kitchen-sink-helpers/commit/092a680f1ff8fe2d54419dd57fa9ba8a81f6f297</p>

<h2>General Theory of Reactivity</h2>

<p>https://github.com/kriskowal/gtor</p>

<p>Reactivity: reacting to external stimuli and propagating events.</p>

<ul>
<li>(functional) reactive programming</li>
<li>bindings</li>
<li><p>operational transform</p></li>
<li><p>Spatial Singular is a value, e.g. 5</p></li>
<li>Spatial Plural is an enumberable/iterable of values</li>
<li>Temporal Singular is an eventual value, e.g. a Promise</li>
<li>Temporal Plural is eventual values, e.g. Observable of values</li>
</ul>


<p>But this glazes over many particulars, and things like Rx boil too much
into a single Observable type that can perform any role.</p>

<h3>Value</h3>

<ul>
<li>Singular</li>
<li>Spatial</li>
<li>Accessible</li>
<li>Modifiable</li>
<li>Composed of a getter and a setter</li>
<li>Data flows from setter to getter</li>
</ul>


<p>Every reactive primitive features getter/setter, producer/consumer, or
writer/reader. See http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2014/Keynote-Duality</p>

<p>Arrays are the above, but plural. Generators are the
producing/writing/setting side, iterators are the read/get/consume.</p>

<p>Promises are singular and temporal. Promises are getters, and
corresponding setter is a resolver. Together, they&#8217;re a kind of
deferred.</p>

<p>Streams are a getter/setter pair of temporal plurals. Producer is a
writer and consumer is a reader. Reader is an async iterator and writer
is an async generator.</p>

<p>Remember that a value encapsulates a getter and setter&#8230; values are:
Deferred (promise + resolver, singular, temporal), Stream (reader +
writer, plural, temporal), Array (iterator + generator, spatial,
plural), and value (getter + setter, spatial, singular).</p>

<p>Promises (singular + temporal) model dependency. The API/experience of
multiple resolvers is the same regardless of who wins the race, and same
w consumers.</p>

<p>Because consumers cannot interfere with another consumer, aborting
promises is not possible; promise is only the result, not the work
leading to that result.</p>

<p>A task, similar to promise, but is unicast.</p>

<p>Unicast: http://en.wikipedia.org/wiki/Unicast - sending messages to a
  single destination</p>

<p>Broadcast: multiple possible destinations (or none)</p>

<p>Because tasks are unicast, consumers can&#8217;t clobber each other (because
there&#8217;s only one), hence they are cancellable. Can be explicitly forked
to create a task that depends on the same result</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/22/daily-journal/"/>
    <updated>2014-08-22T16:32:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/22/daily-journal</id>
    <content type="html"><![CDATA[<h2>Difference b/w XSD and DTD</h2>

<p>They both define the structure of an XML document, but what&#8217;s the
difference?</p>

<p>Awesome SO:
http://stackoverflow.com/questions/1544200/what-is-difference-between-xml-schema-and-dtd</p>

<p>DTD&#8217;s are arguably easier to grok, but the XSD has more features, but at
the expense of understanding the abstractions of data types and what
not. Seems easier to describe recursive structures in XSD than the other
bullsharticles.</p>

<p>XSD is XML, DTD stems from SGML.</p>

<p>I guess XML And HTML also stem from SGML. WHAT DO I KNOW? NOTHING!</p>

<h2>Wolf3d in React</h2>

<p>Apparently I missed this https://github.com/petehunt/wolfenstein3D-react.git</p>

<h2>Breaking the chain in React</h2>

<p>For when you want to tell React &#8220;don&#8217;t mess with my DOM, I&#8217;m doing funky
jQuery shit&#8221;.</p>

<p>Render a div that won&#8217;t invalidate:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L47</p>

<p>Re-render your own children:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L15-L18</p>

<h2>Retcon: retroactive continuity</h2>

<p>http://en.wikipedia.org/wiki/Retroactive_continuity</p>

<p>&#8220;alteration of previously established facts in the continuity of a
fictional work&#8221;</p>

<h2>CVV can mean lower rates</h2>

<p>http://security.stackexchange.com/questions/21168/how-does-amazon-bill-me-without-the-cvc-cvv-cvv2</p>

<p>There are fraud-prevention benefits to using CVV, and as such, payment
handlers will often give you a discount if the CVV is present.</p>

<h2>X-Forwarded-For</h2>

<p>Some servers fall prey to IP spoofing via setting the <code>X-Forwarded-For</code>
header. If your server isn&#8217;t careful, then given a
<code>curl -H "X-Forwarded-For: 1.2.3.4" http://www.machty.com</code>, your
server&#8217;s logs and maybe even IP-dependent application logic (e.g.
language detection) might use 1.2.3.4.</p>

<p>In Rails you can add your known proxy/load-balancing IPs to
<code>TRUSTED_PROXIES</code>. Then the <code>RemoteIp</code> rack middleware will filter out
all of those and pick the most recently set IP, which handles the case
where you might have multiple <code>X-Fowarded-By</code> headers. So the rule is:
use the rightmost, untrusted IP and treat that as the remote ip. Why?
Because when your first proxy is hit, it&#8217;ll see IP X.X.X.X and move that
to the list of <code>X-Forwarded-By</code> headers. Note that the previous
<code>X-Forwarded-By</code> headers, present or no, are untrustable and totally
spoofable.</p>

<p>http://blog.gingerlime.com/2012/rails-ip-spoofing-vulnerabilities-and-protection</p>

<p>So that&#8217;s IP spoofing via HTTP header. How else can you IP spoof?</p>

<p>http://en.wikipedia.org/wiki/IP_address_spoofing</p>

<p>You just rewrite the source IP in the TCP/UDP packet header, which also
means when the application responds, it&#8217;ll send it back to the forged
IP.</p>

<p>There are valid use cases for this as well, such as testing load
balancing software/hardware.</p>

<h2>Types of NAT</h2>

<p>http://think-like-a-computer.com/2011/09/16/types-of-nat/</p>

<h3>Full cone NAT (Static NAT) (port forwarding)</h3>

<p>Manual mapping of public IP and port to LAN IP and port.</p>

<p>e.g. all incoming traffic to port 12345, forward to 192.168.0.10:9999.</p>

<p>Blocks (drops connection):</p>

<ul>
<li>Ports that haven&#8217;t been forwarded</li>
</ul>


<h3>Restricted cone NAT (dynamic)</h3>

<p>Don&#8217;t allow incoming data from an IP unless I&#8217;ve sent packets to it
already. Note that depending on the strictness, if I initiate a
connection to WAN IP 1.2.3.4:1234, I could potentially get data from
1.2.3.4:5678, but in stricter schemes, the port must also match.</p>

<p>But regardless of this strictness, the one requirement is that they send
data to exactly my public IP and port that I sent data out of.</p>

<h3>Symmetric NAT</h3>

<p>http://think-like-a-computer.com/2011/09/19/symmetric-nat/</p>

<p>Sym NAT is like port-restricted cone NAT, but randomly generates
different public source ports when sending to different destinations.</p>

<p>Sym NATs are the only ones that cause problems with other devices behind
NATs.</p>

<h2>Vim registers</h2>

<p>So if I have</p>

<pre><code>&lt;a href="WAT"&gt;&lt;/a&gt;
</code></pre>

<p>and I want to replace the href with a yanked &#8220;LOL&#8221;, then I can <code>di"</code> in
WAT to delete it, then <code>"0P</code> to use the last-yank register 0. Registers
1,2,3,4,5&#8230; get populated with cuts. Unnamed register gets replaced by
any yanking/cutting command. Weird terminology.</p>

<h2>Ember-cli + divshot</h2>

<p>Holy shit this was awesome.</p>

<p>Divshot.com is a static deployment heroku, basically, and ember-cli has
an addon for letting you deploy there.</p>

<pre><code>npm install --save-dev ember-cli-divshot &amp;&amp; ember generate divshot
</code></pre>

<h2>brew install fuck</h2>

<p>naw, but this is a cool script for killing them all:</p>

<pre><code>#!/usr/bin/env ruby
# coding: utf-8

abort "Usage: fuck you &lt;name&gt;" unless ARGV[0] == "you" &amp;&amp; ARGV.size == 2

a = "abcdefghijklmnopqrstuvqxyz".each_char.to_a
b = "ɐqɔpǝɟƃɥıɾʞʃɯuodbɹsʇnʌʍxʎz".each_char.to_a
ws = Hash[a.zip(b)]
ws.default = -&gt;(f){f}

puts "\n  (╯°□°）╯︵ #{ARGV[1].reverse.each_char.map{|f|ws[f]}.join}\n\n"

system("killall -9 #{ARGV[1]}")
exit $?.exitstatus
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/15/daily-journal/"/>
    <updated>2014-08-15T12:17:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/15/daily-journal</id>
    <content type="html"><![CDATA[<h2>Incremental GC</h2>

<p>Tenderlove tweeted this: https://bugs.ruby-lang.org/issues/10137</p>

<ul>
<li>Generational GC already is implemented: distinguish/bucket old and new
generation objects; sweeping new generation objects is fast (minor GC), and the
ones that don&#8217;t get swept up get promoted to old generation, which is
less frequently swept (in a major GC)</li>
<li>Generation GC is always incremental in that it doesn&#8217;t collect ALL
unreachables, &#8230; todo http://stackoverflow.com/questions/5092134/whats-the-difference-between-generational-and-incremental-garbage-collection</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/09/daily-journal/"/>
    <updated>2014-08-09T16:15:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/09/daily-journal</id>
    <content type="html"><![CDATA[<h2>iOS State Preservation</h2>

<p>https://developer.apple.com/library/ios/documentation/iphone/conceptual/iphoneosprogrammingguide/StatePreservation/StatePreservation.html</p>

<h2>Session token storage in localStorage</h2>

<p>Do not store session identifiers in local storage as the data is always accessible by JavaScript. Cookies can mitigate this risk using the httpOnly flag.</p>

<p>It&#8217;s risky? SAY MORE THINGS.</p>

<h2>Loading Ember CLI addons in jsbin</h2>

<h2>Forking in xargs</h2>

<p>Holy shitters, this is how I simultaneously uploaded three tracks to s3
(using my <code>to_s3</code>) script.</p>

<pre><code>find ~/Desktop -name "Audio*" -print0 | xargs -0 -n 1 -P 5 to_s3
</code></pre>

<p><code>-n 1</code> means each invocation takes a max of one arg, and <code>-P 5</code> means a
max of 5 simultaneous processes. So cool.</p>

<h2>Web audio api</h2>

<p>Finish this: http://emberjs.jsbin.com/ucanam/5964/edit</p>

<h2>Liquid Fire Global</h2>

<p>http://jsbin.com/mifuq/1/edit</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/05/daily-journal/"/>
    <updated>2014-08-05T08:47:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/05/daily-journal</id>
    <content type="html"><![CDATA[<h2>ES6 fat arrow</h2>

<pre><code>var a = this;
var fn = () =&gt; {
  console.log(this === a); // true
}
</code></pre>

<p>http://tc39wiki.calculist.org/es6/arrow-functions/</p>

<p>yuno CoffeeScript single arrow syntax?</p>

<blockquote><p>However, we don&#8217;t want CoffeeScript&#8217;s ->, it&#8217;s confusing to have two arrows and dynamic this binding is an oft-fired footgun.</p></blockquote>

<h2>SaltStack</h2>

<p>http://docs.saltstack.com/en/latest/</p>

<h2>Open Core</h2>

<p>http://en.wikipedia.org/wiki/Open_core</p>

<p>Open Source core functionality with paid/proprietary add-ons, e.g.
Sidekiq, or MySQL</p>

<p>Related:</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Crippleware">Crippleware</a>: free versions
cripple the ability to save/export/whatever</li>
<li><a href="http://en.wikipedia.org/wiki/Freemium">Freemium</a>: free core features,
pay for higher usage/capacity, e.g. most heroku add-ons</li>
</ul>


<h2>Ember First Class Actions</h2>

<p>http://emberjs.jsbin.com/ucanam/5919/edit</p>

<p>Questions:</p>

<ul>
<li>singleton vs multiples?</li>
<li>actions that depend on others?</li>
<li>link-to?

<ul>
<li>idea: a LinkView asks the router or url service for an Action
using the route params, query params, etc.</li>
<li>LinkView&#8217;s active CP is <code>action.pending</code> || present day isActive</li>
<li>action will internally delegate to a shared transitionTo action
that everyone in the world can see; everyone can know where it&#8217;s
going, etc etc etc.</li>
</ul>
</li>
</ul>


<p>We need to separate fake link font decoration style from the underlying
action.</p>

<p>Link&#8217;s display components:</p>

<pre><code>routeDescriptor: function() {
  // when resolvedParams change, we need to recalculate
  // our route object... this should refire only when
  // params change, not when the URL changes
  this.urlService.getRouteObject('articles', 1)


  this.urlService.createRouteDescriptor({
    routeName: alias('_linkView.params.firstObject'),
    contexts: alias('_linkView.contexts'),
    queryParams: alias('_linkView.queryParams'),
    _linkView: this
  });
}//.property('resolvedParams')

createRouteDescriptor: function(_attrs) {
  var attrs = {
    router: this.router, // or maybe just `this`?
  };
  Ember.merge(attrs, _attrs);
  return RouteDescriptor.createWithMixins(attrs);
}

RouteDescriptor = Ember.Object.extend({
  // required
  router: null,
  routeName: null,
  contexts: null,
  queryParams: null,

  allParams: computed('routeName', 'contexts', 'queryParams', function() {
    // this is just a perfy thing; since all calculations depend
    // on all these params, we'll avoid the overhead of multiple
    // CPs depending on each of these params
    return this.getProperties(['routeName', 'contexts', 'queryParams']);
  }),

  path: computed('router.url', 'allParams', function() {
    var allParams = this.get('allParams');
    var router = this.get('router');

    // presently we only use router.url as a cue that the router
    // is at a new route
    var url = this.get('router.url');

    // pass crap to routerJS
  }),

  perform: function() {
    // invoke, blah blah blah, same logic as in link to.
    this.get('allParams');
  }
});

service.getRouteDescriptor('articles', 1)

{
  action:   FCA,
  isActive: true,
  path: "/some/dynamic/thing"
}
</code></pre>

<p>RouteDescriptors are objects</p>

<ul>
<li>inactive: !routeObject.active</li>
<li>active:   routeObject.active</li>
<li>visited</li>
</ul>


<p>Weird thing: ember link-to&#8217;s concept of &#8220;active&#8221; doesn&#8217;t match with
<code>&lt;a&gt;</code> tag&#8217;s concept of active; link-to &#8216;active&#8217; means you&#8217;re currently
in the route specified by that link; <code>&lt;a&gt;</code> tag&#8217;s active means you&#8217;re
currently clicking this link.</p>

<p>I think I know how to refactor link-to and LinkView and all that</p>

<p>Goals</p>

<ul>
<li>make linking/routing/active calc logic shareable</li>
<li>make it possible to click a link to make it active before a slow
transition has completed.</li>
<li>support calculating activeness for bootstrap wrapper <code>&lt;li&gt;</code>s and
anything else in general too.</li>
</ul>


<h2>RFCs</h2>

<p>Rust tempered it&#8217;s freewheeling feature additions by requiring RFCs.</p>

<p>https://github.com/rust-lang/rfcs/blob/master/active/0001-rfc-process.md
https://github.com/rust-lang/rfcs/blob/master/active/0039-lifetime-elision.md</p>

<p>Sounds like we&#8217;ll be doing this for Ember.</p>

<h2>Elide</h2>

<blockquote><p>omit (a sound or syllable) when speaking: (as adj. elided) : the indication of elided consonants or vowels.</p></blockquote>

<h2>Variadic</h2>

<p>http://en.wikipedia.org/wiki/Variadic_function</p>

<p>A function that is variadic has an indefinite number of arguments.
<code>.bind</code></p>

<blockquote><p>8:50 PM <spion> bind is variadic and I think it also has to do some stuff with constructors
8:51 PM <spion> (additional arguments can be used for partial application)
8:52 PM <spion> the constructor stuff: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/bind#Bound_functions_used_as_constructors
8:53 PM <spion> (creates significant additional overhead)
8:53 PM <spion> so a simple non-variadic closure implementation of bind has a lot less work to do :P</p></blockquote>

<h2>React forms</h2>

<p>https://github.com/wingspan/wingspan-forms</p>

<p>Powerded by KendoUI</p>

<h2>Reflux</h2>

<p>https://github.com/spoike/refluxjs</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>╔═════════╗       ╔════════╗       ╔═════════════════╗
</span><span class='line'>║ Actions ║──────&gt;║ Stores ║──────&gt;║ View Components ║
</span><span class='line'>╚═════════╝       ╚════════╝       ╚═════════════════╝
</span><span class='line'>     ^                                      │
</span><span class='line'>     └──────────────────────────────────────┘</span></code></pre></td></tr></table></div></figure>


<p>Rationale: http://spoike.ghost.io/deconstructing-reactjss-flux/</p>

<h2>Promixo dedicated</h2>

<p>https://addons.heroku.com/proximo#dedicated</p>

<h2>CIDR: Classless Inter-Domain Routing</h2>

<p>http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing</p>

<p>Classful allocation of IP addresses (pre 1993) defined class A, B, C
network groups split along the 8 bit chunks. Problem is the smallest
allocation (256 addresses, assuming you were allocated something like
123.456.789.XXX) was often too small for companies, whereas the next
step up from that (123.456.XXX.XXX) was generally too huge (65536) for
companies/entities to efficiently take advantage of. SOLUTION: CIDR
blocks and subnet masks.</p>

<blockquote><p>This led to inefficiencies in address use as well as routing because the large number of allocated small (class-C) networks with individual route announcements, being geographically dispersed with little opportunity for route aggregation, created heavy demand on routing equipment.</p></blockquote>

<p>In other words, class C allocations are 123.456.789.XXX allocations,
each containing 256 addresses, with no requirement that they be
geographically grouped, such that routers had to maintain large tables
for very similar looking addresses rather than being able to rely on
some grouping rules to minimize the routing information they had to know
about. But now subnet masking is a thing and blah blah blah I&#8217;m done
learning this shit.</p>

<p>192.168.2.0/24 means that the network is identified by the first 24 bits</p>

<blockquote><p>192.168.100.0/24 represents the given IPv4 address and its associated routing prefix 192.168.100.0, or equivalently, its subnet mask 255.255.255.0 (i.e. 24 &#8220;1&#8221; bits).</p>

<p>the IPv4 block 192.168.100.0/22 represents the 1024 IPv4 addresses from 192.168.100.0 to 192.168.103.255.</p></blockquote>

<h2>TokenEx client-side encryption</h2>

<p>Original misconception:</p>

<ul>
<li>You post directly to TokenEx via AJAX, and they give you an encrypted
value that you can pass to your server and exchange for a token</li>
</ul>


<p>Correction:</p>

<ul>
<li>You only use JSEncrypt to encrypt the PAN via a public key.</li>
</ul>


<p>Wait, I don&#8217;t understand, with tokenizing, if you have a token saved in
the database, then your server, if compromised, could still send data
through to TokenEx, which would proxy it through to whomever.</p>

<h2>Form Factor</h2>

<p>https://www.pcisecuritystandards.org/documents/Mobile_Payment_Security_Guidelines_Merchants_v1.pdf</p>

<blockquote><p>The PCI Security Standards Council charter provides a forum for collaboration across the payment space
to develop security standards and guidance for the protection of payment card data wherever it may be
stored, processed, or transmitted—regardless of the <em>form factor</em> or channel used for payment.</p></blockquote>

<p>the physical size and shape of a piece of computer hardware.</p>

<p>http://en.wikipedia.org/wiki/Mobile_phone_form_factor</p>

<p>or phone.</p>

<p>what a stupid fucking phrase/word/definition.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/02/daily-journal/"/>
    <updated>2014-08-02T21:24:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/02/daily-journal</id>
    <content type="html"><![CDATA[<h2>NPM is killing me</h2>

<p>Apparently this fixed everything.</p>

<pre><code>npm cache clear &amp;&amp; npm install
</code></pre>

<p>https://www.npmjs.org/doc/cli/npm-cache.html</p>

<p>npm caches everything in <code>npm config get cache</code>, which for me is:</p>

<pre><code>~/.npm
</code></pre>

<p>Folder structure is something like</p>

<pre><code>~/.npm/PACKAGE_NAME/VERSION/
</code></pre>

<p>which contains:</p>

<ul>
<li>.cache.json

<ul>
<li>lots of overlap w the project&#8217;s package.json, with additional
cache-specific things like</li>
<li>etag, shasum</li>
<li>deployment-specific data about the package</li>
</ul>
</li>
<li>package.tgz

<ul>
<li>the original tarball downloaded for this packaage</li>
</ul>
</li>
<li>package/

<ul>
<li>the unzipped tarball</li>
</ul>
</li>
</ul>


<p>In other words</p>

<blockquote><p>Additionally, whenever a registry request is made, a .cache.json file is placed at the corresponding URI, to store the ETag and the requested data. This is stored in {cache}/{hostname}/{path}/.cache.json.</p></blockquote>

<h2>Food Shit</h2>

<p>Pok Pok is a legit ass Thai place I need to check out.</p>

<pre><code>http://pokpokny.com/
</code></pre>

<h2><code>sed</code> to select lines</h2>

<pre><code>$ git branch
  cp-qp
* master
  new-doctitle
  setup-controller-qp
</code></pre>

<p>I wanted to switch to the fourth one without typing
<code>setup-controller-qp</code>. Here&#8217;s how you could do it by using the line
number</p>

<pre><code>$ git branch | sed -n '4p' | xargs git checkout
Switched to branch 'setup-controller-qp'
</code></pre>

<p>Obviously this is just a dumb exercise since it&#8217;s waaay more typing.
This is me practicing.</p>

<p>You can also display multiple lines using a syntax similiar to cut&#8217;s
<code>-f1,2</code> syntax:</p>

<pre><code>$ git branch | sed -n '3,4p' 
  new-doctitle
  setup-controller-qp
</code></pre>

<h2>commissary</h2>

<p>From Orange is the New Black</p>

<blockquote><p>commissary: a restaurant in a movie studio, military base, prison, or other institution.</p></blockquote>

<h2>HRT</h2>

<p><a href="http://en.wikipedia.org/wiki/Hormone_replacement_therapy">Hormone replacement therapy</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/29/daily-journal/"/>
    <updated>2014-07-29T07:50:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/29/daily-journal</id>
    <content type="html"><![CDATA[<h2>tar</h2>

<p>Short for Tape Archives.</p>

<p>Had a tar.xz file, just needed to</p>

<pre><code>tar xf thefile.tar.xz
</code></pre>

<h2>Dexing</h2>

<p>Convert string names to numbers to be referenced within compiled Java
whilst packaging android apps.</p>

<h2>Good Food</h2>

<p>Prince St Cafe on Prince and Mott.</p>

<ul>
<li>Awesome burger</li>
<li>Awesome lamb thing</li>
</ul>


<h2>ls -l</h2>

<p>Was curious about an <code>@</code> sign I saw next to a .txt file, from <code>ls(1)</code>:</p>

<blockquote><p>The Long Format</p>

<pre><code>If the -l option is given, the following information is displayed for
each file: file mode, number of links, owner name, group name, number
of bytes in the file, abbreviated month, day-of-month file was last
modified, hour file last modified, minute file last modified, and the
pathname.  In addition, for each directory whose contents are dis-
played, the total number of 512-byte blocks used by the files in the
directory is displayed on a line by itself, immediately before the
information for the files in the directory.  If the file or directory
has extended attributes, the permissions field printed by the -l
option is followed by a '@' character.  Otherwise, if the file or
directory has extended security information (such as an access control
list), the permissions field printed by the -l option is followed by a
'+' character.
</code></pre></blockquote>

<ul>
<li><code>@</code> extended attributes</li>
<li><code>+</code> extended security info</li>
</ul>


<h2>Interrupted System Call</h2>

<p>http://infohost.nmt.edu/~eweiss/222_book/222_book/0201433079/ch10lev1sec5.html</p>

<p>I&#8217;m getting some shit about foreman and interrupted system calls. So
what is it.</p>

<h2>&#8220;data at the edge&#8221;</h2>

<p>Keeping secure data at the edge of your infrastructure, e.g. using
tokens instead of storing CC&#8217;s in your db.</p>

<h2>PAN (primary account number)</h2>

<p>Bank card number.</p>

<p>http://en.wikipedia.org/wiki/Primary_account_number</p>

<h2>CP (card present)</h2>

<p>e.g AuthorizeNetCP</p>

<p>Cheaper rates if you can prove card present (via CVV).</p>

<h2>TokenEx</h2>

<p>ProcessTransaction</p>

<p>ProcessTransactionWithPAN</p>

<ul>
<li>pass in all the CC data; no</li>
</ul>


<h2>Levenshtein Distance</h2>

<p>The minimum number of single-element operations (add, remove,
substitute) between two sequences. Often used for spell-checking
suggestions.</p>

<p>I was thinking of using it to do an array diffing for React-ish stuff.</p>

<pre><code>Array 1: B C D E F
Array 2: A B C D E
</code></pre>

<p>Clearly the answer to how to get from 1 to 2 is</p>

<pre><code>shift A
delete E
</code></pre>

<p>But how to programmatically detect that?</p>

<h2>Ruby String Substring Shorthand</h2>

<p>https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<p>I can&#8217;t believe I didn&#8217;t know this&#8230;</p>

<pre><code>s = "alex is quite maudlin"
s['quite'] = 'very'
s =&gt; "alex is very maudlin"
</code></pre>

<p>and if the substring isn&#8217;t in there, then</p>

<pre><code>IndexError: string not matched
</code></pre>

<p>http://www.ruby-doc.org/core-2.1.2/String.html#method-i-5B-5D-3D</p>

<h2>JRuby the Hard Parts</h2>

<p>Goal: understand this talk https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<h2>Learn about encodings</h2>

<p>I had to resort to this shit:</p>

<pre><code>line = line.force_encoding("iso-8859-1")
</code></pre>

<p>for a bigass file because I was running into</p>

<pre><code>http://stackoverflow.com/questions/15399530/ruby-match-invalid-byte-sequence-in-utf-8
</code></pre>

<p>Apparently you can open files as a certain encoding. Seems good.</p>

<h2>Auto-inline CSS with Roadie</h2>

<p>https://github.com/Mange/roadie</p>

<p>Useful for supporting a vast array of shitty email clients that require
inline CSS. This wouldn&#8217;t be a problem if web components.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal 2]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal-2/"/>
    <updated>2014-07-28T20:43:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal-2</id>
    <content type="html"><![CDATA[<h2>User and Kernel</h2>

<p>http://blog.codinghorror.com/understanding-user-and-kernel-mode/</p>

<p>Non-idle tasks.</p>

<p>The CPU graph is tasty. Red means kernel.</p>

<p>CPU hardware knows all about kernels n shit. It isn&#8217;t just a software
divide. CPU instructions and certain memory locations can only be
accessed by the kernel, enforced by hardware. User mode makes it so that
only the app crashes, not the entire system.</p>

<p>http://en.wikipedia.org/wiki/Ring_(computer_security)</p>

<p>Interesrserseting.</p>

<p>x86 CPU hardware:</p>

<ul>
<li>0 is kernel</li>
<li>3 is user</li>
</ul>


<p>1 and 2 are device drivers but they&#8217;re not often used. On Windows,
device drivers can be user or kernel mode, mostly to the user, but video
cards are often kernel level since they so perfy. In Vista+, the Windows
Driver Display Model is such that only kernel mode is used for executing
the GPU commands, but the translation from API to GPU now takes place in
userland.</p>

<p>Exceptions fire in kernel land I guess? Sometimes?</p>

<h2>Old Foreman Orphans Sidekiq</h2>

<p>After lots of starts/stops of foreman, I noticed lots of sidekiq
instances with ppid 1. They was orphans. I killed em.</p>

<h2>fspawn</h2>

<p>Refers to the fork+exec approach to spawning a process.</p>

<h2>Daemons</h2>

<p>https://github.com/ghazel/daemons</p>

<p>Library of fun little trinkets.</p>

<ul>
<li>given some-server.rb, let&#8217;s you write a some-server-control.rb</li>
<li>inline the server inside such a daemon (you can still run it
without forking via <code>run</code> command)</li>
<li>manage multiple daemons</li>
<li>Ability to take existing server and daemonize it; you do lose control
over the daemon unless you&#8217;re a <code>ps</code>/<code>kill</code> JOURNEYMAN.

<ul>
<li>this takes advantage of the <code>fork</code> <code>getsid</code></li>
</ul>
</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons.rb#L45-L53</p>

<pre><code># 1.  Forks a child (and exits the parent process, if needed)
# 2.  Becomes a session leader (which detaches the program from
#     the controlling terminal).
# 3.  Forks another child process and exits first child. This prevents
#     the potential of acquiring a controlling terminal.
# 4.  Changes the current working directory to "/".
# 5.  Clears the file creation mask (sets +umask+ to 0000).
# 6.  Closes file descriptors (reopens +STDOUT+ and +STDERR+ to point to a logfile if
#     possible).
</code></pre>

<p>Controlling terminal:</p>

<p>http://www.gnu.org/software/libc/manual/html_node/Controlling-Terminal.html</p>

<blockquote><p>An individual process disconnects from its controlling terminal when it calls setsid to become the leader of a new session.</p></blockquote>

<p>Ah I get it:</p>

<ul>
<li>first fork is to orphan the child, but it&#8217;s still connected to a
controlling terminal/session.</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L201</p>

<p>They actually loop through all known IO files to close file
descriptors using ObjectSpace:</p>

<p>http://www.ruby-doc.org/core-2.1.2/ObjectSpace.html</p>

<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L221</p>

<p>That&#8217;s pretty rad. I guess the GC uses it too.</p>

<h2>.pid file</h2>

<p>It&#8217;s a file in a well known location that contains only the pid of
some running process, usually a daemon. Useful because daemons are often
hard to detect, kinda look like forgotten orphan processes, and there
might be multiple similar ones. But pid files let you look up the pid of
the running process so that you can send it signals.</p>

<h2><code>$0</code> or <code>$PROGRAM_NAME</code></h2>

<p>If you run this script</p>

<pre><code>fork {
  $PROGRAM_NAME = "WAT"
  sleep
}
</code></pre>

<p>then <code>ps | grep WOOT</code> yields</p>

<pre><code>62724 ttys022    0:00.00 WOOT
</code></pre>

<p>Woot wat wat wotasoasdas lol.</p>

<h2><code>pidof</code></h2>

<pre><code>brew install pidof

$ pidof bash
754 1246 1748 2308 2498 5380 20397 23552 26224 26973 48454 79258 81847 5226 5346 5443 5851 10659 25008 26375 27009 52684 88768 88882 18853 19116 19246 20275 20476 21364 43211 52269 52390 52637 54869 54974 58037 58950 59080
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal/"/>
    <updated>2014-07-28T08:16:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal</id>
    <content type="html"><![CDATA[<h2>Them processes</h2>

<p>Kernel</p>

<!--more-->


<ul>
<li>sits on top of hardware, doing things like

<ul>
<li>read/write from filesystem</li>
<li>sending/receiving network data</li>
<li>playing audio</li>
</ul>
</li>
<li>programs don&#8217;t have access to this stuff, only the kernel</li>
</ul>


<p>System call is the barrier b/w userland and kernel.</p>

<p>What about memory? I think userland can read memory.</p>

<p>Common man pages for FreeBSD or Linux</p>

<p><code>wat(2)</code> means section 2 of manual, wat: <code>man 2 wat</code></p>

<p>Can&#8217;t execute code without a process.</p>

<p><code>Process.pid == $$</code> global var in Ruby, from Perl/bash, but
<code>Process.pid</code> is way more obvious, duh.</p>

<p>Processes have parents, identified via <code>ppid</code>, <code>Process.ppid</code>, but not
super often used.</p>

<p>In Unixland, everything is a file.</p>

<p>When opening resources, you&#8217;re given a file descriptor number, unique to
your process, unshareable with unrelated processes. These resources are
closed when you exit process, cept forking.</p>

<p>All Ruby <code>IO</code> objects have a <code>fileno</code>, e.g.</p>

<pre><code>2.0.0-p353 :007 &gt; $stdin.fileno
 =&gt; 0
2.0.0-p353 :007 &gt; $stdout.fileno
 =&gt; 1
2.0.0-p353 :008 &gt; $stderr.fileno
 =&gt; 2
</code></pre>

<p>File descriptors are assigned lowest unused value, and are reusable when
old file handlers are closed.</p>

<p>Streams are lovely, before them, each program had to explicitly handle
different keyboard types, etc, but the stream abstraction unified all of
that.</p>

<p><code>fsync</code> flushes file descriptor state to disk, but disk might reorder
writes. The <code>F_FULLFSYNC</code> will ask the drive to write it immediately and
preserve order, useful for things like databases, see <code>fsync</code></p>

<pre><code> For applications that require tighter guarantees about the integrity of their
 data, Mac OS X provides the F_FULLFSYNC fcntl.  The F_FULLFSYNC fcntl asks the
 drive to flush all buffered data to permanent storage.  Applications, such as
 databases, that require a strict ordering of writes should use F_FULLFSYNC to
 ensure that their data is written in the order they expect.  Please see fcntl(2)
 for more detail.
</code></pre>

<p><code>F_FULLFSYNC</code> probably isn&#8217;t available on everything, possibly mac only.</p>

<p>To find the limit of file descriptors you can do <code>Process.getrlimit(:NOFILE)</code></p>

<p>This translates to <code>getrlimit(2)</code>, control max system resource
consumption. <code>r</code> is resource, <code>NOFILE</code> means &#8220;The maximum number of open
files for this process&#8221;.</p>

<pre><code>2.0.0-p353 :001 &gt; Process.getrlimit(:NOFILE)
 =&gt; [2048, 2048]
    #soft, hard
</code></pre>

<p>Soft means an exception will raise but you can reconfigure. Hard limit
might be reconfigurable by superuser, or if the process has permissions.</p>

<p><code>sysctl</code> lets you get or set kernel state, useful for configuring
system-wide kernel details.</p>

<p><code>EMFILE</code> is too many files open. Testable via</p>

<pre><code>machty.github.com :: ruby -e "Process.setrlimit(:NOFILE, 3); File.open('/dev/null')"
-e:1:in `initialize': Too many open files - /dev/null (Errno::EMFILE)
</code></pre>

<p><code>ulimit</code> is a built in command to control resource usage for this shelll
and any of its children. It&#8217;s different from system wide <code>sysctl</code> stuff.
I can change the result above</p>

<p>So I remember <code>ulimit</code> resets the soft limit. If I set to 2046, then</p>

<pre><code>machty.github.com :: ruby -e "puts Process.getrlimit(:NOFILE)"
2046
2046
</code></pre>

<blockquote><p>(Built-in command) In computing, a shell builtin is a command or a function, called from a shell, that is executed directly in the shell itself, instead of an external executable program which the shell would load and execute. ..</p></blockquote>

<p>Use cases for overriding limits</p>

<ul>
<li>stress-testing utilities (e.g. 5000 simultaneous connections)</li>
<li>limiting resources for 3rd party stuff, removing permissions to change</li>
</ul>


<p>Environment is nothing more than Env vars, key values pairs.
Set by parent, inherited by children.</p>

<pre><code>machty.github.com :: A=lol ruby -e "puts ENV['A']"
lol
</code></pre>

<p>Note that env var assignment on its own shell line sets them for the
rest of the process, but followed by a command only sets them for that
command.</p>

<p>Process names are changeable, e.g. <code>$PROCESS_NAME = "fuckles"</code></p>

<pre><code>  PID TTY           TIME CMD
45874 ttys011    0:00.68 fuckles
</code></pre>

<p>Note that TIME is CPU time.</p>

<p>Ah, <code>time</code> makes sense to me now:</p>

<pre><code>machty.github.com :: time sleep 1

real    0m1.012s
user    0m0.001s
sys     0m0.003s
</code></pre>

<p><code>sleep</code> suspends execution thread, consuming no CPU. I think <code>sys</code> means
system call time, such as telling the pthread to sleep. IT IS ALL MAKING
SENSE.</p>

<p>Processes have exit codes, 0 is successful.</p>

<p>All the ways to exit</p>

<ul>
<li>exit, <code>Kernel#exit</code>, exits w 0 by default but you can pass a code,
runs <code>Kernel#at_exit</code> blocks. <code>exit!</code> does a code 1 and doesn&#8217;t run
exit blocks.</li>
<li>abort accepts a string in ruby, runs exit handlers, returns 1</li>
<li>raised exceptions yield exit code 1 and still raise things.</li>
</ul>


<p>Processes can fork, unless you&#8217;re JRuby. That means Unicorn won&#8217;t work
for JRuby.</p>

<p>Forking copies all memory (or copy on write). File descriptors are also
provided to forked thinger.</p>

<pre><code>2.0.0-p353 :016 &gt; fork { puts Process.pid; puts Process.ppid}
 =&gt; 46054
2.0.0-p353 :017 &gt; 46054
45874
2.0.0-p353 :018 &gt;   Process.pid
 =&gt; 45874
</code></pre>

<p>Parent and child can share file descriptors, open files, sockets, etc.
Because forking is faster than booting up fresh copies of servers&#8230; it
is good&#8230;?</p>

<p>Awesome example:</p>

<pre><code>if fork
  puts "YES"
else
  puts "NO"
end
</code></pre>

<p>Hahaha, don&#8217;t run this in irb though, because you&#8217;ll have two processes
reading from the same $stdin, e.g. your keyboard.</p>

<p>Blockless <code>fork</code> returns twice</p>

<ul>
<li>parent gets child pid</li>
<li>child gets nil</li>
</ul>


<p>Explains this output</p>

<pre><code>ruby -e "cid=fork; puts cid || 'none'"
46650
none
</code></pre>

<p>What about threads? Do thread ids change after forking?</p>

<pre><code>machty.github.com :: ruby -e "puts Thread.current; fork; puts Thread.current"
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
</code></pre>

<p>No it seems they don&#8217;t&#8230; forking really makes everything seem totally
the same. I wonder how that works at the pthread level.</p>

<p>http://pubs.opengroup.org/onlinepubs/009695399/functions/fork.html</p>

<blockquote><p>A process shall be created with a single thread. If a multi-threaded process calls fork(), the new process shall contain a replica of the calling thread and its entire address space, possibly including the states of mutexes and other resources. Consequently, to avoid errors, the child process may only execute async-signal-safe operations until such time as one of the exec functions is called. [THR] [Option Start]  Fork handlers may be established by means of the pthread_atfork() function in order to maintain application invariants across fork() calls.</p></blockquote>

<p>So only a single thread is created, and the kernel knows it&#8217;s a separate
thread, but the forked instance still thinks the address of that thread
is the same as before, even though it&#8217;s obviously a different thread.</p>

<p>Forking allows (but doesn&#8217;t guarantee) a process to run on multiple
cores. If the system is busy the forked processes might all run on the
same CPU.</p>

<p>Forking duplicates memory (assuming no copy-on-write; TODO: learn the
terminology for total memory vs not-yet-copied-on-write memory).
Running out of memory due to over-forking is called a fork bomb.</p>

<p>Forking means orphaning if the parent process finishes before children.</p>

<p>Daemon processes are intentionally orphaned so that they can stay
running forever. Orphaned children can be communicated with via signals.</p>

<p>Fork-and-forget vs remembering child process. <code>Process.wait</code> will wait
for ONE child process to terminate before quitting, and returns the pid
of the child process that terminates. Spawn 3 processes, must wait three
times. <code>wait2</code> returns <code>[pid, status]</code>, so you can get codes n shit.
<code>waitpid</code> and <code>waitpid2</code> wait on specific pids. But they are aliased to
the same thing: `wait</p>

<p>The kernel queues child process return info so that waiting on a process
that has already did will return its shit. That said, waiting on
non-existent children raises <code>ECHILD</code>.</p>

<p>Unicorn forks N times, makes sure the processes are still alive,
restarts if necessary, etc.</p>

<p>If you don&#8217;t do <code>Process.wait</code> though, the kernel will keep on storing
information about exit codes, etc. You either need to <code>wait</code> or <code>detach</code>,
or else you get a zombie process.</p>

<p>http://en.wikipedia.org/wiki/Zombie_process</p>

<p>A Zombie process is a process that has called exit but whose parent
hasn&#8217;t called <code>wait</code> or <code>detach</code>.</p>

<ul>
<li>Zombie: un-reaped, terminated child process</li>
<li>Orphan: still active child process whose parent has died.</li>
</ul>


<p>Orphans get attached to <code>init</code> (or <code>launchd</code> in OS X land), which has a
pid of 1.</p>

<p>Oh man, fork bombs are hilarious: http://en.wikipedia.org/wiki/Fork_bomb</p>

<p>So ppid actually automatically updates:</p>

<pre><code>fork do
  loop do
    puts "(#{Process.pid}, #{Process.ppid})"
    sleep 1
  end
end

sleep 1

abort "k i'm done #{Process.pid}"
</code></pre>

<p>Output:</p>

<pre><code>(47598, 47597)
(47598, 47597)
k i'm done 47597
(47598, 1)
(47598, 1)
</code></pre>

<p>Pretty cool.</p>

<p>Also if you <code>brew install pstree</code> and take a look at that, pid 1 is
<code>launchd</code>.</p>

<p>You can check the status of process and how it changes into a zombie and
then when it gets removed from the process table when we call
<code>Process.wait</code>:</p>

<pre><code>cpid = fork {}
puts `ps -p #{cpid} -o state`
sleep 1
puts `ps -p #{cpid} -o state`
Process.wait
puts `ps -p #{cpid} -o state`
</code></pre>

<p>Yields:</p>

<pre><code>STAT
R+
STAT
Z+
STAT
</code></pre>

<p>Note the last STAT is empty because no such pid; shit is dead.
The <code>+</code> means process is in the foreground process group of its control
terminal.</p>

<p>Note that no memory is allocated to the zombie process itself; just the
slot in the process table is used; zombie processes prevent other
processes from taking their place and reusing their PID. Which is
another thing: a parent process might not want a child pid to be reused
when creating a child pid, so it&#8217;ll create the new child, and THEN
<code>wait</code>/<code>detach</code> on original.</p>

<p><code>Process.detach</code> spins up a thread to <code>wait</code> on a process. Here&#8217;s a
really roundabout way to detach and then wait and get the return value:</p>

<pre><code>t = Process.detach(cpid)
puts `ps -p #{cpid} -o state`
puts t.value
</code></pre>

<p><code>t.join</code> before a <code>t.value</code> is a noop; <code>value</code> must always <code>join</code> in
order to get the value.</p>

<p>Fork-and-forget is rare. <code>Process.detach</code> has no system call equiv; it&#8217;s
just a ruby convenience.</p>

<p>SIGCHLD fires when a child process exits. You can trap it and <code>wait</code> for
that process to finish. Problem is, signal delivery is unreliable; if
you&#8217;re handling a signal and another one comes in, you might not receive
that signal. Solution is to pass a second param to <code>wait</code> to describe
how the kernel should wait for this thing, e.g. <code>Process::WNOHANG</code></p>

<p>Shit is so messy</p>

<pre><code>Process.trap(:CHLD) do
  nil while Process.wait(-1, Process::WNOHANG) rescue Errno::ECHILD
end
</code></pre>

<p>Yes you could unravel but come on.</p>

<p>Signals are async, ignorable, actionable, defaultable. Processes use the
kernel to as an intermediary to send messages.</p>

<pre><code>echo "puts 'lol'" | ruby
</code></pre>

<p>Who knew? It accepts input from stdin. So you can pipe Ruby code to it.
Ctrl-C sends an interrupt. You can trap it and ignore. You can also say
<code>trap(:INT, "IGNORE")</code></p>

<p>It&#8217;s good form in lib code to define a trap, though it&#8217;s possibly to
preserve other people&#8217;s callbacks and call them in yours. But you can&#8217;t
restore default behavior. This is fine if your&#8217;e writing a server
though.</p>

<blockquote><p>USR2 - reexecute the running binary. A separate QUIT should be sent to the original process once the child is verified to be up and running.</p></blockquote>

<p>https://github.com/ice799/memprof does some cool stuff with trapping
signals, printing out useful shits.</p>

<p>This guy is boundlessly smart.</p>

<p>Make a pipe, give someone one end to yell into and the other person the
put their ear up to it. Methinks you see where this is going.</p>

<p>Source and Sink, Writer and Reader. Pipe persists until all associated
descriptors are closed. Half-closed pipes are &#8220;widowed&#8221;. Writing to a
widowed pipe yields <code>SIGPIPE</code>, but widowing it is how the reader gets an
EOF signal. <code>SIGPIPE</code> can be disabled via F_SETNOSIGPIPE in fcntl, which
we saw above in this journal for telling a hard drive to actually
preserve write order.</p>

<p>In Ruby you can pass an encoding which tags the read input with that
encoding.</p>

<p>http://ruby-doc.org/core-2.0/IO.html#method-c-pipe</p>

<pre><code>rd, wr = IO.pipe

if fork
  wr.close # REQUIRED
  puts "Parent got: &lt;#{rd.read}&gt;"
  rd.close
  Process.wait
else
  rd.close # REQUIRED
  puts "Sending message to parent"
  wr.write "Hi Dad"
  wr.close
end
</code></pre>

<p>The <code># REQUIRED</code> closes are there because otherwise the data won&#8217;t
flush, EOF&#8217;s won&#8217;t be called.</p>

<p>So that&#8217;s a neat little primitive, but how is it different than just
using a StringIO? Well, aside from the fact that I don&#8217;t think you can
just progressively write into StringIO as you read from it (maybe you
can), Pipe goes through the kernel; there&#8217;s system calls and overhead.
Check this bitchin benchmark:</p>

<pre><code>require 'benchmark'
require 'stringio'

n = 100000
Benchmark.bm do |x|
  x.report("pipes:") {
    n.times do
      rd, wr = IO.pipe
      wr.write "HELLO"
      wr.close
      raise "wat" unless rd.read == "HELLO"
      rd.close
    end
  }

  x.report("StringIO") {
    n.times do
      s = StringIO.new("HELLO")
      raise "wat" unless s.read == "HELLO"
      s.close
    end
  }
end
</code></pre>

<p>yields</p>

<pre><code>              user     system      total        real
  pipes:  0.630000   0.730000   1.360000 (  1.363994)
StringIO  0.080000   0.000000   0.080000 (  0.077973)
</code></pre>

<p>This is skewed by the fact that you&#8217;re not going to be creating and
dumping pipes all the time, but it just highlights the inner workings of
Pipe: because it involves syscalls, much of the time is spent in
<code>system</code>.</p>

<p>With streams (pipes/TCP sockets), you write to a stream followed by a
delimiter. Newline is the delimiter. Unix sockets are intra machine, and
fast.</p>

<p>Use sockets to communicate in datagrams vs delimited stream chunks. You
still have pairs, but rather than read/write pairs, you just have
bidirectional shits, one of which needs to get closed per process.
Sockets are bidirectional!</p>

<p>http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or
http://wiki.secondlife.com/wiki/Message_Queue_Evaluation_Notes</p>

<p>From http://www.ruby-doc.org/core-2.1.0/IO.html</p>

<blockquote><p>In the example below, the two processes close the ends of the pipe that they are not using. This is not just a cosmetic nicety. The read end of a pipe will not generate an end of file condition if there are any writers with the pipe still open. In the case of the parent process, the rd.read will never return if it does not first issue a wr.close.</p></blockquote>

<p>Fuckles and shittles.</p>

<pre><code>man socketpair
</code></pre>

<p>Thom Ass Tover says:</p>

<p>http://www.thomasstover.com/uds.html</p>

<p>So these sockets are Unix Domain Sockets, or local sockets.</p>

<p>Pipes</p>

<ul>
<li>can be given a name</li>
<li>writing to a full one yields <code>SIGSTOP</code></li>
<li>are faster than Unix domain sockets</li>
<li>require context switches w kernel to use read/write</li>
</ul>


<p>Solaris pipes are special in that they are full duplex, where as on
Linux and BSD you&#8217;d need two pipes for full duplex. fifos are named
pipes. I guess they&#8217;re like files.</p>

<p>http://en.wikipedia.org/wiki/Named_pipe</p>

<p>wow:</p>

<pre><code>mkfifo my_pipe
gzip -9 -c &lt; my_pipe &gt; out.gz &amp;
</code></pre>

<p>So, Matt Daemon.</p>

<p><code>init</code> or <code>launchd</code> has ppid 0 and pid 1.</p>

<p><code>exit if fork</code> will fork and close the parent process.</p>

<p><code>Process.setsid</code> creates a new session. It talks about a process groups
and what not. If you call it, your process becomes</p>

<ul>
<li>session leader of new session</li>
<li>process group leader of new process group</li>
<li>and has no controlling terminal</li>
<li>and becomes the only new thing in the thing</li>
</ul>


<p>returns the new process group ID.</p>

<p>Job control is the way processes are managed by terminal. Process group
id is generally same as process ID. Fork and the process group id will
be the same. If they fork and so on then yeah yeah yeah this is how you
know they all came from the same shit. When you do <code>irb</code> in a terminal
it&#8217;ll set the process group to the pid of the command you run.</p>

<p>This is why interrupting a Ruby script that&#8217;s shelled out to thing will
kill all the things if it gets an interrupt; if it&#8217;s still alive, it&#8217;ll
kill children. It&#8217;s only upon normal exiting that you lose
thisetoisjdoiasj.</p>

<p>Session groups are higher up, a collection of process groups. One
session group: <code>echo "lol" | echo "lol"</code>. EPERM fires if you are already
leader (can only call w children).</p>

<p>Look at http://rubygems.org/gems/daemons</p>

<p><code>exec</code> totally transforms your shit, better fork first.</p>

<pre><code>Thread.new {
  sleep 2
  puts "THIS WILL NEVER PRINT"
}
Thread.new {
  sleep 1
  exec 'ls'
}
</code></pre>

<p>It entirely nukes your process context, including any outstanding
threads. You must escape via a fork.</p>

<p>Ruby&#8217;s <code>exec</code> will close file handles, database connections, etc, before
passing control to the new shit, though native <code>exec</code> calls would leave
them open. Sensible default given <code>echo</code> doesn&#8217;t care about your
database. You might accidentally exec another process that doesn&#8217;t do
anything with a db connection, and it never totally closes. But you can
override this default if you want to pass the fileno to the new process
and keep open that handle when it opens it for reading.</p>

<p>Unlike fork, no memory is shared with the resulting process of an exec.</p>

<p>I am so tired.</p>

<p><code>system</code> returns a true or false. Output barfs to stdout.</p>

<p><code>popen</code> opens a bi-directional pipe; you can write to and read from the
process spawned</p>

<p><code>popen3</code> gives you access to all 3.</p>

<p>Forking means a copy of all the parent process&#8217;s context before
<code>exec</code>-ing something super small like <code>ls</code>, but you can use gems that
wrap <code>posix_spawn(2)</code></p>

<p>https://github.com/rtomayko/posix-spawn</p>

<p>Also check out <code>man vfork</code> for virtual memory friendly forking.</p>

<p>Resque forks for memory management; bloating Ruby tasks tend not to
shrink, so fork makes it possible for forked workers to bloat and
disappear.</p>

<p>http://rubydoc.info/github/defunkt/resque/Resque/Worker</p>

<blockquote><p>A Resque Worker processes jobs. On platforms that support fork(2), the worker will fork off a child to process each job. This ensures a clean slate when beginning the next job and cuts down on gradual memory growth as well as low level failures.</p>

<p>It also ensures workers are always listening to signals from you, their master, and can react accordingly.</p></blockquote>

<p>Preforking, is it cool. haidjasoidjasiodj</p>

<p>What&#8217;s the rules on writing to stdout between multiple processes.
You can do it; there&#8217;s not going to be thread-unsafety, i don&#8217;t think.</p>

<p>http://stackoverflow.com/questions/1326067/how-to-lock-io-shared-by-fork-in-ruby</p>

<p>Preforking has load balancing wins similar to message queuing with
multiple consumers; when a consumer is ready, it just listens for the
same thing. A socket is shared b/w forked processes, and kernel makes
sure only one gets it</p>

<p>I need to understand more about $stdout and buffering and what not. It&#8217;s
not thread safe, but process-safe? syscall-safe?</p>

<ul>
<li>fork-safe if the action in question fits within a single syscall</li>
</ul>


<p>I have no fucking IDEA MY BRAIN IS DEAD.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/26/daily-journal/"/>
    <updated>2014-07-26T15:10:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/26/daily-journal</id>
    <content type="html"><![CDATA[<h2>top</h2>

<blockquote><p>display and update sorted information about processes</p></blockquote>

<p><code>top</code> will display a sampled, updating list of processes, ordered by pid
by default. Order by cpu:</p>

<pre><code>top -o cpu
</code></pre>

<p>Filter by a pid</p>

<pre><code>top -pid 12345
</code></pre>

<p>Show a single sample of the pid and thread number for a given pid</p>

<pre><code>top -l1 -pid 1234 -stats pid,th
</code></pre>

<h2>Spawn 50 ruby threads&#8230;</h2>

<p>and you wind up w 52: <code>Thread.main</code> + the 50 you created + Ruby
housekeeping thread (listening for OS signals and piping them
synchronously to main thread).</p>

<p>Ruby creates legit OS threads, vs <code>_____</code> threads, whatever the
terminology is for threads that live entirely in the code.</p>

<h2>Thread#join</h2>

<p>Yes, you have to call it on a spawned thread so that the main thread
will wait on it before prematurely exiting. But did you know that
exceptions thrown in a spawned thread get re-raised on the main thread
if you do <code>.join</code>?</p>

<p><code>Thread#value</code> joins and returns the last value of the thread.</p>

<p><code>Thread#status</code> returns status for live, dead, erroed, dying threads.</p>

<p><code>Thread.stop</code> puts the thread to sleep and it won&#8217;t wake up until
someone calls <code>wakeup</code> on it</p>

<p><code>Thread.pass</code> hints the OS to schedule another thread, but this may be
ignored by the scheduler.</p>

<p><code>Thread#raise</code> lets you externally fire exceptions within another thread
but should not be used because <code>ensure</code> is busted. <code>Thread#kill</code> does
what you expect but should also be aborted for the same reasons.</p>

<p>Multiple threads mean concurrency; they <em>might</em> mean parallelism. One
CPU switching b/w threads means concurrency but not parallelism;
multiple cores means paralleilism if they&#8217;re both executing.</p>

<p>Code can&#8217;t be parallel, only concurrent. The executation of concurrent
code can be parallel if the scheduler so chooses.</p>

<h2>golang concurrency vs parallelism</h2>

<p>http://concur.rspace.googlecode.com/hg/talk/concur.html#slide-2</p>

<p>Concurrency is defined as:</p>

<blockquote><p>Programming as the composition of independently executing processes</p></blockquote>

<p>not Linux processes, but rather the famously harder to define Process.</p>

<p>Parallelism is</p>

<blockquote><p>Programming as the simultaneous execution of (possibly related) computations.</p>

<p>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable</p></blockquote>

<p>Concurrency facilitates but doesn&#8217;t guarantee parallelism.</p>

<p>Goroutines aren&#8217;t threads; they&#8217;re similar but cheaper, won&#8217;t block
other goroutines, and multiplexed onto OS threads as necessary.</p>

<p>Synchronize via channels. I guess this is like Ruby Queue? Sounds like
you&#8217;d never do someGoroutine.value but rather use the channel primitive.</p>

<h2>ruby concurrency and you</h2>

<p>https://blog.engineyard.com/2011/ruby-concurrency-and-you</p>

<p>Green threads</p>

<ul>
<li>scheduled by VM, rather than underlying OS</li>
<li>pre 1.9 Ruby was this way (MRI)</li>
<li>managed in user space rather than kernel space</li>
</ul>


<p>Test: if i run Ruby 1.8.7 and do a top of new threads, I would expect
the thread count to be only whatever I started with.</p>

<p>BEHOLD, on 1.8.7:</p>

<pre><code>PID    #TH
84752  1
</code></pre>

<p>So old ruby didn&#8217;t even spawn another thread for housekeeping&#8230; I guess
maybe it wasn&#8217;t necessary because it didn&#8217;t have to coordinate the
signals landing at any random currently-active thread? Pretty cool.</p>

<p>I guess green threads are easy to implement in any interpreted language:
in the main loop of the interpreter you can just check if 100ms has gone
by and then move to another other known threads.</p>

<p>Early Java had green threads&#8230; I don&#8217;t know enough about Java to
comment here.</p>

<p>Ruby &lt;1.9 was smart enough to know when one of these threads was blocked
on external data so that it could &#8220;sleep&#8221; until the data arrived:</p>

<blockquote><p>MRI 1.8.7 is quite smart, and knows that when a Thread is waiting for some external event (such as a browser to send an HTTP request), the Thread can be put to sleep and be woken up when data is detected.</p></blockquote>

<p>1.9 uses native threads, but there&#8217;s still a GIL because the non-Ruby
parts of MRI 1.9 aren&#8217;t thread-safe.</p>

<p>MRI 1.9 uses the same technique as MRI 1.8 to improve the situation,
namely the GIL is released if a Thread is waiting on an external
event (normally IO) which improves responsiveness.</p>

<p>Great read:</p>

<p>http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/</p>

<p>Threads are hard, but requests are an extremely clean concurrency
primitive: controllers and the models loaded and views rendered, etc.,
are not shared between threads that are processing requests. It&#8217;s only
if you start using global state that problems arise, but why are you
doing that?</p>

<p>Why the Ruby/Rails thread FUD?</p>

<ul>
<li>Early Rails wasn&#8217;t threadsafe; essentially a mutex around each request</li>
<li>Mongrel explicitly mutexed around its Rails adapter, so even when
<code>threadsafe!</code> was added, you&#8217;d still have zero concurrency in mongrel.</li>
</ul>


<blockquote><p>For safety, Ruby does not allow a context switch while in C code unless the C code explicitly tells the VM that it’s ok to do so.</p></blockquote>

<p>And mysql was poorly written in this case. So mysql would block.</p>

<blockquote><p>A lot of people talk about the GIL (global interpreter lock) in Ruby 1.9 as a death knell for concurrency. For the uninitiated, the GIL disallows multiple CPU cores from running Ruby code simultaneously. That does mean that you’ll need one Ruby process (or thereabouts) per CPU core, but it also means that if your multithreaded code is running correctly, you should need only one process per CPU core. I’ve heard tales of six or more processes per core. Since it’s possible to fully utilize a CPU with a single process (even in Ruby 1.8), these applications could get a 4-6x improvement in RAM usage (depending on context-switching overhead) by switching to threadsafe mode and using modern drivers for blocking operations.</p></blockquote>

<p>Node vs Ruby Threading:</p>

<p>Yehuda: &#8220;the main difference is that a callback is smaller in size than a stack&#8221;</p>

<p>In other words, the context switch that happens when switching threads
includes copying over an entire stack of the thread you&#8217;re resuming and
some other details I don&#8217;t know of off the top of my head. But with
callbacks, the callbacks have no stack (is this true in Rubyland? maybe
there&#8217;s stack trace information but probably no stack. The only stack
starts from where the callback/block was created, and the same is true w
threads, but the point is that in a thread-per-request model, the stack
goes all the way up to when the request was first received, which can be
a pretty tall stack).</p>

<p>So what about Fibers? They&#8217;re cooperative, but why is their context
switch not a big deal? They have a stack size limit of 4kb. How can I
test this?</p>

<p>Here&#8217;s a nice article:</p>

<p>http://timetobleed.com/fixing-threads-in-ruby-18-a-2-10x-performance-boost/</p>

<p>Seems to suggest that the stack that needs to be copied when context
switching includes interpreter code, which has many local vars and
sometimes the stack is up to 4kb, which is cray cray.</p>

<p>Green threads: pre-emptible userland threads. userland = not kernel
land.</p>

<p>You can hack into the thread-yielding code of old Ruby to allocate
stacks on the heap so that all you have to do to context switch is
change what rsp (pointer to the bottom of the stack) points to. This
means the stack won&#8217;t grow (so you have to pick a sensible size).</p>

<p>Ruby 1.9 performs way better in the benchmarks than his hacks&#8230; why?
&#8220;Thanks. 1.9 uses pthreads which create stacks in a similar manner to
what I did.&#8221; Awesome.</p>

<p>pthreads = POSIX threads</p>

<p>http://timetobleed.com/threading-models-so-many-different-ways-to-get-stuff-done/</p>

<p>Threads models:</p>

<h3>1:1 (native threads)</h3>

<p>One kernel thread for every user thread.</p>

<p>Pros</p>

<ul>
<li>execute threads on different CPUs</li>
<li>threads don&#8217;t block each other</li>
<li>shared memory b/w threads</li>
</ul>


<p>Cons</p>

<ul>
<li>Setup overhead since creating a thread requires a system call (and
those are slow)</li>
<li>Low upper bound on the number of threads that can be created</li>
</ul>


<p><code>pthread_create</code> is the fn that makes the system call to create the
thread.</p>

<h3>1:N (green threads)</h3>

<p>&#8220;lightweight threads&#8221;</p>

<ul>
<li>thread creation, execution, cleanup are cheap</li>
<li>lots of threads can be created</li>
</ul>


<p>Cons</p>

<ul>
<li>kernel doesn&#8217;t know about it, so no parallel execution across CPUs</li>
<li>blocking IO can block all green threads</li>
</ul>


<p>Forking + threading and cross-process communication is one way around
limitations.</p>

<h3>M:N</h3>

<p>Hybrid of above</p>

<ul>
<li>Multi CPUs</li>
<li>Not all threads blocked by blocking system calls</li>
<li>Cheap</li>
</ul>


<p>Cons</p>

<ul>
<li>Really really hard to synchronize userland and kernel scheduler</li>
<li>Green threads will block within same kernel thread</li>
<li>Difficult to maintain</li>
</ul>


<p>1:1 has shown itself to be more performant, but in some cases M:N might
be the right choice.</p>

<p>TODO: read this http://www.akkadia.org/drepper/nptl-design.pdf</p>

<pre><code>b = nil

t = Thread.new do
  b = Fiber.new {
    puts "FIBER"
  }
end

while !b
  # just wait
end

b.resume
</code></pre>

<p>This results in</p>

<pre><code>fiberthread.rb:13:in `resume': fiber called across threads (FiberError)
        from fiberthread.rb:13:in `&lt;main&gt;'
</code></pre>

<p>Of course it would.</p>

<p>Use strace / dtruss to trace sys calls.</p>

<p>Spinlocks are locks that, rather than sleeping, actively busy-wait until
the lock is free. This only makes sense if the wait is expected to be
short, otherwise it might block other threads.</p>

<p>Interesting, from the wiki:</p>

<blockquote><p>Most operating systems (including Solaris, Mac OS X and FreeBSD) use a hybrid approach called &#8220;adaptive mutex&#8221;. The idea is to use a spinlock when trying to access a resource locked by a currently-running thread, but to sleep if the thread is not currently running. (The latter is always the case on single-processor systems.)</p></blockquote>

<p>The idea is that a lock by an active thread is likely to be finished
soon, and since spinlocks avoid the scheduling overhead of a context
switch, then hooray.</p>

<p>Busy-waiting in general means while-looping until some condition is
true. You can even do this in JS:</p>

<pre><code>var end = +new Date() + 1000;
while (+new Date() &lt; end) {}
</code></pre>

<p>So whether Node or EventMachine, the concept is the same: both run on
callbacks.</p>

<p>Realization: I was thinking that I could demonstrate the difference b/w
green threads and OS threads by seeing if a while(true) in a green
thread would yield to others, but the answer is:</p>

<ul>
<li>of course it would yield; each iteration of the while true is
an iteration of the interpreter loop that&#8217;s running commands, so its
timer would fire at that point.</li>
<li>the only time it&#8217;d block is if you called out to a C extension that
looped and didn&#8217;t yield back control.</li>
</ul>


<p>It seems a Fiber&#8217;s 4k stack begins at the point at which it is created.
Hmm. So does it or does it not include interpreter stuff? Well for one
it&#8217;s in the same thread as a requirement.</p>

<p>Reasons why Fibers are faster than threads:</p>

<ul>
<li>limited 4kb stack for quick context switching</li>
<li>no pre-emption means no aggressive/frequent context switching;
context-switch as infrequently as you&#8217;d like.</li>
</ul>


<p>https://github.com/eventmachine/eventmachine/blob/master/docs/old/LIGHTWEIGHT_CONCURRENCY</p>

<p>Lightweight Concurrency generally means</p>

<ul>
<li>putting thread scheduling under the control of your program</li>
</ul>


<blockquote><p>By &#8220;lighter,&#8221; we mean: less
resource-intensive in one or more dimensions, usually including memory and
CPU usage. In general, you turn to LC in the hope of improving the
performance and scalability of your programs.</p></blockquote>

<p>NOTE: race conditions can happen in concurrent environments, even if
parallelism isn&#8217;t there, e.g. preempting</p>

<p>Mac has a max 2048 thread limit.</p>

<p>&#8220;IO Bound&#8221; means your program is mostly bottlenecked by IO, such that
swapping for a faster IO would boost your program performance immensely.</p>

<p>In such a case, going multi-threaded is a no-brainer rather than
serially getting blocked on each slow thing. But if you over do it then
you might just be wasting memory/CPU resources from thread stacks and
context switching that it&#8217;s not justified.</p>

<p>&#8220;CPU bound&#8221; means doubling CPU would mean the job would get done that
much faster.</p>

<p>Quad-core with 4 threads on CPU bound means mega-wins for Rubinius but
obviously not GIL&#8217;d MRI. If you make it 5, then you get the
context-switching overhead.</p>

<p>Rails apps are combo of IO-bound and CPU-bound</p>

<p>IO:</p>

<ul>
<li>Database</li>
<li>Third party APIs</li>
<li>Files read</li>
</ul>


<p>CPU:</p>

<ul>
<li>Rendering templates</li>
<li>Rendering JSON</li>
</ul>


<p>Measure measure measure.</p>

<p>This is comically incorrect:</p>

<pre><code>Mutex.new.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>should be</p>

<pre><code>m = Mutex.new

# ...create thread...

m.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>&#8220;critical section&#8221; refers to the part of your concurrent code that
alters shared data.</p>

<p>Memory Models describe the guarantees made to threads when
reading-from/writing-to memory, which mostly become important to think
about in a multi-threaded settings. The memory model describes how
caching occurs in the registers before actually writing out to memory,
and it describes the scope of compiler/hardware optimizations that can
be made that lead to non-determinant order of memory operations which
can fuck your shit unless you use <code>volatile</code> in Java or explicit mutexes
in Ruby.  Ruby doesn&#8217;t have a memory model spec yet. Java and Go and
others do. I guess Rust nips this in the bud w ownership.</p>

<p>Mutex is a form of a memory barrier, and I think <code>volatile</code> is too.</p>

<p>Livelocking is when <code>try_lock</code>s repeatedly fail, so the threads are
still technically alive but stuck in the same loop.</p>

<p>Best solution is to declare mutex grabbing in the same order via a mutex
hierarchy.</p>

<h2>Signals in ruby</h2>

<p>Rubyz</p>

<pre><code>Signal.trap("USR1") do
  puts "lol handling your custom user handler"
end
puts Process.pid # =&gt; e.g. 12345
</code></pre>

<p>Shellz</p>

<pre><code>kill -s USR1 12345
</code></pre>

<p>So many ways to kill a program:</p>

<ul>
<li>Abort: often self-initiated by <code>abort</code></li>
</ul>


<h2>Difference b/w seg fault and bus error</h2>

<p>http://stackoverflow.com/questions/838540/bus-error-vs-segmentation-fault</p>

<p>On most architectures I&#8217;ve used, the distinction is that:</p>

<ul>
<li>a SEGV is caused when you access memory you&#8217;re not meant to
(e.g., outside of your address space).</li>
<li>a SIGBUS is caused due to alignment issues with the CPU
(e.g., trying to read a long from an address which isn&#8217;t a multiple of 4).</li>
</ul>


<h2>Signals in C</h2>

<p>This is just for fun, but you can set up signal masks and signal
handles and all that fun crap.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

static int gotSignal = 0;

void wat(int s) {
  printf("Got Signal %d", s);
  gotSignal = 1;
}

int main() {
  /* SIGUSR1 == 16 */
  signal(SIGUSR1, &amp;wat);

  pid_t pid = getpid();
  printf("The process id is %d", pid);

  // prevent signal from getting here
  sigset_t s;
  sigaddset(&amp;s, SIGUSR1);
  // uncomment to block the signal from arriving
  //sigprocmask(SIG_BLOCK, &amp;s, NULL);

  while(!gotSignal) {
    printf(".");
    fflush(stdout);
    sleep(1);
  }

  printf("\nDone!\n");
}
</code></pre>

<p>and you can send it usr1 via</p>

<pre><code>kill -s USR1 12345
</code></pre>

<h2>Signals in Node</h2>

<pre><code>var done = false;

process.on("SIGUSR1", function() {
  done = true;
});

console.log("pid: ", process.pid);

var timerId = setInterval(function() {
  if (done) {
    console.log("DONEZO");
    clearInterval(timerId);
  } else {
    process.stdout.write(".");
  }
}, 500);
</code></pre>

<p>Note that SIGUSR1 is reserved by node.js to start the debugger.
The above code will work but if the debugger&#8217;s enabled then that&#8217;ll also
cause it to start.</p>

<p>Seems that signals are often used to start a debugger, or some kind of
debugging operation. Interesting.</p>

<h2>Condition Variables</h2>

<p>A provider and consumer both use the same mutex. Provider locks when
providing an update. Consumer locks when trying to perform an operation,
but internally does a <code>condvar.wait(mutex)</code> with the locked <code>mutex</code> to
unlock until the <code>condvar</code> is <code>signal</code>ed by the provider.</p>

<p>So why wrap the consumer in a while loop rather than an if (see page 104
of storimer)? Because there could be multiple consumers.</p>

<p><code>ConditionVariable#signal</code> wakes up a single thread, <code>ConditionVariable#broadcast</code>
wakes up all threads.</p>

<h2><code>thread_safe</code> gem</h2>

<ul>
<li>ThreadSafe::Array</li>
<li>ThreadSafe::Hash</li>
<li>ThreadSafe::Cache

<ul>
<li>similar to Hash, but insertion order enumeration isn&#8217;t preserved,
which means it can be faster</li>
</ul>
</li>
</ul>


<h2>Immutable = threadsafe</h2>

<p>Read more about it.</p>

<h2>Globals</h2>

<p>The Ruby AST is a global (is it really an AST at that point? is
dynamically adding a method an example of modifying an AST? ASTs are for
parsing, not so much adding/removing methods from a class obj).</p>

<p>Anyway, Kaminari was bitten by this:</p>

<p>https://github.com/amatsuda/kaminari/issues/214</p>

<h2>Thread-locals</h2>

<p>Variables that are global to everything in the current thread but hidden
to everyone else. So you could do</p>

<pre><code>Thread.current[:some_service] = SomeService.new
</code></pre>

<p>which could open a new connection. Connections are nice concurrency
primitives, much like request objects in Rails. But if you have too many
threads, you might hit a max connection limit, so in that case, use
pools, lol.</p>

<p>Pools let you specify max concurrency, which is likely less than the
number of threads that might want to consume it, and then when
requesting access to a thing in a pool, it&#8217;ll block until a slot&#8217;s
available.</p>

<p>See: https://github.com/mperham/connection_pool</p>

<p>mperham is Mr Sidekiq. Mr. Concurrency in general I guess.</p>

<p>Question: is a connection pool the same as a thread pool? Probably not,
connection pool is just a resource pool that is thread-aware, but
doesn&#8217;t constitute individual threads.</p>

<h2>Rubinius Actor</h2>

<p>https://github.com/rubinius/rubinius-actor</p>

<p>Depends on core Rubinius class <code>Channel</code>. TODO: find out why <code>Channel</code>
doesn&#8217;t/can&#8217;t exist in MRI.</p>

<h2>Rubinius Ruby JITting</h2>

<p>Talking to IRC folk: one of the major reasons for Ruby all the way down
or at least Ruby most of the way down is that more of it can be JITted
rather than having the hard C/C++ boundary after which no more
optimizations can be made.</p>

<p>Also, in some benchmarks b/w Rubinius and JRuby and MRI, etc., one thing
that comes up a lot is the suggestion that the tests run for longer so
that the JIT is primed, all the optimizations have been made, etc etc
etc.</p>

<h2>Rails Batches</h2>

<p>http://api.rubyonrails.org/classes/ActiveRecord/Batches.html</p>

<pre><code>Article.find_each do |a|
  a.wat
end
</code></pre>

<p>this internally splits DB queries into batches of 1000 so that you&#8217;re
not instantiating potentially a billion Ruby objects for each row. In
the end you&#8217;ll still allocate the same amount of memory but it can be
GC&#8217;d along the way vs causing an insane spike and possibly crashing your
server.</p>

<h2>Server-sent events</h2>

<p>http://tenderlovemaking.com/2012/07/30/is-it-live.html</p>

<ol>
<li>A stream obj is added to Rails request object, quacks like IO obj.
You can write to it and close it, but it doesn&#8217;t actually stream live
to the client; it buffers, and then flushes.</li>
<li>With <code>ActionController::Live</code>, it&#8217;ll actually stream live.</li>
<li>Some WebServers, like WEBrick will thwart this by buffering the
response until it&#8217;s complete. Unicorn could work, but it&#8217;s meant for
fast responses; anything taking longer than 30s might get terminated.
Rainbows/Puma/Thin would work.</li>
</ol>


<h2>Celluloid</h2>

<p>Transforms method invocations into blocking messages. Precede w <code>async</code>
to prevent blocking (obviously still happens async);</p>

<pre><code>require 'celluloid'

class DoesStuff
  include Celluloid

  attr_accessor :i

  def foo
    # currently this displays
    # one item per second.
    # if you swap comments with
    # the line after it'll wait
    # until the very end to print them all
    # at once because the each at the end
    # will evaluate the "longest" future first
    sleep i
    #sleep (11 - i)
    i
  end
end


futures = []

10.times do |i|
  thing = DoesStuff.new
  thing.i = i

  futures &lt;&lt; thing.future.foo
end


futures.each do |f|
  puts "Completed: #{f.value.i}"
end

sleep
</code></pre>

<p>This is interesting: https://github.com/celluloid/celluloid/wiki/Frequently-Asked-Questions#q-can-i-do-blocking-io-inside-an-actor-or-do-i-have-to-use-celluloidio</p>

<p>It&#8217;s fine to have blocking IO such as waiting for a DB query to return,
or slow HTTP response, but you shouldn&#8217;t have it waiting on
<em>indefinite</em> IO; for that, use Celluloid::IO.</p>

<p>I believe that an actor can&#8217;t be handling multiple messages at the same
time. Wrong! That&#8217;s only if Erlang/Exclusive mode is on, and you have to
be careful about that because it means a higher risk of deadlock:</p>

<p>https://github.com/celluloid/celluloid/wiki/Exclusive</p>

<p>Sidekiq doesn&#8217;t make use of return values a whole lot; rather actors are
expected to send messages back to their &#8220;callers&#8221;.</p>

<p>Accessing localvars is faster than ivars: https://github.com/puma/puma/commit/fb4e23d628ad77c7978b67625d0da0e5b41fd124</p>

<h2>Compare and set (CAS)</h2>

<p>aka check-and-set</p>

<p>For platforms that support it, CAS is a mutex-free approach to
thread-safety</p>

<pre><code>a += 1
</code></pre>

<p>is not thread safe, but</p>

<pre><code>cur = a.value
new_value = cur + 1
if (!a.compare_and_set(cur, new_value)) 
  # try again
end
</code></pre>

<p>is.</p>

<p>Worth pointing out that Redis supports a form of this using WATCH.</p>

<pre><code>MULTI # begin transaction
SET foo lol
SET bar wat
EXEC # execute
</code></pre>

<p>so basically if you do</p>

<pre><code>WATCH someval
MULTI
set someval lol
EXEC
</code></pre>

<p>and someval changed after the MULTI then it will fail.</p>

<p>So why use CAS over a mutex?</p>

<blockquote><p>If the cost of retrying the operation is cheap, or rare, it may be much less expensive than using a lock.</p></blockquote>

<p>Logic checks out.</p>

<pre><code>require 'atomic'
v = Atomic.new(0)
v.update do |current|
  current + 1
end
</code></pre>

<p>This is the shorthand to the idempotent loop with CAS.</p>

<p>Lockless showed mega improvements relative to locking in Rubinius but
not JRuby for some reason.</p>

<p>Hamster is the immutability gem to check out.</p>

<h2>oni</h2>

<p>https://github.com/olery/oni</p>

<p>Uses SQS, look into it because i am such a nooblet.</p>

<h2>SQS</h2>

<p>Uses a visibility timeout after a consumer has started to receive a
message in which time it is hidden from other consumers, and in this
time it should be deleted.</p>

<ul>
<li>Supports GET/POST requests to public URLs, presuming you pass in a
valid signature

<ul>
<li>This means you could fire requests directly to SQS rather than
having to go to a server first&#8230; that is badass.</li>
</ul>
</li>
<li>Reports of scalability problems</li>
</ul>


<p><a href="http://nsono.net/amazon-sqs-vs-rabbitmq/">Alternative: RabbitMQ</a></p>

<ul>
<li>SQS: consumers must poll for messages, and SQS charges by the request,
even if the response is empty.</li>
<li>RabbitMQ supports push</li>
<li>is free and open source</li>
<li>based on erlang</li>
<li>adheres to AMQP (standard for high performance messages queues)</li>
<li>supports durable queues (crash-recoverable, written to disk)</li>
<li>delivered in order unless message requeued</li>
<li>more consistent (much less likely to deliver a message twice unless
the message actually failed)</li>
</ul>


<p>cons</p>

<ul>
<li>not necessarily highly available (because it&#8217;s a server that runs on
whatever instance you wanna put it on, so you have to manage failover,
redundancy, etc, whereas SQS is a system that handles all of that)</li>
<li>this is configurable, but the default is for RabbitMQ to drop messages
if there are no consumers; surprising to SQS folk.</li>
</ul>


<h2>Heartbeats</h2>

<p>https://www.rabbitmq.com/reliability.html</p>

<blockquote><p>In some types of network failure, packet loss can mean that disrupted TCP connections take some time to be detected by the operating system. AMQP offers a heartbeat feature to ensure that the application layer promptly finds out about disrupted connections (and also completely unresponsive peers). Heartbeats also defend against certain network equipment which may terminate &#8220;idle&#8221; TCP connections. In RabbitMQ versions 3.0 and higher, the broker will attempt to negotiate heartbeats by default (although the client can still veto them). Using earlier versions the client must be configured to request heartbeats.</p></blockquote>

<p>Re: &#8216;Heartbeats also defend against certain network equipment which may
terminate &#8220;idle&#8221; TCP connections.&#8217;: I bet that&#8217;s referring to NAT, which
manages a cache of IP translations and will go inactive if nothings been
sent to / received from an IP for a while.</p>

<p>YAY I WAS RIGHT http://stackoverflow.com/questions/865987/do-i-need-to-heartbeat-to-keep-a-tcp-connection-open#comment1713801_866003</p>

<p>So Heartbeats</p>

<ul>
<li>reassure you the connection is alive in some cases where the failure
conditions aren&#8217;t otherwise detectable</li>
<li>keep the NAT state tables warm for your IP</li>
</ul>


<h2>Celluloid::IO</h2>

<p>https://github.com/celluloid/celluloid-io</p>

<p>Provides a different class of Actor that&#8217;s heavier than normal Celluloid
actors, but contains a high performance reactor like EventMachine or
cool.io (todo: check out cool.io). So unlike EventMachine you can have
multiple loops, e.g. one in each actor (resources permitting). (Also,
does EM really force you to just have one?)</p>

<h2>Autoload</h2>

<p>Yes we know it&#8217;s not threadsafe in MRI. Recent JRuby versions make it
thread safe, but just eager load your shits before spawning threads.</p>

<h2>Requests as concurrency unit</h2>

<p>I guess in general you should always look for the concurrency unit; that
domain object that encapsulates all the data you need to get a job done
so that hopefully you&#8217;re not sharing data between threads. Each request
gets handled by its own thread.</p>

<h2>Queue</h2>

<p><code>Queue#pop</code> will suspend a thread until data is in the queue. Like a
mofuggin stream.</p>

<p>Queue is apparently the only thread-safe data structure that ships with
Ruby.</p>

<h2>JRuby</h2>

<p>Foreign function interface</p>

<p>http://en.wikipedia.org/wiki/Foreign_function_interface</p>

<p>Mechanism for languages to invoke routines from other languages.</p>

<p>Write your extension code in Ruby, FFI will call the write C / Java /
whatever stuff. It won&#8217;t even be compiled. I guess it just links into
dynamic libs?</p>

<p>JRuby obviously doesn&#8217;t support C extensions, but FFI extensions will
work.</p>

<p>JRuby</p>

<ul>
<li>has no fork(), since JVMs mostly can&#8217;t safely be forked
(<code>NotImplementedError: fork is not available on this platform</code>)</li>
<li>Fibers are native threads, rather than MRI green threads, which means
you are constrained to native thread overhead/limits.</li>
</ul>


<h2>Rubinius (rbx)</h2>

<ul>
<li>Designed for concurrency, speed.</li>
<li>Rubinius 2.0 has no GIL</li>
<li>All tools written in Ruby, including bytecode VM, compiler,
generational GC, JIT, etc</li>
<li>No continuations (because dependent on callcc, a C thing)</li>
<li>At some point, when dealing with locks and low level things, you&#8217;ll
find C++.</li>
</ul>


<p>http://rubini.us/2011/02/25/why-use-rubinius/</p>

<h2>Ruby Enterprise Edition</h2>

<p>By Phusion. No longer alive.</p>

<ul>
<li>Compatible w 1.8.7</li>
<li>End of Life since 2012</li>
<li>No more work being done, reasons being:

<ul>
<li>Rails 4 no longer supporting 1.8</li>
<li>COW patch accepted on Ruby 2.0</li>
<li>Many Ruby Enterprise Edition patches addressed in 1.9, 2.0</li>
</ul>
</li>
</ul>


<h2>MacRuby</h2>

<p>Implementation of 1.9 Ruby directly on top of Mac OS X core tech, e.g.</p>

<ul>
<li>Obj-C runtime and GC</li>
<li>LLVM compiler infrastructure</li>
</ul>


<h2>Reactive manifesto</h2>

<p>TODO: read this http://www.reactivemanifesto.org/</p>
]]></content>
  </entry>
  
</feed>
