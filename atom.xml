<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[machty's thoughtz]]></title>
  <link href="http://machty.github.com/atom.xml" rel="self"/>
  <link href="http://machty.github.com/"/>
  <updated>2014-09-20T12:20:34-04:00</updated>
  <id>http://machty.github.com/</id>
  <author>
    <name><![CDATA[Alex Matchneer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Daily Journeaux]]></title>
    <link href="http://machty.github.com/blog/2014/09/17/daily-journeaux/"/>
    <updated>2014-09-17T08:08:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/17/daily-journeaux</id>
    <content type="html"><![CDATA[<h2>nginx book</h2>

<p>This is nice: http://aosabook.org/en/nginx.html</p>

<p>Some random notes:</p>

<p>For CPU-bound loads, number of nginx workers should equal the number of
cores (&#8220;TCP/IP, doing SSL, or compression&#8221;). For IO-bound stuff
(&#8220;serving different sets of content from storage, or heavy proxying&#8221; &#8211;
presumably teh &#8220;different sets&#8221; is important because if it were
the same stuff, it&#8217;d probably be cached which I guess means the IO would
be negligible? unsure) &#8211; you might want 1.5-2 times the number of
cores.</p>

<h2>SSL/TLS random questions:</h2>

<p>I have so many misconceptions? For anyone who reads this, this is stream
of thought as I try to answer my own questions before looking shit up.</p>

<p>How come domains are signed and not IPs?</p>

<p>Reasoned guess: first off, everyone can encrypt data. It&#8217;s just that the
key thing that TLS brings in is certification of a sending. It&#8217;s not
enough to say &#8220;yo here&#8217;s my public key&#8221;, you still have to answer the
question &#8220;uh ok yes but who are you?&#8221;. Certificate authority to the
rescue.</p>

<p>So what if CA&#8217;s certified IPs, rather than domain names (maybe they do,
I don&#8217;t actually know at this point)? Some ideas come to mind:</p>

<ul>
<li>DNS can map to multiple IPs, and a single IP might load balance to
many different servers, all of which should be able to (de)/encrypt
incoming traffic.</li>
</ul>


<p>That&#8217;s actually probably the only reason. I was originally thinking
that since IPs can change, you might certify server A and then the next
day the IP changes to server B, and that that would mean the CA is
giving a stamp of approval to the wrong server, but then, duh, it&#8217;s key
pairs that are being validated, and server B wouldn&#8217;t have these keys
and wouldn&#8217;t know how to do the handshake. I think this is close to
correct, it&#8217;s just I&#8217;m forgetting everything that happens internally
within the handshake.</p>

<p>http://en.wikipedia.org/wiki/Transport_Layer_Security</p>

<h2>Symmetric Key</h2>

<p>A single key encrypts plaintext and decrypts the ciphertext generated
from the encryption.</p>

<p>Example: AES.</p>

<h2>Cipher suite</h2>

<p>https://www.iana.org/assignments/tls-parameters/tls-parameters.xhtml#tls-parameters-4</p>

<p>A triple of</p>

<ul>
<li>authentication</li>
<li>encryption</li>
<li>and message authentication c</li>
</ul>


<h2>SSL / TLS</h2>

<p>Lots of people use them interchaangeably, but SSL was originally created
at Netscape and used to be implemented at the application layer, living
on top of TCP. When it was IETF standardized, it was renamed TLS and
moved out of the application layer.</p>

<p>TLS provides:</p>

<ul>
<li>encryption

<ul>
<li>obfuscate data transmitted from one computer to another</li>
<li>example: plaintext means zero encryption and easily breakable
ciphertext means shitty encryption</li>
</ul>
</li>
<li>authentication</li>
<li>verify that you&#8217;re talking to who you think you&#8217;re talking to</li>
<li>example: the CA validates the certificate that a server sends you</li>
<li>integrity

<ul>
<li>detect message forgery or tampering</li>
<li>example:</li>
</ul>
</li>
</ul>


<h2>Beware the intermediaries</h2>

<p>Intermediaries are caching servers, gateways, web accelerators, content
filters, blah blah blah, all the stuff that&#8217;s come out to aid and extend
HTTP. They&#8217;re often transparent to the end user, but they come with the
limitation that if you start wanting to deviate from HTTP on port 80 in some
application specific way, you&#8217;re boned. And it&#8217;s kinda rare to find
other ports that are open: 80 and 443 (HTTPS) are usually open but
everything else is often closed. These intermediaries might improperly
try to apply their logic to the non HTTP, etc, there&#8217;s no easy way to
detect when or when not to apply.</p>

<p>Solution: HTTPS tunnel all the things. All data is obfuscated from
intermediaries and intermediaries have no way of known whether the
encrypted data is HTTP or some custom proprietary crazy thing.</p>

<h2>Self-signed certificates</h2>

<p>http://www.akadia.com/services/ssh_test_certificate.html</p>

<p>Things learned:</p>

<ul>
<li>&#8220;If the private key is no longer encrypted, it is critical that this file only be readable by the root user!&#8221;</li>
<li>You can remove the DES from the private key so that you don&#8217;t have to
type in the password all the god damn time when your server starts.
(Verified this with a node app)</li>
</ul>


<p>Turns out you could also just run the following:</p>

<pre><code>openssl req -new 
</code></pre>

<p>So why is DES required at all? I&#8217;m guessing it&#8217;s possible to generate a
CSR without it, right?</p>

<h2>ALPN: Application-Layer Protocol Negotiation</h2>

<p>Note to dummy: there&#8217;s no TLS 3 way handshake. You&#8217;re thinking of TCP
ACK SYN SYNACK that has to happen before app data is exchanged.</p>

<p>ALPN takes place during the</p>

<h2>SNI: Server Name Indication</h2>

<p><a href="https://www.ietf.org/rfc/rfc3546.txt">rfc, page 8</a></p>

<p>If you have a server that you want to host multiple sites with their own
respective TLS certificates,</p>

<h2>self-signed-certificate</h2>

<p>Useful for testing SSL before you go ahead and buy a certificate for 3rd
party validation.</p>

<h2>AES vs RSA</h2>

<p>AES is symmetric, and generally speaking symmetric encryption/decryption
is a lot faster than assymetric, hence AES is used for the
encryption/decryption of data.</p>

<h2>Sprite gotchas</h2>

<p>I used to think sprites were bitchin; save HTTP requests, combine all
your images into one. Obviously, these are lame application-level
optimizations/hacks to cover the ass of the transport layer&#8217;s (HTTP&#8217;s)
shortcomings (addressed in SPDY / HTTP 2.0).</p>

<p>Downsides of sprites:</p>

<ul>
<li>all the application-layer crap you have to do to handle it</li>
<li>change a single pixel of a single image and you&#8217;ve busted a massive
cached of all the other images in the sprite</li>
<li>memory intensive; you might not be using each image but you have to
load all of it in memory, might be too much for mobile clients</li>
</ul>


<h2>Octet</h2>

<p>It means byte. Saw it all over the place in the
<a href="https://datatracker.ietf.org/doc/draft-ietf-httpbis-http2/?include_text=1">HTTP 2 spec draft</a></p>

<h2>nginx</h2>

<p>After <code>brew install nginx</code></p>

<pre><code>Docroot is: /usr/local/var/www

The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that
nginx can run without sudo.

To have launchd start nginx at login:
    ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
Then to load nginx now:
    launchctl load ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist
Or, if you don't want/need launchctl, you can just run:
    nginx

WARNING: launchctl will fail when run under tmux.
</code></pre>

<p>What is docroot?</p>

<ul>
<li>It&#8217;s a file&#8230; not a directory?</li>
<li>But you can delete it and replace with a directory and put an
index.html in there and it works</li>
<li>So I guess there&#8217;s some default configuration of nginx that just hosts
static files from this doc root directory</li>
</ul>


<p>What do them commands does?</p>

<pre><code>ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
</code></pre>

<p>What are launchd and launchctl?</p>

<p><code>launchd</code> is a daemon (conventions dictate that daemons end in a <code>d</code>).
<code>launchctl</code> is what you use to control that daemon. So if you want to
schedule something to start</p>

<p>What&#8217;s the <code>mxcl</code> in <code>homebrew.mxcl.redis.plist</code>?</p>

<p>It refers to <code>mxcl</code>, maintainer of Homebrew. Just normal reverse domain
name notation. So does that mean any homebrew-installed domains get
prefixed like that? I&#8217;m guessing <code>mxcl</code> also made the Redis recipe.
Or maybe every homebrew daemon gets prefixed like that? Not sure, who
cares.</p>

<pre><code> In the launchd lexicon, a "daemon" is, by definition, a system-wide service of
 which there is one instance for all clients. An "agent" is a service that runs
 on a per-user basis. Daemons should not attempt to display UI or interact
 directly with a user's login session. Any and all work that involves interacting
 with a user should be done through agents.
</code></pre>

<p><a href="https://developer.apple.com/library/mac/technotes/tn2083/_index.html">TN2083 - Daemons and Agents</a></p>

<p>Wow, &#8220;Daemonomicon&#8221; is an awesome word: &#8220;formal definition of the types
of bg programs you can write&#8221;.</p>

<ul>
<li>bootstrap server: launchd</li>
<li>root session: first and last session. Boot-time processes and daemons
live here. User-independent. e.g. <code>mDNSResponder</code></li>
<li>login session: proceses launched by or for a user live in login
session. Login sessions are associated w authenticated users. Each
user</li>
</ul>


<p>If I</p>

<h2>Origins of TTY</h2>

<p>http://www.linusakesson.net/programming/tty/</p>

<ul>
<li>stock tickers, then ASCII teletype within a network called Telex.</li>
<li>Telex was a network that used level of current to respresent different
characters, vs different voltages used by analog telephone shit</li>
<li>Telex existed before integration w computers</li>
<li>When command lines became the norm, teletypes were used as input and
output since they were readily available on the market</li>
<li>Lots of different models, needed to standardize in some way; UNIX
philosophy dictated letting kernel handle low level word length, baud
rate, flow control, etc., later things like color output, cursor
movement, etc, was left to application (not kernel)</li>
<li>Line editing is managed by OS-provided line discipline. Default is
cooked/canonical mode. raw mode disables things like editing,
backspace, and generally disables any IO processing within the line
discipline.</li>
</ul>


<p>Skipping ahead, you can force your terminal into stty raw mode via</p>

<pre><code>stty raw #enable
stty -raw #disable
</code></pre>

<p>Now I know how to write a Ruby impl of Press Any Key</p>

<pre><code>print "Press any key... "

begin
  system("stty raw -echo")
  c = STDIN.getc
ensure
  # re-enable
  system("stty -raw echo")
end

puts "Thanks!"
</code></pre>

<p>Note that it&#8217;ll consume CTRL-C as well rather than signalling an
interrupt (hence CTRL-C prints &#8220;Thanks!&#8221; rather than terminating
immediately).</p>

<p>This is also how any text editor functions.</p>

<p>This must be what&#8217;s happening when I kill some script when it doesn&#8217;t
expect it and then my terminals fucked. Typing in <code>stty -raw</code> even
though I can&#8217;t see it probably would fix it&#8230; need to try.</p>

<p>Back to the thing:</p>

<ul>
<li>Kernel provides many line disciplines, only one attached to serial
device at a time. Default is <code>n_tty</code>. I guess that&#8217;s what we&#8217;re
configuring when we futz w <code>stty</code></li>
<li>Other disciplines are for things like packet switched data</li>
<li><a href="http://www.cs.fsu.edu/~baker/devices/lxr/http/source/linux/drivers/char/n_tty.c">tty C source code</a></li>
<li>UART (Universal Async Receiver and Transmitter): converts teletype
signal into bytes that the OS can process. OS has a UART driver.</li>
<li>TTY driver: allows user to kill/suspend an infinite looped program,
bg processes can process til they try to write to terminal (at which
point they suspend), and user input to fg process only.
(implemented in <code>tty_io.c</code>)</li>
<li>TTY Device: triplet of UART driver, line discipline, and TTY driver.</li>
<li>TTY devices live in <code>/dev</code> w file mode <code>c</code> for &#8220;Character special
file&#8221;. To manipulate one, you need ownership of the device file
(e.g. via <code>login</code>).</li>
<li>TTYs are just objects. Not alive. Other things plug into it. Those
other things have execution contexts.</li>
<li>pty = pseudoterminal, as opposed to TTY.</li>
</ul>


<p><code>ps -o stat</code> prints out <code>Ss</code> <code>Ss+</code>, etc&#8230; here&#8217;s what the capital
letters mean:</p>

<pre><code>R   Running or runnable (on run queue)
D   Uninterruptible sleep (waiting for some event)
S   Interruptible sleep (waiting for some event or signal)
T   Stopped, either by a job control signal or because it is being traced by a debugger.
Z   Zombie process, terminated but not yet reaped by its parent.
</code></pre>

<p>Most things are in <code>S</code>. An example of <code>R</code>:</p>

<pre><code>ruby -e 'loop {}'
</code></pre>

<p><code>s</code> means session group leader. <code>+</code> means process is part of foreground
process group.</p>

<ul>
<li>Ctrl Z suspends a process, puts it in <code>T</code> state.</li>
</ul>


<p>Jobs, e.g. <code>fg</code> and <code>bg</code> are just process groups. Consider</p>

<pre><code>ruby -e 'loop {}'  | grep a | grep a | grep a
</code></pre>

<p>This causes as CPU-intensive loop and will be in R state.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R+   s045    7:03.43 ruby -e loop {}
machty 45755 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>and when I suspend:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 T    s045    7:29.05 ruby -e loop {}
machty 45755 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 T    s045    0:00.00 grep a
</code></pre>

<p>Everything below it suspends.</p>

<p><code>jobs</code> are tied to session leaders, and terminals are session leaders.
If I go to another tmux pane and type <code>jobs</code>, the suspended job <em>won&#8217;t</em>
show up; I have to be in the same terminal that started it. TODO: can I
change session IDs?</p>

<p>If I <code>bg 1</code>, the following happens:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R    s045    7:39.63 ruby -e loop {}
machty 45755 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S    s045    0:00.00 grep a
</code></pre>

<p>Note how it&#8217;s back to running, but note the missing foreground <code>+</code>. <code>fg 1</code>
would bring it back.</p>

<p>Note that we could turn one of those greps into <code>R</code> if it was actively
processing data, e.g.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 46054 45014 46054      0    4 R+   s045    0:37.84 ruby -e loop { puts "a" }
machty 46055 45014 46054      0    4 R+   s045    0:45.56 grep a
machty 46056 45014 46054      0    4 R+   s045    0:27.01 grep b
machty 46057 45014 46054      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>(Actually, the first 3 R&#8217;s might be S&#8217;s if you re-run this command;
there&#8217;s a race condition as to whether the CPU is actually running code
or whether it&#8217;s blocked on an IO syscall waiting for piped data to come
in, but the last grep is always S+ because it never gets output from the
<code>grep b</code>).</p>

<p>A Job is a Processs Group.</p>

<p>If you&#8217;re just starting/stopping/piping processes, all those child
processes with have a parent process ID of <code>bash</code>&#8217;s pid.</p>

<p>What constitutes a job/process group? Piped commands for one.
Let&#8217;s see about Process Subsitution. Answer: process substitution
doesn&#8217;t consider it as a pipe. It considers it as a shit of epic
fartitude. In other words, process substitution ends up being miserably
old and mortal and definitely going to die. In other words, process
substitution is not in the same process group. It&#8217;s its own process
group. If you do <code>echo &lt;(some long living thing)</code>, the long living thing
will survive as a sibling process, in its own process GROUP WHO CARES.</p>

<p>You can only read from  / write to TTY if you&#8217;re foreground. If you&#8217;re
not <code>fg</code> and you try and write to TTY, kernel will suspend your ass.</p>

<ul>
<li><code>ioctl</code> is the UNIX swiss army knife; manipulates special files like
terminals.</li>
<li><code>ioctl</code> requests must be initated from processes, so the kernel can&#8217;t
asyncly communicate w an application unless the app asked for it.</li>
<li>Signals are how kernel communicates asyncly w a process. Messy and
error prone they are.</li>
</ul>


<p>Question: nohup detaches into its own session id to prevent closing on
SIGHUP&#8230; why does it have to do that? Why can&#8217;t it just ignore that
signal? Let&#8217;s see.</p>

<pre><code>Signal.trap(:HUP) do
  puts "I WILL NOT"
end
sleep
</code></pre>

<p>If I ssh localhost and run that in background (with <code>&amp;</code>) and then
logout, it stays running, PPID changes to 1 (root). So how is that
different than nohup? TODO: find out. Something with setsid, etc.</p>

<p>SIGINT&#8217;s originate from the terminal&#8230; is it correct to say they
originate from TTY? I think it is based on the <code>n_tty.c</code> code.
Also, in raw mode it doesn&#8217;t even fire. COOL.</p>

<ul>
<li>SIGPIPE isn&#8217;t just an error but also a way to know whoever was
listening to you has stopped listening to you, e.g. <code>yes | head</code>.</li>
<li>SIGSTOP is to SIGTSTP as SIGKILL is to SIGQUIT.</li>
<li>SIGCONT can be sent to a ^Z-suspended process. It behaves as if you
started the process with <code>&amp;</code>. It&#8217;s running, but it&#8217;s bg. In other
words, if you have a suspended process 12345, <code>bg 1</code> or
<code>kill -CONT 12345</code> would do the same thing; it&#8217;d start running in the
background, spitting out output</li>
<li>You can break shit with
<code>ruby -e 'Signal.trap(:TTIN) { puts "wat" }; sleep 1; gets' &amp;</code>
(recursive SIGTTIN). You try and write to TTY in the background and
then keep ignoring the signal that it&#8217;s failing. I don&#8217;t know what
causes the deadlock though, but <em>something</em> screwing up sounds right.</li>
<li>If you press ^Z, that sends a message to the foreground process group.
The line discipline sends <code>SIGTSTP</code> to the foreground process group.
This will suspend the whole process group, whatever the main</li>
</ul>


<p>Question: if you use pipes combined with <code>&amp;</code>, what gets put into the
background? All tasks? Answer (I think): <code>&amp;</code> ultimately results in a
process group getting put into the background, and a process group
contains any pipes, child processes, etc, so it <em>must</em> apply to all of
the different processes as a whole, and there&#8217;s no way to say that only
one of the pipe segments runs in the background.</p>

<p>Fun fact: you can reimplement the default ^Z behavior as follows:</p>

<pre><code>has_ignored = false
Signal.trap(:TSTP) do
  if has_ignored
    Process.kill(:STOP, Process.getpgrp)
  else
    has_ignored = true
    puts "ignoring"
  end
end

sleep
</code></pre>

<p>TL;DR the default SIGTSTP ^Z handler fires a STOP. You can catch TSTP
and immediately do the same for the same effect.</p>

<p>Vim&#8217;s source code (and probably everyone&#8217;s) does some variant of</p>

<pre><code>settmode(TMODE_COOK);
kill(0, SIGTSTP);       /* send ourselves a STOP signal */
</code></pre>

<p>So, you return TTY mode to cook mode.</p>

<ul>
<li>If you run something like <code>echo "wat" | less &amp;</code>, you&#8217;ll immediately
see <code>[2]+  Stopped   echo "wat" | less</code> because <code>less</code> is always going
to try and write to TTY in a raw manner&#8230;?</li>
<li>If you suspend, say, vim, vim will catch the SIGTSTP, move the cursor
to the last line of the screen w control signals (it&#8217;s still attached
to TTY) and then fires a SIGSTOP.</li>
<li>Once stopped, a SIGCHLD is sent to the session leader with the pid of
the suspended process. When all processes in fg have been suspended
(T&#8217;d), the current TTY config is stashed for later restoration
(<code>stty -g</code> is one way of doing this).</li>
</ul>


<p>So why doesn&#8217;t ^Z suspend bash?</p>

<p>Ahh, so here&#8217;s how you get TTOU to fire (and cause a process to suspend)</p>

<pre><code>ruby -r "io/console" -e "IO.console.raw { puts 'wat' }" &amp;
</code></pre>

<p>Note that if we hadn&#8217;t used <code>.raw</code> to put TTY in raw mode, it would have
just printed &#8220;wat&#8221; into the same terminal even though the process is
running in the background, but if you grab full control of the TTY with
<code>raw</code>, it&#8217;ll cause a TTOU.</p>

<p>You can go in and configure another TTY to update its rows/cols. I can
fuck w the vim in another tmux pane, tell it its skinnier/wider than it
is, but once i resized a tmux pane then BOOM it fires its own tty
commands, and tty fires a SIGWINCH, and then that causes vim to query
the tty for the current width and repaint.</p>

<p>Ah: realization: the ultimate decider in whether TTOU fires is whether
topstop</p>

<h2><code>read</code></h2>

<pre><code>read words &lt; &lt;(echo "wat")
echo $words
</code></pre>

<h2>resetting the keyboard when things go crazy</h2>

<p><code>reset</code>, or typing Escape and c.</p>

<pre><code>stty raw
reset
</code></pre>

<p>and we&#8217;re back. It resets your TTY driver, I guess.</p>

<h2><code>yes</code></h2>

<p>Repeatedly enter <code>y</code> for saying yes to everything. Like the dropper bird
from the simpsons when homer gets fat. You can also do <code>yes no</code> to say
other things.</p>

<h2>Ack</h2>

<p>is written in Perl.</p>

<h2>100 Continue status</h2>

<p>An HTTP 1.1 mechanism.</p>

<p>http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html</p>

<p>In some cases, a server knows just by looking at request headers that it
won&#8217;t process the request, making it potentially wasteful for the client to send a
giant doomed-to-fail payload. In these cases, the client can decide not
the send the full payload unless the server has told it &#8220;based on your
headers, you should Continue sending this full payload because I don&#8217;t
see any reason why it should fail, just by looking at the headers.&#8221;</p>

<p>To opt into this, the client must provide the following header:</p>

<pre><code>Expect: 100-continue
</code></pre>

<p>The server will see this, decide if the request will succeed, and if so,
it send back 100 Continue and keeps reading from the input stream.
Client then sends the whole payload.</p>

<p>Proxies can reject if it knows the next-hop server is HTTP 1.0 or less
with a 417 Expectation Failed.</p>

<h2>IOS8 breaks file uploads in Safari</h2>

<p>http://blog.fineuploader.com/2014/09/10/ios8-presents-serious-issues-that-prevent-file-uploading/</p>

<p>Jesus. No workaround? Apple, you suck.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/09/15/daily-journal/"/>
    <updated>2014-09-15T19:57:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/15/daily-journal</id>
    <content type="html"><![CDATA[<h2>FTP</h2>

<p>Plaintext, unless you&#8217;re using SFTP or some variant.</p>

<p>FTP uses multiple connections: 1 control connection for sending
commands and tracking current directory, etc, and a connection for
actually streaming the file data.</p>

<p>How the second connection (data) is established depends on active vs
passive mode: in active mode, the server will try to connect back to the
client at PORT+1, and in most modern cases, this will fail due to NATs
and firewalls, hence passive mode (via PASV) command is meant to get
around this. In passive mode, the client requests an IP and port from
the server (via the control connection), and then the client makes the
second connection to whatever the server returns. This works as clients can
generally connect to servers without NAT/firewall issues.</p>

<p>Note that active connections are rare. The man page for <code>ftp</code> is
telling:</p>

<pre><code>-A          Force active mode ftp.  By default, ftp will try to use passive mode
            ftp and fall back to active mode if passive is not supported by the
            server.  This option causes ftp to always use an active connection.
            It is only useful for connecting to very old servers that do not
            implement passive mode properly.
</code></pre>

<h2>Application-level gateway</h2>

<p>http://en.wikipedia.org/wiki/Application-level_gateway</p>

<p>TODO: learn more.</p>

<h2>Process per connection</h2>

<p>One way of handling a new connection is to fork and let the forked
process handle that connection. Makes sense for the parent instance to
use Ruby&#8217;s <code>Process.detach</code>, which doesn&#8217;t have a native kernel
equivalent but is just a Ruby convenience that spins up a thread that
calls <code>wait()</code> on the forked process to prevent it from becoming a
zombie if the parent process exits before the forked one.</p>

<p>Remember that forking isn&#8217;t available on Windows or JRuby.</p>

<p><code>shotgun</code> is a Ruby server that forks per connection. Why? Isn&#8217;t this
wasteful (relative to pre-forking solutions like Unicorn)? Yes, but it
has specific purpose: assuming it&#8217;s not painfully expensive to spin up
your server (like Rails), and that you don&#8217;t have a mechanism for
reloading after code changes (like Rails), <code>shotgun</code> will fork per
connection and entirely reload / spin up the rack server, less reloading
the latest version of any Ruby code, thus not requiring you to manually
restart your server.</p>

<h2>Thread per connection</h2>

<p>Typical state-sharing caveats apply when working with threads, hence
it&#8217;s useful to thing about the simple unit of concurrency that will keep
your threads isolate and minimize their access to shared data. That unit
would be a connection; each thread should get its own connection object.
Create a connection object, immediately create a new thread, and let
that connection object fall out of scope in the creator thread so that
only the newly spawned thread has access to it. Simple enough.</p>

<h2>How to verify your code is on multiple cores</h2>

<p>You have to dig in a little bit to verify that Ruby code you&#8217;re writing
is actually being processed on multiple CPU cores. There are many
variables:</p>

<ol>
<li>Does your system even have more than one core? (try <code>system_profiler | grep 'Total Number of Cores'</code> to find out, probably some other ways too)</li>
<li>Does your Ruby have a GIL? (MRI does, Rubinius and JRuby don&#8217;t)</li>
<li>Some third thing to pad my arbitrary list of bullshit.</li>
</ol>


<p>Anyway, one easy way is to run the following code:</p>

<pre><code>NUM_CORES = 2

threads = []
NUM_CORES.times do |t|
  threads &lt;&lt; Thread.new do
    log_every = 1000000
    i = 0
    loop do
      i += 1
      if i == log_every
        i = 0
        putc t.to_s
      end
    end
  end
end

threads.each(&amp;:join)
</code></pre>

<p>Running this on MRI Ruby results in 100% CPU usage. Running in JRuby
yields 200%, which means two cores are operating at 100%. Pretty rad,
yes?</p>

<p>CPU usage reported by activity monitor or <code>top -o cpu</code>.</p>

<h2>Preforking</h2>

<p>e.g Unicorn</p>

<p>What&#8217;s nice is that the kernel will handle load-balancing for us: when
there are no incoming requests, you have N forked instances blocked on
<code>accept</code>, and the kernel will choose which instance gets the next
incoming request. If all forked instances are busy, the kernel will just
queue up the request internally. If the queue gets full, you&#8217;ll get an
ECONNREFUSED. Easy peazy.</p>

<p>Unicorn (and probably Rainbows) does some extra tracking on child
processes to make sure it&#8217;s not getting stuck on long requests, etc.</p>

<p>Main disadvantage is memory usage. By the time you fork, if the parent
process is 100 mb, then 4 forks and you&#8217;re at 500 mb&#8230; unless 1) your
OS has COW and 2) you don&#8217;t write to it all that much.</p>

<h2>Reactor</h2>

<p>e.g. Node.js, Twisted, EventMachine</p>

<p>High levels of concurrency (not necessarily parallelism) achievable,
relative to threading/forking models, which hit their RAM limit much
faster (Reactor patterns mean that everything is just heap allocations
on the same thread).</p>

<p>Impacts on programming model:</p>

<ul>
<li>No processes/threads, so no shared memory, synchronization, etc, to
have to worry about</li>
<li>Don&#8217;t block the single Reactor thread (because nothing else will be able to
run). You wouldn&#8217;t have to worry about this in thread/processland.
This is why if you&#8217;re using EventMachine, your gems must be
event-machine aware, otherwise they&#8217;ll block (which would be fine in a
threading/forking environment).</li>
</ul>


<h2>Node cluster</h2>

<p>http://nodejs.org/api/cluster.html</p>

<p>Based on the fact that you can use child process forking to split heavy
duty work into process that can each live on a different core, if that&#8217;s
what you&#8217;re about.</p>

<p>Note that there&#8217;s no C-like or Ruby-like fork in Node; you can&#8217;t just
call fork and then have both the parent and newly forked child process
continue execution from that <code>fork()</code> invocation&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/09/06/daily-journal/"/>
    <updated>2014-09-06T14:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/06/daily-journal</id>
    <content type="html"><![CDATA[<h2>netcat (nc)</h2>

<p>Utility to spinning up arbitrary tcp servers for testing, sending
packets, etc.</p>

<pre><code>Socket.new(Socket::AF_INET, Socket::SOCK_STREAM)
or symbols:
Socket.new(:INET6, :STREAM)
</code></pre>

<p>INET = internet, specifically IPv4, <code>SOCK_STREAM</code> means a TCP stream
will be set up, as opposed to <code>DGRAM</code>, which would set up UDP.</p>

<p>Set up bullshit listener:</p>

<pre><code>nc -l localhost 4481
</code></pre>

<h2>Loopback</h2>

<p><code>localhost</code> is a loopback, which is a virtual interface where any data
sent to the loopback is immediately received. <code>127.0.0.1</code> is the IP.</p>

<p>Check dat <code>/etc/hosts</code> file:</p>

<pre><code>##
# Host Database
#
# localhost is used to configure the loopback interface
# when the system is booting.  Do not change this entry.
##
</code></pre>

<p>Funny how I never notice stuff like that until someone officially
defines it for me.</p>

<h2>&#8220;well-known&#8221; ports</h2>

<p>Hosted by IANA.org, the Internet Assigned Numbers Authority.</p>

<h2>Gerrymandering</h2>

<blockquote><p>manipulate the boundaries of (an electoral constituency) so as to favor one party or class.</p></blockquote>

<p>Knew what this was, forgot the word for it.</p>

<h2>AWS Spot Instances</h2>

<p>Running interruption-tolerant applications on EC2 unused capacity, where
you can bid on price per hour and maximum bid price.</p>

<h2>Chekhov&#8217;s Gun</h2>

<p>http://en.wikipedia.org/wiki/Chekhov&#8217;s_gun</p>

<blockquote><p>Remove everything that has no relevance to the story. If you say in the first chapter that there is a rifle hanging on the wall, in the second or third chapter it absolutely must go off. If it&#8217;s not going to be fired, it shouldn&#8217;t be hanging there.</p></blockquote>

<p>Anton Chekhov is considered to be among the greatest writers of short
stories in history. Guess I should start reading.</p>

<h2>Binding to an interface</h2>

<p>You can bind to a single interface, or ALL interfaces, lol!</p>

<p><code>0.0.0.0</code> means all interfaces. I guess that means that requests to
localhost, and potentially some other external facing interface, will
route requests to this socket. So what if someone has already bound
specifically to localhost:12345 and you try to bind to <code>0.0.0.0:12345</code>?</p>

<p>Answer: I don&#8217;t know&#8230; need to learn about what other interfaces are
available</p>

<p>REVISED ANSWER: I can use the IP provided by my router.</p>

<pre><code>ruby -run -e httpd . --port=4124 --bind-address=192.168.1.3
</code></pre>

<p>Then if I type <code>localhost:4124</code> in the browser, it don&#8217;t work, but if I
type <code>192.168.1.3:4124</code> in the browser, IT WORKS. :)</p>

<p>But to the original question, it turns out you can run ALL THREE of
these:</p>

<pre><code>ruby -run -e httpd . --port=4123 --bind-address=0.0.0.0
ruby -run -e httpd . --port=4123 --bind-address=192.168.1.3
ruby -run -e httpd . --port=4123 --bind-address=localhost
</code></pre>

<p>So the first and 3rd of these should be able to respond to</p>

<pre><code>curl localhost:4123 &gt; /dev/null
</code></pre>

<p>It seems that the third (localhost) always wins. Makes sense. What about</p>

<pre><code>curl 192.168.1.3:4123 &gt; /dev/null
</code></pre>

<p>And the more specific second one always wins. So I guess the OS will
look for a match of interface+port before falling back to 0.0.0.0.
Makes sense.</p>

<h2>listen queue size</h2>

<pre><code>socket.listen(10)
</code></pre>

<p>This means your socket will buffer up to 10 connections before
<code>ECONNREFUSED</code> is return to the shits on the other side.</p>

<p>If you&#8217;re getting a lot of ECONNREFUSED, it probably means users are
already experiencing some some queue-based lag, and you should rethink
your architecture, spin up more server instances, etc. But you can also
just set to the max size via</p>

<pre><code>server.listen(Socket::SOMAXCONN)
</code></pre>

<h2>A connection is a socket</h2>

<p>When you accept() after binding, you&#8217;ll get a connection object, which
is just a Socket, but different from your server socket; it&#8217;s just a
file wrapper for that particular connection that you can write shit to.</p>

<h2>quadruple of remote/ip/port must be unique</h2>

<p>You can&#8217;t have more than one connection where</p>

<pre><code>local addr, local port, remote addr, and remote port
</code></pre>

<p>are not totally unique. Hmmm, so where is this prevented? TODO</p>

<h2>Close socket file descriptors</h2>

<p>Why, doesn&#8217;t this happen automatically on exit/GC?</p>

<ol>
<li>GC might not clean up for you fast enough;</li>
<li>Might hit file descriptor limit</li>
</ol>


<p>Wat wat wat wat in the boot.</p>

<p>You can close the read side, or close the write side, or both. This make
use of <code>shutdown</code>, and shutdown will close a side of a connection even
if you&#8217;re dup&#8217;d file descriptors (explicitly or via fork). <code>close</code>
wouldn&#8217;t actually close unless there were no other file descriptors
holding on to that socket.</p>

<h2>Keybase</h2>

<p>Uses social media accounts to prove crypto identity.</p>

<h2>Clients don&#8217;t need to bind</h2>

<p>to a port when connecting to a server. For obvious reasons. Namely that
a server needs to have a known/consistent port in order for clients to
reach it, but a client can just send from any ol po,]rt.</p>

<h2>Long ass timeouts</h2>

<pre><code>require 'socket'
socket = Socket.new(:INET, :STREAM)
remote_addr = Socket.pack_sockaddr_in(666, 'machty.com')
socket.connect(remote_addr)
</code></pre>

<p>This won&#8217;t fail any time soon. (Note if i&#8217;d given a BS DNS then it would: SocketError
exception from getaddrinfo). Only after a long ass time do you get a
ETIMEDOUT.</p>

<p>getaddrinfo seems cool. I guess it&#8217;s the C function that does a DNS
lookup? Nevermind, man <code>getaddrinfo</code> makes me cry.</p>

<p>So when does ECONNREFUSED happen vs just a long ass timeout? I guess it
means you&#8217;ve hit a server but a) no app is bound to the requested port
or b) the queue is full, and probably c) some other reason. No that&#8217;s
not valid; google.com:70 hangs for a while rather than ECONNREFUSED.</p>

<p>Maybe localhost knows what&#8217;s connected or not? I have NO IDEA.</p>

<h2><code>TIME_WAIT</code></h2>

<p>If you close a socket with pending outbound data, it won&#8217;t discard that
data but rather finish sending (and wait for ack) before totally closing
the socket. This is the <code>TIME_WAIT</code> state. Unless you&#8217;ve enabled
<code>REUSEADDR</code>, you&#8217;ll get an <code>EADDRINUSE</code> if you try to bind to a socket
that&#8217;s still in <code>TIME_WAIT</code> state.</p>

<h2><code>EAGAIN</code></h2>

<p>Commonly seen in non-blocking IO operations when there&#8217;s no data
available to read. Reading nonblockingly from a socket that hasn&#8217;t had EOF set yet but
doesn&#8217;t have data at the moment would cause that.</p>

<p>Non blocking reads will find any data in Ruby buffers, followed by
kernel buffers. If there&#8217;s nothing in there, then blocking read is
necessary.</p>

<h2>Ruby IO.write</h2>

<p><code>IO.write_nonblock</code> behavior maps to sys call <code>write()</code>, in that it can
fail to write all the data you provided it. Ruby&#8217;s <code>IO.write</code> tries to
be helpful and might internally call <code>write()</code> many times.</p>

<p>A saturated <code>write()</code> followed immediately by <code>write()</code> will cause an
<code>EAGAIN</code> because you haven&#8217;t given the kernel/network enough time to
flush the data you gave it. This is when you&#8217;d use <code>IO.select</code> to let
you know when a socket is available for writing/reading again.</p>

<p>Wat wat wat. In the BOOT.</p>

<p><code>select</code> returns an array of descriptors that are ready to be written
to. I guess it blocks?</p>

<p>Writes are blocked by TCP congestion prevention algo requirements
(cwnd, rwnd, etc).</p>

<p>There&#8217;s also <code>accept_nonblock</code> which <code>EAGAIN</code>s if there are no pending
connection on dat queue.</p>

<p><code>connect_nonblock</code> is sp</p>

<h2>TPC Resets</h2>

<p>http://en.wikipedia.org/wiki/TCP_reset_attack</p>

<p>There&#8217;s a usually-0 flag in a packet that can be set to 1 that tells the
receiver to stop using this TCP connection. Useful, for instance, when a
computer&#8217;s crashed, gets a packet it has no context for, so it tells the
sender to stop it, so that it might make a new connection and start from
there.</p>

<h2>Edge Device</h2>

<p>http://en.wikipedia.org/wiki/Edge_device</p>

<p>Basically, all the stuff that separates the public network (internet)
from your private network.</p>

<ul>
<li>routers</li>
<li>routing switches</li>
</ul>


<h2>traceroute</h2>

<p>I&#8217;ve already written about this before, but traceroute is useful for
tracing all the gateways your packet goes through to get to its
destination.</p>

<p>A gateway is any node that might forward packets along to some other
destination. Could be a router, switch, etc. Could also be a protocol
converter. Gateways could be software too.</p>

<p>Anyway, traceroute makes use of ICMP <code>TIME_EXCEEDED</code> response.</p>

<p><a href="http://en.wikipedia.org/wiki/Internet_Control_Message_Protocol">What is ICMP?</a></p>

<p>One of the many protocols that can be communicated via packets. Packets
have an 8 bit protocol field. The protocol values are decided by the
IANA (just like common/reserved ports&#8230; MIND BLOWN).</p>

<p>The list is here: http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml</p>

<h2><code>host google.com</code></h2>

<p>I noticed that the DNS lookup results via <code>host google.com</code> differed
almost each time I ran it.</p>

<pre><code>google.com has address 74.125.226.72
google.com has address 74.125.226.65
google.com has address 74.125.226.68
google.com has address 74.125.226.67
google.com has address 74.125.226.64
google.com has address 74.125.226.70
google.com has address 74.125.226.78
google.com has address 74.125.226.69
google.com has address 74.125.226.73
google.com has address 74.125.226.71
google.com has address 74.125.226.66
...
</code></pre>

<p>and then</p>

<pre><code>google.com has address 74.125.226.2
google.com has address 74.125.226.5
google.com has address 74.125.226.8
google.com has address 74.125.226.9
google.com has address 74.125.226.6
google.com has address 74.125.226.4
google.com has address 74.125.226.3
google.com has address 74.125.226.14
google.com has address 74.125.226.7
google.com has address 74.125.226.0
google.com has address 74.125.226.1
...
</code></pre>

<p>I&#8217;m asking the friendly folk at <code>##networking</code>. They turned me on to
<code>dig</code>. <code>dig</code> is the most raw and flexible DNS lookup tool. <code>host</code> is
apparently for chumps (i.e. it&#8217;s useful/quick/easy but not as much
functionality).</p>

<pre><code>dig google.com @ns1.google.com +short | sort | md5
</code></pre>

<p>This queries a specific name server&#8230;</p>

<p>OK i have a bunch of questions:</p>

<p>Why do DNS records contain
<a href="http://en.wikipedia.org/wiki/Fully_qualified_domain_name">Fully Qualified Domain Names</a>
as references to name servers? That seems to make no sense&#8230; you have
to turn something like <code>ns1.google.com</code> into an IP by querying&#8230; the
DNS system?</p>

<p>Answer: http://en.wikipedia.org/wiki/Domain_Name_System#Circular_dependencies_and_glue_records</p>

<ul>
<li>GET www.example.com /

<ul>
<li>Look up record, find its NS records</li>
<li>NS ns1.example.com</li>
<li>Need to get IP of ns1.example.com (we need to issue another DNS
request)</li>
<li>&#8230; circular dependency: you have to look up a name server&#8217;s IP
using that name server. Need some way to break dependency</li>
<li><p>Dependency broken by <code>AUTHORITY SECTION</code>, e.g.</p>

<p>;; AUTHORITY SECTION:
google.com.             60      IN      SOA     ns1.google.com. dns-admin.google.com. 1566886 7200 1800 1209600 300</p></li>
</ul>
</li>
</ul>


<p>This is called the &#8220;glue&#8221;. It&#8217;s either in Authority or Additional
section? (I should find this out.)</p>

<p>Related: http://support.dnsimple.com/articles/vanity-nameservers/</p>

<p>DNSimple allows &#8220;vanity&#8221; name servers, which lets you pretend like
you&#8217;re a bigass enough company to own/maintain your own name servers,
and anyone looking at your DNS records will see your fake name servers,
like ns1.machty.com, but these servers obviously don&#8217;t actually exist;
DNSimple provides this service by sending &#8220;glue&#8221; that maps your fake
name servers to the IP addresses of their actual name servers.</p>

<p>Top-level domains live under root (.).</p>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<p>That&#8217;s why sometimes you&#8217;ll see stuff ending in a period, like
<code>ns1.dnsimple.com.</code>.</p>

<pre><code>;; ANSWER SECTION:
dnssimple.com.          597     IN      A       184.168.221.96
</code></pre>

<p>The dot is important! You know how you can just put <code>www</code> is the record
value? You could also do a fully qualified shit e.g. <code>www.machty.com.</code>
(note the period at the end).</p>

<p>So my question is: when does the glue record get sent?</p>

<p>Gimme the NS records for www.machty.com</p>

<pre><code>$ dig machty.com NS
...
;; ANSWER SECTION:
machty.com.             3481    IN      NS      ns1.dnsimple.com.
machty.com.             3481    IN      NS      ns1a.dnsimple.com.
machty.com.             3481    IN      NS      ns2.dnsimple.com.
machty.com.             3481    IN      NS      ns2a.dnsimple.com.
machty.com.             3481    IN      NS      ns3.dnsimple.com.
machty.com.             3481    IN      NS      ns3a.dnsimple.com.
machty.com.             3481    IN      NS      ns4.dnsimple.com.
machty.com.             3481    IN      NS      ns4a.dnsimple.com.
</code></pre>

<p>Cool, so internally it&#8217;d need to look up ns1.dnsimple.com, so something
like:</p>

<pre><code>$ dig @ns1.dnsimple.com. www.machty.com
</code></pre>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<blockquote><p>+norec means that dig is asking non-recursive questions so that we get to do the recursion ourselves. The other options are to reduce the amount of dig produces so this won&#8217;t go on for too many pages:</p></blockquote>

<pre><code>a.root-servers.net. 518400  IN  A   198.41.0.4
a.root-servers.net. 518400  IN  AAAA    2001:503:ba3e:0:0:0:2:30
</code></pre>

<p>AAAA records serve the same purpose as A records, just that they are
IPv6.</p>

<p>WebPageTest.org: breaks your requests down into blah blah blah why is
this different than Network tab in devtools? Ah because it does it from
many different browsers.</p>

<p>162.212.105.24</p>

<h2>Turntable.fm</h2>

<p>Me: &#8220;there should be an app where multiple people have a playlist, but
there&#8217;s a single player that alternates between different people&#8217;s
playlists.&#8221;</p>

<p>Person next to me: &#8220;yes, that&#8217;s turntable.fm&#8221;</p>

<p>Should probably check that out.</p>

<h2>non-blocking connect</h2>

<p>http://stackoverflow.com/questions/8277970/what-are-possible-reason-for-socket-error-einprogress-in-solaris</p>

<p>There are two error codes for &#8220;shit is underway&#8221; when doing a
non-blocking connect/accept:</p>

<pre><code> [EALREADY]         The socket is non-blocking and a previous connection attempt
                    has not yet been completed.

 [EINPROGRESS]      The socket is non-blocking and the connection cannot be com-
                    pleted immediately.  It is possible to select(2) for comple-
                    tion by selecting the socket for writing.
</code></pre>

<p>Nice docs yo. The difference is that <code>EINPROGRESS</code> is the error that
gets returned if the operation has started but hasn&#8217;t finished (as
opposed to not yet being able to start because it can&#8217;t allocate the
resources it needs, file handlers, sockets, etc.). Most likely, the 3
way handshake packets have been sent, but SYN-ACK hasn&#8217;t been sent.</p>

<h2>Inversion of Control / DI</h2>

<p>Matthew Beale and I were discussing whether the proposed
<code>Ember.service()</code> violated the inversion of control that dependency
injection is meant to provide, e.g.:</p>

<pre><code>export default Controller.extend({
  foo: Ember.service() // request that 'service:foo' be injected
});
</code></pre>

<p>The fact that the consumer is requesting a specific thing to be injected
into it seems like it might be an IOC violation, but to me, all that&#8217;s
happening is that you&#8217;re specifying a provider, and it&#8217;s still up to the
outside world to decide what it&#8217;ll specifically inject into you. Also,
regardless of whether it&#8217;s explicit or not, if you use whatever is
injected into you, you are implicitly specifying a duck-typed provider
interface by the consumer; in other words, if we do things the classic
way and use <code>app.inject('controller:article', 'articleLookup', 'service:article-lookup')</code>,
this may seem like we&#8217;re moving all &#8220;control&#8221; to the injector, but
still, the article controller is going access <code>articleLookup</code>&#8217;s
properties and methods in a very specific way, which is the most
powerful / crucial way that you could specify a dependency (by
describing / using the duck type interface).</p>

<p>So, tl;dr, your consumer is always going to be specifying its
dependency, whether explicitly (<code>Ember.service()</code>) or implicitly (by
whatever methods/properties it uses from <code>this.injectedThing</code>), and it&#8217;s
therefore not a violation for a consumer to specify a Provider of the
dependency, so long as it&#8217;s still possible for the injector to disregard
the specifically-requested provider and substitute another one (e.g. a
stub) in its place.</p>

<p>This is what Angular&#8217;s <a href="https://github.com/angular/di.js">di.js</a> does
and I think it&#8217;s correct. I want it.</p>

<h2>Password-less SSH</h2>

<p>I&#8217;ve done this a bunch of times before but always forget, now I&#8217;m
writing about it:</p>

<p>The remote server you&#8217;re SSHing into needs to have your public key if
you want to be able to skip providing a password every time you ssh in.
I wanted to use a different public rsa key, so I made a new one:</p>

<pre><code>ssh-keygen
</code></pre>

<p>The optional passphrase you&#8217;re asked to supply is NOT the same password
you would have otherwise needed to use to log into SSH (which we&#8217;re
trying to avoid). Rather, it&#8217;s an additional security measure that&#8217;s
required every time you want to use your private RSA key to try and
decrypt data. I guess: if private RSA keys are a kind of password, the
passphrase is a password for your password. It means that someone who
steals your private key also needs to know your passphrase in order to
use it.</p>

<p>Anyway, let&#8217;s say I save the newly generated key pair to
<code>~/.ssh/shortcut_rsa</code> and <code>~/.ssh/shortcut_rsa.pub</code>, now I want to make
it possible to just type <code>ssh shortcut</code> and have it never ask me for a
password again. This means I need a few things:</p>

<ol>
<li><code>ssh shortcut</code> should translate into the IP I&#8217;m connecting to
(because I&#8217;d rather not type the IP every time and <code>shortcut</code> is not
a domain name that&#8217;d do the translating for me)</li>
<li><code>ssh shortcut</code> should supply the user name that the remote machine
expects (so that I don&#8217;t have to do <code>ssh remote_user_name@shortcut</code>).</li>
<li><code>ssh shortcut</code> should use the key pair I just generated w
<code>ssh-keygen</code>.</li>
</ol>


<p>To do all of these things, I need to append the following to
<code>~/.ssh/config</code>.</p>

<pre><code>Host shortcut
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>Pretty self explanatory and does the job. Note that you&#8217;ll be prompted
for the passphrase you provided for your RSA private key, but that&#8217;ll be
cached for a little while, and if you want, you can just save it to your
Apple keychain if you feel safe doing that.</p>

<p>The SSH config file also allows for wildcards, so you could literally do</p>

<pre><code>Host *
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>and then this would cause <code>ssh somerandombullshit</code> to connect to the
same remote machine. Obviously that use case is a little nuts, but it&#8217;s
useful if you wanna say &#8220;every remote machine I connect to should use
this same RSA key pair&#8221;.</p>

<h2>say+say+say = choir</h2>

<p>I devised the most badass script.</p>

<pre><code>#!/usr/bin/env sh

# use/uncomment this instead to weed out the annoying singing voices
#voices=`say -v ? | grep en_US | grep -v Cellos | grep -v Good | grep -v Hysterical | grep -v Bad | grep -v Pipe | grep -v Bells | cut -f1 -d ' '`
voices=`say -v ? | grep en_US | cut -f1 -d ' '`
num=`echo $voices | wc -w`
echo $voices | xargs -n 1 -P $num say $* -v
</code></pre>

<h2>How many segments are sent per SSH character?</h2>

<p>http://blog.hyfather.com/blog/2013/04/18/ssh-uses-four-tcp-segments-for-each-character/</p>

<p>Answer: 4</p>

<ol>
<li>You: Hey SSH server, user pressed &#8216;b&#8217;</li>
<li>SSH: cool, got it (ack)</li>
<li>SSH: hey btw, this is what <code>bash</code> (or whatever shell) ended up doing
with that character you type (description of screen update)</li>
<li>You: cool, got it (ack)</li>
</ol>


<p>What&#8217;s the difference between a segment and a packet?</p>

<ul>
<li>Segment: TCP header + application data</li>
<li>Packet: wraps segment w IP header information; a packet is a routable
piece of data</li>
</ul>


<p>This seems like the best answer: http://superuser.com/a/505134</p>

<p>A TCP segment is not enough information to know where to route data
within a network; you need IP headers for that, and where do those shits
live? In packets.</p>

<p>Take a packet and rip off its IP head: voila, a packet. Take a packet
and rip off its TCP (or UDP) head: voila, application data.</p>

<p>Don&#8217;t forget &#8220;frames&#8221;: frames wrap packets. If you wanna send your shit
over an ethernet, you need to wrap in a frame, whether wired or
wireless. Frames have MAC addresses. MAC addresses are generally
hard-wired into some hardware and are never expected to collide, lest
undefined behavior.</p>

<p>Now my question is: does TCP ever have access to IP headers? I guess it
must get forwarded along in some way&#8230; then again I dunno.</p>

<h2>RFC3439: Some Internet Architectural Guidelines and Philosophy</h2>

<p>http://tools.ietf.org/html/rfc3439</p>

<p>Clearly I need to read this.</p>

<h2>Nagle&#8217;s Algo</h2>

<p>When sending data:</p>

<ol>
<li>If there&#8217;s enough data in local packet buffer to comprise a whole TCP
packet, send that shit.</li>
<li>If no pending data in buffers and no pending acks, send immediately.</li>
<li>If there&#8217;s a pending ack, and not enough data to fill a packet, put
data in local buffer.</li>
</ol>


<p>This prevents protocols like telnet from saturating with
one-packet-per-char traffic. For telnet, if you type a bunch of chars in
a row, you could expect that the first char would send immediately and
the following ones would buffer and then send once the first char&#8217;s ack
came back.</p>

<p>All Ruby servers disable this since Ruby does its own internal buffering
in the socket lib. You disable by sending with NODELAY.</p>

<h2>URG flag</h2>

<p>Apparently you can break the FIFO-ness of TCP with Urgent data.</p>

<p><code>Socket#send</code> is the same as <code>write</code> except that you can pass flags to
<code>send</code>, e.g.</p>

<pre><code>socket.send 'urgent data', Socket::MSG_OOB
</code></pre>

<p>OOB stands for out of band. Note that the receiver must use the same
flag w <code>recv</code> to read the OOB data or else it won&#8217;t notice it.</p>

<p>OOB is rarely used because:</p>

<ul>
<li>only one byte of urgent data can be sent</li>
<li>there are issues w <code>select</code> wherein consumed urgent data continues to
be reported as unread, requires additional state tracking to get
right, etc.</li>
</ul>


<p>You could also use OOBINLINE flag to stick in an urgent byte amidst
normal queued data, and <code>read</code> will stop once it hits an urgent thing.</p>

<p>I&#8217;m guessing OOB is only a TCP thing since in UDP there&#8217;s no concept of
connection and &#8220;in order&#8221;.</p>

<h2>Datagram</h2>

<p>Data + telegram. From RFC 1594:</p>

<blockquote><p>A self-contained, independent entity of data carrying sufficient information to be routed from the source to the destination computer without reliance on earlier exchanges between this source and destination computer and the transporting network.</p>

<p>The term datagram is often considered synonymous to packet but there are some nuances. The term datagram is generally reserved for packets of an unreliable service, which cannot notify the sender if delivery fails, while the term packet applies to any packet, reliable or not. Datagrams are the IP packets that provide a quick and unreliable service like UDP, and all IP packets are datagrams;[4] however, at the TCP layer what is termed a TCP segment is the sometimes necessary IP fragmentation of a datagram,[5] but those are referred to as &#8220;packets&#8221;.</p></blockquote>

<p>So, datagrams imply unreliability of delivery, whereas packet could
refer to reliable or unreliable packets. I guess a TCP segment is a
packet. But you can&#8217;t call it a datagram, since the protocol makes it
its business to be a shit.</p>

<h2>Bill Burr</h2>

<p>How&#8217;s your danish?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/28/daily-journal/"/>
    <updated>2014-08-28T13:10:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/28/daily-journal</id>
    <content type="html"><![CDATA[<h2>Why can&#8217;t React render() return multiple elements?</h2>

<p>you can&#8217;t do</p>

<pre><code>return &lt;div/&gt;&lt;div/&gt;
</code></pre>

<p>Pete Hunt tells me it&#8217;s because of how <code>ref</code>s work; it&#8217;s a common
pattern to do <code>this.refs.x.getDOMNode()</code>, but if the component returns
multiple DOM nodes, which one do you return?</p>

<p>It&#8217;s an admitted shortcoming but not a major major push to fix any time
soon.</p>

<h2>Ruby Fixnum vs Bignum</h2>

<pre><code>2.0.0-p353 :004 &gt; (100).class
 =&gt; Fixnum
2.0.0-p353 :005 &gt; (100234234234234234234).class
 =&gt; Bignum
</code></pre>

<h2>Postgres indexing</h2>

<p>I need to optimize. Most of the queries in my app are very specific
&#8220;SELECT WHERE bleh = wat, lol = yeah, foo = bar&#8221;. By default Rails
creates a btree index, which handles many common indexing use cases, but
there&#8217;s also a &#8220;hash&#8221; index, which Postgres only considers for usage for
<code>bleh = bleh</code> queries (you can&#8217;t use it for ordering, sorting,
whatever), so it seemed ideal for me:</p>

<blockquote><p>Hash indexes can only handle simple equality comparisons. The query planner will consider using a hash index whenever an indexed column is involved in a comparison using the = operator.</p></blockquote>

<p>But then I&#8217;d like it to match multiple columns, not just a single one,
so I&#8217;d like to consider a multi-column index, but then:</p>

<blockquote><p>Currently, only the B-tree, GiST and GIN index types support multicolumn indexes. Up to 32 columns can be specified. (This limit can be altered when building PostgreSQL; see the file pg_config_manual.h.)</p></blockquote>

<p>So I guess Hash is out of the question. So the final thing I need to
figure out is: does it make sense for me to use a multi-column index if
I have three columns that need to be <code>=</code> matched?</p>

<p>Partial indexes: http://www.postgresql.org/docs/8.2/static/indexes-partial.html</p>

<p>Useful for when you&#8217;d like to exclude common values from consideration
in an index (because indexes lose value the more duplicates there are in
a database).</p>

<h2>V8 optimizes based on AST size</h2>

<p>&#8230;and comments are part of the AST:</p>

<p>https://github.com/broccolijs/broccoli-kitchen-sink-helpers/commit/092a680f1ff8fe2d54419dd57fa9ba8a81f6f297</p>

<h2>General Theory of Reactivity</h2>

<p>https://github.com/kriskowal/gtor</p>

<p>Reactivity: reacting to external stimuli and propagating events.</p>

<ul>
<li>(functional) reactive programming</li>
<li>bindings</li>
<li><p>operational transform</p></li>
<li><p>Spatial Singular is a value, e.g. 5</p></li>
<li>Spatial Plural is an enumberable/iterable of values</li>
<li>Temporal Singular is an eventual value, e.g. a Promise</li>
<li>Temporal Plural is eventual values, e.g. Observable of values</li>
</ul>


<p>But this glazes over many particulars, and things like Rx boil too much
into a single Observable type that can perform any role.</p>

<h3>Value</h3>

<ul>
<li>Singular</li>
<li>Spatial</li>
<li>Accessible</li>
<li>Modifiable</li>
<li>Composed of a getter and a setter</li>
<li>Data flows from setter to getter</li>
</ul>


<p>Every reactive primitive features getter/setter, producer/consumer, or
writer/reader. See http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2014/Keynote-Duality</p>

<p>Arrays are the above, but plural. Generators are the
producing/writing/setting side, iterators are the read/get/consume.</p>

<p>Promises are singular and temporal. Promises are getters, and
corresponding setter is a resolver. Together, they&#8217;re a kind of
deferred.</p>

<p>Streams are a getter/setter pair of temporal plurals. Producer is a
writer and consumer is a reader. Reader is an async iterator and writer
is an async generator.</p>

<p>Remember that a value encapsulates a getter and setter&#8230; values are:
Deferred (promise + resolver, singular, temporal), Stream (reader +
writer, plural, temporal), Array (iterator + generator, spatial,
plural), and value (getter + setter, spatial, singular).</p>

<p>Promises (singular + temporal) model dependency. The API/experience of
multiple resolvers is the same regardless of who wins the race, and same
w consumers.</p>

<p>Because consumers cannot interfere with another consumer, aborting
promises is not possible; promise is only the result, not the work
leading to that result.</p>

<p>A task, similar to promise, but is unicast.</p>

<p>Unicast: http://en.wikipedia.org/wiki/Unicast - sending messages to a
  single destination</p>

<p>Broadcast: multiple possible destinations (or none)</p>

<p>Because tasks are unicast, consumers can&#8217;t clobber each other (because
there&#8217;s only one), hence they are cancellable. Can be explicitly forked
to create a task that depends on the same result</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/22/daily-journal/"/>
    <updated>2014-08-22T16:32:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/22/daily-journal</id>
    <content type="html"><![CDATA[<h2>Difference b/w XSD and DTD</h2>

<p>They both define the structure of an XML document, but what&#8217;s the
difference?</p>

<p>Awesome SO:
http://stackoverflow.com/questions/1544200/what-is-difference-between-xml-schema-and-dtd</p>

<p>DTD&#8217;s are arguably easier to grok, but the XSD has more features, but at
the expense of understanding the abstractions of data types and what
not. Seems easier to describe recursive structures in XSD than the other
bullsharticles.</p>

<p>XSD is XML, DTD stems from SGML.</p>

<p>I guess XML And HTML also stem from SGML. WHAT DO I KNOW? NOTHING!</p>

<h2>Wolf3d in React</h2>

<p>Apparently I missed this https://github.com/petehunt/wolfenstein3D-react.git</p>

<h2>Breaking the chain in React</h2>

<p>For when you want to tell React &#8220;don&#8217;t mess with my DOM, I&#8217;m doing funky
jQuery shit&#8221;.</p>

<p>Render a div that won&#8217;t invalidate:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L47</p>

<p>Re-render your own children:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L15-L18</p>

<h2>Retcon: retroactive continuity</h2>

<p>http://en.wikipedia.org/wiki/Retroactive_continuity</p>

<p>&#8220;alteration of previously established facts in the continuity of a
fictional work&#8221;</p>

<h2>CVV can mean lower rates</h2>

<p>http://security.stackexchange.com/questions/21168/how-does-amazon-bill-me-without-the-cvc-cvv-cvv2</p>

<p>There are fraud-prevention benefits to using CVV, and as such, payment
handlers will often give you a discount if the CVV is present.</p>

<h2>X-Forwarded-For</h2>

<p>Some servers fall prey to IP spoofing via setting the <code>X-Forwarded-For</code>
header. If your server isn&#8217;t careful, then given a
<code>curl -H "X-Forwarded-For: 1.2.3.4" http://www.machty.com</code>, your
server&#8217;s logs and maybe even IP-dependent application logic (e.g.
language detection) might use 1.2.3.4.</p>

<p>In Rails you can add your known proxy/load-balancing IPs to
<code>TRUSTED_PROXIES</code>. Then the <code>RemoteIp</code> rack middleware will filter out
all of those and pick the most recently set IP, which handles the case
where you might have multiple <code>X-Fowarded-By</code> headers. So the rule is:
use the rightmost, untrusted IP and treat that as the remote ip. Why?
Because when your first proxy is hit, it&#8217;ll see IP X.X.X.X and move that
to the list of <code>X-Forwarded-By</code> headers. Note that the previous
<code>X-Forwarded-By</code> headers, present or no, are untrustable and totally
spoofable.</p>

<p>http://blog.gingerlime.com/2012/rails-ip-spoofing-vulnerabilities-and-protection</p>

<p>So that&#8217;s IP spoofing via HTTP header. How else can you IP spoof?</p>

<p>http://en.wikipedia.org/wiki/IP_address_spoofing</p>

<p>You just rewrite the source IP in the TCP/UDP packet header, which also
means when the application responds, it&#8217;ll send it back to the forged
IP.</p>

<p>There are valid use cases for this as well, such as testing load
balancing software/hardware.</p>

<h2>Types of NAT</h2>

<p>http://think-like-a-computer.com/2011/09/16/types-of-nat/</p>

<h3>Full cone NAT (Static NAT) (port forwarding)</h3>

<p>Manual mapping of public IP and port to LAN IP and port.</p>

<p>e.g. all incoming traffic to port 12345, forward to 192.168.0.10:9999.</p>

<p>Blocks (drops connection):</p>

<ul>
<li>Ports that haven&#8217;t been forwarded</li>
</ul>


<h3>Restricted cone NAT (dynamic)</h3>

<p>Don&#8217;t allow incoming data from an IP unless I&#8217;ve sent packets to it
already. Note that depending on the strictness, if I initiate a
connection to WAN IP 1.2.3.4:1234, I could potentially get data from
1.2.3.4:5678, but in stricter schemes, the port must also match.</p>

<p>But regardless of this strictness, the one requirement is that they send
data to exactly my public IP and port that I sent data out of.</p>

<h3>Symmetric NAT</h3>

<p>http://think-like-a-computer.com/2011/09/19/symmetric-nat/</p>

<p>Sym NAT is like port-restricted cone NAT, but randomly generates
different public source ports when sending to different destinations.</p>

<p>Sym NATs are the only ones that cause problems with other devices behind
NATs.</p>

<h2>Vim registers</h2>

<p>So if I have</p>

<pre><code>&lt;a href="WAT"&gt;&lt;/a&gt;
</code></pre>

<p>and I want to replace the href with a yanked &#8220;LOL&#8221;, then I can <code>di"</code> in
WAT to delete it, then <code>"0P</code> to use the last-yank register 0. Registers
1,2,3,4,5&#8230; get populated with cuts. Unnamed register gets replaced by
any yanking/cutting command. Weird terminology.</p>

<h2>Ember-cli + divshot</h2>

<p>Holy shit this was awesome.</p>

<p>Divshot.com is a static deployment heroku, basically, and ember-cli has
an addon for letting you deploy there.</p>

<pre><code>npm install --save-dev ember-cli-divshot &amp;&amp; ember generate divshot
</code></pre>

<h2>brew install fuck</h2>

<p>naw, but this is a cool script for killing them all:</p>

<pre><code>#!/usr/bin/env ruby
# coding: utf-8

abort "Usage: fuck you &lt;name&gt;" unless ARGV[0] == "you" &amp;&amp; ARGV.size == 2

a = "abcdefghijklmnopqrstuvqxyz".each_char.to_a
b = "qpuodbsnxz".each_char.to_a
ws = Hash[a.zip(b)]
ws.default = -&gt;(f){f}

puts "\n  ( #{ARGV[1].reverse.each_char.map{|f|ws[f]}.join}\n\n"

system("killall -9 #{ARGV[1]}")
exit $?.exitstatus
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/15/daily-journal/"/>
    <updated>2014-08-15T12:17:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/15/daily-journal</id>
    <content type="html"><![CDATA[<h2>Incremental GC</h2>

<p>Tenderlove tweeted this: https://bugs.ruby-lang.org/issues/10137</p>

<ul>
<li>Generational GC already is implemented: distinguish/bucket old and new
generation objects; sweeping new generation objects is fast (minor GC), and the
ones that don&#8217;t get swept up get promoted to old generation, which is
less frequently swept (in a major GC)</li>
<li>Generation GC is always incremental in that it doesn&#8217;t collect ALL
unreachables, &#8230; todo http://stackoverflow.com/questions/5092134/whats-the-difference-between-generational-and-incremental-garbage-collection</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/09/daily-journal/"/>
    <updated>2014-08-09T16:15:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/09/daily-journal</id>
    <content type="html"><![CDATA[<h2>iOS State Preservation</h2>

<p>https://developer.apple.com/library/ios/documentation/iphone/conceptual/iphoneosprogrammingguide/StatePreservation/StatePreservation.html</p>

<h2>Session token storage in localStorage</h2>

<p>Do not store session identifiers in local storage as the data is always accessible by JavaScript. Cookies can mitigate this risk using the httpOnly flag.</p>

<p>It&#8217;s risky? SAY MORE THINGS.</p>

<h2>Loading Ember CLI addons in jsbin</h2>

<h2>Forking in xargs</h2>

<p>Holy shitters, this is how I simultaneously uploaded three tracks to s3
(using my <code>to_s3</code>) script.</p>

<pre><code>find ~/Desktop -name "Audio*" -print0 | xargs -0 -n 1 -P 5 to_s3
</code></pre>

<p><code>-n 1</code> means each invocation takes a max of one arg, and <code>-P 5</code> means a
max of 5 simultaneous processes. So cool.</p>

<h2>Web audio api</h2>

<p>Finish this: http://emberjs.jsbin.com/ucanam/5964/edit</p>

<h2>Liquid Fire Global</h2>

<p>http://jsbin.com/mifuq/1/edit</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/05/daily-journal/"/>
    <updated>2014-08-05T08:47:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/05/daily-journal</id>
    <content type="html"><![CDATA[<h2>ES6 fat arrow</h2>

<pre><code>var a = this;
var fn = () =&gt; {
  console.log(this === a); // true
}
</code></pre>

<p>http://tc39wiki.calculist.org/es6/arrow-functions/</p>

<p>yuno CoffeeScript single arrow syntax?</p>

<blockquote><p>However, we don&#8217;t want CoffeeScript&#8217;s ->, it&#8217;s confusing to have two arrows and dynamic this binding is an oft-fired footgun.</p></blockquote>

<h2>SaltStack</h2>

<p>http://docs.saltstack.com/en/latest/</p>

<h2>Open Core</h2>

<p>http://en.wikipedia.org/wiki/Open_core</p>

<p>Open Source core functionality with paid/proprietary add-ons, e.g.
Sidekiq, or MySQL</p>

<p>Related:</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Crippleware">Crippleware</a>: free versions
cripple the ability to save/export/whatever</li>
<li><a href="http://en.wikipedia.org/wiki/Freemium">Freemium</a>: free core features,
pay for higher usage/capacity, e.g. most heroku add-ons</li>
</ul>


<h2>Ember First Class Actions</h2>

<p>http://emberjs.jsbin.com/ucanam/5919/edit</p>

<p>Questions:</p>

<ul>
<li>singleton vs multiples?</li>
<li>actions that depend on others?</li>
<li>link-to?

<ul>
<li>idea: a LinkView asks the router or url service for an Action
using the route params, query params, etc.</li>
<li>LinkView&#8217;s active CP is <code>action.pending</code> || present day isActive</li>
<li><p>action will internally delegate to a shared transitionTo action
that everyone in the world can see; everyone can know where it&#8217;s
going, etc etc etc.</p>

<p><code>{{link-to action=myAction}}</code>
any reason for this? what do you gain? nothing?</p></li>
</ul>
</li>
</ul>


<p>We need to separate fake link font decoration style from the underlying
action.</p>

<p>Link&#8217;s display components:</p>

<pre><code>routeDescriptor: function() {
  // when resolvedParams change, we need to recalculate
  // our route object... this should refire only when
  // params change, not when the URL changes
  this.urlService.getRouteObject('articles', 1)


  this.urlService.createRouteDescriptor({
    routeName: alias('_linkView.params.firstObject'),
    contexts: alias('_linkView.contexts'),
    queryParams: alias('_linkView.queryParams'),
    _linkView: this
  });
}//.property('resolvedParams')

createRouteDescriptor: function(_attrs) {
  var attrs = {
    router: this.router, // or maybe just `this`?
  };
  Ember.merge(attrs, _attrs);
  return RouteDescriptor.createWithMixins(attrs);
}

RouteDescriptor = Ember.Object.extend({
  // required
  router: null,
  routeName: null,
  contexts: null,
  queryParams: null,

  allParams: computed('routeName', 'contexts', 'queryParams', function() {
    // this is just a perfy thing; since all calculations depend
    // on all these params, we'll avoid the overhead of multiple
    // CPs depending on each of these params
    return this.getProperties(['routeName', 'contexts', 'queryParams']);
  }),

  path: computed('router.url', 'allParams', function() {
    var allParams = this.get('allParams');
    var router = this.get('router');

    // presently we only use router.url as a cue that the router
    // is at a new route
    var url = this.get('router.url');

    // pass crap to routerJS
  }),

  perform: function() {
    // invoke, blah blah blah, same logic as in link to.
    this.get('allParams');
  }
});

service.getRouteDescriptor('articles', 1)

{
  action:   FCA,
  isActive: true,
  path: "/some/dynamic/thing"
}
</code></pre>

<p>RouteDescriptors are objects</p>

<ul>
<li>inactive: !routeObject.active</li>
<li>active:   routeObject.active</li>
<li>visited</li>
</ul>


<p>Weird thing: ember link-to&#8217;s concept of &#8220;active&#8221; doesn&#8217;t match with
<code>&lt;a&gt;</code> tag&#8217;s concept of active; link-to &#8216;active&#8217; means you&#8217;re currently
in the route specified by that link; <code>&lt;a&gt;</code> tag&#8217;s active means you&#8217;re
currently clicking this link.</p>

<p>I think I know how to refactor link-to and LinkView and all that</p>

<p>Goals</p>

<ul>
<li>make linking/routing/active calc logic shareable</li>
<li>make it possible to click a link to make it active before a slow
transition has completed.</li>
<li><p>support calculating activeness for bootstrap wrapper <code>&lt;li&gt;</code>s and
anything else in general too.</p>

<p>  {{#link-wrapper tagName=&#8221;li&#8221; |w|}}</p>

<pre><code>{{w.link-to "wat" 1 2 3 (query-params)}}
</code></pre>

<p>  {{/link-wrapper}}</p>

<p>  {{#link-to &#8216;articles&#8217; article.id |l|}}</p>

<pre><code>{{! providing block params kicks it into
    wrapper mode }}

&lt;li class="{{l.active}}"&gt;
  {{#l.tag}}
    {{article.title}}
  {{/l.tag}}
&lt;/li&gt;
</code></pre>

<p>  {{/link-to}}</p></li>
</ul>


<h2>RFCs</h2>

<p>Rust tempered it&#8217;s freewheeling feature additions by requiring RFCs.</p>

<p>https://github.com/rust-lang/rfcs/blob/master/active/0001-rfc-process.md
https://github.com/rust-lang/rfcs/blob/master/active/0039-lifetime-elision.md</p>

<p>Sounds like we&#8217;ll be doing this for Ember.</p>

<h2>Elide</h2>

<blockquote><p>omit (a sound or syllable) when speaking: (as adj. elided) : the indication of elided consonants or vowels.</p></blockquote>

<h2>Variadic</h2>

<p>http://en.wikipedia.org/wiki/Variadic_function</p>

<p>A function that is variadic has an indefinite number of arguments.
<code>.bind</code></p>

<blockquote><p>8:50 PM <spion> bind is variadic and I think it also has to do some stuff with constructors
8:51 PM <spion> (additional arguments can be used for partial application)
8:52 PM <spion> the constructor stuff: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/bind#Bound_functions_used_as_constructors
8:53 PM <spion> (creates significant additional overhead)
8:53 PM <spion> so a simple non-variadic closure implementation of bind has a lot less work to do :P</p></blockquote>

<h2>React forms</h2>

<p>https://github.com/wingspan/wingspan-forms</p>

<p>Powerded by KendoUI</p>

<h2>Reflux</h2>

<p>https://github.com/spoike/refluxjs</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>              
</span><span class='line'> Actions &gt; Stores &gt; View Components 
</span><span class='line'>              
</span><span class='line'>     ^                                      
</span><span class='line'>     </span></code></pre></td></tr></table></div></figure>


<p>Rationale: http://spoike.ghost.io/deconstructing-reactjss-flux/</p>

<h2>Promixo dedicated</h2>

<p>https://addons.heroku.com/proximo#dedicated</p>

<h2>CIDR: Classless Inter-Domain Routing</h2>

<p>http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing</p>

<p>Classful allocation of IP addresses (pre 1993) defined class A, B, C
network groups split along the 8 bit chunks. Problem is the smallest
allocation (256 addresses, assuming you were allocated something like
123.456.789.XXX) was often too small for companies, whereas the next
step up from that (123.456.XXX.XXX) was generally too huge (65536) for
companies/entities to efficiently take advantage of. SOLUTION: CIDR
blocks and subnet masks.</p>

<blockquote><p>This led to inefficiencies in address use as well as routing because the large number of allocated small (class-C) networks with individual route announcements, being geographically dispersed with little opportunity for route aggregation, created heavy demand on routing equipment.</p></blockquote>

<p>In other words, class C allocations are 123.456.789.XXX allocations,
each containing 256 addresses, with no requirement that they be
geographically grouped, such that routers had to maintain large tables
for very similar looking addresses rather than being able to rely on
some grouping rules to minimize the routing information they had to know
about. But now subnet masking is a thing and blah blah blah I&#8217;m done
learning this shit.</p>

<p>192.168.2.0/24 means that the network is identified by the first 24 bits</p>

<blockquote><p>192.168.100.0/24 represents the given IPv4 address and its associated routing prefix 192.168.100.0, or equivalently, its subnet mask 255.255.255.0 (i.e. 24 &#8220;1&#8221; bits).</p>

<p>the IPv4 block 192.168.100.0/22 represents the 1024 IPv4 addresses from 192.168.100.0 to 192.168.103.255.</p></blockquote>

<h2>TokenEx client-side encryption</h2>

<p>Original misconception:</p>

<ul>
<li>You post directly to TokenEx via AJAX, and they give you an encrypted
value that you can pass to your server and exchange for a token</li>
</ul>


<p>Correction:</p>

<ul>
<li>You only use JSEncrypt to encrypt the PAN via a public key.</li>
</ul>


<p>Wait, I don&#8217;t understand, with tokenizing, if you have a token saved in
the database, then your server, if compromised, could still send data
through to TokenEx, which would proxy it through to whomever.</p>

<h2>Form Factor</h2>

<p>https://www.pcisecuritystandards.org/documents/Mobile_Payment_Security_Guidelines_Merchants_v1.pdf</p>

<blockquote><p>The PCI Security Standards Council charter provides a forum for collaboration across the payment space
to develop security standards and guidance for the protection of payment card data wherever it may be
stored, processed, or transmittedregardless of the <em>form factor</em> or channel used for payment.</p></blockquote>

<p>the physical size and shape of a piece of computer hardware.</p>

<p>http://en.wikipedia.org/wiki/Mobile_phone_form_factor</p>

<p>or phone.</p>

<p>what a stupid fucking phrase/word/definition.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/02/daily-journal/"/>
    <updated>2014-08-02T21:24:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/02/daily-journal</id>
    <content type="html"><![CDATA[<h2>NPM is killing me</h2>

<p>Apparently this fixed everything.</p>

<pre><code>npm cache clear &amp;&amp; npm install
</code></pre>

<p>https://www.npmjs.org/doc/cli/npm-cache.html</p>

<p>npm caches everything in <code>npm config get cache</code>, which for me is:</p>

<pre><code>~/.npm
</code></pre>

<p>Folder structure is something like</p>

<pre><code>~/.npm/PACKAGE_NAME/VERSION/
</code></pre>

<p>which contains:</p>

<ul>
<li>.cache.json

<ul>
<li>lots of overlap w the project&#8217;s package.json, with additional
cache-specific things like</li>
<li>etag, shasum</li>
<li>deployment-specific data about the package</li>
</ul>
</li>
<li>package.tgz

<ul>
<li>the original tarball downloaded for this packaage</li>
</ul>
</li>
<li>package/

<ul>
<li>the unzipped tarball</li>
</ul>
</li>
</ul>


<p>In other words</p>

<blockquote><p>Additionally, whenever a registry request is made, a .cache.json file is placed at the corresponding URI, to store the ETag and the requested data. This is stored in {cache}/{hostname}/{path}/.cache.json.</p></blockquote>

<h2>Food Shit</h2>

<p>Pok Pok is a legit ass Thai place I need to check out.</p>

<pre><code>http://pokpokny.com/
</code></pre>

<h2><code>sed</code> to select lines</h2>

<pre><code>$ git branch
  cp-qp
* master
  new-doctitle
  setup-controller-qp
</code></pre>

<p>I wanted to switch to the fourth one without typing
<code>setup-controller-qp</code>. Here&#8217;s how you could do it by using the line
number</p>

<pre><code>$ git branch | sed -n '4p' | xargs git checkout
Switched to branch 'setup-controller-qp'
</code></pre>

<p>Obviously this is just a dumb exercise since it&#8217;s waaay more typing.
This is me practicing.</p>

<p>You can also display multiple lines using a syntax similiar to cut&#8217;s
<code>-f1,2</code> syntax:</p>

<pre><code>$ git branch | sed -n '3,4p' 
  new-doctitle
  setup-controller-qp
</code></pre>

<h2>commissary</h2>

<p>From Orange is the New Black</p>

<blockquote><p>commissary: a restaurant in a movie studio, military base, prison, or other institution.</p></blockquote>

<h2>HRT</h2>

<p><a href="http://en.wikipedia.org/wiki/Hormone_replacement_therapy">Hormone replacement therapy</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/29/daily-journal/"/>
    <updated>2014-07-29T07:50:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/29/daily-journal</id>
    <content type="html"><![CDATA[<h2>tar</h2>

<p>Short for Tape Archives.</p>

<p>Had a tar.xz file, just needed to</p>

<pre><code>tar xf thefile.tar.xz
</code></pre>

<h2>Dexing</h2>

<p>Convert string names to numbers to be referenced within compiled Java
whilst packaging android apps.</p>

<h2>Good Food</h2>

<p>Prince St Cafe on Prince and Mott.</p>

<ul>
<li>Awesome burger</li>
<li>Awesome lamb thing</li>
</ul>


<h2>ls -l</h2>

<p>Was curious about an <code>@</code> sign I saw next to a .txt file, from <code>ls(1)</code>:</p>

<blockquote><p>The Long Format</p>

<pre><code>If the -l option is given, the following information is displayed for
each file: file mode, number of links, owner name, group name, number
of bytes in the file, abbreviated month, day-of-month file was last
modified, hour file last modified, minute file last modified, and the
pathname.  In addition, for each directory whose contents are dis-
played, the total number of 512-byte blocks used by the files in the
directory is displayed on a line by itself, immediately before the
information for the files in the directory.  If the file or directory
has extended attributes, the permissions field printed by the -l
option is followed by a '@' character.  Otherwise, if the file or
directory has extended security information (such as an access control
list), the permissions field printed by the -l option is followed by a
'+' character.
</code></pre></blockquote>

<ul>
<li><code>@</code> extended attributes</li>
<li><code>+</code> extended security info</li>
</ul>


<h2>Interrupted System Call</h2>

<p>http://infohost.nmt.edu/~eweiss/222_book/222_book/0201433079/ch10lev1sec5.html</p>

<p>I&#8217;m getting some shit about foreman and interrupted system calls. So
what is it.</p>

<h2>&#8220;data at the edge&#8221;</h2>

<p>Keeping secure data at the edge of your infrastructure, e.g. using
tokens instead of storing CC&#8217;s in your db.</p>

<h2>PAN (primary account number)</h2>

<p>Bank card number.</p>

<p>http://en.wikipedia.org/wiki/Primary_account_number</p>

<h2>CP (card present)</h2>

<p>e.g AuthorizeNetCP</p>

<p>Cheaper rates if you can prove card present (via CVV).</p>

<h2>TokenEx</h2>

<p>ProcessTransaction</p>

<p>ProcessTransactionWithPAN</p>

<ul>
<li>pass in all the CC data; no</li>
</ul>


<h2>Levenshtein Distance</h2>

<p>The minimum number of single-element operations (add, remove,
substitute) between two sequences. Often used for spell-checking
suggestions.</p>

<p>I was thinking of using it to do an array diffing for React-ish stuff.</p>

<pre><code>Array 1: B C D E F
Array 2: A B C D E
</code></pre>

<p>Clearly the answer to how to get from 1 to 2 is</p>

<pre><code>shift A
delete E
</code></pre>

<p>But how to programmatically detect that?</p>

<h2>Ruby String Substring Shorthand</h2>

<p>https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<p>I can&#8217;t believe I didn&#8217;t know this&#8230;</p>

<pre><code>s = "alex is quite maudlin"
s['quite'] = 'very'
s =&gt; "alex is very maudlin"
</code></pre>

<p>and if the substring isn&#8217;t in there, then</p>

<pre><code>IndexError: string not matched
</code></pre>

<p>http://www.ruby-doc.org/core-2.1.2/String.html#method-i-5B-5D-3D</p>

<h2>JRuby the Hard Parts</h2>

<p>Goal: understand this talk https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<h2>Learn about encodings</h2>

<p>I had to resort to this shit:</p>

<pre><code>line = line.force_encoding("iso-8859-1")
</code></pre>

<p>for a bigass file because I was running into</p>

<pre><code>http://stackoverflow.com/questions/15399530/ruby-match-invalid-byte-sequence-in-utf-8
</code></pre>

<p>Apparently you can open files as a certain encoding. Seems good.</p>

<h2>Auto-inline CSS with Roadie</h2>

<p>https://github.com/Mange/roadie</p>

<p>Useful for supporting a vast array of shitty email clients that require
inline CSS. This wouldn&#8217;t be a problem if web components.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal 2]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal-2/"/>
    <updated>2014-07-28T20:43:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal-2</id>
    <content type="html"><![CDATA[<h2>User and Kernel</h2>

<p>http://blog.codinghorror.com/understanding-user-and-kernel-mode/</p>

<p>Non-idle tasks.</p>

<p>The CPU graph is tasty. Red means kernel.</p>

<p>CPU hardware knows all about kernels n shit. It isn&#8217;t just a software
divide. CPU instructions and certain memory locations can only be
accessed by the kernel, enforced by hardware. User mode makes it so that
only the app crashes, not the entire system.</p>

<p>http://en.wikipedia.org/wiki/Ring_(computer_security)</p>

<p>Interesrserseting.</p>

<p>x86 CPU hardware:</p>

<ul>
<li>0 is kernel</li>
<li>3 is user</li>
</ul>


<p>1 and 2 are device drivers but they&#8217;re not often used. On Windows,
device drivers can be user or kernel mode, mostly to the user, but video
cards are often kernel level since they so perfy. In Vista+, the Windows
Driver Display Model is such that only kernel mode is used for executing
the GPU commands, but the translation from API to GPU now takes place in
userland.</p>

<p>Exceptions fire in kernel land I guess? Sometimes?</p>

<h2>Old Foreman Orphans Sidekiq</h2>

<p>After lots of starts/stops of foreman, I noticed lots of sidekiq
instances with ppid 1. They was orphans. I killed em.</p>

<h2>fspawn</h2>

<p>Refers to the fork+exec approach to spawning a process.</p>

<h2>Daemons</h2>

<p>https://github.com/ghazel/daemons</p>

<p>Library of fun little trinkets.</p>

<ul>
<li>given some-server.rb, let&#8217;s you write a some-server-control.rb</li>
<li>inline the server inside such a daemon (you can still run it
without forking via <code>run</code> command)</li>
<li>manage multiple daemons</li>
<li>Ability to take existing server and daemonize it; you do lose control
over the daemon unless you&#8217;re a <code>ps</code>/<code>kill</code> JOURNEYMAN.

<ul>
<li>this takes advantage of the <code>fork</code> <code>getsid</code></li>
</ul>
</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons.rb#L45-L53</p>

<pre><code># 1.  Forks a child (and exits the parent process, if needed)
# 2.  Becomes a session leader (which detaches the program from
#     the controlling terminal).
# 3.  Forks another child process and exits first child. This prevents
#     the potential of acquiring a controlling terminal.
# 4.  Changes the current working directory to "/".
# 5.  Clears the file creation mask (sets +umask+ to 0000).
# 6.  Closes file descriptors (reopens +STDOUT+ and +STDERR+ to point to a logfile if
#     possible).
</code></pre>

<p>Controlling terminal:</p>

<p>http://www.gnu.org/software/libc/manual/html_node/Controlling-Terminal.html</p>

<blockquote><p>An individual process disconnects from its controlling terminal when it calls setsid to become the leader of a new session.</p></blockquote>

<p>Ah I get it:</p>

<ul>
<li>first fork is to orphan the child, but it&#8217;s still connected to a
controlling terminal/session.</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L201</p>

<p>They actually loop through all known IO files to close file
descriptors using ObjectSpace:</p>

<p>http://www.ruby-doc.org/core-2.1.2/ObjectSpace.html</p>

<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L221</p>

<p>That&#8217;s pretty rad. I guess the GC uses it too.</p>

<h2>.pid file</h2>

<p>It&#8217;s a file in a well known location that contains only the pid of
some running process, usually a daemon. Useful because daemons are often
hard to detect, kinda look like forgotten orphan processes, and there
might be multiple similar ones. But pid files let you look up the pid of
the running process so that you can send it signals.</p>

<h2><code>$0</code> or <code>$PROGRAM_NAME</code></h2>

<p>If you run this script</p>

<pre><code>fork {
  $PROGRAM_NAME = "WAT"
  sleep
}
</code></pre>

<p>then <code>ps | grep WOOT</code> yields</p>

<pre><code>62724 ttys022    0:00.00 WOOT
</code></pre>

<p>Woot wat wat wotasoasdas lol.</p>

<h2><code>pidof</code></h2>

<pre><code>brew install pidof

$ pidof bash
754 1246 1748 2308 2498 5380 20397 23552 26224 26973 48454 79258 81847 5226 5346 5443 5851 10659 25008 26375 27009 52684 88768 88882 18853 19116 19246 20275 20476 21364 43211 52269 52390 52637 54869 54974 58037 58950 59080
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal/"/>
    <updated>2014-07-28T08:16:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal</id>
    <content type="html"><![CDATA[<h2>Them processes</h2>

<p>Kernel</p>

<!--more-->


<ul>
<li>sits on top of hardware, doing things like

<ul>
<li>read/write from filesystem</li>
<li>sending/receiving network data</li>
<li>playing audio</li>
</ul>
</li>
<li>programs don&#8217;t have access to this stuff, only the kernel</li>
</ul>


<p>System call is the barrier b/w userland and kernel.</p>

<p>What about memory? I think userland can read memory.</p>

<p>Common man pages for FreeBSD or Linux</p>

<p><code>wat(2)</code> means section 2 of manual, wat: <code>man 2 wat</code></p>

<p>Can&#8217;t execute code without a process.</p>

<p><code>Process.pid == $$</code> global var in Ruby, from Perl/bash, but
<code>Process.pid</code> is way more obvious, duh.</p>

<p>Processes have parents, identified via <code>ppid</code>, <code>Process.ppid</code>, but not
super often used.</p>

<p>In Unixland, everything is a file.</p>

<p>When opening resources, you&#8217;re given a file descriptor number, unique to
your process, unshareable with unrelated processes. These resources are
closed when you exit process, cept forking.</p>

<p>All Ruby <code>IO</code> objects have a <code>fileno</code>, e.g.</p>

<pre><code>2.0.0-p353 :007 &gt; $stdin.fileno
 =&gt; 0
2.0.0-p353 :007 &gt; $stdout.fileno
 =&gt; 1
2.0.0-p353 :008 &gt; $stderr.fileno
 =&gt; 2
</code></pre>

<p>File descriptors are assigned lowest unused value, and are reusable when
old file handlers are closed.</p>

<p>Streams are lovely, before them, each program had to explicitly handle
different keyboard types, etc, but the stream abstraction unified all of
that.</p>

<p><code>fsync</code> flushes file descriptor state to disk, but disk might reorder
writes. The <code>F_FULLFSYNC</code> will ask the drive to write it immediately and
preserve order, useful for things like databases, see <code>fsync</code></p>

<pre><code> For applications that require tighter guarantees about the integrity of their
 data, Mac OS X provides the F_FULLFSYNC fcntl.  The F_FULLFSYNC fcntl asks the
 drive to flush all buffered data to permanent storage.  Applications, such as
 databases, that require a strict ordering of writes should use F_FULLFSYNC to
 ensure that their data is written in the order they expect.  Please see fcntl(2)
 for more detail.
</code></pre>

<p><code>F_FULLFSYNC</code> probably isn&#8217;t available on everything, possibly mac only.</p>

<p>To find the limit of file descriptors you can do <code>Process.getrlimit(:NOFILE)</code></p>

<p>This translates to <code>getrlimit(2)</code>, control max system resource
consumption. <code>r</code> is resource, <code>NOFILE</code> means &#8220;The maximum number of open
files for this process&#8221;.</p>

<pre><code>2.0.0-p353 :001 &gt; Process.getrlimit(:NOFILE)
 =&gt; [2048, 2048]
    #soft, hard
</code></pre>

<p>Soft means an exception will raise but you can reconfigure. Hard limit
might be reconfigurable by superuser, or if the process has permissions.</p>

<p><code>sysctl</code> lets you get or set kernel state, useful for configuring
system-wide kernel details.</p>

<p><code>EMFILE</code> is too many files open. Testable via</p>

<pre><code>machty.github.com :: ruby -e "Process.setrlimit(:NOFILE, 3); File.open('/dev/null')"
-e:1:in `initialize': Too many open files - /dev/null (Errno::EMFILE)
</code></pre>

<p><code>ulimit</code> is a built in command to control resource usage for this shelll
and any of its children. It&#8217;s different from system wide <code>sysctl</code> stuff.
I can change the result above</p>

<p>So I remember <code>ulimit</code> resets the soft limit. If I set to 2046, then</p>

<pre><code>machty.github.com :: ruby -e "puts Process.getrlimit(:NOFILE)"
2046
2046
</code></pre>

<blockquote><p>(Built-in command) In computing, a shell builtin is a command or a function, called from a shell, that is executed directly in the shell itself, instead of an external executable program which the shell would load and execute. ..</p></blockquote>

<p>Use cases for overriding limits</p>

<ul>
<li>stress-testing utilities (e.g. 5000 simultaneous connections)</li>
<li>limiting resources for 3rd party stuff, removing permissions to change</li>
</ul>


<p>Environment is nothing more than Env vars, key values pairs.
Set by parent, inherited by children.</p>

<pre><code>machty.github.com :: A=lol ruby -e "puts ENV['A']"
lol
</code></pre>

<p>Note that env var assignment on its own shell line sets them for the
rest of the process, but followed by a command only sets them for that
command.</p>

<p>Process names are changeable, e.g. <code>$PROCESS_NAME = "fuckles"</code></p>

<pre><code>  PID TTY           TIME CMD
45874 ttys011    0:00.68 fuckles
</code></pre>

<p>Note that TIME is CPU time.</p>

<p>Ah, <code>time</code> makes sense to me now:</p>

<pre><code>machty.github.com :: time sleep 1

real    0m1.012s
user    0m0.001s
sys     0m0.003s
</code></pre>

<p><code>sleep</code> suspends execution thread, consuming no CPU. I think <code>sys</code> means
system call time, such as telling the pthread to sleep. IT IS ALL MAKING
SENSE.</p>

<p>Processes have exit codes, 0 is successful.</p>

<p>All the ways to exit</p>

<ul>
<li>exit, <code>Kernel#exit</code>, exits w 0 by default but you can pass a code,
runs <code>Kernel#at_exit</code> blocks. <code>exit!</code> does a code 1 and doesn&#8217;t run
exit blocks.</li>
<li>abort accepts a string in ruby, runs exit handlers, returns 1</li>
<li>raised exceptions yield exit code 1 and still raise things.</li>
</ul>


<p>Processes can fork, unless you&#8217;re JRuby. That means Unicorn won&#8217;t work
for JRuby.</p>

<p>Forking copies all memory (or copy on write). File descriptors are also
provided to forked thinger.</p>

<pre><code>2.0.0-p353 :016 &gt; fork { puts Process.pid; puts Process.ppid}
 =&gt; 46054
2.0.0-p353 :017 &gt; 46054
45874
2.0.0-p353 :018 &gt;   Process.pid
 =&gt; 45874
</code></pre>

<p>Parent and child can share file descriptors, open files, sockets, etc.
Because forking is faster than booting up fresh copies of servers&#8230; it
is good&#8230;?</p>

<p>Awesome example:</p>

<pre><code>if fork
  puts "YES"
else
  puts "NO"
end
</code></pre>

<p>Hahaha, don&#8217;t run this in irb though, because you&#8217;ll have two processes
reading from the same $stdin, e.g. your keyboard.</p>

<p>Blockless <code>fork</code> returns twice</p>

<ul>
<li>parent gets child pid</li>
<li>child gets nil</li>
</ul>


<p>Explains this output</p>

<pre><code>ruby -e "cid=fork; puts cid || 'none'"
46650
none
</code></pre>

<p>What about threads? Do thread ids change after forking?</p>

<pre><code>machty.github.com :: ruby -e "puts Thread.current; fork; puts Thread.current"
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
</code></pre>

<p>No it seems they don&#8217;t&#8230; forking really makes everything seem totally
the same. I wonder how that works at the pthread level.</p>

<p>http://pubs.opengroup.org/onlinepubs/009695399/functions/fork.html</p>

<blockquote><p>A process shall be created with a single thread. If a multi-threaded process calls fork(), the new process shall contain a replica of the calling thread and its entire address space, possibly including the states of mutexes and other resources. Consequently, to avoid errors, the child process may only execute async-signal-safe operations until such time as one of the exec functions is called. [THR] [Option Start]  Fork handlers may be established by means of the pthread_atfork() function in order to maintain application invariants across fork() calls.</p></blockquote>

<p>So only a single thread is created, and the kernel knows it&#8217;s a separate
thread, but the forked instance still thinks the address of that thread
is the same as before, even though it&#8217;s obviously a different thread.</p>

<p>Forking allows (but doesn&#8217;t guarantee) a process to run on multiple
cores. If the system is busy the forked processes might all run on the
same CPU.</p>

<p>Forking duplicates memory (assuming no copy-on-write; TODO: learn the
terminology for total memory vs not-yet-copied-on-write memory).
Running out of memory due to over-forking is called a fork bomb.</p>

<p>Forking means orphaning if the parent process finishes before children.</p>

<p>Daemon processes are intentionally orphaned so that they can stay
running forever. Orphaned children can be communicated with via signals.</p>

<p>Fork-and-forget vs remembering child process. <code>Process.wait</code> will wait
for ONE child process to terminate before quitting, and returns the pid
of the child process that terminates. Spawn 3 processes, must wait three
times. <code>wait2</code> returns <code>[pid, status]</code>, so you can get codes n shit.
<code>waitpid</code> and <code>waitpid2</code> wait on specific pids. But they are aliased to
the same thing: `wait</p>

<p>The kernel queues child process return info so that waiting on a process
that has already did will return its shit. That said, waiting on
non-existent children raises <code>ECHILD</code>.</p>

<p>Unicorn forks N times, makes sure the processes are still alive,
restarts if necessary, etc.</p>

<p>If you don&#8217;t do <code>Process.wait</code> though, the kernel will keep on storing
information about exit codes, etc. You either need to <code>wait</code> or <code>detach</code>,
or else you get a zombie process.</p>

<p>http://en.wikipedia.org/wiki/Zombie_process</p>

<p>A Zombie process is a process that has called exit but whose parent
hasn&#8217;t called <code>wait</code> or <code>detach</code>.</p>

<ul>
<li>Zombie: un-reaped, terminated child process</li>
<li>Orphan: still active child process whose parent has died.</li>
</ul>


<p>Orphans get attached to <code>init</code> (or <code>launchd</code> in OS X land), which has a
pid of 1.</p>

<p>Oh man, fork bombs are hilarious: http://en.wikipedia.org/wiki/Fork_bomb</p>

<p>So ppid actually automatically updates:</p>

<pre><code>fork do
  loop do
    puts "(#{Process.pid}, #{Process.ppid})"
    sleep 1
  end
end

sleep 1

abort "k i'm done #{Process.pid}"
</code></pre>

<p>Output:</p>

<pre><code>(47598, 47597)
(47598, 47597)
k i'm done 47597
(47598, 1)
(47598, 1)
</code></pre>

<p>Pretty cool.</p>

<p>Also if you <code>brew install pstree</code> and take a look at that, pid 1 is
<code>launchd</code>.</p>

<p>You can check the status of process and how it changes into a zombie and
then when it gets removed from the process table when we call
<code>Process.wait</code>:</p>

<pre><code>cpid = fork {}
puts `ps -p #{cpid} -o state`
sleep 1
puts `ps -p #{cpid} -o state`
Process.wait
puts `ps -p #{cpid} -o state`
</code></pre>

<p>Yields:</p>

<pre><code>STAT
R+
STAT
Z+
STAT
</code></pre>

<p>Note the last STAT is empty because no such pid; shit is dead.
The <code>+</code> means process is in the foreground process group of its control
terminal.</p>

<p>Note that no memory is allocated to the zombie process itself; just the
slot in the process table is used; zombie processes prevent other
processes from taking their place and reusing their PID. Which is
another thing: a parent process might not want a child pid to be reused
when creating a child pid, so it&#8217;ll create the new child, and THEN
<code>wait</code>/<code>detach</code> on original.</p>

<p><code>Process.detach</code> spins up a thread to <code>wait</code> on a process. Here&#8217;s a
really roundabout way to detach and then wait and get the return value:</p>

<pre><code>t = Process.detach(cpid)
puts `ps -p #{cpid} -o state`
puts t.value
</code></pre>

<p><code>t.join</code> before a <code>t.value</code> is a noop; <code>value</code> must always <code>join</code> in
order to get the value.</p>

<p>Fork-and-forget is rare. <code>Process.detach</code> has no system call equiv; it&#8217;s
just a ruby convenience.</p>

<p>SIGCHLD fires when a child process exits. You can trap it and <code>wait</code> for
that process to finish. Problem is, signal delivery is unreliable; if
you&#8217;re handling a signal and another one comes in, you might not receive
that signal. Solution is to pass a second param to <code>wait</code> to describe
how the kernel should wait for this thing, e.g. <code>Process::WNOHANG</code></p>

<p>Shit is so messy</p>

<pre><code>Process.trap(:CHLD) do
  nil while Process.wait(-1, Process::WNOHANG) rescue Errno::ECHILD
end
</code></pre>

<p>Yes you could unravel but come on.</p>

<p>Signals are async, ignorable, actionable, defaultable. Processes use the
kernel to as an intermediary to send messages.</p>

<pre><code>echo "puts 'lol'" | ruby
</code></pre>

<p>Who knew? It accepts input from stdin. So you can pipe Ruby code to it.
Ctrl-C sends an interrupt. You can trap it and ignore. You can also say
<code>trap(:INT, "IGNORE")</code></p>

<p>It&#8217;s good form in lib code to define a trap, though it&#8217;s possibly to
preserve other people&#8217;s callbacks and call them in yours. But you can&#8217;t
restore default behavior. This is fine if your&#8217;e writing a server
though.</p>

<blockquote><p>USR2 - reexecute the running binary. A separate QUIT should be sent to the original process once the child is verified to be up and running.</p></blockquote>

<p>https://github.com/ice799/memprof does some cool stuff with trapping
signals, printing out useful shits.</p>

<p>This guy is boundlessly smart.</p>

<p>Make a pipe, give someone one end to yell into and the other person the
put their ear up to it. Methinks you see where this is going.</p>

<p>Source and Sink, Writer and Reader. Pipe persists until all associated
descriptors are closed. Half-closed pipes are &#8220;widowed&#8221;. Writing to a
widowed pipe yields <code>SIGPIPE</code>, but widowing it is how the reader gets an
EOF signal. <code>SIGPIPE</code> can be disabled via F_SETNOSIGPIPE in fcntl, which
we saw above in this journal for telling a hard drive to actually
preserve write order.</p>

<p>In Ruby you can pass an encoding which tags the read input with that
encoding.</p>

<p>http://ruby-doc.org/core-2.0/IO.html#method-c-pipe</p>

<pre><code>rd, wr = IO.pipe

if fork
  wr.close # REQUIRED
  puts "Parent got: &lt;#{rd.read}&gt;"
  rd.close
  Process.wait
else
  rd.close # REQUIRED
  puts "Sending message to parent"
  wr.write "Hi Dad"
  wr.close
end
</code></pre>

<p>The <code># REQUIRED</code> closes are there because otherwise the data won&#8217;t
flush, EOF&#8217;s won&#8217;t be called.</p>

<p>So that&#8217;s a neat little primitive, but how is it different than just
using a StringIO? Well, aside from the fact that I don&#8217;t think you can
just progressively write into StringIO as you read from it (maybe you
can), Pipe goes through the kernel; there&#8217;s system calls and overhead.
Check this bitchin benchmark:</p>

<pre><code>require 'benchmark'
require 'stringio'

n = 100000
Benchmark.bm do |x|
  x.report("pipes:") {
    n.times do
      rd, wr = IO.pipe
      wr.write "HELLO"
      wr.close
      raise "wat" unless rd.read == "HELLO"
      rd.close
    end
  }

  x.report("StringIO") {
    n.times do
      s = StringIO.new("HELLO")
      raise "wat" unless s.read == "HELLO"
      s.close
    end
  }
end
</code></pre>

<p>yields</p>

<pre><code>              user     system      total        real
  pipes:  0.630000   0.730000   1.360000 (  1.363994)
StringIO  0.080000   0.000000   0.080000 (  0.077973)
</code></pre>

<p>This is skewed by the fact that you&#8217;re not going to be creating and
dumping pipes all the time, but it just highlights the inner workings of
Pipe: because it involves syscalls, much of the time is spent in
<code>system</code>.</p>

<p>With streams (pipes/TCP sockets), you write to a stream followed by a
delimiter. Newline is the delimiter. Unix sockets are intra machine, and
fast.</p>

<p>Use sockets to communicate in datagrams vs delimited stream chunks. You
still have pairs, but rather than read/write pairs, you just have
bidirectional shits, one of which needs to get closed per process.
Sockets are bidirectional!</p>

<p>http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or
http://wiki.secondlife.com/wiki/Message_Queue_Evaluation_Notes</p>

<p>From http://www.ruby-doc.org/core-2.1.0/IO.html</p>

<blockquote><p>In the example below, the two processes close the ends of the pipe that they are not using. This is not just a cosmetic nicety. The read end of a pipe will not generate an end of file condition if there are any writers with the pipe still open. In the case of the parent process, the rd.read will never return if it does not first issue a wr.close.</p></blockquote>

<p>Fuckles and shittles.</p>

<pre><code>man socketpair
</code></pre>

<p>Thom Ass Tover says:</p>

<p>http://www.thomasstover.com/uds.html</p>

<p>So these sockets are Unix Domain Sockets, or local sockets.</p>

<p>Pipes</p>

<ul>
<li>can be given a name</li>
<li>writing to a full one yields <code>SIGSTOP</code></li>
<li>are faster than Unix domain sockets</li>
<li>require context switches w kernel to use read/write</li>
</ul>


<p>Solaris pipes are special in that they are full duplex, where as on
Linux and BSD you&#8217;d need two pipes for full duplex. fifos are named
pipes. I guess they&#8217;re like files.</p>

<p>http://en.wikipedia.org/wiki/Named_pipe</p>

<p>wow:</p>

<pre><code>mkfifo my_pipe
gzip -9 -c &lt; my_pipe &gt; out.gz &amp;
</code></pre>

<p>So, Matt Daemon.</p>

<p><code>init</code> or <code>launchd</code> has ppid 0 and pid 1.</p>

<p><code>exit if fork</code> will fork and close the parent process.</p>

<p><code>Process.setsid</code> creates a new session. It talks about a process groups
and what not. If you call it, your process becomes</p>

<ul>
<li>session leader of new session</li>
<li>process group leader of new process group</li>
<li>and has no controlling terminal</li>
<li>and becomes the only new thing in the thing</li>
</ul>


<p>returns the new process group ID.</p>

<p>Job control is the way processes are managed by terminal. Process group
id is generally same as process ID. Fork and the process group id will
be the same. If they fork and so on then yeah yeah yeah this is how you
know they all came from the same shit. When you do <code>irb</code> in a terminal
it&#8217;ll set the process group to the pid of the command you run.</p>

<p>This is why interrupting a Ruby script that&#8217;s shelled out to thing will
kill all the things if it gets an interrupt; if it&#8217;s still alive, it&#8217;ll
kill children. It&#8217;s only upon normal exiting that you lose
thisetoisjdoiasj.</p>

<p>Session groups are higher up, a collection of process groups. One
session group: <code>echo "lol" | echo "lol"</code>. EPERM fires if you are already
leader (can only call w children).</p>

<p>Look at http://rubygems.org/gems/daemons</p>

<p><code>exec</code> totally transforms your shit, better fork first.</p>

<pre><code>Thread.new {
  sleep 2
  puts "THIS WILL NEVER PRINT"
}
Thread.new {
  sleep 1
  exec 'ls'
}
</code></pre>

<p>It entirely nukes your process context, including any outstanding
threads. You must escape via a fork.</p>

<p>Ruby&#8217;s <code>exec</code> will close file handles, database connections, etc, before
passing control to the new shit, though native <code>exec</code> calls would leave
them open. Sensible default given <code>echo</code> doesn&#8217;t care about your
database. You might accidentally exec another process that doesn&#8217;t do
anything with a db connection, and it never totally closes. But you can
override this default if you want to pass the fileno to the new process
and keep open that handle when it opens it for reading.</p>

<p>Unlike fork, no memory is shared with the resulting process of an exec.</p>

<p>I am so tired.</p>

<p><code>system</code> returns a true or false. Output barfs to stdout.</p>

<p><code>popen</code> opens a bi-directional pipe; you can write to and read from the
process spawned</p>

<p><code>popen3</code> gives you access to all 3.</p>

<p>Forking means a copy of all the parent process&#8217;s context before
<code>exec</code>-ing something super small like <code>ls</code>, but you can use gems that
wrap <code>posix_spawn(2)</code></p>

<p>https://github.com/rtomayko/posix-spawn</p>

<p>Also check out <code>man vfork</code> for virtual memory friendly forking.</p>

<p>Resque forks for memory management; bloating Ruby tasks tend not to
shrink, so fork makes it possible for forked workers to bloat and
disappear.</p>

<p>http://rubydoc.info/github/defunkt/resque/Resque/Worker</p>

<blockquote><p>A Resque Worker processes jobs. On platforms that support fork(2), the worker will fork off a child to process each job. This ensures a clean slate when beginning the next job and cuts down on gradual memory growth as well as low level failures.</p>

<p>It also ensures workers are always listening to signals from you, their master, and can react accordingly.</p></blockquote>

<p>Preforking, is it cool. haidjasoidjasiodj</p>

<p>What&#8217;s the rules on writing to stdout between multiple processes.
You can do it; there&#8217;s not going to be thread-unsafety, i don&#8217;t think.</p>

<p>http://stackoverflow.com/questions/1326067/how-to-lock-io-shared-by-fork-in-ruby</p>

<p>Preforking has load balancing wins similar to message queuing with
multiple consumers; when a consumer is ready, it just listens for the
same thing. A socket is shared b/w forked processes, and kernel makes
sure only one gets it</p>

<p>I need to understand more about $stdout and buffering and what not. It&#8217;s
not thread safe, but process-safe? syscall-safe?</p>

<ul>
<li>fork-safe if the action in question fits within a single syscall</li>
</ul>


<p>I have no fucking IDEA MY BRAIN IS DEAD.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/26/daily-journal/"/>
    <updated>2014-07-26T15:10:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/26/daily-journal</id>
    <content type="html"><![CDATA[<h2>top</h2>

<blockquote><p>display and update sorted information about processes</p></blockquote>

<p><code>top</code> will display a sampled, updating list of processes, ordered by pid
by default. Order by cpu:</p>

<pre><code>top -o cpu
</code></pre>

<p>Filter by a pid</p>

<pre><code>top -pid 12345
</code></pre>

<p>Show a single sample of the pid and thread number for a given pid</p>

<pre><code>top -l1 -pid 1234 -stats pid,th
</code></pre>

<h2>Spawn 50 ruby threads&#8230;</h2>

<p>and you wind up w 52: <code>Thread.main</code> + the 50 you created + Ruby
housekeeping thread (listening for OS signals and piping them
synchronously to main thread).</p>

<p>Ruby creates legit OS threads, vs <code>_____</code> threads, whatever the
terminology is for threads that live entirely in the code.</p>

<h2>Thread#join</h2>

<p>Yes, you have to call it on a spawned thread so that the main thread
will wait on it before prematurely exiting. But did you know that
exceptions thrown in a spawned thread get re-raised on the main thread
if you do <code>.join</code>?</p>

<p><code>Thread#value</code> joins and returns the last value of the thread.</p>

<p><code>Thread#status</code> returns status for live, dead, erroed, dying threads.</p>

<p><code>Thread.stop</code> puts the thread to sleep and it won&#8217;t wake up until
someone calls <code>wakeup</code> on it</p>

<p><code>Thread.pass</code> hints the OS to schedule another thread, but this may be
ignored by the scheduler.</p>

<p><code>Thread#raise</code> lets you externally fire exceptions within another thread
but should not be used because <code>ensure</code> is busted. <code>Thread#kill</code> does
what you expect but should also be aborted for the same reasons.</p>

<p>Multiple threads mean concurrency; they <em>might</em> mean parallelism. One
CPU switching b/w threads means concurrency but not parallelism;
multiple cores means paralleilism if they&#8217;re both executing.</p>

<p>Code can&#8217;t be parallel, only concurrent. The executation of concurrent
code can be parallel if the scheduler so chooses.</p>

<h2>golang concurrency vs parallelism</h2>

<p>http://concur.rspace.googlecode.com/hg/talk/concur.html#slide-2</p>

<p>Concurrency is defined as:</p>

<blockquote><p>Programming as the composition of independently executing processes</p></blockquote>

<p>not Linux processes, but rather the famously harder to define Process.</p>

<p>Parallelism is</p>

<blockquote><p>Programming as the simultaneous execution of (possibly related) computations.</p>

<p>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable</p></blockquote>

<p>Concurrency facilitates but doesn&#8217;t guarantee parallelism.</p>

<p>Goroutines aren&#8217;t threads; they&#8217;re similar but cheaper, won&#8217;t block
other goroutines, and multiplexed onto OS threads as necessary.</p>

<p>Synchronize via channels. I guess this is like Ruby Queue? Sounds like
you&#8217;d never do someGoroutine.value but rather use the channel primitive.</p>

<h2>ruby concurrency and you</h2>

<p>https://blog.engineyard.com/2011/ruby-concurrency-and-you</p>

<p>Green threads</p>

<ul>
<li>scheduled by VM, rather than underlying OS</li>
<li>pre 1.9 Ruby was this way (MRI)</li>
<li>managed in user space rather than kernel space</li>
</ul>


<p>Test: if i run Ruby 1.8.7 and do a top of new threads, I would expect
the thread count to be only whatever I started with.</p>

<p>BEHOLD, on 1.8.7:</p>

<pre><code>PID    #TH
84752  1
</code></pre>

<p>So old ruby didn&#8217;t even spawn another thread for housekeeping&#8230; I guess
maybe it wasn&#8217;t necessary because it didn&#8217;t have to coordinate the
signals landing at any random currently-active thread? Pretty cool.</p>

<p>I guess green threads are easy to implement in any interpreted language:
in the main loop of the interpreter you can just check if 100ms has gone
by and then move to another other known threads.</p>

<p>Early Java had green threads&#8230; I don&#8217;t know enough about Java to
comment here.</p>

<p>Ruby &lt;1.9 was smart enough to know when one of these threads was blocked
on external data so that it could &#8220;sleep&#8221; until the data arrived:</p>

<blockquote><p>MRI 1.8.7 is quite smart, and knows that when a Thread is waiting for some external event (such as a browser to send an HTTP request), the Thread can be put to sleep and be woken up when data is detected.</p></blockquote>

<p>1.9 uses native threads, but there&#8217;s still a GIL because the non-Ruby
parts of MRI 1.9 aren&#8217;t thread-safe.</p>

<p>MRI 1.9 uses the same technique as MRI 1.8 to improve the situation,
namely the GIL is released if a Thread is waiting on an external
event (normally IO) which improves responsiveness.</p>

<p>Great read:</p>

<p>http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/</p>

<p>Threads are hard, but requests are an extremely clean concurrency
primitive: controllers and the models loaded and views rendered, etc.,
are not shared between threads that are processing requests. It&#8217;s only
if you start using global state that problems arise, but why are you
doing that?</p>

<p>Why the Ruby/Rails thread FUD?</p>

<ul>
<li>Early Rails wasn&#8217;t threadsafe; essentially a mutex around each request</li>
<li>Mongrel explicitly mutexed around its Rails adapter, so even when
<code>threadsafe!</code> was added, you&#8217;d still have zero concurrency in mongrel.</li>
</ul>


<blockquote><p>For safety, Ruby does not allow a context switch while in C code unless the C code explicitly tells the VM that its ok to do so.</p></blockquote>

<p>And mysql was poorly written in this case. So mysql would block.</p>

<blockquote><p>A lot of people talk about the GIL (global interpreter lock) in Ruby 1.9 as a death knell for concurrency. For the uninitiated, the GIL disallows multiple CPU cores from running Ruby code simultaneously. That does mean that youll need one Ruby process (or thereabouts) per CPU core, but it also means that if your multithreaded code is running correctly, you should need only one process per CPU core. Ive heard tales of six or more processes per core. Since its possible to fully utilize a CPU with a single process (even in Ruby 1.8), these applications could get a 4-6x improvement in RAM usage (depending on context-switching overhead) by switching to threadsafe mode and using modern drivers for blocking operations.</p></blockquote>

<p>Node vs Ruby Threading:</p>

<p>Yehuda: &#8220;the main difference is that a callback is smaller in size than a stack&#8221;</p>

<p>In other words, the context switch that happens when switching threads
includes copying over an entire stack of the thread you&#8217;re resuming and
some other details I don&#8217;t know of off the top of my head. But with
callbacks, the callbacks have no stack (is this true in Rubyland? maybe
there&#8217;s stack trace information but probably no stack. The only stack
starts from where the callback/block was created, and the same is true w
threads, but the point is that in a thread-per-request model, the stack
goes all the way up to when the request was first received, which can be
a pretty tall stack).</p>

<p>So what about Fibers? They&#8217;re cooperative, but why is their context
switch not a big deal? They have a stack size limit of 4kb. How can I
test this?</p>

<p>Here&#8217;s a nice article:</p>

<p>http://timetobleed.com/fixing-threads-in-ruby-18-a-2-10x-performance-boost/</p>

<p>Seems to suggest that the stack that needs to be copied when context
switching includes interpreter code, which has many local vars and
sometimes the stack is up to 4kb, which is cray cray.</p>

<p>Green threads: pre-emptible userland threads. userland = not kernel
land.</p>

<p>You can hack into the thread-yielding code of old Ruby to allocate
stacks on the heap so that all you have to do to context switch is
change what rsp (pointer to the bottom of the stack) points to. This
means the stack won&#8217;t grow (so you have to pick a sensible size).</p>

<p>Ruby 1.9 performs way better in the benchmarks than his hacks&#8230; why?
&#8220;Thanks. 1.9 uses pthreads which create stacks in a similar manner to
what I did.&#8221; Awesome.</p>

<p>pthreads = POSIX threads</p>

<p>http://timetobleed.com/threading-models-so-many-different-ways-to-get-stuff-done/</p>

<p>Threads models:</p>

<h3>1:1 (native threads)</h3>

<p>One kernel thread for every user thread.</p>

<p>Pros</p>

<ul>
<li>execute threads on different CPUs</li>
<li>threads don&#8217;t block each other</li>
<li>shared memory b/w threads</li>
</ul>


<p>Cons</p>

<ul>
<li>Setup overhead since creating a thread requires a system call (and
those are slow)</li>
<li>Low upper bound on the number of threads that can be created</li>
</ul>


<p><code>pthread_create</code> is the fn that makes the system call to create the
thread.</p>

<h3>1:N (green threads)</h3>

<p>&#8220;lightweight threads&#8221;</p>

<ul>
<li>thread creation, execution, cleanup are cheap</li>
<li>lots of threads can be created</li>
</ul>


<p>Cons</p>

<ul>
<li>kernel doesn&#8217;t know about it, so no parallel execution across CPUs</li>
<li>blocking IO can block all green threads</li>
</ul>


<p>Forking + threading and cross-process communication is one way around
limitations.</p>

<h3>M:N</h3>

<p>Hybrid of above</p>

<ul>
<li>Multi CPUs</li>
<li>Not all threads blocked by blocking system calls</li>
<li>Cheap</li>
</ul>


<p>Cons</p>

<ul>
<li>Really really hard to synchronize userland and kernel scheduler</li>
<li>Green threads will block within same kernel thread</li>
<li>Difficult to maintain</li>
</ul>


<p>1:1 has shown itself to be more performant, but in some cases M:N might
be the right choice.</p>

<p>TODO: read this http://www.akkadia.org/drepper/nptl-design.pdf</p>

<pre><code>b = nil

t = Thread.new do
  b = Fiber.new {
    puts "FIBER"
  }
end

while !b
  # just wait
end

b.resume
</code></pre>

<p>This results in</p>

<pre><code>fiberthread.rb:13:in `resume': fiber called across threads (FiberError)
        from fiberthread.rb:13:in `&lt;main&gt;'
</code></pre>

<p>Of course it would.</p>

<p>Use strace / dtruss to trace sys calls.</p>

<p>Spinlocks are locks that, rather than sleeping, actively busy-wait until
the lock is free. This only makes sense if the wait is expected to be
short, otherwise it might block other threads.</p>

<p>Interesting, from the wiki:</p>

<blockquote><p>Most operating systems (including Solaris, Mac OS X and FreeBSD) use a hybrid approach called &#8220;adaptive mutex&#8221;. The idea is to use a spinlock when trying to access a resource locked by a currently-running thread, but to sleep if the thread is not currently running. (The latter is always the case on single-processor systems.)</p></blockquote>

<p>The idea is that a lock by an active thread is likely to be finished
soon, and since spinlocks avoid the scheduling overhead of a context
switch, then hooray.</p>

<p>Busy-waiting in general means while-looping until some condition is
true. You can even do this in JS:</p>

<pre><code>var end = +new Date() + 1000;
while (+new Date() &lt; end) {}
</code></pre>

<p>So whether Node or EventMachine, the concept is the same: both run on
callbacks.</p>

<p>Realization: I was thinking that I could demonstrate the difference b/w
green threads and OS threads by seeing if a while(true) in a green
thread would yield to others, but the answer is:</p>

<ul>
<li>of course it would yield; each iteration of the while true is
an iteration of the interpreter loop that&#8217;s running commands, so its
timer would fire at that point.</li>
<li>the only time it&#8217;d block is if you called out to a C extension that
looped and didn&#8217;t yield back control.</li>
</ul>


<p>It seems a Fiber&#8217;s 4k stack begins at the point at which it is created.
Hmm. So does it or does it not include interpreter stuff? Well for one
it&#8217;s in the same thread as a requirement.</p>

<p>Reasons why Fibers are faster than threads:</p>

<ul>
<li>limited 4kb stack for quick context switching</li>
<li>no pre-emption means no aggressive/frequent context switching;
context-switch as infrequently as you&#8217;d like.</li>
</ul>


<p>https://github.com/eventmachine/eventmachine/blob/master/docs/old/LIGHTWEIGHT_CONCURRENCY</p>

<p>Lightweight Concurrency generally means</p>

<ul>
<li>putting thread scheduling under the control of your program</li>
</ul>


<blockquote><p>By &#8220;lighter,&#8221; we mean: less
resource-intensive in one or more dimensions, usually including memory and
CPU usage. In general, you turn to LC in the hope of improving the
performance and scalability of your programs.</p></blockquote>

<p>NOTE: race conditions can happen in concurrent environments, even if
parallelism isn&#8217;t there, e.g. preempting</p>

<p>Mac has a max 2048 thread limit.</p>

<p>&#8220;IO Bound&#8221; means your program is mostly bottlenecked by IO, such that
swapping for a faster IO would boost your program performance immensely.</p>

<p>In such a case, going multi-threaded is a no-brainer rather than
serially getting blocked on each slow thing. But if you over do it then
you might just be wasting memory/CPU resources from thread stacks and
context switching that it&#8217;s not justified.</p>

<p>&#8220;CPU bound&#8221; means doubling CPU would mean the job would get done that
much faster.</p>

<p>Quad-core with 4 threads on CPU bound means mega-wins for Rubinius but
obviously not GIL&#8217;d MRI. If you make it 5, then you get the
context-switching overhead.</p>

<p>Rails apps are combo of IO-bound and CPU-bound</p>

<p>IO:</p>

<ul>
<li>Database</li>
<li>Third party APIs</li>
<li>Files read</li>
</ul>


<p>CPU:</p>

<ul>
<li>Rendering templates</li>
<li>Rendering JSON</li>
</ul>


<p>Measure measure measure.</p>

<p>This is comically incorrect:</p>

<pre><code>Mutex.new.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>should be</p>

<pre><code>m = Mutex.new

# ...create thread...

m.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>&#8220;critical section&#8221; refers to the part of your concurrent code that
alters shared data.</p>

<p>Memory Models describe the guarantees made to threads when
reading-from/writing-to memory, which mostly become important to think
about in a multi-threaded settings. The memory model describes how
caching occurs in the registers before actually writing out to memory,
and it describes the scope of compiler/hardware optimizations that can
be made that lead to non-determinant order of memory operations which
can fuck your shit unless you use <code>volatile</code> in Java or explicit mutexes
in Ruby.  Ruby doesn&#8217;t have a memory model spec yet. Java and Go and
others do. I guess Rust nips this in the bud w ownership.</p>

<p>Mutex is a form of a memory barrier, and I think <code>volatile</code> is too.</p>

<p>Livelocking is when <code>try_lock</code>s repeatedly fail, so the threads are
still technically alive but stuck in the same loop.</p>

<p>Best solution is to declare mutex grabbing in the same order via a mutex
hierarchy.</p>

<h2>Signals in ruby</h2>

<p>Rubyz</p>

<pre><code>Signal.trap("USR1") do
  puts "lol handling your custom user handler"
end
puts Process.pid # =&gt; e.g. 12345
</code></pre>

<p>Shellz</p>

<pre><code>kill -s USR1 12345
</code></pre>

<p>So many ways to kill a program:</p>

<ul>
<li>Abort: often self-initiated by <code>abort</code></li>
</ul>


<h2>Difference b/w seg fault and bus error</h2>

<p>http://stackoverflow.com/questions/838540/bus-error-vs-segmentation-fault</p>

<p>On most architectures I&#8217;ve used, the distinction is that:</p>

<ul>
<li>a SEGV is caused when you access memory you&#8217;re not meant to
(e.g., outside of your address space).</li>
<li>a SIGBUS is caused due to alignment issues with the CPU
(e.g., trying to read a long from an address which isn&#8217;t a multiple of 4).</li>
</ul>


<h2>Signals in C</h2>

<p>This is just for fun, but you can set up signal masks and signal
handles and all that fun crap.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

static int gotSignal = 0;

void wat(int s) {
  printf("Got Signal %d", s);
  gotSignal = 1;
}

int main() {
  /* SIGUSR1 == 16 */
  signal(SIGUSR1, &amp;wat);

  pid_t pid = getpid();
  printf("The process id is %d", pid);

  // prevent signal from getting here
  sigset_t s;
  sigaddset(&amp;s, SIGUSR1);
  // uncomment to block the signal from arriving
  //sigprocmask(SIG_BLOCK, &amp;s, NULL);

  while(!gotSignal) {
    printf(".");
    fflush(stdout);
    sleep(1);
  }

  printf("\nDone!\n");
}
</code></pre>

<p>and you can send it usr1 via</p>

<pre><code>kill -s USR1 12345
</code></pre>

<h2>Signals in Node</h2>

<pre><code>var done = false;

process.on("SIGUSR1", function() {
  done = true;
});

console.log("pid: ", process.pid);

var timerId = setInterval(function() {
  if (done) {
    console.log("DONEZO");
    clearInterval(timerId);
  } else {
    process.stdout.write(".");
  }
}, 500);
</code></pre>

<p>Note that SIGUSR1 is reserved by node.js to start the debugger.
The above code will work but if the debugger&#8217;s enabled then that&#8217;ll also
cause it to start.</p>

<p>Seems that signals are often used to start a debugger, or some kind of
debugging operation. Interesting.</p>

<h2>Condition Variables</h2>

<p>A provider and consumer both use the same mutex. Provider locks when
providing an update. Consumer locks when trying to perform an operation,
but internally does a <code>condvar.wait(mutex)</code> with the locked <code>mutex</code> to
unlock until the <code>condvar</code> is <code>signal</code>ed by the provider.</p>

<p>So why wrap the consumer in a while loop rather than an if (see page 104
of storimer)? Because there could be multiple consumers.</p>

<p><code>ConditionVariable#signal</code> wakes up a single thread, <code>ConditionVariable#broadcast</code>
wakes up all threads.</p>

<h2><code>thread_safe</code> gem</h2>

<ul>
<li>ThreadSafe::Array</li>
<li>ThreadSafe::Hash</li>
<li>ThreadSafe::Cache

<ul>
<li>similar to Hash, but insertion order enumeration isn&#8217;t preserved,
which means it can be faster</li>
</ul>
</li>
</ul>


<h2>Immutable = threadsafe</h2>

<p>Read more about it.</p>

<h2>Globals</h2>

<p>The Ruby AST is a global (is it really an AST at that point? is
dynamically adding a method an example of modifying an AST? ASTs are for
parsing, not so much adding/removing methods from a class obj).</p>

<p>Anyway, Kaminari was bitten by this:</p>

<p>https://github.com/amatsuda/kaminari/issues/214</p>

<h2>Thread-locals</h2>

<p>Variables that are global to everything in the current thread but hidden
to everyone else. So you could do</p>

<pre><code>Thread.current[:some_service] = SomeService.new
</code></pre>

<p>which could open a new connection. Connections are nice concurrency
primitives, much like request objects in Rails. But if you have too many
threads, you might hit a max connection limit, so in that case, use
pools, lol.</p>

<p>Pools let you specify max concurrency, which is likely less than the
number of threads that might want to consume it, and then when
requesting access to a thing in a pool, it&#8217;ll block until a slot&#8217;s
available.</p>

<p>See: https://github.com/mperham/connection_pool</p>

<p>mperham is Mr Sidekiq. Mr. Concurrency in general I guess.</p>

<p>Question: is a connection pool the same as a thread pool? Probably not,
connection pool is just a resource pool that is thread-aware, but
doesn&#8217;t constitute individual threads.</p>

<h2>Rubinius Actor</h2>

<p>https://github.com/rubinius/rubinius-actor</p>

<p>Depends on core Rubinius class <code>Channel</code>. TODO: find out why <code>Channel</code>
doesn&#8217;t/can&#8217;t exist in MRI.</p>

<h2>Rubinius Ruby JITting</h2>

<p>Talking to IRC folk: one of the major reasons for Ruby all the way down
or at least Ruby most of the way down is that more of it can be JITted
rather than having the hard C/C++ boundary after which no more
optimizations can be made.</p>

<p>Also, in some benchmarks b/w Rubinius and JRuby and MRI, etc., one thing
that comes up a lot is the suggestion that the tests run for longer so
that the JIT is primed, all the optimizations have been made, etc etc
etc.</p>

<h2>Rails Batches</h2>

<p>http://api.rubyonrails.org/classes/ActiveRecord/Batches.html</p>

<pre><code>Article.find_each do |a|
  a.wat
end
</code></pre>

<p>this internally splits DB queries into batches of 1000 so that you&#8217;re
not instantiating potentially a billion Ruby objects for each row. In
the end you&#8217;ll still allocate the same amount of memory but it can be
GC&#8217;d along the way vs causing an insane spike and possibly crashing your
server.</p>

<h2>Server-sent events</h2>

<p>http://tenderlovemaking.com/2012/07/30/is-it-live.html</p>

<ol>
<li>A stream obj is added to Rails request object, quacks like IO obj.
You can write to it and close it, but it doesn&#8217;t actually stream live
to the client; it buffers, and then flushes.</li>
<li>With <code>ActionController::Live</code>, it&#8217;ll actually stream live.</li>
<li>Some WebServers, like WEBrick will thwart this by buffering the
response until it&#8217;s complete. Unicorn could work, but it&#8217;s meant for
fast responses; anything taking longer than 30s might get terminated.
Rainbows/Puma/Thin would work.</li>
</ol>


<h2>Celluloid</h2>

<p>Transforms method invocations into blocking messages. Precede w <code>async</code>
to prevent blocking (obviously still happens async);</p>

<pre><code>require 'celluloid'

class DoesStuff
  include Celluloid

  attr_accessor :i

  def foo
    # currently this displays
    # one item per second.
    # if you swap comments with
    # the line after it'll wait
    # until the very end to print them all
    # at once because the each at the end
    # will evaluate the "longest" future first
    sleep i
    #sleep (11 - i)
    i
  end
end


futures = []

10.times do |i|
  thing = DoesStuff.new
  thing.i = i

  futures &lt;&lt; thing.future.foo
end


futures.each do |f|
  puts "Completed: #{f.value.i}"
end

sleep
</code></pre>

<p>This is interesting: https://github.com/celluloid/celluloid/wiki/Frequently-Asked-Questions#q-can-i-do-blocking-io-inside-an-actor-or-do-i-have-to-use-celluloidio</p>

<p>It&#8217;s fine to have blocking IO such as waiting for a DB query to return,
or slow HTTP response, but you shouldn&#8217;t have it waiting on
<em>indefinite</em> IO; for that, use Celluloid::IO.</p>

<p>I believe that an actor can&#8217;t be handling multiple messages at the same
time. Wrong! That&#8217;s only if Erlang/Exclusive mode is on, and you have to
be careful about that because it means a higher risk of deadlock:</p>

<p>https://github.com/celluloid/celluloid/wiki/Exclusive</p>

<p>Sidekiq doesn&#8217;t make use of return values a whole lot; rather actors are
expected to send messages back to their &#8220;callers&#8221;.</p>

<p>Accessing localvars is faster than ivars: https://github.com/puma/puma/commit/fb4e23d628ad77c7978b67625d0da0e5b41fd124</p>

<h2>Compare and set (CAS)</h2>

<p>aka check-and-set</p>

<p>For platforms that support it, CAS is a mutex-free approach to
thread-safety</p>

<pre><code>a += 1
</code></pre>

<p>is not thread safe, but</p>

<pre><code>cur = a.value
new_value = cur + 1
if (!a.compare_and_set(cur, new_value)) 
  # try again
end
</code></pre>

<p>is.</p>

<p>Worth pointing out that Redis supports a form of this using WATCH.</p>

<pre><code>MULTI # begin transaction
SET foo lol
SET bar wat
EXEC # execute
</code></pre>

<p>so basically if you do</p>

<pre><code>WATCH someval
MULTI
set someval lol
EXEC
</code></pre>

<p>and someval changed after the MULTI then it will fail.</p>

<p>So why use CAS over a mutex?</p>

<blockquote><p>If the cost of retrying the operation is cheap, or rare, it may be much less expensive than using a lock.</p></blockquote>

<p>Logic checks out.</p>

<pre><code>require 'atomic'
v = Atomic.new(0)
v.update do |current|
  current + 1
end
</code></pre>

<p>This is the shorthand to the idempotent loop with CAS.</p>

<p>Lockless showed mega improvements relative to locking in Rubinius but
not JRuby for some reason.</p>

<p>Hamster is the immutability gem to check out.</p>

<h2>oni</h2>

<p>https://github.com/olery/oni</p>

<p>Uses SQS, look into it because i am such a nooblet.</p>

<h2>SQS</h2>

<p>Uses a visibility timeout after a consumer has started to receive a
message in which time it is hidden from other consumers, and in this
time it should be deleted.</p>

<ul>
<li>Supports GET/POST requests to public URLs, presuming you pass in a
valid signature

<ul>
<li>This means you could fire requests directly to SQS rather than
having to go to a server first&#8230; that is badass.</li>
</ul>
</li>
<li>Reports of scalability problems</li>
</ul>


<p><a href="http://nsono.net/amazon-sqs-vs-rabbitmq/">Alternative: RabbitMQ</a></p>

<ul>
<li>SQS: consumers must poll for messages, and SQS charges by the request,
even if the response is empty.</li>
<li>RabbitMQ supports push</li>
<li>is free and open source</li>
<li>based on erlang</li>
<li>adheres to AMQP (standard for high performance messages queues)</li>
<li>supports durable queues (crash-recoverable, written to disk)</li>
<li>delivered in order unless message requeued</li>
<li>more consistent (much less likely to deliver a message twice unless
the message actually failed)</li>
</ul>


<p>cons</p>

<ul>
<li>not necessarily highly available (because it&#8217;s a server that runs on
whatever instance you wanna put it on, so you have to manage failover,
redundancy, etc, whereas SQS is a system that handles all of that)</li>
<li>this is configurable, but the default is for RabbitMQ to drop messages
if there are no consumers; surprising to SQS folk.</li>
</ul>


<h2>Heartbeats</h2>

<p>https://www.rabbitmq.com/reliability.html</p>

<blockquote><p>In some types of network failure, packet loss can mean that disrupted TCP connections take some time to be detected by the operating system. AMQP offers a heartbeat feature to ensure that the application layer promptly finds out about disrupted connections (and also completely unresponsive peers). Heartbeats also defend against certain network equipment which may terminate &#8220;idle&#8221; TCP connections. In RabbitMQ versions 3.0 and higher, the broker will attempt to negotiate heartbeats by default (although the client can still veto them). Using earlier versions the client must be configured to request heartbeats.</p></blockquote>

<p>Re: &#8216;Heartbeats also defend against certain network equipment which may
terminate &#8220;idle&#8221; TCP connections.&#8217;: I bet that&#8217;s referring to NAT, which
manages a cache of IP translations and will go inactive if nothings been
sent to / received from an IP for a while.</p>

<p>YAY I WAS RIGHT http://stackoverflow.com/questions/865987/do-i-need-to-heartbeat-to-keep-a-tcp-connection-open#comment1713801_866003</p>

<p>So Heartbeats</p>

<ul>
<li>reassure you the connection is alive in some cases where the failure
conditions aren&#8217;t otherwise detectable</li>
<li>keep the NAT state tables warm for your IP</li>
</ul>


<h2>Celluloid::IO</h2>

<p>https://github.com/celluloid/celluloid-io</p>

<p>Provides a different class of Actor that&#8217;s heavier than normal Celluloid
actors, but contains a high performance reactor like EventMachine or
cool.io (todo: check out cool.io). So unlike EventMachine you can have
multiple loops, e.g. one in each actor (resources permitting). (Also,
does EM really force you to just have one?)</p>

<h2>Autoload</h2>

<p>Yes we know it&#8217;s not threadsafe in MRI. Recent JRuby versions make it
thread safe, but just eager load your shits before spawning threads.</p>

<h2>Requests as concurrency unit</h2>

<p>I guess in general you should always look for the concurrency unit; that
domain object that encapsulates all the data you need to get a job done
so that hopefully you&#8217;re not sharing data between threads. Each request
gets handled by its own thread.</p>

<h2>Queue</h2>

<p><code>Queue#pop</code> will suspend a thread until data is in the queue. Like a
mofuggin stream.</p>

<p>Queue is apparently the only thread-safe data structure that ships with
Ruby.</p>

<h2>JRuby</h2>

<p>Foreign function interface</p>

<p>http://en.wikipedia.org/wiki/Foreign_function_interface</p>

<p>Mechanism for languages to invoke routines from other languages.</p>

<p>Write your extension code in Ruby, FFI will call the write C / Java /
whatever stuff. It won&#8217;t even be compiled. I guess it just links into
dynamic libs?</p>

<p>JRuby obviously doesn&#8217;t support C extensions, but FFI extensions will
work.</p>

<p>JRuby</p>

<ul>
<li>has no fork(), since JVMs mostly can&#8217;t safely be forked
(<code>NotImplementedError: fork is not available on this platform</code>)</li>
<li>Fibers are native threads, rather than MRI green threads, which means
you are constrained to native thread overhead/limits.</li>
</ul>


<h2>Rubinius (rbx)</h2>

<ul>
<li>Designed for concurrency, speed.</li>
<li>Rubinius 2.0 has no GIL</li>
<li>All tools written in Ruby, including bytecode VM, compiler,
generational GC, JIT, etc</li>
<li>No continuations (because dependent on callcc, a C thing)</li>
<li>At some point, when dealing with locks and low level things, you&#8217;ll
find C++.</li>
</ul>


<p>http://rubini.us/2011/02/25/why-use-rubinius/</p>

<h2>Ruby Enterprise Edition</h2>

<p>By Phusion. No longer alive.</p>

<ul>
<li>Compatible w 1.8.7</li>
<li>End of Life since 2012</li>
<li>No more work being done, reasons being:

<ul>
<li>Rails 4 no longer supporting 1.8</li>
<li>COW patch accepted on Ruby 2.0</li>
<li>Many Ruby Enterprise Edition patches addressed in 1.9, 2.0</li>
</ul>
</li>
</ul>


<h2>MacRuby</h2>

<p>Implementation of 1.9 Ruby directly on top of Mac OS X core tech, e.g.</p>

<ul>
<li>Obj-C runtime and GC</li>
<li>LLVM compiler infrastructure</li>
</ul>


<h2>Reactive manifesto</h2>

<p>TODO: read this http://www.reactivemanifesto.org/</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/19/daily-journal/"/>
    <updated>2014-07-19T11:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/19/daily-journal</id>
    <content type="html"><![CDATA[<h2>Crank</h2>

<p>Meth.</p>

<p>An eccentric person, esp. one who is obsessed by a particular subject or
theory: when he first started to air his views, they labeled him a
crank | [ as modifier ] : I am used to getting crank calls from
conspiracy theorists.</p>

<h2>Roko&#8217;s modern basilisk</h2>

<p>It&#8217;s happening.</p>

<h2>Transactional UIs</h2>

<p>People build forms. Ember gives you sweet syntax sugar for 2wb.
Not for transactional UI, anything that needs a buffer.</p>

<p>Old mindset: if you need 1wb, just&#8230; don&#8217;t set on the other side of a
2wb.</p>

<p>TODO: ask kris more about the async/sync cocoa observer binding
limitations.</p>

<ul>
<li>Most observers just do something and stop.</li>
<li>And they mostly want to know the last thing they cared about.</li>
</ul>


<p>Bubbling doesn&#8217;t describe actions; actions go wherever. Bubbling only in
route hierarchy.</p>

<p>Services:</p>

<ul>
<li>session/user</li>
<li>timer</li>
<li>websocket</li>
<li>analytics</li>
</ul>


<p>Idea: components provide services to the components the render. They
have a ServiceCertificate</p>

<p>Goal:</p>

<ul>
<li>Try and associate actions with objects.</li>
<li><code>actions</code> themselves can just be passed into the <code>actions</code></li>
</ul>


<h2>Non-dynamic routes</h2>

<pre><code>resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}

resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}
</code></pre>

<p>Initializers vs <code>applicationRoute#beforeModel</code>.</p>

<p>retcon for how to use controllers</p>

<p>asop to data binding</p>

<p>HTMLbars knows what parts of the template are dynamic vs static.</p>

<p>In React, if you have a conditional</p>

<h2>Skunkworks project</h2>

<blockquote><p>A skunkworks project is a project developed by a small and loosely
structured group of people who research and develop a project
primarily for the sake of radical innovation.[1] The terms
originated with Lockheed&#8217;s World War II Skunk Works project.</p></blockquote>

<p>http://en.wikipedia.org/wiki/Skunk_Works</p>

<blockquote><p>The designation &#8220;skunk works&#8221;, or &#8220;skunkworks&#8221;, is widely used
in business, engineering, and technical fields to describe a
group within an organization given a high degree of autonomy
and unhampered by bureaucracy, tasked with working on advanced
or secret projects.</p></blockquote>

<p>Lockheed Martin&#8217;s Skunk Works project made SR-71.</p>

<h2>Project Svelte</h2>

<p>http://www.trustedreviews.com/opinions/android-4-4-kitkat-s-project-svelte-what-it-is-and-why-you-should-care</p>

<blockquote><p>dogfooding  that is making its employees use and live with their own projects</p></blockquote>

<p>They dogfooded their employees by forcing them to dev on handicapped
phones. Android 4.4 was the result, apparently it was way more
performant.</p>

<h2>RACK_ENV vs RAILS_ENV</h2>

<p><code>Rails.env</code> is decided by <code>RAILS_ENV || RACK_ENV || "development"</code>. It&#8217;s
common to set <code>RACK_ENV</code> which will also set <code>RAILS_ENV</code>, but if you
have any rack middleware that behaves differently in different
environments, you might screw yourself if you&#8217;re using <code>RAILS_ENV</code>.</p>

<h2>wythoughts on blocks</h2>

<p>The reason <code>|i|</code> is ok is for the same reason you can&#8217;t do the following
in Ruby:</p>

<pre><code>a = { |it| wat }
</code></pre>

<p>You have to do</p>

<pre><code>a = proc { |it| wat }
</code></pre>

<p>Case in point you need an fn to save a block.</p>

<h2>mythoughts on mutability</h2>

<p>Can/should we swap POJOs when an observed property changes? Is there any
value to</p>

<pre><code>var pojo = {
  a: {
    b: 123
  }
};

var a = pojo.a;
Ember.set(pojo, 'a.b'
</code></pre>

<h2>ASI: automatic semicolon insertion</h2>

<p>Nuff said.</p>

<h2>old browser disagreements on ws</h2>

<pre><code>[ text ws text]
</code></pre>

<p>cloneNode produces:</p>

<ul>
<li>ie8: 1 node</li>
<li>ie9: 2 nodes</li>
<li>else: 3 nodes</li>
</ul>


<h2>NoScope</h2>

<p>http://www.thecssninja.com/javascript/noscope</p>

<p>tldr NoScope is an old IE categorization of nodes, and NoScope dictates
that innerHTML and cloneNode will strip these els.</p>

<h2>Ropes: DAG of string implementation for FF/Chrome</h2>

<p>http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=181EEF66EB411F4277C009A1D492CF75?doi=10.1.1.14.9450&amp;rep=rep1&amp;type=pdf</p>

<p>Look into this more. Too lazy to read / comment.</p>

<p>How to force Chrome to not use a rope:</p>

<ul>
<li>Less than 12 chars</li>
</ul>


<p>What does it mean to intern strings?</p>

<h2>CSP: Content Security Policy</h2>

<p>http://www.html5rocks.com/en/tutorials/security/content-security-policy/</p>

<h2>String interning</h2>

<pre><code>String.prototype.intern = (function() {
   "use strict";
   var o = {"- ": 0};
   delete o["- "];
   return function() {
       var str = this;
       o[str] = true;
       var ret = Object.keys(o)[0];
       delete o[str];
       return ret;
       try {} finally {}
   };
})();
</code></pre>

<h2>Component pinning</h2>

<p>Associating the re-render with the pre-existing fragment.</p>

<h2>localStorage on iOS Cordova webviews</h2>

<ol>
<li>Run dev, set <code>localStorage.wat = "lol"</code></li>
<li>Stop and re-run the app, and <code>localStorage.wat</code> still is &#8220;lol&#8221;</li>
<li>Delete the app, re-install, still dev, <code>localStorage.wat</code> is undefined</li>
</ol>


<p>I don&#8217;t even have to check&#8230; your app can&#8217;t run in both dev and prod.
You can&#8217;t share userSessions across dev and prod apps. Then again, our
servers could maintain keys for both APNS and APNS_SANDBOX.</p>

<h2>GCM project number vs project ID</h2>

<p>https://developers.google.com/compute/docs/faq#whatisthedifference</p>

<p>You pick project ID, they pick project number. Project number is the
Sender ID you use for GCM.</p>

<h2>Pointer comparisons for such perf</h2>

<pre><code>if (wat === false) {
}
</code></pre>

<p><code>false</code> can be implemented to just refer to a unique memory location,
such that all browsers need to comparison in the above code is <code>wat</code>&#8217;s
memory address against <code>false</code>&#8217;s.</p>

<p>Same goes with</p>

<pre><code>if (wat === undefined) {
}
</code></pre>

<p>just that the presence of <code>foo</code> in <code>cache.foo</code> is ambiguous without
testing <code>foo in cache</code>; might be easier to do <code>cache.foo = UNDEFINED</code>
where</p>

<pre><code>function UNDEFINED() {}
</code></pre>

<p>Sentinel as fuck.</p>

<h2>PushPlugin</h2>

<p>Only starts firing PNs after <code>register</code>. We need a user session to
register, right? Seems weird we can&#8217;t query it for information before
immediately registering&#8230; either way, works fine for us, at least we
killed Zalgo.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/18/daily-journal/"/>
    <updated>2014-07-18T03:50:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/18/daily-journal</id>
    <content type="html"><![CDATA[<h2>Cookies</h2>

<p>What ends up in <code>document.cookie</code>?</p>

<p>Test: kill a previous localhost:5000 server, start a server for a
separate project. Reload the page. Request headers sent include
a transient cookie from the previous server. I bet it was due to
Turbolinks. I was right!</p>

<p>From http://tools.ietf.org/html/rfc6265#section-4.1.1</p>

<blockquote><p> Origin servers MAY send a Set-Cookie response header with any
 response.  User agents MAY ignore Set-Cookie headers contained in
 responses with 100-level status codes but MUST process Set-Cookie
 headers contained in other responses (including responses with 400-
 and 500-level status codes).  An origin server can include multiple
 Set-Cookie header fields in a single response.  The presence of a
 Cookie or a Set-Cookie header field does not preclude HTTP caches
 from storing and reusing a response.</p></blockquote>

<p>So you can send multiple headers with the same key. Makes sense, since
comma separation will conflict with the UTC date (e.g. <code>Aug 12, 2014</code>).</p>

<p>So how do you set multiple cookies in Rack?</p>

<p>Interesting: https://github.com/rack/rack/blob/master/lib/rack/utils.rb#L266</p>

<p>Anyway, split cookies with newlines and Rack will cause this to send two
<code>Set-Cookie</code> headers, which is totally fine.</p>

<p>You can also use <code>set_cookie</code> on <code>Rack::Response</code> if you&#8217;re into that
sort of thing..</p>

<p>I psyched myself out thinking cookies were overwriting each other by doing:</p>

<pre><code>"Set-Cookie" =&gt; "foo\nbar\nbaz"
</code></pre>

<p><code>document.cookie</code> was only revealing <code>baz</code>. But, I&#8217;m a dumb: cookies
need to be key-value pairs, which fixed it.</p>

<p>You can use <code>HttpOnly</code> to prevent JS (and other APIs?) access to the
cookie sent by the server. Makes sense; less likely that&#8217;ll break
something.</p>

<p>Getting <code>document.cookie</code> returns all the cookies available to JS.
Setting it will only set the cookie you provide.</p>

<blockquote><p>Notice that servers can delete cookies by sending the user agent a
new cookie with an Expires attribute with a value in the past.</p></blockquote>

<h2>JavaScript set focus</h2>

<p><code>focus()</code> is a method on input elements. So is <code>blur()</code>.</p>

<p><code>document.activeElement</code> in modern browsers points to the focused
element, which might also include scroll windows.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/document.activeElement</p>

<p>In older browsers, to <code>blur</code> the active element, you&#8217;d have to know what
that element was; there was no way to query. Might be wrong about this.</p>

<h2>React Nested Router</h2>

<p>http://www.youtube.com/watch?v=P6xTa3RRzfA</p>

<ul>
<li>State is just data</li>
<li>Your route is data, e.g. you could render a top-level App component
and tell it what its route is, and render everything a la React,
pretend like you&#8217;re redrawing the whole page.</li>
<li>Rather than switch-statement-based routing, the <code>activeRoute</code> just
gets passed in via <code>props</code> like any other property

<ul>
<li><code>router.match</code> handlers will create all the routes, and pass in a
single <code>activeRoute</code>; every route segment along the way just knows
about with its activeRoute child is, if one exists.</li>
<li>e.g. <code>contact/profile</code>, app.activeRoute = contact,
contact.activeRoute = profile</li>
</ul>
</li>
<li>API

<ul>
<li>Route component

<ul>
<li>handler = a React Class</li>
</ul>
</li>
</ul>
</li>
<li>Differences w Ember

<ul>
<li>No auto-gen &#8216;index&#8217; routes</li>
<li>paths don&#8217;t inherit parent paths

<ul>
<li>this means if you&#8217;re &#8220;overwriting&#8221; a parent dynamic segment, the
dynamic segment must appear <em>somewhere</em> in the child route so you
can actually load that data.

<ul>
<li>AH, the router will detect when children omit ids that their
parents have declared. That&#8217;s nice.</li>
<li>also yells at you if you use the same path in two places.</li>
</ul>
</li>
<li>nice that it lets you have <code>/profile</code> vs <code>/user</code></li>
</ul>
</li>
<li>Ember is less typing, but

<ul>
<li>React makes it easier to share handlers</li>
<li>Overwriting URL is nice when you need it, error checking is nice</li>
</ul>
</li>
</ul>
</li>
<li>So each non leaf handler gets <code>activeRoute</code>, all handlers get all
<code>params</code>.</li>
<li>Refactorability/decoupling:

<ul>
<li>Because route names and paths are fully specified and all params are provided to
each handler, changing the nesting of a route means you don&#8217;t have
to rewrite all your link-tos from &#8220;wat.foo&#8221; to &#8220;foo&#8221;. Then again
if you&#8217;re using resources you don&#8217;t have to do that either.</li>
</ul>
</li>
<li>Question: what about other <code>props</code> you&#8217;d want to pass into a
component?

<ul>
<li>Answer: Route components aren&#8217;t concerned with props other than how
to be a route handler.</li>
</ul>
</li>
</ul>


<p>http://jsbin.com/vukacule/6/edit</p>

<p>It is really cool that you can switch between rendering a route with App
as a handler vs just rendering App. The difference is that, when
route-driven, it gets passed props.</p>

<p>The <code>Route</code> components you use are obviously stateless; all state lives
on the Handlers.</p>

<p>Ah, in React <code>` syntax just means</code>{blah: &#8220;wat&#8221;}` inside
the normal single-curly.</p>

<p>How do Links work? They call transitionTo and there&#8217;s a single URLStore
singleton.</p>

<h2>TLS Replay?</h2>

<p>I had it in my head that man-in-the-middle wasn&#8217;t a problem for TLS but
maybe they could replay the messages? Turns out I am wrong; TLS includes
a sequence mechanism.</p>

<p>That being said, your app might send repeat messages, which demands its
own double checking / application-level sequencing or some other
prevention mechanism.</p>

<h2>chroot</h2>

<p>http://en.wikipedia.org/wiki/Chroot</p>

<p>Learned about this when speculating w Ember Core about how the front
page Rust evaluator works at http://www.rust-lang.org/</p>

<p>It runs a program with the assumption that <code>/</code> is somewhere else, and it
can&#8217;t access it.</p>

<p>Change</p>

<h2>process.nextTick</h2>

<p><code>process</code> doesn&#8217;t exist on the browser, so therefore neither does
<code>nextTick</code>, but you can hack it if you&#8217;re on a browser that has a native
<code>Promise</code> object, since the <a href="http://promisesaplus.com/">spec</a> mentions
that resolution callbacks must happen when the execution context
consists only of platform code.</p>

<blockquote><p>onFulfilled or onRejected must not be called until the execution
context stack contains only platform code. [3.1].</p></blockquote>

<p>So here&#8217;s how you could write nextTick, note that there&#8217;s no need to</p>

<pre><code>var p = Promise.resolve();
function nextTick(cb) {
  p.then(cb);
}
</code></pre>

<h2>Visibility API</h2>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/Guide/User_experience/Using_the_Page_Visibility_API">mdn</a></p>

<p>e.g.</p>

<ul>
<li>pause video when you tab-away</li>
<li>stop requestAnimationFrame</li>
</ul>


<h2>Closing over <code>let i</code></h2>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p>The above code has the gotcha that by the time the <code>fns</code> functions run,
they&#8217;ll all print out <code>10</code>, rather than the value of <code>i</code> when the
closing-over function was created. This is part of the reason why jshint
will yell at you for creating functions in a loop, e.g.</p>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(makeCallback(i));
}

function makeCallback(num) {
  return function() {
    console.log(num);
  }
}
</code></pre>

<p>Then <code>i</code> will be uniquely preserved for each callback.</p>

<p>The es6 <code>let</code> keyword gives you block scope, which includes everything
declared within the for loop. If you just use <code>let</code> in the original
code, you can do</p>

<pre><code>var fns = [];
for (let i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p><code>i</code> doesn&#8217;t get hoisted; rather, each iteration gets its own <code>i</code> value
that gets closed over.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/16/daily-journal/"/>
    <updated>2014-07-16T00:40:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/16/daily-journal</id>
    <content type="html"><![CDATA[<h2>WeakMap</h2>

<p>Use objects as keys. If you lose access to a key, it and its value will
eventually be removed by GC because references to keys are weak. This
also means WeakMaps are non enumerable since GC is non-deterministic and
a key that might exist pre GC might not exist after.</p>

<h2>ES6 Symbols</h2>

<p>They&#8217;re nothing like Ruby symbols.</p>

<p>They&#8217;re used to create unique, non-enumerable, keys that can&#8217;t be
determined publicly unless the symbol is exported. So you could prevent
tampering with a player&#8217;s score by storing the score on the player using
an unshared symbol as the key:</p>

<p>http://tc39wiki.calculist.org/es6/symbols/</p>

<h2>ES6 === Harmony === ES.next</h2>

<p>They&#8217;re all the same thing.</p>

<h2>JS 1.7 vs ES6, etc</h2>

<p><a href="http://ejohn.org/blog/versions-of-javascript/">jeresig clears this up a bit</a></p>

<p>All modern browsers support ECMAScript; JavaScript is a variant of it
that Mozilla&#8217;s largely been adding features to. ES3 === JS 1.5.</p>

<p>So I see <code>let</code> was added to JavaScript 1.7, so why is it now being
described as a new upcoming feature of ES6? Ah, because all browsers
track ECMAScript standards, even if they call their enhanced language in
the browser something else. Mozilla has been blazing ahead and trying
new shit, but other browsers won&#8217;t pick it up until it&#8217;s actually
standardized into ECMAScript.</p>

<p>Why would Microsoft follow ECMAScript? Well, for starters, it delivered
JScript to Ecma back in the day for standardization.</p>

<blockquote><p>The name &#8220;ECMAScript&#8221; was a compromise between the organizations involved in standardizing the language, especially Netscape and Microsoft, whose disputes dominated the early standards sessions.</p></blockquote>

<p>Interesting, and:</p>

<blockquote><p>While both JavaScript and JScript aim to be compatible with ECMAScript, they also provide additional features not described in the ECMA specifications</p></blockquote>

<p>Also, some reason I thought TC39 was part of Mozilla. I see that I am
obviously incorrect: http://www.ecma-international.org/memento/TC39.htm</p>

<p>It&#8217;s Ecma-TC39. The things I don&#8217;t know.</p>

<p>W3C Tag, Ecma-TC39. W3C Tag, Ecma-TC39.</p>

<h2><code>let</code></h2>

<p><code>let</code> behaves like C++ declarations; the obj is only available in the
curlies, or in for loops, or whatever, and there&#8217;s no hoisting. Outside
of the block, the variable is undefined.</p>

<h2>Cloudfront TTL</h2>

<p>TTL lets you specify a min time before CF checks the origin to see if it
has a new version of the file/response. You still need your origin
server&#8217;s Cache-Control headers setup correctly.</p>

<p><a href="http://stackoverflow.com/questions/10621099/what-is-a-ttl-0-in-cloudfront-useful-for">TTL can be 0</a>.
Why? TTL 0 means that it delegates Cache-Control entirely to the origin.
This means CF will always make a GET request w <code>If-Modified-Since</code>
header to let the server return <code>304 Not Modified</code>.</p>

<h2>Drag and Drop</h2>

<p>Draggable elements need to be marked as <code>draggable="true"</code>.</p>

<p>Then listen to the <code>ondragstart</code> event, e.g.
<code>ondragstart="drag(event)"</code>.</p>

<p>And then say what data is associated with the dragged el&#8230;</p>

<pre><code>ev.dataTransfer.setData("Text", ev.target.id);
</code></pre>

<p>This seems strange.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/DataTransfer</p>

<p>It really is a class associated only w drag and drop.</p>

<p>Should probably be reading this rather than fucking w3schools. Why do I
still do that?
https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Drag_and_drop</p>

<p>Ah I get it, you use dataTransfer as part of the mechanism for
dynamically determining drop targets. You have to prevent bubbling
(return false or preventDefault) on droppable targets, and in that fn
they have the option of looking up the data transfer to see if they want
to accept the data from that drag drop.</p>

<p>You can also configure drag drag visual details to indicate copying,
moving, etc. LOL such drag and drop.</p>

<p>Oof apparently it&#8217;s a fucking disaster: http://www.quirksmode.org/blog/archives/2009/09/the_html5_drag.html</p>

<p>Criticisms:</p>

<ul>
<li>7 fucking events, such API surface</li>
<li>&#8220;For the drop event to fire at all, you have to cancel the defaults of both the dragover and the dragenter event.&#8221;</li>
</ul>


<h2>Cordova events: sticky != buffered</h2>

<p>Sticky events (e.g. deviceready) just mean that once fired, they stay in
a fired state. This means you can&#8217;t have multiple events fire if it&#8217;s a
sticky event. I was originally thinking sticky meant all the events were
cached until the first handler was registered.</p>

<p>Ended up making this: https://gist.github.com/machty/e1cc485060f2951aeb6c</p>

<h2>Why <code>-print0</code> in <code>find</code>?</h2>

<p>Often you pipe the results of <code>find</code> into <code>xargs</code> to pass the results of
a <code>find</code> so that some utility can operate on each file found. GOOD
ENGRISH, MATCHNEER.</p>

<p>But since <code>xargs</code> splits based on whitespace by default, this will break
for files with newlines or or spaces in them, so <code>-print0</code> separates
files w null bytes, and <code>-0</code> tells xargs to split via null bytes as
well. Win win win. No difference if you have no files with spaces in
them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Forgotten things]]></title>
    <link href="http://machty.github.com/blog/2014/07/15/forgotten-things/"/>
    <updated>2014-07-15T12:18:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/15/forgotten-things</id>
    <content type="html"><![CDATA[<p>Here&#8217;s a progressively-updated list of things I forget throughout the
day. This is different from the list of things I&#8217;ve learned; that
approach is useful for packing the things into my brain, hopefully; the
purpose of this list is to pack things back in when I forget. And for
now it&#8217;ll just be one giant progressively-updated blog.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/14/daily-journal/"/>
    <updated>2014-07-14T09:33:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/14/daily-journal</id>
    <content type="html"><![CDATA[<h2>Website Push != Push Notifications</h2>

<p>So when you&#8217;re rummaging through the Apple Dev Portal, don&#8217;t confuse the
two and generate the wrong certs. K?</p>

<h2>WWDC 2011 video on UIViewController Containment</h2>

<pre><code>https://developer.apple.com/videos/wwdc/2011/
</code></pre>

<p>First off, WWDC stands for the Apple World-Wide Developer Conference.</p>

<h2>Why view controllers</h2>

<ul>
<li>Make it easy to make high quality apps</li>
<li>Reusable</li>
</ul>


<p>A View Controller just a Controller. Mediates model data with many
views. View controllers maintain entire hierarchies of views. They&#8217;re
heavyweight, meant to manage a &#8220;screenful of content&#8221;. Often packaged
with a model, e.g.</p>

<ul>
<li>TweetViewController</li>
<li>ImagePickerController</li>
</ul>


<p>View Controllers are social, meant to connect to each other. They push
and pop each other, etc. They talk to each other a lot.</p>

<p>The &#8220;manage a screenful of content&#8221;:</p>

<p>View Controllers anticipate being presented in different ways. More
accurately: they should maintain a unit of content. Only
<code>rootViewController</code> manages a &#8220;screenful of content&#8221;, specifically the
<code>rootViewController</code> property of the window object. Knows how to forward
rotation events, decides overall layout.</p>

<p>How to use View Controllers</p>

<ul>
<li>subclass UIViewController</li>
<li>associate VC w view hierarchy</li>
<li>override callbacks</li>
</ul>


<p>Apperance callbacks: viewWillAppear, viewDidAppear, etc
Rotation callbacks: viewWillRotate, etc</p>

<p>ViewControllers manage an entire view hierarchy. Not just one to one
with a view.</p>

<p>View Controller Containers, a tale of Two Hierarchies: view hierarchies
and view controller hierarchies.</p>

<p>Container controllers</p>

<ul>
<li>responsible for parent child relationships

<ul>
<li>API like <code>initWithRootViewController</code> implies parent-child in nav
controller</li>
<li>split view controllers lets you set view controller children.</li>
</ul>
</li>
</ul>


<p>Controller container api</p>

<ul>
<li>addChildViewController

<ul>
<li>not meant to be called by anyone but its own implementation; don&#8217;t
call it on other controllers, basically</li>
</ul>
</li>
<li>remoteFromParentViewController

<ul>
<li>^^ ditto</li>
</ul>
</li>
<li>childViewControllers array</li>
<li>callbacks

<ul>
<li>willMoveToParentViewController</li>
<li>didMoveToParentViewController</li>
</ul>
</li>
</ul>


<p>Shouldn&#8217;t be able to walk up view hierarchy and totally skip over a
parent view controller: UIViewControllerHierarchyInconsistencyException,
prevents you from manually adding views into the wrong view controller
hierarchy.</p>

<p>When are appearance callbacks called?</p>

<p>viewWillAppear etc has nothing to do w addChildViewController, which has
nothing to do w view appearance.</p>

<p>viewWillAppear just means it&#8217;s in the window view hiearchy, but doesn&#8217;t
mean it&#8217;s actually visible (same w viewDidAppear).</p>

<p>TODO: what is view layoutSubviews?</p>

<p>viewDidAppear after the view added to viewHierarchy. Called after
layoutSubviews.</p>

<p>When implementing transitions, you have to implement
didTransitionToBlahBlah, one of the options is <code>animations</code> lambda.</p>

<p>VS Layout callbacks:</p>

<ul>
<li>viewWillLayoutSubviews&#8230;</li>
</ul>


<p>Presentation and Dismissal of VCs</p>

<p>set presentation style and then do presentViewController</p>

<p>Can also present VCs by direct subview manipulation.</p>

<pre><code>[root.someView addSubview: vc.view]
</code></pre>

<p>But this is bad form; better to make the VC a child of the root VC. VC
knows where subviews should go rather than the ass backwards way.</p>

<p>When to create a custom view controller container?</p>

<ul>
<li>Hopefully you don&#8217;t need to, so think twice first</li>
<li>Aesthetics</li>
<li>Custom app flows</li>
<li>Your app manipulates view hiearchy directly</li>
</ul>


<p>Use case: make split view show up in both landscape and portrait: no
need to make custom VC because now there&#8217;s API to just better configure
split view.</p>

<p>View controllers know themselves if they&#8217;re moving to or from parent
view controllers within viewWillAppear and viewDidAppear by checking:</p>

<pre><code>// used in viewDid/WillAppear
- (BOOL)isMovingToParentViewController;

// used in viewDid/WillDisappear
- (BOOL)isMovingFromParentViewController;

- isBeingPresented;
- isBeingDismissed;
</code></pre>

<p>Lol:</p>

<pre><code>- (BOOL) automaticallyForwardAppearanceAndRotationMethodsToChildViewControllers;
</code></pre>

<h2>RFC</h2>

<p>RFC&#8217;s (Request for Comments):</p>

<blockquote><p>Memos in the Requests for Comments (RFC) document series contain technical and organizational notes about the Internet</p></blockquote>

<p>http://www.ietf.org/about/</p>

<p>So many standards organizations. How am I supposed to keep this separate
from IEEE?</p>

<p>Anyway, RFCs are docs produced by IETF. I don&#8217;t think anyone else
(notable) produces docs called RFCs.</p>

<h2>Push Notifications</h2>

<p>Two levels of trust involved in publishing a push notifications:</p>

<h3>Connection Trust</h3>

<ul>
<li>Provider-side: provider proves it is an authorized provider that
Apple&#8217;s agreed to publish notifications for</li>
<li>Device-side: APNs must validate the connection is a with a legit
device</li>
</ul>


<h3>Token Trust</h3>

<p>Establishes certainty that messages are routed correctly; a provider
shouldn&#8217;t be able to send messages to random iPhones.</p>

<ul>
<li>APNs gives device a token</li>
<li>Devices gives it to provider</li>
<li>Provider uses it when publishing to APNs</li>
<li>APNs uses it to route back to device</li>
</ul>


<p>A <code>device token</code> is not a device <code>UDID</code>; aside from being a totally
different string, it is conceptually different in that it identifies not
only the unique device, but the application the Push Notification is
delivered to.</p>

<p>Maybe that&#8217;s what&#8217;s confusing: don&#8217;t call it a <code>device token</code>, call
it&#8230; an app-token? I get confused by the easiest things.</p>

<h3>Providers must maintain persistent connection</h3>

<p>If you want to send a notification through APNS (and GCM),
you must maintain a persistent connection to the server. In other words,
you can&#8217;t just connect-sendmessage-disconnect a la HTTP, which makes
push notifications inconvenient for Rails-y architectures without
using Sidekiq/Resque to reuse a persistent connection.</p>

<p>I both:</p>

<ol>
<li>failed to realize that this was a requirement for a while and</li>
<li>failed to understand why</li>
</ol>


<p>The best justification for this architecture that I can determine from
the docs and people I&#8217;ve talked to is that constantly
connecting/disconnecting to what is a high-performance, low-latency,
distributed system would be a colossal waste of resources and a latency
hit. An app capable of notifications is essentially a stream that APNS
consumes, and might be sending thousands of messages, so either way
they&#8217;d at least need to support a persistent connection for performance
reasons, and if they&#8217;re going to support that, why bother supporting
an obviously deficient connect/disconnect-based server interaction.</p>

<p>How many other services can be considered consumers of your stream?</p>

<h3>Service-to-Device Connection Trust</h3>

<p>Device identity is established via TLS peer-to-peer auth (internally;
iOS devs don&#8217;t need to implement this).</p>

<ul>
<li>Device TLS auths w APNs</li>
<li>APNs returns certificate, which it validates</li>
<li>Device sends device certificate to APNs</li>
<li>APNs valiates device certificate</li>
</ul>


<p>So I guess this prevents:</p>

<ul>
<li>an iPhone mimicker pretending to be something it&#8217;s not</li>
<li>an APNs ripoff pretending to be something it&#8217;s not</li>
</ul>


<h3>Provider-to-APNS connection trust</h3>

<p>Same process as above, just w provider (your server) and APNS.</p>

<p>A connection to APNs can only serve a single application, identified by
the topic (bundle ID) specified in the certificate, presumably the
one you generate in the online dev console. Also, APNs has a certificate
revocation list; if a provider is on that list, it&#8217;s connection will be
refused/closed. I think this would happen if you didn&#8217;t implement a
persistent connection to APNs but rather treated it like HTTP and kept
closing/opening the connection.</p>

<h3>Token Generation and Dispersal / token trust</h3>

<p>Jesus christ why don&#8217;t I just RTFM? It solves all the problems. Ah yes,
arm-chair ADD.</p>

<ul>
<li>Application asks system to register</li>
<li>System (iOS) forwards this to APNs</li>
<li>APNs generates device token using info in the certficate (presumably
the one established as described above) and encrypts it, and sends
back the encrypted token</li>
<li>App gets the encrypted key as an <code>NSData</code>, and must send it to the
provider in hexidecimal format</li>
</ul>


<p>This guarantees that only APNs generated the token used for routing
(since it&#8217;s encrypted by some private key within APNs). This token can
only be used for the device that originally connected to receive
notifications.</p>

<h3>Trust components</h3>

<p>e.g. keys/certificates you need to create/provide to APNs for all of
this shit to work:</p>

<ul>
<li><p>Provider</p>

<ul>
<li>unique provider certificate and private key for validating
connection to APNs</li>
<li>certificate identifies a topic that the provide can publish to (the
app&#8217;s bundle id).</li>
<li>Provider provides device token.</li>
<li>Provider can additionally validate that it&#8217;s talking to APNs using
the public server certificate provide&#8230; at connection time?</li>
</ul>
</li>
<li><p>Device</p>

<ul>
<li>obvious stuff already covered</li>
</ul>
</li>
</ul>


<p>Note: &#8220;topic&#8221; today is literally the bundle ID of the app. A certificate
identifies which apps it&#8217;s allowed to broadcast notifications to via
this topic. Maybe in the future, topics can refer to multiple apps?
Right now it&#8217;s coupled to bundle ID, in the future, this could be a
configurable thing&#8230; multiple apps could subscribe to the same topic?
This is all bullshit atm but what I think based on their terminology.
It&#8217;s really just a really constrained pub-sub, where apps can&#8217;t
subscribe to message channels other than the one that uniquely
identifies their app+device tuple.</p>

<h3>Coalescing</h3>

<p>APNs is last-write wins in that that in the case of multiple
notifications, only the last one will be stored-forwarded to the app.
This isn&#8217;t to say they coalesce within your device (validated by the
fact that you&#8217;ll see multiple messages from IRCCloud rather than a
single one saying &#8220;new messages available&#8221;), but specifically refers to
the storage of messages undeliverable because the client app&#8217;s turned
off. GCM gives you more fine-grained control over this.</p>

<h3>Summary</h3>

<p>So, given that I&#8217;ve been fighting this bullshit, realizations:</p>

<p>I need to stop revoking/re-creating the APNs app certificate generated
in the Apple Dev console. It&#8217;s not like it&#8217;s tied to some private/public
key or anything.</p>

<h2>Difference b/w .pem and .cer, etc</h2>

<p>I had to run this to convert .cer to .pem</p>

<pre><code>openssl x509 -in aps_development.cer -inform DER -out aps_development.pem
</code></pre>

<h3>X.509</h3>

<pre><code>http://en.wikipedia.org/wiki/X.509
</code></pre>

<p>X.509 is an ITU-T (Telecommunication Standardization Sector)
standard that describes certificate generation, revocation, and other
utilities. <code>openssl</code> just happens to support x509 certificate
generation.</p>

<p>Remember: x509 means one thing: certificates. If you see x509 in the
wild, it&#8217;s probably talking about certificates. x509 certificates.
Certificates.</p>

<p>x509 is unlike PGP in that it maintains a hierarchical chain of
certificate signers, each validated by the previous, with a root CA
(Certificate Authority) starting the chain. PGP relies (or at least
originally relied on) a Web of Trust.</p>

<h3>PEM</h3>

<p><code>---BEGIN CERTIFICATE---</code> and <code>---END CERTIFICATE---</code>.</p>

<p>Can contain multiple certificate and even the prviate key. &#8220;The private
key&#8221;? Which private key? Answer: the one that&#8217;s automatically generated
by Keychain Access and similar utilities when you create a Certificate
Signing Request (CSR).</p>

<p><a href="http://stackoverflow.com/a/7947362/914123">See here</a></p>

<p>TODO: can you even use an existing public/private key? Probably, but
possibly less secure:</p>

<p><a href="http://en.wikipedia.org/wiki/Certificate_signing_request">Read the wiki, you dingus</a></p>

<h2>PKCS</h2>

<p>(public key cryptography standards) created by RSA Security in the 90s.
It&#8217;s a family of standards relating to cryptography.</p>

<p>PCKS 1 is a standard, PCKS 9 is a standard, PCKS 12 is a standard.</p>

<p>Exporting multiple cryptography shits in a single file falls under the
PKCS 12 standard. PKCS 12 also handles bundling all the members of a
CHAIN OF TRUST.</p>

<blockquote><p>It is commonly used to bundle a private key with its X.509 certificate or to bundle all the members of a chain of trust.</p></blockquote>

<p>Makes sense, must be a common thing. Apple obviously does that. AWS SNS
expects you to upload a <code>.p12</code> that it splits into a cert and priv key.</p>

<p>File name extension is <code>.p12</code> (which I&#8217;ve seen) or <code>.pfx</code> which I&#8217;ve
not.</p>

<p><a href="http://en.wikipedia.org/wiki/PKCS_12">Wiki</a></p>

<p>So if I understand correctly, the purpose of certificate is so that you
can encrypt data, and anyone who wants to validate that you are who you
say you are can look up the certificate chain.</p>

<p>You create a pub/priv key pair, create a CSR with it, and then the
approving authority gives you a certificate that you can hand to other
people. The certificate can be used to validate that whatever you
encrypted with your (still unshared and totally) private key, can be
guaranteed to have originated from you. Without certification, you&#8217;re
just some entity with a pub/priv key pair&#8230; and&#8230; I don&#8217;t know, need
to read up more on the implications of this. Amazing how hard this stuff
is.</p>

<p>Anyway, <code>pkcs12</code> is the <code>openssl</code> file utility for creating/parsing
pkcs12 file.</p>

<h2><code>man</code> page sections</h2>

<p>Valid:</p>

<pre><code>man crontab
man 1 crontab # equiv to above
man -s 1 crontab # equiv to above
man 5 crontab 
man -s 5 crontab # equiv to above
</code></pre>

<p>Invalid:</p>

<pre><code>man 2 crontab # No entry for crontab in section 2 of the manual
man 3 crontab # ditto
man 4 crontab # ditto
</code></pre>

<p>Why would it have pages 1 and 5 but not 2-4?</p>

<p><a href="http://en.wikipedia.org/wiki/Man_page">Ahhhh!</a></p>

<p>Turns out there are sections (that vary by platform):</p>

<pre><code>1   General commands
2   System calls
3   Library functions, covering in particular the C standard library
4   Special files (usually devices, those found in /dev) and drivers
5   File formats and conventions
6   Games and screensavers
7   Miscellanea
8   System administration commands and daemons
</code></pre>

<p><code>crontab</code> has no system calls, lib fns, special files, but it does have
general commands and file formats.</p>

<p><code>man</code> isn&#8217;t just unix commands, but also lib, system calls, C functions,
etc.</p>

<p>These sections also handle cases when unrelated concepts have the same
name&#8230; there might be an <code>exit</code> C fn (there is) and an <code>exit</code> terminal
command.</p>

<p>This explains the wording here:</p>

<pre><code>No entry for printf in section 4 of the manual
</code></pre>

<p>You don&#8217;t look up the <code>printf</code> page, and then its section 4
subsection&#8230; rather, you look up entries in a section of <code>man</code>.</p>

<p>That&#8217;s the same reason it&#8217;s <code>man 3 printf</code> rather than <code>man printf 3</code></p>

<p>God, such an obvious thing I never understood/remembered.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/13/daily-journal/"/>
    <updated>2014-07-13T15:18:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/13/daily-journal</id>
    <content type="html"><![CDATA[<h2>HTML is an API, getAttribute</h2>

<p>HTML is just a string of characters that get converted into DOM. You can
also create DOM via the JavaScript DOM API. Seems like an obvious thing
I guess but it just clicked for me.</p>

<p>What&#8217;s an attribute? It&#8217;s any key-value pair (or occasional boolean)
within an open tag.</p>

<pre><code>&lt;div id="lol" snaggletooth="blorg"&gt;&lt;/div&gt;
</code></pre>

<p><code>id</code> and <code>snaggletooth</code> are attributes. During HTML parsing, the browser
will convert this isn&#8217;t an HTML element (which is a node). HTML elements
have a fixed set of <em>properties</em>. All the <em>attributes</em> you provide in
your HTML that map to known properties will set the values of those
properties, hence <code>.id</code> gets set to &#8220;lol&#8221;, but <code>.snaggletooth</code> would
yield <code>undefined</code>, because that&#8217;s obviously not a real property name.</p>

<p>http://jsbin.com/bejog/1/edit</p>

<p>This also explains why you can set an <code>&lt;input&gt;</code>&#8217;s value to &#8220;wat&#8221;, then
type in a new value in the input field, and <code>getAttribute("value")</code> will
still yield <code>"wat"</code> even though <code>inputElement.value</code> will equal whatever
you typed in.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/08/daily-journal/"/>
    <updated>2014-07-08T14:31:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/08/daily-journal</id>
    <content type="html"><![CDATA[<p>This blog left intentionally blank. There are flashcards about browser
networking attached to it.</p>
]]></content>
  </entry>
  
</feed>
