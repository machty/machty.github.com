<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[machty's thoughtz]]></title>
  <link href="http://machty.github.com/atom.xml" rel="self"/>
  <link href="http://machty.github.com/"/>
  <updated>2014-09-30T18:26:05-04:00</updated>
  <id>http://machty.github.com/</id>
  <author>
    <name><![CDATA[Alex Matchneer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Daily Shnurgle]]></title>
    <link href="http://machty.github.com/blog/2014/09/27/daily-shnurgle/"/>
    <updated>2014-09-27T09:29:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/27/daily-shnurgle</id>
    <content type="html"><![CDATA[<h2>lseek</h2>

<p>&#8220;long&#8221; (int) seek. There used to just be a <code>seek</code> that took a smaller
int.</p>

<p>You can seek past EOF and the kernel will be fine with it; reads yield 0
and set EOF flag, but writing will cause a &#8220;file hole&#8221; to exist, wherein
null bytes are returned but aren&#8217;t actually written to disk until
someone writes into the hole.</p>

<pre><code>File.open("seektestfile", "r+") do |f|
  f.write("begin")
  f.seek(10, IO::SEEK_SET)
  f.write("end")
end
</code></pre>

<p>Then open <code>seektestfile</code> in vim to see the null bytes. Pretty rad. But
again keep in mind that those null bytes aren&#8217;t actually there on disk
(well actually I guess it&#8217;s up to the kernel to figure out whether the
hole is large enough to warrant the overhead of splitting into a
different block; some file systems don&#8217;t offer file holes at all).</p>

<p>A file is just a collection of allocated disk blocks. No guarantee their
in the same order. But you could use <code>posix_fallocate</code> to reserve
multiple blocks even if you&#8217;re writing to different places in it to make
sure that future writes will succeed rather than risk some other
application filling a hole and blah.</p>

<p>How many bytes in a block/sector in OS X? <code>diskutil info /</code> reveals
(among other things):</p>

<pre><code>Device Block Size:        512 Bytes
</code></pre>

<p>That&#8217;s the hardware block size, which can be different than the file system
block size (the fs block size must of course be >= device block size).</p>

<p>The <code>stat</code> command tells you information about files, like their size n
shit. It has a format option which is like printf. You could be like
<code>stat -f "hello world"</code> and &#8220;hello world&#8221; would be the output, having
run <code>lstat</code> on STDIN and printing out no actual information about it.</p>

<p><code>ioctl</code> is useful for special-cased IO scenarios, like controlling a
terminal device special file. You pass it an op code which determines
what the remaining parameters are.</p>

<h2>syscalls and atomicity</h2>

<p>Examples of system calls that accept flags to ease race condition pain:</p>

<ol>
<li><code>O_EXCL</code> when opening a file throws an error if it already exists;
otherwise you&#8217;d have to try and open it (to see if it exists), and
then try to create it if it doesn&#8217;t, in which time another process
could have come in and created it. <code>O_EXCL</code> guarantees that if the
open succeeds, that process is the owner of the new file.</li>
<li><code>O_APPEND</code> opens a file AND moves its pointer to the end in one shot,
otherwise two processes trying to append might clobber each other
between their <code>seek</code> and <code>write</code>s. Some systems like NFS don&#8217;t
support it and are prone to this race condition. WRONG. I wrote the
wrong thing. <code>O_APPEND</code> actually works by opening the file, flagging
it in such a way that all writes also atomically include an EOF seek.
If <code>O_APPEND</code> worked the way I first described (an <code>open</code> + a
<code>seek</code>), the race condition described could still happen.</li>
</ol>


<h2>File descriptors vs open files</h2>

<p>You can have multiple file descriptors point to the same open file. This
for example happens automatically every time you fork a program (its FDs
get dup&#8217;d).</p>

<p>The kernel maintains</p>

<ul>
<li>a per-process table of descriptors

<ul>
<li>close-on-exec flag</li>
<li>reference to the system-wide open file description</li>
</ul>
</li>
<li>a system-wide table of open file descriptions (the open file table)

<ul>
<li>current file offset (from reads/writes/seeks)</li>
<li>status flags from when the file was open()ed (read-only, etc)</li>
<li>reference to the i-node</li>
</ul>
</li>
<li>file system i-node table</li>
</ul>


<p>Note that there&#8217;s an on-disk i-node and an in-memory i-node that has a
lot more information about locks and other kernel-specific things that only make sense
to open files rather than just static files living on a disk somewhere.</p>

<p><code>fork</code>ing and UNIX domain sockets are two (of many? maybe?) ways for two
processes to have a file descriptor that points to the same system wide
descriptions.</p>

<p>I originally thought the file offset was stored per descriptor, but
apparently it lives in the shared description record? Only one way to
find out:</p>

<pre><code>File.open('shareddesctest.txt', 'w') do |f|
  if fork
    # parent
    f.seek(1, IO::SEEK_SET)
    Process.wait
  else
    # child
    sleep 1
    f.write "wat"
  end
end
</code></pre>

<p>If I open vim, I see <code>^@wat</code>, which means in fact the offset is shared:
parent seeks to offset 1, child waits for this to happen, and then
writes to a file descriptor it hasn&#8217;t touched yet, and it starts writing
at where the parent <code>seek</code>ed to. So indeed offsets are stored in the
shared system-level open file description.</p>

<h2>Redirection and dup2</h2>

<p><code>./a.out &gt; wat 2&gt;&amp;1</code> will pipe both STDOUT and STDERR into the <code>wat</code>
file, using a single system-level file description. How does this work?
Pretty hilariously-jankly.</p>

<ul>
<li>File descriptors are just integers (stdout=1, stderr=2)</li>
<li>To redirect stderr to stdout, you have to duplicate stdout&#8217;s file
descriptor but make sure that that final descriptor has a value of 2,
so that code that writes to stderr (2) is unaffected and will
successfully keeping writing to the newly redirected stream.</li>
<li>File descriptor integers are reused; the various syscalls that
allocate file descriptors always choose the smallest unused file
descriptor int.</li>
<li>So you could 1. close stderr and 2. dup stdout, and this would work,
but not if stdin (0) had already been closed, since the new handle
would take the lower value 0. LOL.</li>
<li>So you have to use <code>dup2</code>, which lets you specify the number of the
file descriptor you&#8217;d like to allocate. Which is what shells with
stream redirection support. :)</li>
</ul>


<p>Duping FDs can also be done w <code>fcntl</code> and <code>F_DUPFD</code>.</p>

<h2>IO at specific offset</h2>

<p>Good for concurrent processes in some cases, you can use <code>pread</code> and
<code>pwrite</code> to perform IO at a specific offset without modifying the file
pointer.</p>

<p>A single syscall is way more performant than multiple ones, hence the
value in <code>pread</code> and friends. You also sidestep certain race conditions.
Then again the time to do IO often dwarfs syscall overhead.</p>

<h2>Scatter IO</h2>

<p><code>readv</code> reads a contiguous chunk of data from a file descriptor and
distributes into multiple buffers supplied to the syscall. <code>writev</code>
writes a contiguous chunk of data to the file.</p>

<p>This avoids certain race conditions, allows you to combine multiple
reads/writes.</p>

<h2><code>/dev/fd</code></h2>

<p>Virtual directory of file descriptors, e.g. 0, 1, 2 (stdin, stdout,
stderr, and some others). Useful for passing a command line utility a
filename when you really want it to read from stdin, e.g.</p>

<pre><code>echo 'wat' | diff /dev/fd/0 olderwat
</code></pre>

<p>Note that you could also do process substitution:</p>

<pre><code>diff &lt;(echo 'wat') olderwat
</code></pre>

<p>which has the same effect but creates a new descriptor rather than
reusing the stdin descriptor.</p>

<p>Note that these process subsitution file handles also live in <code>/dev/fd</code>:</p>

<pre><code>echo &lt;(echo wat) 
# /dev/fd/63
</code></pre>

<h2>&#8220;Header Search Paths&#8221; vs &#8220;User Header Search Paths&#8221;</h2>

<p>User: <code>#include "wat.h"</code>
Non-user: <code>#include &lt;wat.h&gt;</code></p>

<h2>Process vs Program</h2>

<p>A Process is an instance of a Program. A Program is a description of how
to construct a Process.</p>

<p>Program consists of:</p>

<ul>
<li>Binary format ID: describes the format of the executable.</li>
<li>Machine code</li>
<li>Program entry point address; address to <code>int main</code>, or something that
quickly calls <code>int main</code>.</li>
<li>data (constants, default starting values)</li>
<li>symbol/relocation tables: locations and names of functions, for
debugging purposes but also dynamic linking</li>
<li>shared libs: list of dynamic libs for run time linking</li>
</ul>


<p>A process has an initialized data segment and uninitialized data
segment. The former contains all starting values for a program, hence
it&#8217;s stored in disk space, whereas uninitialized data gets initialized
at process start up through a more dynamic process and hence the space
it occupies doesn&#8217;t need to be stored on disk. Uninitialized data gets
zeroed out.</p>

<ul>
<li>Program break: the &#8220;top&#8221; of the heap</li>
</ul>


<p>Application Binary Interface (ABI) set of rules for what registers are
set, etc., when interacting with some low-level service, like the
kernel. SUSv3 standardizes this API so that you&#8217;re using a higher level
than some ultra low level API.</p>

<h2>Locality of reference</h2>

<p>In regards to memory access and optimizations based thereupon.</p>

<ul>
<li>spatial locality: tendency for memory accesses to be near recent
memory accesses (e.g. traversing a data structure, sequential
execution of code)</li>
<li>temporal locality: tendency to access a recently accessed location
(e.g. a loop)</li>
</ul>


<p>This is part of what makes virtual memory possible; it&#8217;s largely pretty
rare to suddenly need to access a non-resident page.</p>

<p>Each process has a page table, which maps pages to their physical RAM
locations. If you access a page that&#8217;s not in RAM, then page fault
occurs (kernel takes over).</p>

<p>Not all virtual memory address regions have a corresponding page, in
which case, SIGSEGV.</p>

<p>The range of valid virtual addresses changes as the stack grows and more
stuff is allocated on the heap (malloc). Also when you run <code>mmap</code>.</p>

<p>Virtual memory requires hardware support, specifically a Paged Memory
Management Unit, which needs to be smart enough to do address
translating but also notify the kernel of page faults.</p>

<p>VM keeps memory isolated between processes unless you really really want
to share: <code>shmget</code> and <code>mmap</code> let you do this as a means of
Inter-Process Communication. It works by having page table entries point
to the same region of RAM, allowing for the different process page table
entries to have different permissions, e.g. one process might have read
access but other has write access to the same page frame in physical
memory.</p>

<p>There&#8217;s a per-process kernel stack which maps to kernel RAM and is
therefore inaccessible when not in kernel mode. This is used for syscall
stacks. I need to read more about this; why can&#8217;t there be a system-wide
kernel stack shared between processes? Isn&#8217;t only one process going to
be in kernel mode at any given time? Maybe not&#8230; if multiple processes
are blocked on IO, does that mean they&#8217;re all in kernel mode? TODO: come
back to dis shiz.</p>

<h2>argv argc</h2>

<p><code>argv[0]</code> is the process name which can be used to switch the behavior
of multiple commands that all point to the same executable.
<code>gzip/gunzip/etc</code> is an example of this. <code>ls -lai</code> yields:</p>

<pre><code>343041 -rwxr-xr-x  4 root  wheel  43200 Oct 31  2013 /usr/bin/gzip
343041 -rwxr-xr-x  4 root  wheel  43200 Oct 31  2013 /usr/bin/gunzip
</code></pre>

<p>Same inode 343041. Here&#8217;s all of em (<code>find /usr/bin -inum 343041</code>):</p>

<pre><code>/usr/bin/gunzip
/usr/bin/gzcat
/usr/bin/gzip
/usr/bin/zcat
</code></pre>

<p>Apparently there&#8217;s no easy way to find all the files that link to an
inode (the above was simple only because they all happened to be in the
same directory).</p>

<p>Note that you can&#8217;t hard-link directories.</p>

<p>Short of stashing global vars, you can&#8217;t access argv and argc (Ruby
facilitates this for you though), unless you&#8217;re willing to do some
non-portable stuff.</p>

<pre><code>kernel
argv,environ
stack
...
heap
uninitialized data
initialized data
text (program code)
...?
</code></pre>

<p><code>argv</code> lives right above the stack.</p>

<h2>env vars</h2>

<p>If you just do</p>

<pre><code>wat=lol
</code></pre>

<p>that sets a shell variable, not strictly an env var tied to the shell
process that gets with children. Functionally, it&#8217;s an environment var
that doesn&#8217;t get passed to children when forked.</p>

<p>You could then put it into the process env via</p>

<pre><code>export wat
</code></pre>

<p>or in one shot</p>

<pre><code>export wat=lol
</code></pre>

<p>You can set a child processes env var (without polluting parent shell
variable list or environment vars) via</p>

<pre><code>wat=lol somecommand
</code></pre>

<p>in which case ARGC for somecommand will be 0. If you did</p>

<pre><code>somecommand wat=lol
</code></pre>

<p>ARGC would be 1, and ARGV[1] would be &#8220;wat=lol&#8221; rather than an env var.</p>

<p>Order of env vars is implementation specific; you don&#8217;t want to rely on
this shiznittletons.</p>

<h2>Streams and LazyValue</h2>

<p>LazyValue is coming to Ember along with HTMLbars. LazyValues are a kind
of / relative of Observables, with the unique feature that they avoid
the back pressure of pushing values into the stream by merely replacing
the current value and notifying an end consumer that the stream has been
invalidated, letting the final consumer decide when it should consume
and actually flush the lazy value through all of its transformations.</p>

<p>I was wondering what the technical term for a stream that doesn&#8217;t mind
&#8220;dropping&#8221; &#8220;samples&#8221; before it has a chance to consume the latest value.
Apparently the word for that is a &#8220;signal&#8221;&#8230;?</p>

<h2>brk and sbrk</h2>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;

int main() {
  void *curBrk;

  for (int i = 0; i &lt; 1; ++i) {
    curBrk = sbrk(0);
    printf("brk is %p\n", curBrk);
  }

  return 0;
}
</code></pre>

<p>brk sets the brk lowest address of a process&#8217;s data segment
(uninitialized) to addr.</p>

<p>These are mad deprecated. Use malloc. Malloc will grow the heap for you
rather than making you set the break. <code>free</code> won&#8217;t shrink the break but
rather just return a chunk to the free list. Why?</p>

<ul>
<li>most frees are in the middle of the heap (as opposed to the edge,
where shrinking the break makes sense)</li>
<li>syscalls are expensive</li>
</ul>


<p>Mac OS X specifics: just from a few experiments I can verify that the
stack grows downward, the break is really small, but malloc seems to be
producing pointer values much closer to the stack than the break. What
gives? No idea.</p>

<p><code>free(NULL)</code> is a noop. <code>malloc(NULL)</code> might return a small piece of
memory that can be freed.</p>

<p><code>malloc</code> scans the free list for something >= the required amount. If >
than the required amount, the free block is split. Different
implementations might be first-fit or best-fit. If nothing found, <code>sbrk</code>
is called to increase it, by some multiple of the virtual memory page
size.</p>

<p><code>free</code> knows the size of the block to free because malloc sneakishly
inserts the length at the beginning of a chunk of allocated memory.</p>

<p>Wow, the algorithm for free and malloc is pretty awesome.</p>

<p>Let&#8217;s see nothing&#8217;s been allocated on the heap. Your free list is a
single element doubly-link list</p>

<pre><code>|Length of Block|prevBlock*|nextBlock*|empty space|
</code></pre>

<p>Then you <code>malloc(4)</code>. It&#8217;ll start at the beginning of that list, see
that <code>4</code> is less than the length of the block, and then it&#8217;ll split that
block. Hmm, so the pointer to the free list needs to remain the same&#8230;
so either malloc&#8217;d block could get put at the end, length of block is
decremented. Yeah that&#8217;s probably how it works.</p>

<p>TL;DR: the free list is a doubly-linked list whose nodes are stored in
the same chunk of memory that&#8217;ll be distributed when mallocs occur. I
always wondered where the &#8220;free list&#8221; lived&#8230; it seemed like one of
those problems where it&#8217;d be mallocs all the way down, but this is
a pretty elegant solution, but it also explains how quickly shit can go
haywire if you accidentally futz with freed values.</p>

<p>The specific algorithm can vary; glibc uses a boundary tag approach,
wherein an allocated chunk includes size of previous chunk, size of
current chunk, and then user space, then size of chunk.</p>

<p>So how are SIGSEGVs detected on double-frees?</p>

<p>http://www.opensource.apple.com/source/Libc/Libc-594.1.4/gen/malloc.c</p>

<p>I think Apple&#8217;s version of malloc tracks allocated blocks (rather than
just a free list). So it&#8217;ll loop through that list and make sure it&#8217;s
actually in there. I think glibc see does something else, where it loops
through the free list to see if it&#8217;s already in there? Or some other
efficient thing using the boundaries stored in adjacent blocks? Unsure.</p>

<p><code>alloca</code> lets you dynamically allocate on the stack by moving the stack
frame pointer downward. It gets &#8220;collected&#8221; one you return from the
function. Not standardized but most systems have it? It&#8217;s useful if
you&#8217;re actually writing a program that necessitates <code>longjump</code> since
heap-allocated memory in the stack frames you&#8217;re skipping over can&#8217;t
possibly be freed, but you get the &#8220;free&#8221; for free if it was allocated
via <code>alloca</code>. That being said, you probably shouldn&#8217;t use it. :)</p>

<h2>Users and Groups</h2>

<p>You can have multiple usernames/passwords map to the same UID. This
means multiple users can be granted the exact same privileges by nature
of them literally being distinguishable by username but not UID.</p>

<p><code>wheel</code> comes from the phrase &#8220;big wheel&#8221; (&#8220;she&#8217;s a big wheel at
Microsoft&#8221;), it refers to a group with admin privileges. <code>admin</code> is
also one such group. <code>root</code> is a member of both:</p>

<pre><code>wheel:*:0:root
admin:*:80:root
</code></pre>

<p>On Mac OpenDirectory is used instead; you can see all of the
<code>/etc/group</code> groups in Directory Utility. <code>wheel</code> is System Group,
<code>admin</code> is Administrators, and there&#8217;s a bunch of other ones specific to
applications, which seem to be prefixed via underscore blah blah blah
who cares.</p>

<h2>groups, permissions</h2>

<p>A process with effective user ID of 0 is a <em>privileged process</em>.</p>

<p>A process starts off with a real user and group ID and can change its
effective user and group ID.</p>

<p>Processes that don&#8217;t start off with the privileges they need can be
granted the ability to set their effective user and group ids, but only
to the owner or group, e.g. I, user <code>peon</code>, can execute <code>a.out</code> (if it
has <code>a+x</code> perms) and have <code>a.out</code> grant itself the permissions that its
owner has.</p>

<pre><code>machty.github.com :: ls -la wat
-rw-r--r--  1 machty  staff  0 Sep 28 09:23 wat
machty.github.com :: chmod u+s wat
machty.github.com :: ls -la wat
-rwSr--r--  1 machty  staff  0 Sep 28 09:23 wat
</code></pre>

<p>The capital <code>S</code> means set-user-id-able but non-executable (this is rare
and maybe useless?). If I do <code>chmod u+x wat</code> it becomes:</p>

<pre><code>-rwsr--r--  1 machty  staff  0 Sep 28 09:23 wat
</code></pre>

<p>If I set group, it&#8217;d be the next column of bits.</p>

<p>Note that there&#8217;s no setUID call that the process has to make to enter
this mode; rather, the bit causes the kernel to set the effective user
or group ID once the process begins to run.</p>

<p>Here&#8217;s all the <code>/usr/bin</code>s that have set-user-id</p>

<pre><code>machty.github.com :: ls -la /usr/bin | grep '^...[Ss]'
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 at
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 atq
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 atrm
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 batch
-rwsr-xr-x     1 root   wheel     35136 Oct 31  2013 crontab
-rws--x--x     1 root   wheel     23008 Oct 31  2013 ipcs
-r-sr-xr-x     1 root   wheel     68240 Mar 10  2014 login
-r-sr-xr-x     1 root   wheel     44416 Mar 10  2014 newgrp
-r-sr-xr-x     1 root   wheel     19664 Oct 31  2013 quota
-r-sr-xr-x     1 root   wheel     20720 Mar 10  2014 rlogin
-r-sr-xr-x     1 root   wheel     19856 Mar 10  2014 rsh
-rwsr-xr-x     1 root   wheel     21488 Oct 31  2013 su
-r-s--x--x     1 root   wheel    164896 Oct 31  2013 sudo
-r-sr-xr-x     1 root   wheel     83856 Oct 31  2013 top
</code></pre>

<p>and all the set-group-ids</p>

<pre><code>machty.github.com :: ls -la /usr/bin | grep '^......[Ss]'
-rwxr-sr-x     1 root   mail      24640 Oct 31  2013 lockfile
-rwxr-sr-x     1 root   mail      84656 Oct 31  2013 procmail
-r-xr-sr-x     1 root   tty       20832 Mar 10  2014 wall
-r-xr-sr-x     1 root   tty       19920 Oct 31  2013 write
</code></pre>

<p><code>wall</code> writes some nonsense to everyone&#8217;s terminal: <code>echo wat | wall</code>.</p>

<p>Processes have the ability to switch in and out of their set-uids and
set-group ids. In other words, a program might have its set-uid enabled
(and its owner is root), but it&#8217;s bad/unsafe practice to let a program
just run in root mode the whole time; rather, it should only switch into
root mode when doing stuff that requires privileges, and then switch
back.</p>

<p>In Linux there&#8217;s also the concept of file-system IDs and groupd IDs,
which follow effective ID/group except when <code>setfsuid</code> and <code>setfsfid</code>
are called. But they&#8217;re seldom used. They only exist to cover use cases
of <code>NFS</code>.</p>

<h2>Ruby Base64</h2>

<pre><code>require 'base64'
Base64.encode64("borf") # =&gt; "Ym9yZg==\n"
Base64.strict_encode64("borf") # =&gt; "Ym9yZg=="
</code></pre>

<ul>
<li><code>encode64</code> implements the base64 referenced in
<a href="https://www.ietf.org/rfc/rfc2045.txt">IETF 2045</a>,
the RFC on Multipurpose Internet Mail Extensions (MIME).</li>
<li><code>strict_encode64</code> implements the base64 specified
in <a href="http://tools.ietf.org/html/rfc4648">IETF 4648</a>, which
goes into more detail, gets rid of the newlines</li>
</ul>


<p>I used to have to do <code>gsub(/\n/, "")</code> after encoding to get Ruby&#8217;s
<code>encode64</code> to be compatible with some other that was more picky about
Base64.</p>

<p>Also, I was wondering why the <code>==</code> exist. Base64 converts any bytestream
to a 64 bit alphabet. In other words, 2<sup>6</sup> characters. Consider the
following random 3 byte stream:</p>

<pre><code>01011010 00001111 10101111
</code></pre>

<p>We&#8217;re used to thinking of them split by 8 bits, but a base64 character
can only account for 6 bits, so you&#8217;d actually think of it like:</p>

<pre><code>010110 100000 111110 101111
</code></pre>

<p>This explains why encoding as base 64 has a 4/3 size overhead, an
important consideration before willy nilly encoding a bunch of giant
assets at base 64.</p>

<p>It also explains why encoding strings whose lengths aren&#8217;t a multiple of
3 end up adding <code>=</code> padding (&#8220;borf&#8221; => &#8220;Ym9yZg==\n&#8221;).</p>

<h2><code>ls -d</code></h2>

<p>e.g. <code>ls -ld somedir</code> to show the directory entry rather than expanding
it and listing all of its files.</p>

<h2>Y2K for epoch 32 bit = year 2038</h2>

<p>The epoch + 32 bit signed int max = year 2038.</p>

<h2>Service Workers</h2>

<p>http://www.w3.org/TR/service-workers/#motivations</p>

<p>https://github.com/slightlyoff/ServiceWorker/blob/master/explainer.md</p>

<p>Alex Russell&#8217;s been working on this. It&#8217;s a huge improvement over the
declarative app cache. A ServiceWorker is a WebWorker that can get
installed on page load, and then once installed, is consulted on future
page loads, even if there isn&#8217;t any internet.</p>

<blockquote><p>Documents live out their whole lives using the ServiceWorker they start with.</p></blockquote>

<p>This means if no service worker existed at initial doc download, then
installing a ServiceWorker on the first load means the ServiceWorker
will have to completely sit out for the lifetime of that page. It&#8217;s only
on feature reload where it might get consulted. This slightly off
behavior results in:</p>

<ul>
<li>better fallback for unsupporting browsers</li>
<li>makes sure that people write good URLs whether using ServiceWorkers
or not</li>
<li>Zalgo issues with pages suddenly switching in and out of being managed
by a ServiceWorker</li>
</ul>


<p>Other things of note:</p>

<ul>
<li>ServiceWorkers can die, be aborted, be restarted</li>
<li>So don&#8217;t write them to be stateful.</li>
<li>Or if so, use IndexedDB. (If ServiceWorkers are available, IndexedDB
is available)</li>
</ul>


<h2><code>od</code>: octal decimal dumps</h2>

<pre><code>echo "a" | od

0000000    005141
0000002
</code></pre>

<p>I&#8217;d expect just one stupid byte, why are there multiples?</p>

<p>Oh duh because <code>echo</code> includes a newline.</p>

<pre><code>echo -n "a" | od 

0000000    000141
0000001
</code></pre>

<p>Wat.</p>

<pre><code>echo -n "aa" | od
0000000    060541
0000002
</code></pre>

<p>Oh right, this is an octal dump. Here&#8217;s binary</p>

<pre><code>echo -n "aa" | od -b
0000000   141 141
0000002
</code></pre>

<p>Makes more sense. The leftmost column is just a row indicator.
At some point it&#8217;ll wrap, and you always look at the last one for an
indicator of the length thus far.</p>

<pre><code>echo -n "big ass set of bytes" | od -b
0000000   142 151 147 040 141 163 163 040 163 145 164 040 157 146 040 142
0000020   171 164 145 163
0000024
</code></pre>

<p>See? It wraps automagically.</p>

<h2>cwd</h2>

<p>Processes have <code>cwd</code>s. They&#8217;re the starting point for filename lookups.
A shell&#8217;s current directory is that shell&#8217;s <code>cwd</code>. You can use
<code>getcwd(3)</code> to get the current one.</p>

<p>What&#8217;s the difference between <code>pwd</code> and <code>cwd</code>? <code>pwd</code> is a command that
stands for Print Working Directory. It prints the <code>cwd</code>. But it does so
with the <code>PWD</code></p>

<p><code>$PWD</code> is an env var you can check. <code>$OLDPWD</code> is set when you <code>cd</code> and
<code>cd -</code> uses it.</p>

<p>Soooo I believe the answer to everything is this: the kernel knows about
<code>cwd</code>, but doesn&#8217;t track the absolute path to it in string form; it&#8217;s
just a pointer, which is all it needs in conjunction with relative file
paths to locate and open/create/unlink files, etc.</p>

<p>Shells on the other hand provide a convenience built-in <code>pwd</code> and
expose/manage the <code>$PWD</code> var (et al) to provide a string.</p>

<h2>Hard-linking directories.</h2>

<p>Forbidden in most things, allowed in Mac OS X; twas responsible for
the data loss bug in Broccoli, since <code>rm -rf</code> ing a directory would
follow that link and kill shit.</p>

<p>Why does Mac allow it? Apparently it&#8217;s used in Time Machine. If a
directory hasn&#8217;t changed, a new snapshot can just point to the same
directory inode without duplicating it.</p>

<p>Great explanation: http://stackoverflow.com/a/4707231/914123</p>

<p>By the way <code>ln</code> and <code>link</code> are the same executable:</p>

<pre><code>$ ls -lai `which link`
11551 -rwxr-xr-x  2 root  wheel  14976 Oct 31  2013 /bin/link
$ ls -lai `which ln`
11551 -rwxr-xr-x  2 root  wheel  14976 Oct 31  2013 /bin/ln
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Snaggletooth]]></title>
    <link href="http://machty.github.com/blog/2014/09/23/daily-snaggletooth/"/>
    <updated>2014-09-23T11:18:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/23/daily-snaggletooth</id>
    <content type="html"><![CDATA[<h2>Nginx Heroku Buildpack</h2>

<p>https://github.com/ryandotsmith/nginx-buildpack</p>

<blockquote><p>Some application servers (e.g. Ruby&#8217;s Unicorn) halt progress when
dealing with network I/O.</p></blockquote>

<p>This was confusing at first but I think it just means that since
Heroku&#8217;s router only buffers headers and not the entire request, it&#8217;s
possible that a slow client with a large payload will hog a unicorn
worker due to a slow blocking <code>read()</code>, in which time that worker isn&#8217;t
available to process other requests.</p>

<p>The proposed nginx buildpack solution is to put nginx in front of an
IO-bound (and poorly designed/optimized) server and buffer the entire
request and not engage the app server until all the data is there, and
then it can barf the entire request into the app server in one shot,
minimizing blocking IO.</p>

<p>In general though Unicorn is non-ideal in the following cases:</p>

<ul>
<li>Slow client and/or large payload</li>
<li>The app server is internally IO-bound and makes, say, lots of long
slow 3rd party API requests, because in that time it&#8217;s blocking
requests that otherwise could have been handled in a less IO-bound
setting</li>
</ul>


<h2>TTL: Time to Live</h2>

<p>http://en.wikipedia.org/wiki/Time_to_live#IP_packets</p>

<p>Some reason I always pronounced &#8220;live&#8221; as a-live. Rather than the verb
&#8220;live&#8221;. Why? I don&#8217;t know. Time to Live (verb) makes way more sense. How
much time it has to live, rather than, how much time until it is live.
Ridiculous.</p>

<ul>
<li>IP: a per-gateway decrementing value (as opposed to a unit of time).
In other words: IP TTL is max hop.</li>
<li>DNS: time in seconds that a DNS record can be cached. Low values tax
authoritative name servers. Higher values risk staleness. 86400 (24
hours) is common. Before a DNS change, DNS admins might change to a
lower number in advance. QUESTION: why would I, selfish DNS admin, not
just choose a TTL of 1 all the time? Presumable answer: DNS is another
roundtrip unless cached; I might be making my application slower.
Additionally, if DNS goes down (probably rare?), my clients can
still use
<code>#networking</code> validates my presumable answer.</li>
</ul>


<h2>HTTPSAP</h2>

<p>HTTPS Ain&#8217;t a Protocol. It&#8217;s just HTTP layered over TLS, an encrypted
transport layer.</p>

<h2>Resetting Wifi of Remote Mac server</h2>

<p>Heh, this worked</p>

<pre><code>#!/bin/bash

networksetup -setairportpower en1 off
sleep 10
networksetup -setairportpower en1 on
</code></pre>

<p>Run via <code>nohup ./thisdumbscript &amp;</code>.</p>

<p>SSH will be unresponsive for 10+ seconds and then recover. The Magic of
the INTERNET!</p>

<h2>WebSockets and proxy servers</h2>

<p>http://www.infoq.com/articles/Web-Sockets-Proxy-Servers</p>

<p>Websockets work on port 80 and 443:</p>

<blockquote><p>HTML5 Web Sockets do not require new hardware to be installed, or new ports to be opened on corporate networks&#8211;two things that would stop the adoption of any new protocol dead in its tracks.</p></blockquote>

<p>Transparent proxy server: let&#8217;s stuff through, might manipulate content?</p>

<h2>BOSH: Bidirectional-streams Over Synchronous HTTP</h2>

<p>http://en.wikipedia.org/wiki/BOSH</p>

<p>Isn&#8217;t this just long polling? It&#8217;s long polling with the assurance that
immediately after receiving a &#8220;push&#8221;, the client makes a new long-lived
request on the same keep-alive connection. And it can make no more than
one connection whenever it needs to send data. Why does this have its
own stupid name?</p>

<h2>SSH Tunneling</h2>

<p>First off, you can just execute commands like</p>

<pre><code>ssh machty@whatever.com ls
</code></pre>

<p>and assuming I&#8217;ve already done the keygen stuff, that&#8217;ll log in, run
<code>ls</code>, and output the result of that.</p>

<p>But you can use <code>ssh</code> to spin up a local server that makes your SSH
connection act as a proxy to some other IP/port, map that to a local
port, and then connect other things through to that local port.</p>

<p>If I did</p>

<pre><code>ssh machty@wat.com -L 8080:somesite.com:80
</code></pre>

<p>Then I could do</p>

<pre><code>curl localhost:8080
</code></pre>

<p>and then see the contents of somesite.com as a request originating from
the wat.com server I &#8220;logged&#8221; into. (Except that most sites don&#8217;t
respond the way you&#8217;d like if <code>Host</code> and other headers are incorrect).</p>

<h2>What is my public IP?</h2>

<p>You need some third party to tell your your public IP after all the NAT
traversals. You shouldn&#8217;t use this for super sensitive stuff (it&#8217;s
possible the 3rd party server was compromised and maaaaybe there&#8217;s some
exploit if you use this fake IP for some internal thing?).</p>

<p>But this worked for me:</p>

<pre><code>curl icanhazip.com
</code></pre>

<p>Someone on SO suggested this: http://www.moanmyip.com/</p>

<p>I can&#8217;t believe that exists.</p>

<h2>SOCKS proxy</h2>

<p>https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-tunneling-on-a-vps</p>

<p>http://en.wikipedia.org/wiki/SOCKS</p>

<p>With a SOCKS proxy</p>

<h2>tcptraceroute</h2>

<p>Instead of ICMP ECHO packets, which often get filtered out at some point
by some asshole proxy along the way to the destination, tcptraceroute
uses TCP SYN packets instead. What&#8217;s that you say? Don&#8217;t we still need
the incrementing TTL that ICMP uses? TRICK QUESTION: TTL is an octet in
the IP packet, which wraps TCP/UDP/ICMP. So <code>tcptraceroute</code> still uses
TTL. It&#8217;s also nice enough to send a TCP RST (reset) package if the the
destination responds with a SYN|ACK so that you don&#8217;t leave it in a
connection-half-opened state (normally you&#8217;re supposed to send an ACK
and then start sending application data).</p>

<p>Interesting: you need root privileges to run tcptraceroute. Why? Because
the custom SYN packets it creates requires root privileges, probably to
prevent non-privileged users from doing malicious things with packets.
I&#8217;d be curious to know exactly where that takes place though.</p>

<h2>IP packets have no port</h2>

<p>Why? Because ports map to applications, a concept which IP packets don&#8217;t
care about; they&#8217;re all about getting messages to an address. Leave it
to the UDP/TCP packets to provide a source and destination</p>

<p>So hmmm how does ICMP traceroute work? How do the ECHO&#8217;d packets know to
come back to that specific traceroute command?</p>

<h2>ICMP</h2>

<ul>
<li>No port</li>
</ul>


<p>There&#8217;s a single ICMP socket apparently?</p>

<p>https://www.cs.utah.edu/~swalton/listings/sockets/programs/part4/chap18/ping.c</p>

<pre><code>/*
 * pr_pack --
 *  Print out the packet, if it came from us.  This logic is necessary
 * because ALL readers of the ICMP socket get a copy of ALL ICMP packets
 * which arrive ('tis only fair).  This permits multiple copies of this
 * program to be run without having intermingled output (or statistics!).
 */
</code></pre>

<ul>
<li>ident = getpid() &amp; 0xFFFF;

<ul>
<li>this is how a pong that returns is identified as originating from a
pong.</li>
</ul>
</li>
</ul>


<p>Anyway here&#8217;s a little Ruby program you can run with <code>sudo</code>
that&#8217;ll open a raw socket and print a Base64&#8217;d ping packet if you
<code>ping localhost</code>.</p>

<pre><code>require 'socket'
require 'base64'

rsock = Socket.open(:INET, :RAW)

loop do
  s = rsock.recv(1024)
  enc = Base64.encode64(s)
  puts enc
end
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Juggernaut]]></title>
    <link href="http://machty.github.com/blog/2014/09/20/daily-juggernaut/"/>
    <updated>2014-09-20T12:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/20/daily-juggernaut</id>
    <content type="html"><![CDATA[<h2>Rust is a &#8220;Systems&#8221; programming language</h2>

<p>Seems vague. You can use it for games (<code>#rust-gamedev</code> or
<code>/r/rust_gamedev</code>). What does systems mean?</p>

<p><code>#rust</code> tells me more vague stuff, but basically:</p>

<ul>
<li>Rust doesn&#8217;t impose garbage collection, so you maintain fine-grained
control over memory in that regard</li>
<li>Rust integrates nicely with C</li>
</ul>


<p>These features are often compared with Go. Go has GC. Go apparently
doesn&#8217;t integrate as nicely with C (not sure how true this is, need to
dig in). Apparently Go used to advertise itself as systems, then they
stopped, and Rust adopted that term to make it clear how it is different
from the oft-compared Go.</p>

<h2><code>source</code> and <code>export</code></h2>

<p>I always knew the <code>source</code> command as the command you use when you want
to run a script with a bunch of <code>export</code> definitions, but all it really
means is that <code>source</code> doesn&#8217;t actually make new process but just runs
the code in the source file as shell commands. As such, it means that
any environment vars set in the sourced command don&#8217;t get set in a
separate child process that dies and forgets set vars.</p>

<p><code>export</code> makes sure that an env var gets passed to child processes. Just
setting an env var without <code>export</code> won&#8217;t mark it to be shared with
child processes.</p>

<p>You can verify all of this by <code>source</code>ing a script with a long <code>sleep</code>
and then checking <code>ps</code> to verify that <code>sleep</code> is a direct child of
<code>bash</code>; there&#8217;s no intermediate process running that execution.</p>

<h2>prey project</h2>

<p>Protect your devices from theft:</p>

<p>https://preyproject.com/</p>

<p>TODO: look into this shit.</p>

<h2>awesome cheese</h2>

<p>Stompetoren Grand Cru. With Effie&#8217;s Homemade Oatcakes.</p>

<p>So fucking good.</p>

<p>http://bedfordcheeseshop.com/products/stompetoren-gouda-grand-cru</p>

<h2>Why is CORS disabled for XHR but not a 3rd party post?</h2>

<p>CSRF is still a thing, but falls outside of CORS because CORS intends to
make JavaScript-initiated requests safe. Then again didn&#8217;t
Chrome/Mozilla just make fonts CORS-y?</p>

<h2>Access-Control-Allow-Origin</h2>

<p>I&#8217;d get this error in devtools console whenever my Rails code errored
out during an XHR request:</p>

<pre><code>XMLHttpRequest cannot load http://localhost:5000/wat
No 'Access-Control-Allow-Origin' header is present on the requested resource.
Origin 'http://localhost:4200' is therefore not allowed access. 
</code></pre>

<p>It&#8217;s misleading since I have CORS set up correctly, but apparently not
for erroring requests? Basically, using XMLHTTPRequest (ajax) is going
to set the <code>Origin</code> request header, which flags the server to send back
CORS headers. If the browser doesn&#8217;t see those CORS headers, or the
provided ones don&#8217;t match / grant proper permissions, then the XHR
request will fail.</p>

<p>So basically I have an error in my server code I need to fix. Maybe it&#8217;s
good that CORS fails upon error? Because if not, then I might be opening
up some third party door that&#8217;s sniffing my site due via erroneous
requets? I can&#8217;t really see it but maybe.</p>

<h2>Why won&#8217;t my dumbass server work?</h2>

<p>Scenario: I have a remote Minecraft server. It runs from a persistent
tmux session so that I can log in and run server commands on it. I can
ping it successfully but when I try to join, it fails to connect with
authentication servers. There&#8217;s lots of reported issues online with
authentication servers but I think in my case no outbound requests are
succeeding. <code>curl google.com</code> yields no response, and neither do pings.</p>

<p>Whoops. I just remotely turned off the server&#8217;s wifi and got
disconnected. I figured I&#8217;d turn it off and on again to see if that
&#8220;rebooted&#8221; things. But, uh, kinda need internet through that whole
process. Dumbest moment of 2014.</p>

<h2>Do shells fork to start new processes?</h2>

<p>Yes. Bash will fork itself and then calls execve to transform itself
into a new process.</p>

<p>There&#8217;s also an <code>exec</code> built-in command that will replace your bash
instance with whatever you wanna run, which means when the new command
terminates, your bash terminal will close, e.g.:</p>

<pre><code>exec sleep 1
</code></pre>

<p>An &#8220;Environment list&#8221; maintains the key value pairs of env vars. When
you exec a new process, it either inherits the env of its parent or gets
a new one. In C-land, the <code>char ** environ</code> variable is exposed contain
all env vars, testable via:</p>

<pre><code>#include &lt;stdio.h&gt;
extern char **environ;
int main() {
  printf("%s\n", environ[0]);
  return 0;
}
</code></pre>

<h2>mmap</h2>

<p>Virtual memory mapping. It&#8217;s a syscall to map a region of virtual memory
to a file, or to create an anonymous mapping that doesn&#8217;t write to a
file.</p>

<h2>CGI / Rack limitations</h2>

<p><a href="http://en.wikipedia.org/wiki/Common_Gateway_Interface">Common Gateway Interface</a></p>

<p>http://blog.plataformatec.com.br/2012/06/why-your-web-framework-should-not-adopt-rack-api/</p>

<p>Shortcoming: middlewares that allocate/release resources</p>

<h2>Mac Desktop Shell Scripts</h2>

<p>Save this with <code>+x</code> chmod permissions as <code>~/Desktop/wat.command</code>.</p>

<pre><code>#!/bin/bash
echo "wat"
</code></pre>

<h2>htop</h2>

<p><code>brew install htop</code></p>

<p>It&#8217;s top but way way more bitchin. OMG, it even has a tree mode.</p>

<h2>man vs info</h2>

<p>Just discovered that there&#8217;s both <code>man bash</code> and <code>info bash</code>. <code>info</code> was
added in the 90s by GNU, who felt <code>man</code> was too crappy a manual system for
sophisticated software.</p>

<h2>Job control / monitor mode</h2>

<p>Bash (et al, but apparently not Bourne?) implement job control, the
ability to suspend resume jobs (process groups) via an interactive
shell. Job control is enabled when &#8220;monitor mode&#8221; is on. In bash, this
is enabled by default. To disable: <code>set +m</code>. To enable: <code>set -m</code>. When
disabled, you&#8217;ll see things like:</p>

<pre><code>$ fg
-bash: fg: no job control
</code></pre>

<p>You also won&#8217;t be able to ^Z out of a running process (a SIGTSTP still
fires but bash ignores it). <code>ruby -e "Process.kill(:TSTP,0)"</code> runs to
completion when monitor mode is disabled.</p>

<p>Actually hmm, interesting, if you disable monitor mode and run</p>

<pre><code>ruby -e "Process.kill(:STOP, 0); puts 'done'"
</code></pre>

<p>then it just runs to completion? How is that possible?
My guess is that the process stops, and then is immediately resumed
because there&#8217;s nothing to take its place? Seems SIGSTOP is ignored even
when you sent it from another terminal to a terminal with -m.</p>

<p>Also, you can display all the shell options via <code>echo $-</code></p>

<pre><code>himBH
hiBH # monitor mode disabled
</code></pre>

<h2>Dollar signs</h2>

<p>http://stackoverflow.com/a/5163260/914123</p>

<pre><code> 1. Positional parameters `$1,$2,$3â€¦` and their corresponding array representation, count and IFS expansion `$@`, `$#`, and `$*`.
 2. `$-` current options set for the shell.
 3. `$$` pid of the current shell (not subshell)
 4. `$_` most recent parameter (or the abs path of the command to start the current shell immediately after startup)
 5. `$IFS` the (input) field separator
 6. `$?` most recent foreground pipeline exit status
 7. `$!` PID of the most recent background command
 8. `$0` name of the shell or shell script
</code></pre>

<h2>syscalls</h2>

<p>Example: <a href="http://www.opensource.apple.com/source/tcl/tcl-5/tcl/compat/waitpid.c">waitpid</a></p>

<p>Wrapper C functions stash args in registers, stash syscall id in <code>%eax</code>,
and then runs a <code>trap</code> machine instruction, which tells the processor to
switch into kernel mode. (Recent hardware uses <code>sysenter</code> instead of
slower <code>trap</code>, which incurred interrupt overhead&#8230; TODO: learn about
interrupts!). The rest is obvious enough.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journeaux]]></title>
    <link href="http://machty.github.com/blog/2014/09/17/daily-journeaux/"/>
    <updated>2014-09-17T08:08:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/17/daily-journeaux</id>
    <content type="html"><![CDATA[<h2>nginx book</h2>

<p>This is nice: http://aosabook.org/en/nginx.html</p>

<p>Some random notes:</p>

<p>For CPU-bound loads, number of nginx workers should equal the number of
cores (&#8220;TCP/IP, doing SSL, or compression&#8221;). For IO-bound stuff
(&#8220;serving different sets of content from storage, or heavy proxying&#8221; &#8211;
presumably teh &#8220;different sets&#8221; is important because if it were
the same stuff, it&#8217;d probably be cached which I guess means the IO would
be negligible? unsure) &#8211; you might want 1.5-2 times the number of
cores.</p>

<h2>SSL/TLS random questions:</h2>

<p>I have so many misconceptions? For anyone who reads this, this is stream
of thought as I try to answer my own questions before looking shit up.</p>

<p>How come domains are signed and not IPs?</p>

<p>Reasoned guess: first off, everyone can encrypt data. It&#8217;s just that the
key thing that TLS brings in is certification of a sending. It&#8217;s not
enough to say &#8220;yo here&#8217;s my public key&#8221;, you still have to answer the
question &#8220;uh ok yes but who are you?&#8221;. Certificate authority to the
rescue.</p>

<p>So what if CA&#8217;s certified IPs, rather than domain names (maybe they do,
I don&#8217;t actually know at this point)? Some ideas come to mind:</p>

<ul>
<li>DNS can map to multiple IPs, and a single IP might load balance to
many different servers, all of which should be able to (de)/encrypt
incoming traffic.</li>
</ul>


<p>That&#8217;s actually probably the only reason. I was originally thinking
that since IPs can change, you might certify server A and then the next
day the IP changes to server B, and that that would mean the CA is
giving a stamp of approval to the wrong server, but then, duh, it&#8217;s key
pairs that are being validated, and server B wouldn&#8217;t have these keys
and wouldn&#8217;t know how to do the handshake. I think this is close to
correct, it&#8217;s just I&#8217;m forgetting everything that happens internally
within the handshake.</p>

<p>http://en.wikipedia.org/wiki/Transport_Layer_Security</p>

<h2>Symmetric Key</h2>

<p>A single key encrypts plaintext and decrypts the ciphertext generated
from the encryption.</p>

<p>Example: AES.</p>

<h2>Cipher suite</h2>

<p>https://www.iana.org/assignments/tls-parameters/tls-parameters.xhtml#tls-parameters-4</p>

<p>A triple of</p>

<ul>
<li>authentication</li>
<li>encryption</li>
<li>and message authentication c</li>
</ul>


<h2>SSL / TLS</h2>

<p>Lots of people use them interchaangeably, but SSL was originally created
at Netscape and used to be implemented at the application layer, living
on top of TCP. When it was IETF standardized, it was renamed TLS and
moved out of the application layer.</p>

<p>TLS provides:</p>

<ul>
<li>encryption

<ul>
<li>obfuscate data transmitted from one computer to another</li>
<li>example: plaintext means zero encryption and easily breakable
ciphertext means shitty encryption</li>
</ul>
</li>
<li>authentication</li>
<li>verify that you&#8217;re talking to who you think you&#8217;re talking to</li>
<li>example: the CA validates the certificate that a server sends you</li>
<li>integrity

<ul>
<li>detect message forgery or tampering</li>
<li>example:</li>
</ul>
</li>
</ul>


<h2>Beware the intermediaries</h2>

<p>Intermediaries are caching servers, gateways, web accelerators, content
filters, blah blah blah, all the stuff that&#8217;s come out to aid and extend
HTTP. They&#8217;re often transparent to the end user, but they come with the
limitation that if you start wanting to deviate from HTTP on port 80 in some
application specific way, you&#8217;re boned. And it&#8217;s kinda rare to find
other ports that are open: 80 and 443 (HTTPS) are usually open but
everything else is often closed. These intermediaries might improperly
try to apply their logic to the non HTTP, etc, there&#8217;s no easy way to
detect when or when not to apply.</p>

<p>Solution: HTTPS tunnel all the things. All data is obfuscated from
intermediaries and intermediaries have no way of known whether the
encrypted data is HTTP or some custom proprietary crazy thing.</p>

<h2>Self-signed certificates</h2>

<p>http://www.akadia.com/services/ssh_test_certificate.html</p>

<p>Things learned:</p>

<ul>
<li>&#8220;If the private key is no longer encrypted, it is critical that this file only be readable by the root user!&#8221;</li>
<li>You can remove the DES from the private key so that you don&#8217;t have to
type in the password all the god damn time when your server starts.
(Verified this with a node app)</li>
</ul>


<p>Turns out you could also just run the following:</p>

<pre><code>openssl req -new 
</code></pre>

<p>So why is DES required at all? I&#8217;m guessing it&#8217;s possible to generate a
CSR without it, right?</p>

<h2>ALPN: Application-Layer Protocol Negotiation</h2>

<p>Note to dummy: there&#8217;s no TLS 3 way handshake. You&#8217;re thinking of TCP
ACK SYN SYNACK that has to happen before app data is exchanged.</p>

<p>ALPN takes place during the</p>

<h2>SNI: Server Name Indication</h2>

<p><a href="https://www.ietf.org/rfc/rfc3546.txt">rfc, page 8</a></p>

<p>If you have a server that you want to host multiple sites with their own
respective TLS certificates,</p>

<h2>self-signed-certificate</h2>

<p>Useful for testing SSL before you go ahead and buy a certificate for 3rd
party validation.</p>

<h2>AES vs RSA</h2>

<p>AES is symmetric, and generally speaking symmetric encryption/decryption
is a lot faster than assymetric, hence AES is used for the
encryption/decryption of data.</p>

<h2>Sprite gotchas</h2>

<p>I used to think sprites were bitchin; save HTTP requests, combine all
your images into one. Obviously, these are lame application-level
optimizations/hacks to cover the ass of the transport layer&#8217;s (HTTP&#8217;s)
shortcomings (addressed in SPDY / HTTP 2.0).</p>

<p>Downsides of sprites:</p>

<ul>
<li>all the application-layer crap you have to do to handle it</li>
<li>change a single pixel of a single image and you&#8217;ve busted a massive
cached of all the other images in the sprite</li>
<li>memory intensive; you might not be using each image but you have to
load all of it in memory, might be too much for mobile clients</li>
</ul>


<h2>Octet</h2>

<p>It means byte. Saw it all over the place in the
<a href="https://datatracker.ietf.org/doc/draft-ietf-httpbis-http2/?include_text=1">HTTP 2 spec draft</a></p>

<h2>nginx</h2>

<p>After <code>brew install nginx</code></p>

<pre><code>Docroot is: /usr/local/var/www

The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that
nginx can run without sudo.

To have launchd start nginx at login:
    ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
Then to load nginx now:
    launchctl load ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist
Or, if you don't want/need launchctl, you can just run:
    nginx

WARNING: launchctl will fail when run under tmux.
</code></pre>

<p>What is docroot?</p>

<ul>
<li>It&#8217;s a file&#8230; not a directory?</li>
<li>But you can delete it and replace with a directory and put an
index.html in there and it works</li>
<li>So I guess there&#8217;s some default configuration of nginx that just hosts
static files from this doc root directory</li>
</ul>


<p>What do them commands does?</p>

<pre><code>ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
</code></pre>

<p>What are launchd and launchctl?</p>

<p><code>launchd</code> is a daemon (conventions dictate that daemons end in a <code>d</code>).
<code>launchctl</code> is what you use to control that daemon. So if you want to
schedule something to start</p>

<p>What&#8217;s the <code>mxcl</code> in <code>homebrew.mxcl.redis.plist</code>?</p>

<p>It refers to <code>mxcl</code>, maintainer of Homebrew. Just normal reverse domain
name notation. So does that mean any homebrew-installed domains get
prefixed like that? I&#8217;m guessing <code>mxcl</code> also made the Redis recipe.
Or maybe every homebrew daemon gets prefixed like that? Not sure, who
cares.</p>

<pre><code> In the launchd lexicon, a "daemon" is, by definition, a system-wide service of
 which there is one instance for all clients. An "agent" is a service that runs
 on a per-user basis. Daemons should not attempt to display UI or interact
 directly with a user's login session. Any and all work that involves interacting
 with a user should be done through agents.
</code></pre>

<p><a href="https://developer.apple.com/library/mac/technotes/tn2083/_index.html">TN2083 - Daemons and Agents</a></p>

<p>Wow, &#8220;Daemonomicon&#8221; is an awesome word: &#8220;formal definition of the types
of bg programs you can write&#8221;.</p>

<ul>
<li>bootstrap server: launchd</li>
<li>root session: first and last session. Boot-time processes and daemons
live here. User-independent. e.g. <code>mDNSResponder</code></li>
<li>login session: proceses launched by or for a user live in login
session. Login sessions are associated w authenticated users. Each
user</li>
</ul>


<p>If I</p>

<h2>Origins of TTY</h2>

<p>http://www.linusakesson.net/programming/tty/</p>

<ul>
<li>stock tickers, then ASCII teletype within a network called Telex.</li>
<li>Telex was a network that used level of current to respresent different
characters, vs different voltages used by analog telephone shit</li>
<li>Telex existed before integration w computers</li>
<li>When command lines became the norm, teletypes were used as input and
output since they were readily available on the market</li>
<li>Lots of different models, needed to standardize in some way; UNIX
philosophy dictated letting kernel handle low level word length, baud
rate, flow control, etc., later things like color output, cursor
movement, etc, was left to application (not kernel)</li>
<li>Line editing is managed by OS-provided line discipline. Default is
cooked/canonical mode. raw mode disables things like editing,
backspace, and generally disables any IO processing within the line
discipline.</li>
</ul>


<p>Skipping ahead, you can force your terminal into stty raw mode via</p>

<pre><code>stty raw #enable
stty -raw #disable
</code></pre>

<p>Now I know how to write a Ruby impl of Press Any Key</p>

<pre><code>print "Press any key... "

begin
  system("stty raw -echo")
  c = STDIN.getc
ensure
  # re-enable
  system("stty -raw echo")
end

puts "Thanks!"
</code></pre>

<p>Note that it&#8217;ll consume CTRL-C as well rather than signalling an
interrupt (hence CTRL-C prints &#8220;Thanks!&#8221; rather than terminating
immediately).</p>

<p>This is also how any text editor functions.</p>

<p>This must be what&#8217;s happening when I kill some script when it doesn&#8217;t
expect it and then my terminals fucked. Typing in <code>stty -raw</code> even
though I can&#8217;t see it probably would fix it&#8230; need to try.</p>

<p>Back to the thing:</p>

<ul>
<li>Kernel provides many line disciplines, only one attached to serial
device at a time. Default is <code>n_tty</code>. I guess that&#8217;s what we&#8217;re
configuring when we futz w <code>stty</code></li>
<li>Other disciplines are for things like packet switched data</li>
<li><a href="http://www.cs.fsu.edu/~baker/devices/lxr/http/source/linux/drivers/char/n_tty.c">tty C source code</a></li>
<li>UART (Universal Async Receiver and Transmitter): converts teletype
signal into bytes that the OS can process. OS has a UART driver.</li>
<li>TTY driver: allows user to kill/suspend an infinite looped program,
bg processes can process til they try to write to terminal (at which
point they suspend), and user input to fg process only.
(implemented in <code>tty_io.c</code>)</li>
<li>TTY Device: triplet of UART driver, line discipline, and TTY driver.</li>
<li>TTY devices live in <code>/dev</code> w file mode <code>c</code> for &#8220;Character special
file&#8221;. To manipulate one, you need ownership of the device file
(e.g. via <code>login</code>).</li>
<li>TTYs are just objects. Not alive. Other things plug into it. Those
other things have execution contexts.</li>
<li>pty = pseudoterminal, as opposed to TTY.</li>
</ul>


<p><code>ps -o stat</code> prints out <code>Ss</code> <code>Ss+</code>, etc&#8230; here&#8217;s what the capital
letters mean:</p>

<pre><code>R   Running or runnable (on run queue)
D   Uninterruptible sleep (waiting for some event)
S   Interruptible sleep (waiting for some event or signal)
T   Stopped, either by a job control signal or because it is being traced by a debugger.
Z   Zombie process, terminated but not yet reaped by its parent.
</code></pre>

<p>Most things are in <code>S</code>. An example of <code>R</code>:</p>

<pre><code>ruby -e 'loop {}'
</code></pre>

<p><code>s</code> means session group leader. <code>+</code> means process is part of foreground
process group.</p>

<ul>
<li>Ctrl Z suspends a process, puts it in <code>T</code> state.</li>
</ul>


<p>Jobs, e.g. <code>fg</code> and <code>bg</code> are just process groups. Consider</p>

<pre><code>ruby -e 'loop {}'  | grep a | grep a | grep a
</code></pre>

<p>This causes as CPU-intensive loop and will be in R state.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R+   s045    7:03.43 ruby -e loop {}
machty 45755 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>and when I suspend:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 T    s045    7:29.05 ruby -e loop {}
machty 45755 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 T    s045    0:00.00 grep a
</code></pre>

<p>Everything below it suspends.</p>

<p><code>jobs</code> are tied to session leaders, and terminals are session leaders.
If I go to another tmux pane and type <code>jobs</code>, the suspended job <em>won&#8217;t</em>
show up; I have to be in the same terminal that started it. TODO: can I
change session IDs?</p>

<p>If I <code>bg 1</code>, the following happens:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R    s045    7:39.63 ruby -e loop {}
machty 45755 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S    s045    0:00.00 grep a
</code></pre>

<p>Note how it&#8217;s back to running, but note the missing foreground <code>+</code>. <code>fg 1</code>
would bring it back.</p>

<p>Note that we could turn one of those greps into <code>R</code> if it was actively
processing data, e.g.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 46054 45014 46054      0    4 R+   s045    0:37.84 ruby -e loop { puts "a" }
machty 46055 45014 46054      0    4 R+   s045    0:45.56 grep a
machty 46056 45014 46054      0    4 R+   s045    0:27.01 grep b
machty 46057 45014 46054      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>(Actually, the first 3 R&#8217;s might be S&#8217;s if you re-run this command;
there&#8217;s a race condition as to whether the CPU is actually running code
or whether it&#8217;s blocked on an IO syscall waiting for piped data to come
in, but the last grep is always S+ because it never gets output from the
<code>grep b</code>).</p>

<p>A Job is a Processs Group.</p>

<p>If you&#8217;re just starting/stopping/piping processes, all those child
processes with have a parent process ID of <code>bash</code>&#8217;s pid.</p>

<p>What constitutes a job/process group? Piped commands for one.
Let&#8217;s see about Process Subsitution. Answer: process substitution
doesn&#8217;t consider it as a pipe. It considers it as a shit of epic
fartitude. In other words, process substitution ends up being miserably
old and mortal and definitely going to die. In other words, process
substitution is not in the same process group. It&#8217;s its own process
group. If you do <code>echo &lt;(some long living thing)</code>, the long living thing
will survive as a sibling process, in its own process GROUP WHO CARES.</p>

<p>You can only read from  / write to TTY if you&#8217;re foreground. If you&#8217;re
not <code>fg</code> and you try and write to TTY, kernel will suspend your ass.</p>

<ul>
<li><code>ioctl</code> is the UNIX swiss army knife; manipulates special files like
terminals.</li>
<li><code>ioctl</code> requests must be initated from processes, so the kernel can&#8217;t
asyncly communicate w an application unless the app asked for it.</li>
<li>Signals are how kernel communicates asyncly w a process. Messy and
error prone they are.</li>
</ul>


<p>Question: nohup detaches into its own session id to prevent closing on
SIGHUP&#8230; why does it have to do that? Why can&#8217;t it just ignore that
signal? Let&#8217;s see.</p>

<pre><code>Signal.trap(:HUP) do
  puts "I WILL NOT"
end
sleep
</code></pre>

<p>If I ssh localhost and run that in background (with <code>&amp;</code>) and then
logout, it stays running, PPID changes to 1 (root). So how is that
different than nohup? TODO: find out. Something with setsid, etc.</p>

<p>SIGINT&#8217;s originate from the terminal&#8230; is it correct to say they
originate from TTY? I think it is based on the <code>n_tty.c</code> code.
Also, in raw mode it doesn&#8217;t even fire. COOL.</p>

<ul>
<li>SIGPIPE isn&#8217;t just an error but also a way to know whoever was
listening to you has stopped listening to you, e.g. <code>yes | head</code>.</li>
<li>SIGSTOP is to SIGTSTP as SIGKILL is to SIGQUIT.</li>
<li>SIGCONT can be sent to a ^Z-suspended process. It behaves as if you
started the process with <code>&amp;</code>. It&#8217;s running, but it&#8217;s bg. In other
words, if you have a suspended process 12345, <code>bg 1</code> or
<code>kill -CONT 12345</code> would do the same thing; it&#8217;d start running in the
background, spitting out output</li>
<li>You can break shit with
<code>ruby -e 'Signal.trap(:TTIN) { puts "wat" }; sleep 1; gets' &amp;</code>
(recursive SIGTTIN). You try and write to TTY in the background and
then keep ignoring the signal that it&#8217;s failing. I don&#8217;t know what
causes the deadlock though, but <em>something</em> screwing up sounds right.</li>
<li>If you press ^Z, that sends a message to the foreground process group.
The line discipline sends <code>SIGTSTP</code> to the foreground process group.
This will suspend the whole process group, whatever the main</li>
</ul>


<p>Question: if you use pipes combined with <code>&amp;</code>, what gets put into the
background? All tasks? Answer (I think): <code>&amp;</code> ultimately results in a
process group getting put into the background, and a process group
contains any pipes, child processes, etc, so it <em>must</em> apply to all of
the different processes as a whole, and there&#8217;s no way to say that only
one of the pipe segments runs in the background.</p>

<p>Fun fact: you can reimplement the default ^Z behavior as follows:</p>

<pre><code>has_ignored = false
Signal.trap(:TSTP) do
  if has_ignored
    Process.kill(:STOP, Process.getpgrp)
  else
    has_ignored = true
    puts "ignoring"
  end
end

sleep
</code></pre>

<p>TL;DR the default SIGTSTP ^Z handler fires a STOP. You can catch TSTP
and immediately do the same for the same effect.</p>

<p>Vim&#8217;s source code (and probably everyone&#8217;s) does some variant of</p>

<pre><code>settmode(TMODE_COOK);
kill(0, SIGTSTP);       /* send ourselves a STOP signal */
</code></pre>

<p>So, you return TTY mode to cook mode.</p>

<ul>
<li>If you run something like <code>echo "wat" | less &amp;</code>, you&#8217;ll immediately
see <code>[2]+  Stopped   echo "wat" | less</code> because <code>less</code> is always going
to try and write to TTY in a raw manner&#8230;?</li>
<li>If you suspend, say, vim, vim will catch the SIGTSTP, move the cursor
to the last line of the screen w control signals (it&#8217;s still attached
to TTY) and then fires a SIGSTOP.</li>
<li>Once stopped, a SIGCHLD is sent to the session leader with the pid of
the suspended process. When all processes in fg have been suspended
(T&#8217;d), the current TTY config is stashed for later restoration
(<code>stty -g</code> is one way of doing this).</li>
</ul>


<p>So why doesn&#8217;t ^Z suspend bash?</p>

<p>Ahh, so here&#8217;s how you get TTOU to fire (and cause a process to suspend)</p>

<pre><code>ruby -r "io/console" -e "IO.console.raw { puts 'wat' }" &amp;
</code></pre>

<p>Note that if we hadn&#8217;t used <code>.raw</code> to put TTY in raw mode, it would have
just printed &#8220;wat&#8221; into the same terminal even though the process is
running in the background, but if you grab full control of the TTY with
<code>raw</code>, it&#8217;ll cause a TTOU.</p>

<p>You can go in and configure another TTY to update its rows/cols. I can
fuck w the vim in another tmux pane, tell it its skinnier/wider than it
is, but once i resized a tmux pane then BOOM it fires its own tty
commands, and tty fires a SIGWINCH, and then that causes vim to query
the tty for the current width and repaint.</p>

<p>Ah: realization: the ultimate decider in whether TTOU fires is whether
topstop</p>

<h2><code>read</code></h2>

<pre><code>read words &lt; &lt;(echo "wat")
echo $words
</code></pre>

<h2>resetting the keyboard when things go crazy</h2>

<p><code>reset</code>, or typing Escape and c.</p>

<pre><code>stty raw
reset
</code></pre>

<p>and we&#8217;re back. It resets your TTY driver, I guess.</p>

<h2><code>yes</code></h2>

<p>Repeatedly enter <code>y</code> for saying yes to everything. Like the dropper bird
from the simpsons when homer gets fat. You can also do <code>yes no</code> to say
other things.</p>

<h2>Ack</h2>

<p>is written in Perl.</p>

<h2>100 Continue status</h2>

<p>An HTTP 1.1 mechanism.</p>

<p>http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html</p>

<p>In some cases, a server knows just by looking at request headers that it
won&#8217;t process the request, making it potentially wasteful for the client to send a
giant doomed-to-fail payload. In these cases, the client can decide not
the send the full payload unless the server has told it &#8220;based on your
headers, you should Continue sending this full payload because I don&#8217;t
see any reason why it should fail, just by looking at the headers.&#8221;</p>

<p>To opt into this, the client must provide the following header:</p>

<pre><code>Expect: 100-continue
</code></pre>

<p>The server will see this, decide if the request will succeed, and if so,
it send back 100 Continue and keeps reading from the input stream.
Client then sends the whole payload.</p>

<p>Proxies can reject if it knows the next-hop server is HTTP 1.0 or less
with a 417 Expectation Failed.</p>

<h2>IOS8 breaks file uploads in Safari</h2>

<p>http://blog.fineuploader.com/2014/09/10/ios8-presents-serious-issues-that-prevent-file-uploading/</p>

<p>Jesus. No workaround? Apple, you suck.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/09/15/daily-journal/"/>
    <updated>2014-09-15T19:57:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/15/daily-journal</id>
    <content type="html"><![CDATA[<h2>FTP</h2>

<p>Plaintext, unless you&#8217;re using SFTP or some variant.</p>

<p>FTP uses multiple connections: 1 control connection for sending
commands and tracking current directory, etc, and a connection for
actually streaming the file data.</p>

<p>How the second connection (data) is established depends on active vs
passive mode: in active mode, the server will try to connect back to the
client at PORT+1, and in most modern cases, this will fail due to NATs
and firewalls, hence passive mode (via PASV) command is meant to get
around this. In passive mode, the client requests an IP and port from
the server (via the control connection), and then the client makes the
second connection to whatever the server returns. This works as clients can
generally connect to servers without NAT/firewall issues.</p>

<p>Note that active connections are rare. The man page for <code>ftp</code> is
telling:</p>

<pre><code>-A          Force active mode ftp.  By default, ftp will try to use passive mode
            ftp and fall back to active mode if passive is not supported by the
            server.  This option causes ftp to always use an active connection.
            It is only useful for connecting to very old servers that do not
            implement passive mode properly.
</code></pre>

<h2>Application-level gateway</h2>

<p>http://en.wikipedia.org/wiki/Application-level_gateway</p>

<p>TODO: learn more.</p>

<h2>Process per connection</h2>

<p>One way of handling a new connection is to fork and let the forked
process handle that connection. Makes sense for the parent instance to
use Ruby&#8217;s <code>Process.detach</code>, which doesn&#8217;t have a native kernel
equivalent but is just a Ruby convenience that spins up a thread that
calls <code>wait()</code> on the forked process to prevent it from becoming a
zombie if the parent process exits before the forked one.</p>

<p>Remember that forking isn&#8217;t available on Windows or JRuby.</p>

<p><code>shotgun</code> is a Ruby server that forks per connection. Why? Isn&#8217;t this
wasteful (relative to pre-forking solutions like Unicorn)? Yes, but it
has specific purpose: assuming it&#8217;s not painfully expensive to spin up
your server (like Rails), and that you don&#8217;t have a mechanism for
reloading after code changes (like Rails), <code>shotgun</code> will fork per
connection and entirely reload / spin up the rack server, less reloading
the latest version of any Ruby code, thus not requiring you to manually
restart your server.</p>

<h2>Thread per connection</h2>

<p>Typical state-sharing caveats apply when working with threads, hence
it&#8217;s useful to thing about the simple unit of concurrency that will keep
your threads isolate and minimize their access to shared data. That unit
would be a connection; each thread should get its own connection object.
Create a connection object, immediately create a new thread, and let
that connection object fall out of scope in the creator thread so that
only the newly spawned thread has access to it. Simple enough.</p>

<h2>How to verify your code is on multiple cores</h2>

<p>You have to dig in a little bit to verify that Ruby code you&#8217;re writing
is actually being processed on multiple CPU cores. There are many
variables:</p>

<ol>
<li>Does your system even have more than one core? (try <code>system_profiler | grep 'Total Number of Cores'</code> to find out, probably some other ways too)</li>
<li>Does your Ruby have a GIL? (MRI does, Rubinius and JRuby don&#8217;t)</li>
<li>Some third thing to pad my arbitrary list of bullshit.</li>
</ol>


<p>Anyway, one easy way is to run the following code:</p>

<pre><code>NUM_CORES = 2

threads = []
NUM_CORES.times do |t|
  threads &lt;&lt; Thread.new do
    log_every = 1000000
    i = 0
    loop do
      i += 1
      if i == log_every
        i = 0
        putc t.to_s
      end
    end
  end
end

threads.each(&amp;:join)
</code></pre>

<p>Running this on MRI Ruby results in 100% CPU usage. Running in JRuby
yields 200%, which means two cores are operating at 100%. Pretty rad,
yes?</p>

<p>CPU usage reported by activity monitor or <code>top -o cpu</code>.</p>

<h2>Preforking</h2>

<p>e.g Unicorn</p>

<p>What&#8217;s nice is that the kernel will handle load-balancing for us: when
there are no incoming requests, you have N forked instances blocked on
<code>accept</code>, and the kernel will choose which instance gets the next
incoming request. If all forked instances are busy, the kernel will just
queue up the request internally. If the queue gets full, you&#8217;ll get an
ECONNREFUSED. Easy peazy.</p>

<p>Unicorn (and probably Rainbows) does some extra tracking on child
processes to make sure it&#8217;s not getting stuck on long requests, etc.</p>

<p>Main disadvantage is memory usage. By the time you fork, if the parent
process is 100 mb, then 4 forks and you&#8217;re at 500 mb&#8230; unless 1) your
OS has COW and 2) you don&#8217;t write to it all that much.</p>

<h2>Reactor</h2>

<p>e.g. Node.js, Twisted, EventMachine</p>

<p>High levels of concurrency (not necessarily parallelism) achievable,
relative to threading/forking models, which hit their RAM limit much
faster (Reactor patterns mean that everything is just heap allocations
on the same thread).</p>

<p>Impacts on programming model:</p>

<ul>
<li>No processes/threads, so no shared memory, synchronization, etc, to
have to worry about</li>
<li>Don&#8217;t block the single Reactor thread (because nothing else will be able to
run). You wouldn&#8217;t have to worry about this in thread/processland.
This is why if you&#8217;re using EventMachine, your gems must be
event-machine aware, otherwise they&#8217;ll block (which would be fine in a
threading/forking environment).</li>
</ul>


<h2>Node cluster</h2>

<p>http://nodejs.org/api/cluster.html</p>

<p>Based on the fact that you can use child process forking to split heavy
duty work into process that can each live on a different core, if that&#8217;s
what you&#8217;re about.</p>

<p>Note that there&#8217;s no C-like or Ruby-like fork in Node; you can&#8217;t just
call fork and then have both the parent and newly forked child process
continue execution from that <code>fork()</code> invocation&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/09/06/daily-journal/"/>
    <updated>2014-09-06T14:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/09/06/daily-journal</id>
    <content type="html"><![CDATA[<h2>netcat (nc)</h2>

<p>Utility to spinning up arbitrary tcp servers for testing, sending
packets, etc.</p>

<pre><code>Socket.new(Socket::AF_INET, Socket::SOCK_STREAM)
or symbols:
Socket.new(:INET6, :STREAM)
</code></pre>

<p>INET = internet, specifically IPv4, <code>SOCK_STREAM</code> means a TCP stream
will be set up, as opposed to <code>DGRAM</code>, which would set up UDP.</p>

<p>Set up bullshit listener:</p>

<pre><code>nc -l localhost 4481
</code></pre>

<h2>Loopback</h2>

<p><code>localhost</code> is a loopback, which is a virtual interface where any data
sent to the loopback is immediately received. <code>127.0.0.1</code> is the IP.</p>

<p>Check dat <code>/etc/hosts</code> file:</p>

<pre><code>##
# Host Database
#
# localhost is used to configure the loopback interface
# when the system is booting.  Do not change this entry.
##
</code></pre>

<p>Funny how I never notice stuff like that until someone officially
defines it for me.</p>

<h2>&#8220;well-known&#8221; ports</h2>

<p>Hosted by IANA.org, the Internet Assigned Numbers Authority.</p>

<h2>Gerrymandering</h2>

<blockquote><p>manipulate the boundaries of (an electoral constituency) so as to favor one party or class.</p></blockquote>

<p>Knew what this was, forgot the word for it.</p>

<h2>AWS Spot Instances</h2>

<p>Running interruption-tolerant applications on EC2 unused capacity, where
you can bid on price per hour and maximum bid price.</p>

<h2>Chekhov&#8217;s Gun</h2>

<p>http://en.wikipedia.org/wiki/Chekhov&#8217;s_gun</p>

<blockquote><p>Remove everything that has no relevance to the story. If you say in the first chapter that there is a rifle hanging on the wall, in the second or third chapter it absolutely must go off. If it&#8217;s not going to be fired, it shouldn&#8217;t be hanging there.</p></blockquote>

<p>Anton Chekhov is considered to be among the greatest writers of short
stories in history. Guess I should start reading.</p>

<h2>Binding to an interface</h2>

<p>You can bind to a single interface, or ALL interfaces, lol!</p>

<p><code>0.0.0.0</code> means all interfaces. I guess that means that requests to
localhost, and potentially some other external facing interface, will
route requests to this socket. So what if someone has already bound
specifically to localhost:12345 and you try to bind to <code>0.0.0.0:12345</code>?</p>

<p>Answer: I don&#8217;t know&#8230; need to learn about what other interfaces are
available</p>

<p>REVISED ANSWER: I can use the IP provided by my router.</p>

<pre><code>ruby -run -e httpd . --port=4124 --bind-address=192.168.1.3
</code></pre>

<p>Then if I type <code>localhost:4124</code> in the browser, it don&#8217;t work, but if I
type <code>192.168.1.3:4124</code> in the browser, IT WORKS. :)</p>

<p>But to the original question, it turns out you can run ALL THREE of
these:</p>

<pre><code>ruby -run -e httpd . --port=4123 --bind-address=0.0.0.0
ruby -run -e httpd . --port=4123 --bind-address=192.168.1.3
ruby -run -e httpd . --port=4123 --bind-address=localhost
</code></pre>

<p>So the first and 3rd of these should be able to respond to</p>

<pre><code>curl localhost:4123 &gt; /dev/null
</code></pre>

<p>It seems that the third (localhost) always wins. Makes sense. What about</p>

<pre><code>curl 192.168.1.3:4123 &gt; /dev/null
</code></pre>

<p>And the more specific second one always wins. So I guess the OS will
look for a match of interface+port before falling back to 0.0.0.0.
Makes sense.</p>

<h2>listen queue size</h2>

<pre><code>socket.listen(10)
</code></pre>

<p>This means your socket will buffer up to 10 connections before
<code>ECONNREFUSED</code> is return to the shits on the other side.</p>

<p>If you&#8217;re getting a lot of ECONNREFUSED, it probably means users are
already experiencing some some queue-based lag, and you should rethink
your architecture, spin up more server instances, etc. But you can also
just set to the max size via</p>

<pre><code>server.listen(Socket::SOMAXCONN)
</code></pre>

<h2>A connection is a socket</h2>

<p>When you accept() after binding, you&#8217;ll get a connection object, which
is just a Socket, but different from your server socket; it&#8217;s just a
file wrapper for that particular connection that you can write shit to.</p>

<h2>quadruple of remote/ip/port must be unique</h2>

<p>You can&#8217;t have more than one connection where</p>

<pre><code>local addr, local port, remote addr, and remote port
</code></pre>

<p>are not totally unique. Hmmm, so where is this prevented? TODO</p>

<h2>Close socket file descriptors</h2>

<p>Why, doesn&#8217;t this happen automatically on exit/GC?</p>

<ol>
<li>GC might not clean up for you fast enough;</li>
<li>Might hit file descriptor limit</li>
</ol>


<p>Wat wat wat wat in the boot.</p>

<p>You can close the read side, or close the write side, or both. This make
use of <code>shutdown</code>, and shutdown will close a side of a connection even
if you&#8217;re dup&#8217;d file descriptors (explicitly or via fork). <code>close</code>
wouldn&#8217;t actually close unless there were no other file descriptors
holding on to that socket.</p>

<h2>Keybase</h2>

<p>Uses social media accounts to prove crypto identity.</p>

<h2>Clients don&#8217;t need to bind</h2>

<p>to a port when connecting to a server. For obvious reasons. Namely that
a server needs to have a known/consistent port in order for clients to
reach it, but a client can just send from any ol po,]rt.</p>

<h2>Long ass timeouts</h2>

<pre><code>require 'socket'
socket = Socket.new(:INET, :STREAM)
remote_addr = Socket.pack_sockaddr_in(666, 'machty.com')
socket.connect(remote_addr)
</code></pre>

<p>This won&#8217;t fail any time soon. (Note if i&#8217;d given a BS DNS then it would: SocketError
exception from getaddrinfo). Only after a long ass time do you get a
ETIMEDOUT.</p>

<p>getaddrinfo seems cool. I guess it&#8217;s the C function that does a DNS
lookup? Nevermind, man <code>getaddrinfo</code> makes me cry.</p>

<p>So when does ECONNREFUSED happen vs just a long ass timeout? I guess it
means you&#8217;ve hit a server but a) no app is bound to the requested port
or b) the queue is full, and probably c) some other reason. No that&#8217;s
not valid; google.com:70 hangs for a while rather than ECONNREFUSED.</p>

<p>Maybe localhost knows what&#8217;s connected or not? I have NO IDEA.</p>

<h2><code>TIME_WAIT</code></h2>

<p>If you close a socket with pending outbound data, it won&#8217;t discard that
data but rather finish sending (and wait for ack) before totally closing
the socket. This is the <code>TIME_WAIT</code> state. Unless you&#8217;ve enabled
<code>REUSEADDR</code>, you&#8217;ll get an <code>EADDRINUSE</code> if you try to bind to a socket
that&#8217;s still in <code>TIME_WAIT</code> state.</p>

<h2><code>EAGAIN</code></h2>

<p>Commonly seen in non-blocking IO operations when there&#8217;s no data
available to read. Reading nonblockingly from a socket that hasn&#8217;t had EOF set yet but
doesn&#8217;t have data at the moment would cause that.</p>

<p>Non blocking reads will find any data in Ruby buffers, followed by
kernel buffers. If there&#8217;s nothing in there, then blocking read is
necessary.</p>

<h2>Ruby IO.write</h2>

<p><code>IO.write_nonblock</code> behavior maps to sys call <code>write()</code>, in that it can
fail to write all the data you provided it. Ruby&#8217;s <code>IO.write</code> tries to
be helpful and might internally call <code>write()</code> many times.</p>

<p>A saturated <code>write()</code> followed immediately by <code>write()</code> will cause an
<code>EAGAIN</code> because you haven&#8217;t given the kernel/network enough time to
flush the data you gave it. This is when you&#8217;d use <code>IO.select</code> to let
you know when a socket is available for writing/reading again.</p>

<p>Wat wat wat. In the BOOT.</p>

<p><code>select</code> returns an array of descriptors that are ready to be written
to. I guess it blocks?</p>

<p>Writes are blocked by TCP congestion prevention algo requirements
(cwnd, rwnd, etc).</p>

<p>There&#8217;s also <code>accept_nonblock</code> which <code>EAGAIN</code>s if there are no pending
connection on dat queue.</p>

<p><code>connect_nonblock</code> is sp</p>

<h2>TPC Resets</h2>

<p>http://en.wikipedia.org/wiki/TCP_reset_attack</p>

<p>There&#8217;s a usually-0 flag in a packet that can be set to 1 that tells the
receiver to stop using this TCP connection. Useful, for instance, when a
computer&#8217;s crashed, gets a packet it has no context for, so it tells the
sender to stop it, so that it might make a new connection and start from
there.</p>

<h2>Edge Device</h2>

<p>http://en.wikipedia.org/wiki/Edge_device</p>

<p>Basically, all the stuff that separates the public network (internet)
from your private network.</p>

<ul>
<li>routers</li>
<li>routing switches</li>
</ul>


<h2>traceroute</h2>

<p>I&#8217;ve already written about this before, but traceroute is useful for
tracing all the gateways your packet goes through to get to its
destination.</p>

<p>A gateway is any node that might forward packets along to some other
destination. Could be a router, switch, etc. Could also be a protocol
converter. Gateways could be software too.</p>

<p>Anyway, traceroute makes use of ICMP <code>TIME_EXCEEDED</code> response.</p>

<p><a href="http://en.wikipedia.org/wiki/Internet_Control_Message_Protocol">What is ICMP?</a></p>

<p>One of the many protocols that can be communicated via packets. Packets
have an 8 bit protocol field. The protocol values are decided by the
IANA (just like common/reserved ports&#8230; MIND BLOWN).</p>

<p>The list is here: http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml</p>

<h2><code>host google.com</code></h2>

<p>I noticed that the DNS lookup results via <code>host google.com</code> differed
almost each time I ran it.</p>

<pre><code>google.com has address 74.125.226.72
google.com has address 74.125.226.65
google.com has address 74.125.226.68
google.com has address 74.125.226.67
google.com has address 74.125.226.64
google.com has address 74.125.226.70
google.com has address 74.125.226.78
google.com has address 74.125.226.69
google.com has address 74.125.226.73
google.com has address 74.125.226.71
google.com has address 74.125.226.66
...
</code></pre>

<p>and then</p>

<pre><code>google.com has address 74.125.226.2
google.com has address 74.125.226.5
google.com has address 74.125.226.8
google.com has address 74.125.226.9
google.com has address 74.125.226.6
google.com has address 74.125.226.4
google.com has address 74.125.226.3
google.com has address 74.125.226.14
google.com has address 74.125.226.7
google.com has address 74.125.226.0
google.com has address 74.125.226.1
...
</code></pre>

<p>I&#8217;m asking the friendly folk at <code>##networking</code>. They turned me on to
<code>dig</code>. <code>dig</code> is the most raw and flexible DNS lookup tool. <code>host</code> is
apparently for chumps (i.e. it&#8217;s useful/quick/easy but not as much
functionality).</p>

<pre><code>dig google.com @ns1.google.com +short | sort | md5
</code></pre>

<p>This queries a specific name server&#8230;</p>

<p>OK i have a bunch of questions:</p>

<p>Why do DNS records contain
<a href="http://en.wikipedia.org/wiki/Fully_qualified_domain_name">Fully Qualified Domain Names</a>
as references to name servers? That seems to make no sense&#8230; you have
to turn something like <code>ns1.google.com</code> into an IP by querying&#8230; the
DNS system?</p>

<p>Answer: http://en.wikipedia.org/wiki/Domain_Name_System#Circular_dependencies_and_glue_records</p>

<ul>
<li>GET www.example.com /

<ul>
<li>Look up record, find its NS records</li>
<li>NS ns1.example.com</li>
<li>Need to get IP of ns1.example.com (we need to issue another DNS
request)</li>
<li>&#8230; circular dependency: you have to look up a name server&#8217;s IP
using that name server. Need some way to break dependency</li>
<li><p>Dependency broken by <code>AUTHORITY SECTION</code>, e.g.</p>

<p>;; AUTHORITY SECTION:
google.com.             60      IN      SOA     ns1.google.com. dns-admin.google.com. 1566886 7200 1800 1209600 300</p></li>
</ul>
</li>
</ul>


<p>This is called the &#8220;glue&#8221;. It&#8217;s either in Authority or Additional
section? (I should find this out.)</p>

<p>Related: http://support.dnsimple.com/articles/vanity-nameservers/</p>

<p>DNSimple allows &#8220;vanity&#8221; name servers, which lets you pretend like
you&#8217;re a bigass enough company to own/maintain your own name servers,
and anyone looking at your DNS records will see your fake name servers,
like ns1.machty.com, but these servers obviously don&#8217;t actually exist;
DNSimple provides this service by sending &#8220;glue&#8221; that maps your fake
name servers to the IP addresses of their actual name servers.</p>

<p>Top-level domains live under root (.).</p>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<p>That&#8217;s why sometimes you&#8217;ll see stuff ending in a period, like
<code>ns1.dnsimple.com.</code>.</p>

<pre><code>;; ANSWER SECTION:
dnssimple.com.          597     IN      A       184.168.221.96
</code></pre>

<p>The dot is important! You know how you can just put <code>www</code> is the record
value? You could also do a fully qualified shit e.g. <code>www.machty.com.</code>
(note the period at the end).</p>

<p>So my question is: when does the glue record get sent?</p>

<p>Gimme the NS records for www.machty.com</p>

<pre><code>$ dig machty.com NS
...
;; ANSWER SECTION:
machty.com.             3481    IN      NS      ns1.dnsimple.com.
machty.com.             3481    IN      NS      ns1a.dnsimple.com.
machty.com.             3481    IN      NS      ns2.dnsimple.com.
machty.com.             3481    IN      NS      ns2a.dnsimple.com.
machty.com.             3481    IN      NS      ns3.dnsimple.com.
machty.com.             3481    IN      NS      ns3a.dnsimple.com.
machty.com.             3481    IN      NS      ns4.dnsimple.com.
machty.com.             3481    IN      NS      ns4a.dnsimple.com.
</code></pre>

<p>Cool, so internally it&#8217;d need to look up ns1.dnsimple.com, so something
like:</p>

<pre><code>$ dig @ns1.dnsimple.com. www.machty.com
</code></pre>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<blockquote><p>+norec means that dig is asking non-recursive questions so that we get to do the recursion ourselves. The other options are to reduce the amount of dig produces so this won&#8217;t go on for too many pages:</p></blockquote>

<pre><code>a.root-servers.net. 518400  IN  A   198.41.0.4
a.root-servers.net. 518400  IN  AAAA    2001:503:ba3e:0:0:0:2:30
</code></pre>

<p>AAAA records serve the same purpose as A records, just that they are
IPv6.</p>

<p>WebPageTest.org: breaks your requests down into blah blah blah why is
this different than Network tab in devtools? Ah because it does it from
many different browsers.</p>

<p>162.212.105.24</p>

<h2>Turntable.fm</h2>

<p>Me: &#8220;there should be an app where multiple people have a playlist, but
there&#8217;s a single player that alternates between different people&#8217;s
playlists.&#8221;</p>

<p>Person next to me: &#8220;yes, that&#8217;s turntable.fm&#8221;</p>

<p>Should probably check that out.</p>

<h2>non-blocking connect</h2>

<p>http://stackoverflow.com/questions/8277970/what-are-possible-reason-for-socket-error-einprogress-in-solaris</p>

<p>There are two error codes for &#8220;shit is underway&#8221; when doing a
non-blocking connect/accept:</p>

<pre><code> [EALREADY]         The socket is non-blocking and a previous connection attempt
                    has not yet been completed.

 [EINPROGRESS]      The socket is non-blocking and the connection cannot be com-
                    pleted immediately.  It is possible to select(2) for comple-
                    tion by selecting the socket for writing.
</code></pre>

<p>Nice docs yo. The difference is that <code>EINPROGRESS</code> is the error that
gets returned if the operation has started but hasn&#8217;t finished (as
opposed to not yet being able to start because it can&#8217;t allocate the
resources it needs, file handlers, sockets, etc.). Most likely, the 3
way handshake packets have been sent, but SYN-ACK hasn&#8217;t been sent.</p>

<h2>Inversion of Control / DI</h2>

<p>Matthew Beale and I were discussing whether the proposed
<code>Ember.service()</code> violated the inversion of control that dependency
injection is meant to provide, e.g.:</p>

<pre><code>export default Controller.extend({
  foo: Ember.service() // request that 'service:foo' be injected
});
</code></pre>

<p>The fact that the consumer is requesting a specific thing to be injected
into it seems like it might be an IOC violation, but to me, all that&#8217;s
happening is that you&#8217;re specifying a provider, and it&#8217;s still up to the
outside world to decide what it&#8217;ll specifically inject into you. Also,
regardless of whether it&#8217;s explicit or not, if you use whatever is
injected into you, you are implicitly specifying a duck-typed provider
interface by the consumer; in other words, if we do things the classic
way and use <code>app.inject('controller:article', 'articleLookup', 'service:article-lookup')</code>,
this may seem like we&#8217;re moving all &#8220;control&#8221; to the injector, but
still, the article controller is going access <code>articleLookup</code>&#8217;s
properties and methods in a very specific way, which is the most
powerful / crucial way that you could specify a dependency (by
describing / using the duck type interface).</p>

<p>So, tl;dr, your consumer is always going to be specifying its
dependency, whether explicitly (<code>Ember.service()</code>) or implicitly (by
whatever methods/properties it uses from <code>this.injectedThing</code>), and it&#8217;s
therefore not a violation for a consumer to specify a Provider of the
dependency, so long as it&#8217;s still possible for the injector to disregard
the specifically-requested provider and substitute another one (e.g. a
stub) in its place.</p>

<p>This is what Angular&#8217;s <a href="https://github.com/angular/di.js">di.js</a> does
and I think it&#8217;s correct. I want it.</p>

<h2>Password-less SSH</h2>

<p>I&#8217;ve done this a bunch of times before but always forget, now I&#8217;m
writing about it:</p>

<p>The remote server you&#8217;re SSHing into needs to have your public key if
you want to be able to skip providing a password every time you ssh in.
I wanted to use a different public rsa key, so I made a new one:</p>

<pre><code>ssh-keygen
</code></pre>

<p>The optional passphrase you&#8217;re asked to supply is NOT the same password
you would have otherwise needed to use to log into SSH (which we&#8217;re
trying to avoid). Rather, it&#8217;s an additional security measure that&#8217;s
required every time you want to use your private RSA key to try and
decrypt data. I guess: if private RSA keys are a kind of password, the
passphrase is a password for your password. It means that someone who
steals your private key also needs to know your passphrase in order to
use it.</p>

<p>Anyway, let&#8217;s say I save the newly generated key pair to
<code>~/.ssh/shortcut_rsa</code> and <code>~/.ssh/shortcut_rsa.pub</code>, now I want to make
it possible to just type <code>ssh shortcut</code> and have it never ask me for a
password again. This means I need a few things:</p>

<ol>
<li><code>ssh shortcut</code> should translate into the IP I&#8217;m connecting to
(because I&#8217;d rather not type the IP every time and <code>shortcut</code> is not
a domain name that&#8217;d do the translating for me)</li>
<li><code>ssh shortcut</code> should supply the user name that the remote machine
expects (so that I don&#8217;t have to do <code>ssh remote_user_name@shortcut</code>).</li>
<li><code>ssh shortcut</code> should use the key pair I just generated w
<code>ssh-keygen</code>.</li>
</ol>


<p>To do all of these things, I need to append the following to
<code>~/.ssh/config</code>.</p>

<pre><code>Host shortcut
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>Pretty self explanatory and does the job. Note that you&#8217;ll be prompted
for the passphrase you provided for your RSA private key, but that&#8217;ll be
cached for a little while, and if you want, you can just save it to your
Apple keychain if you feel safe doing that.</p>

<p>The SSH config file also allows for wildcards, so you could literally do</p>

<pre><code>Host *
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>and then this would cause <code>ssh somerandombullshit</code> to connect to the
same remote machine. Obviously that use case is a little nuts, but it&#8217;s
useful if you wanna say &#8220;every remote machine I connect to should use
this same RSA key pair&#8221;.</p>

<h2>say+say+say = choir</h2>

<p>I devised the most badass script.</p>

<pre><code>#!/usr/bin/env sh

# use/uncomment this instead to weed out the annoying singing voices
#voices=`say -v ? | grep en_US | grep -v Cellos | grep -v Good | grep -v Hysterical | grep -v Bad | grep -v Pipe | grep -v Bells | cut -f1 -d ' '`
voices=`say -v ? | grep en_US | cut -f1 -d ' '`
num=`echo $voices | wc -w`
echo $voices | xargs -n 1 -P $num say $* -v
</code></pre>

<h2>How many segments are sent per SSH character?</h2>

<p>http://blog.hyfather.com/blog/2013/04/18/ssh-uses-four-tcp-segments-for-each-character/</p>

<p>Answer: 4</p>

<ol>
<li>You: Hey SSH server, user pressed &#8216;b&#8217;</li>
<li>SSH: cool, got it (ack)</li>
<li>SSH: hey btw, this is what <code>bash</code> (or whatever shell) ended up doing
with that character you type (description of screen update)</li>
<li>You: cool, got it (ack)</li>
</ol>


<p>What&#8217;s the difference between a segment and a packet?</p>

<ul>
<li>Segment: TCP header + application data</li>
<li>Packet: wraps segment w IP header information; a packet is a routable
piece of data</li>
</ul>


<p>This seems like the best answer: http://superuser.com/a/505134</p>

<p>A TCP segment is not enough information to know where to route data
within a network; you need IP headers for that, and where do those shits
live? In packets.</p>

<p>Take a packet and rip off its IP head: voila, a packet. Take a packet
and rip off its TCP (or UDP) head: voila, application data.</p>

<p>Don&#8217;t forget &#8220;frames&#8221;: frames wrap packets. If you wanna send your shit
over an ethernet, you need to wrap in a frame, whether wired or
wireless. Frames have MAC addresses. MAC addresses are generally
hard-wired into some hardware and are never expected to collide, lest
undefined behavior.</p>

<p>Now my question is: does TCP ever have access to IP headers? I guess it
must get forwarded along in some way&#8230; then again I dunno.</p>

<h2>RFC3439: Some Internet Architectural Guidelines and Philosophy</h2>

<p>http://tools.ietf.org/html/rfc3439</p>

<p>Clearly I need to read this.</p>

<h2>Nagle&#8217;s Algo</h2>

<p>When sending data:</p>

<ol>
<li>If there&#8217;s enough data in local packet buffer to comprise a whole TCP
packet, send that shit.</li>
<li>If no pending data in buffers and no pending acks, send immediately.</li>
<li>If there&#8217;s a pending ack, and not enough data to fill a packet, put
data in local buffer.</li>
</ol>


<p>This prevents protocols like telnet from saturating with
one-packet-per-char traffic. For telnet, if you type a bunch of chars in
a row, you could expect that the first char would send immediately and
the following ones would buffer and then send once the first char&#8217;s ack
came back.</p>

<p>All Ruby servers disable this since Ruby does its own internal buffering
in the socket lib. You disable by sending with NODELAY.</p>

<h2>URG flag</h2>

<p>Apparently you can break the FIFO-ness of TCP with Urgent data.</p>

<p><code>Socket#send</code> is the same as <code>write</code> except that you can pass flags to
<code>send</code>, e.g.</p>

<pre><code>socket.send 'urgent data', Socket::MSG_OOB
</code></pre>

<p>OOB stands for out of band. Note that the receiver must use the same
flag w <code>recv</code> to read the OOB data or else it won&#8217;t notice it.</p>

<p>OOB is rarely used because:</p>

<ul>
<li>only one byte of urgent data can be sent</li>
<li>there are issues w <code>select</code> wherein consumed urgent data continues to
be reported as unread, requires additional state tracking to get
right, etc.</li>
</ul>


<p>You could also use OOBINLINE flag to stick in an urgent byte amidst
normal queued data, and <code>read</code> will stop once it hits an urgent thing.</p>

<p>I&#8217;m guessing OOB is only a TCP thing since in UDP there&#8217;s no concept of
connection and &#8220;in order&#8221;.</p>

<h2>Datagram</h2>

<p>Data + telegram. From RFC 1594:</p>

<blockquote><p>â€œA self-contained, independent entity of data carrying sufficient information to be routed from the source to the destination computer without reliance on earlier exchanges between this source and destination computer and the transporting network.â€</p>

<p>The term datagram is often considered synonymous to packet but there are some nuances. The term datagram is generally reserved for packets of an unreliable service, which cannot notify the sender if delivery fails, while the term packet applies to any packet, reliable or not. Datagrams are the IP packets that provide a quick and unreliable service like UDP, and all IP packets are datagrams;[4] however, at the TCP layer what is termed a TCP segment is the sometimes necessary IP fragmentation of a datagram,[5] but those are referred to as &#8220;packets&#8221;.</p></blockquote>

<p>So, datagrams imply unreliability of delivery, whereas packet could
refer to reliable or unreliable packets. I guess a TCP segment is a
packet. But you can&#8217;t call it a datagram, since the protocol makes it
its business to be a shit.</p>

<h2>Bill Burr</h2>

<p>How&#8217;s your danish?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/28/daily-journal/"/>
    <updated>2014-08-28T13:10:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/28/daily-journal</id>
    <content type="html"><![CDATA[<h2>Why can&#8217;t React render() return multiple elements?</h2>

<p>you can&#8217;t do</p>

<pre><code>return &lt;div/&gt;&lt;div/&gt;
</code></pre>

<p>Pete Hunt tells me it&#8217;s because of how <code>ref</code>s work; it&#8217;s a common
pattern to do <code>this.refs.x.getDOMNode()</code>, but if the component returns
multiple DOM nodes, which one do you return?</p>

<p>It&#8217;s an admitted shortcoming but not a major major push to fix any time
soon.</p>

<h2>Ruby Fixnum vs Bignum</h2>

<pre><code>2.0.0-p353 :004 &gt; (100).class
 =&gt; Fixnum
2.0.0-p353 :005 &gt; (100234234234234234234).class
 =&gt; Bignum
</code></pre>

<h2>Postgres indexing</h2>

<p>I need to optimize. Most of the queries in my app are very specific
&#8220;SELECT WHERE bleh = wat, lol = yeah, foo = bar&#8221;. By default Rails
creates a btree index, which handles many common indexing use cases, but
there&#8217;s also a &#8220;hash&#8221; index, which Postgres only considers for usage for
<code>bleh = bleh</code> queries (you can&#8217;t use it for ordering, sorting,
whatever), so it seemed ideal for me:</p>

<blockquote><p>Hash indexes can only handle simple equality comparisons. The query planner will consider using a hash index whenever an indexed column is involved in a comparison using the = operator.</p></blockquote>

<p>But then I&#8217;d like it to match multiple columns, not just a single one,
so I&#8217;d like to consider a multi-column index, but then:</p>

<blockquote><p>Currently, only the B-tree, GiST and GIN index types support multicolumn indexes. Up to 32 columns can be specified. (This limit can be altered when building PostgreSQL; see the file pg_config_manual.h.)</p></blockquote>

<p>So I guess Hash is out of the question. So the final thing I need to
figure out is: does it make sense for me to use a multi-column index if
I have three columns that need to be <code>=</code> matched?</p>

<p>Partial indexes: http://www.postgresql.org/docs/8.2/static/indexes-partial.html</p>

<p>Useful for when you&#8217;d like to exclude common values from consideration
in an index (because indexes lose value the more duplicates there are in
a database).</p>

<h2>V8 optimizes based on AST size</h2>

<p>&#8230;and comments are part of the AST:</p>

<p>https://github.com/broccolijs/broccoli-kitchen-sink-helpers/commit/092a680f1ff8fe2d54419dd57fa9ba8a81f6f297</p>

<h2>General Theory of Reactivity</h2>

<p>https://github.com/kriskowal/gtor</p>

<p>Reactivity: reacting to external stimuli and propagating events.</p>

<ul>
<li>(functional) reactive programming</li>
<li>bindings</li>
<li><p>operational transform</p></li>
<li><p>Spatial Singular is a value, e.g. 5</p></li>
<li>Spatial Plural is an enumberable/iterable of values</li>
<li>Temporal Singular is an eventual value, e.g. a Promise</li>
<li>Temporal Plural is eventual values, e.g. Observable of values</li>
</ul>


<p>But this glazes over many particulars, and things like Rx boil too much
into a single Observable type that can perform any role.</p>

<h3>Value</h3>

<ul>
<li>Singular</li>
<li>Spatial</li>
<li>Accessible</li>
<li>Modifiable</li>
<li>Composed of a getter and a setter</li>
<li>Data flows from setter to getter</li>
</ul>


<p>Every reactive primitive features getter/setter, producer/consumer, or
writer/reader. See http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2014/Keynote-Duality</p>

<p>Arrays are the above, but plural. Generators are the
producing/writing/setting side, iterators are the read/get/consume.</p>

<p>Promises are singular and temporal. Promises are getters, and
corresponding setter is a resolver. Together, they&#8217;re a kind of
deferred.</p>

<p>Streams are a getter/setter pair of temporal plurals. Producer is a
writer and consumer is a reader. Reader is an async iterator and writer
is an async generator.</p>

<p>Remember that a value encapsulates a getter and setter&#8230; values are:
Deferred (promise + resolver, singular, temporal), Stream (reader +
writer, plural, temporal), Array (iterator + generator, spatial,
plural), and value (getter + setter, spatial, singular).</p>

<p>Promises (singular + temporal) model dependency. The API/experience of
multiple resolvers is the same regardless of who wins the race, and same
w consumers.</p>

<p>Because consumers cannot interfere with another consumer, aborting
promises is not possible; promise is only the result, not the work
leading to that result.</p>

<p>A task, similar to promise, but is unicast.</p>

<p>Unicast: http://en.wikipedia.org/wiki/Unicast - sending messages to a
  single destination</p>

<p>Broadcast: multiple possible destinations (or none)</p>

<p>Because tasks are unicast, consumers can&#8217;t clobber each other (because
there&#8217;s only one), hence they are cancellable. Can be explicitly forked
to create a task that depends on the same result</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/22/daily-journal/"/>
    <updated>2014-08-22T16:32:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/22/daily-journal</id>
    <content type="html"><![CDATA[<h2>Difference b/w XSD and DTD</h2>

<p>They both define the structure of an XML document, but what&#8217;s the
difference?</p>

<p>Awesome SO:
http://stackoverflow.com/questions/1544200/what-is-difference-between-xml-schema-and-dtd</p>

<p>DTD&#8217;s are arguably easier to grok, but the XSD has more features, but at
the expense of understanding the abstractions of data types and what
not. Seems easier to describe recursive structures in XSD than the other
bullsharticles.</p>

<p>XSD is XML, DTD stems from SGML.</p>

<p>I guess XML And HTML also stem from SGML. WHAT DO I KNOW? NOTHING!</p>

<h2>Wolf3d in React</h2>

<p>Apparently I missed this https://github.com/petehunt/wolfenstein3D-react.git</p>

<h2>Breaking the chain in React</h2>

<p>For when you want to tell React &#8220;don&#8217;t mess with my DOM, I&#8217;m doing funky
jQuery shit&#8221;.</p>

<p>Render a div that won&#8217;t invalidate:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L47</p>

<p>Re-render your own children:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L15-L18</p>

<h2>Retcon: retroactive continuity</h2>

<p>http://en.wikipedia.org/wiki/Retroactive_continuity</p>

<p>&#8220;alteration of previously established facts in the continuity of a
fictional work&#8221;</p>

<h2>CVV can mean lower rates</h2>

<p>http://security.stackexchange.com/questions/21168/how-does-amazon-bill-me-without-the-cvc-cvv-cvv2</p>

<p>There are fraud-prevention benefits to using CVV, and as such, payment
handlers will often give you a discount if the CVV is present.</p>

<h2>X-Forwarded-For</h2>

<p>Some servers fall prey to IP spoofing via setting the <code>X-Forwarded-For</code>
header. If your server isn&#8217;t careful, then given a
<code>curl -H "X-Forwarded-For: 1.2.3.4" http://www.machty.com</code>, your
server&#8217;s logs and maybe even IP-dependent application logic (e.g.
language detection) might use 1.2.3.4.</p>

<p>In Rails you can add your known proxy/load-balancing IPs to
<code>TRUSTED_PROXIES</code>. Then the <code>RemoteIp</code> rack middleware will filter out
all of those and pick the most recently set IP, which handles the case
where you might have multiple <code>X-Fowarded-By</code> headers. So the rule is:
use the rightmost, untrusted IP and treat that as the remote ip. Why?
Because when your first proxy is hit, it&#8217;ll see IP X.X.X.X and move that
to the list of <code>X-Forwarded-By</code> headers. Note that the previous
<code>X-Forwarded-By</code> headers, present or no, are untrustable and totally
spoofable.</p>

<p>http://blog.gingerlime.com/2012/rails-ip-spoofing-vulnerabilities-and-protection</p>

<p>So that&#8217;s IP spoofing via HTTP header. How else can you IP spoof?</p>

<p>http://en.wikipedia.org/wiki/IP_address_spoofing</p>

<p>You just rewrite the source IP in the TCP/UDP packet header, which also
means when the application responds, it&#8217;ll send it back to the forged
IP.</p>

<p>There are valid use cases for this as well, such as testing load
balancing software/hardware.</p>

<h2>Types of NAT</h2>

<p>http://think-like-a-computer.com/2011/09/16/types-of-nat/</p>

<h3>Full cone NAT (Static NAT) (port forwarding)</h3>

<p>Manual mapping of public IP and port to LAN IP and port.</p>

<p>e.g. all incoming traffic to port 12345, forward to 192.168.0.10:9999.</p>

<p>Blocks (drops connection):</p>

<ul>
<li>Ports that haven&#8217;t been forwarded</li>
</ul>


<h3>Restricted cone NAT (dynamic)</h3>

<p>Don&#8217;t allow incoming data from an IP unless I&#8217;ve sent packets to it
already. Note that depending on the strictness, if I initiate a
connection to WAN IP 1.2.3.4:1234, I could potentially get data from
1.2.3.4:5678, but in stricter schemes, the port must also match.</p>

<p>But regardless of this strictness, the one requirement is that they send
data to exactly my public IP and port that I sent data out of.</p>

<h3>Symmetric NAT</h3>

<p>http://think-like-a-computer.com/2011/09/19/symmetric-nat/</p>

<p>Sym NAT is like port-restricted cone NAT, but randomly generates
different public source ports when sending to different destinations.</p>

<p>Sym NATs are the only ones that cause problems with other devices behind
NATs.</p>

<h2>Vim registers</h2>

<p>So if I have</p>

<pre><code>&lt;a href="WAT"&gt;&lt;/a&gt;
</code></pre>

<p>and I want to replace the href with a yanked &#8220;LOL&#8221;, then I can <code>di"</code> in
WAT to delete it, then <code>"0P</code> to use the last-yank register 0. Registers
1,2,3,4,5&#8230; get populated with cuts. Unnamed register gets replaced by
any yanking/cutting command. Weird terminology.</p>

<h2>Ember-cli + divshot</h2>

<p>Holy shit this was awesome.</p>

<p>Divshot.com is a static deployment heroku, basically, and ember-cli has
an addon for letting you deploy there.</p>

<pre><code>npm install --save-dev ember-cli-divshot &amp;&amp; ember generate divshot
</code></pre>

<h2>brew install fuck</h2>

<p>naw, but this is a cool script for killing them all:</p>

<pre><code>#!/usr/bin/env ruby
# coding: utf-8

abort "Usage: fuck you &lt;name&gt;" unless ARGV[0] == "you" &amp;&amp; ARGV.size == 2

a = "abcdefghijklmnopqrstuvqxyz".each_char.to_a
b = "ÉqÉ”pÇÉŸÆƒÉ¥Ä±É¾ÊžÊƒÉ¯uodbÉ¹sÊ‡nÊŒÊxÊŽz".each_char.to_a
ws = Hash[a.zip(b)]
ws.default = -&gt;(f){f}

puts "\n  (â•¯Â°â–¡Â°ï¼‰â•¯ï¸µ #{ARGV[1].reverse.each_char.map{|f|ws[f]}.join}\n\n"

system("killall -9 #{ARGV[1]}")
exit $?.exitstatus
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/15/daily-journal/"/>
    <updated>2014-08-15T12:17:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/15/daily-journal</id>
    <content type="html"><![CDATA[<h2>Incremental GC</h2>

<p>Tenderlove tweeted this: https://bugs.ruby-lang.org/issues/10137</p>

<ul>
<li>Generational GC already is implemented: distinguish/bucket old and new
generation objects; sweeping new generation objects is fast (minor GC), and the
ones that don&#8217;t get swept up get promoted to old generation, which is
less frequently swept (in a major GC)</li>
<li>Generation GC is always incremental in that it doesn&#8217;t collect ALL
unreachables, &#8230; todo http://stackoverflow.com/questions/5092134/whats-the-difference-between-generational-and-incremental-garbage-collection</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/09/daily-journal/"/>
    <updated>2014-08-09T16:15:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/09/daily-journal</id>
    <content type="html"><![CDATA[<h2>iOS State Preservation</h2>

<p>https://developer.apple.com/library/ios/documentation/iphone/conceptual/iphoneosprogrammingguide/StatePreservation/StatePreservation.html</p>

<h2>Session token storage in localStorage</h2>

<p>Do not store session identifiers in local storage as the data is always accessible by JavaScript. Cookies can mitigate this risk using the httpOnly flag.</p>

<p>It&#8217;s risky? SAY MORE THINGS.</p>

<h2>Loading Ember CLI addons in jsbin</h2>

<h2>Forking in xargs</h2>

<p>Holy shitters, this is how I simultaneously uploaded three tracks to s3
(using my <code>to_s3</code>) script.</p>

<pre><code>find ~/Desktop -name "Audio*" -print0 | xargs -0 -n 1 -P 5 to_s3
</code></pre>

<p><code>-n 1</code> means each invocation takes a max of one arg, and <code>-P 5</code> means a
max of 5 simultaneous processes. So cool.</p>

<h2>Web audio api</h2>

<p>Finish this: http://emberjs.jsbin.com/ucanam/5964/edit</p>

<h2>Liquid Fire Global</h2>

<p>http://jsbin.com/mifuq/1/edit</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/05/daily-journal/"/>
    <updated>2014-08-05T08:47:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/05/daily-journal</id>
    <content type="html"><![CDATA[<h2>ES6 fat arrow</h2>

<pre><code>var a = this;
var fn = () =&gt; {
  console.log(this === a); // true
}
</code></pre>

<p>http://tc39wiki.calculist.org/es6/arrow-functions/</p>

<p>yuno CoffeeScript single arrow syntax?</p>

<blockquote><p>However, we don&#8217;t want CoffeeScript&#8217;s ->, it&#8217;s confusing to have two arrows and dynamic this binding is an oft-fired footgun.</p></blockquote>

<h2>SaltStack</h2>

<p>http://docs.saltstack.com/en/latest/</p>

<h2>Open Core</h2>

<p>http://en.wikipedia.org/wiki/Open_core</p>

<p>Open Source core functionality with paid/proprietary add-ons, e.g.
Sidekiq, or MySQL</p>

<p>Related:</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Crippleware">Crippleware</a>: free versions
cripple the ability to save/export/whatever</li>
<li><a href="http://en.wikipedia.org/wiki/Freemium">Freemium</a>: free core features,
pay for higher usage/capacity, e.g. most heroku add-ons</li>
</ul>


<h2>Ember First Class Actions</h2>

<p>http://emberjs.jsbin.com/ucanam/5919/edit</p>

<p>Questions:</p>

<ul>
<li>singleton vs multiples?</li>
<li>actions that depend on others?</li>
<li>link-to?

<ul>
<li>idea: a LinkView asks the router or url service for an Action
using the route params, query params, etc.</li>
<li>LinkView&#8217;s active CP is <code>action.pending</code> || present day isActive</li>
<li>action will internally delegate to a shared transitionTo action
that everyone in the world can see; everyone can know where it&#8217;s
going, etc etc etc.</li>
</ul>
</li>
</ul>


<p>We need to separate fake link font decoration style from the underlying
action.</p>

<p>Link&#8217;s display components:</p>

<pre><code>routeDescriptor: function() {
  // when resolvedParams change, we need to recalculate
  // our route object... this should refire only when
  // params change, not when the URL changes
  this.urlService.getRouteObject('articles', 1)


  this.urlService.createRouteDescriptor({
    routeName: alias('_linkView.params.firstObject'),
    contexts: alias('_linkView.contexts'),
    queryParams: alias('_linkView.queryParams'),
    _linkView: this
  });
}//.property('resolvedParams')

createRouteDescriptor: function(_attrs) {
  var attrs = {
    router: this.router, // or maybe just `this`?
  };
  Ember.merge(attrs, _attrs);
  return RouteDescriptor.createWithMixins(attrs);
}

RouteDescriptor = Ember.Object.extend({
  // required
  router: null,
  routeName: null,
  contexts: null,
  queryParams: null,

  allParams: computed('routeName', 'contexts', 'queryParams', function() {
    // this is just a perfy thing; since all calculations depend
    // on all these params, we'll avoid the overhead of multiple
    // CPs depending on each of these params
    return this.getProperties(['routeName', 'contexts', 'queryParams']);
  }),

  path: computed('router.url', 'allParams', function() {
    var allParams = this.get('allParams');
    var router = this.get('router');

    // presently we only use router.url as a cue that the router
    // is at a new route
    var url = this.get('router.url');

    // pass crap to routerJS
  }),

  perform: function() {
    // invoke, blah blah blah, same logic as in link to.
    this.get('allParams');
  }
});

service.getRouteDescriptor('articles', 1)

{
  action:   FCA,
  isActive: true,
  path: "/some/dynamic/thing"
}
</code></pre>

<p>RouteDescriptors are objects</p>

<ul>
<li>inactive: !routeObject.active</li>
<li>active:   routeObject.active</li>
<li>visited</li>
</ul>


<p>Weird thing: ember link-to&#8217;s concept of &#8220;active&#8221; doesn&#8217;t match with
<code>&lt;a&gt;</code> tag&#8217;s concept of active; link-to &#8216;active&#8217; means you&#8217;re currently
in the route specified by that link; <code>&lt;a&gt;</code> tag&#8217;s active means you&#8217;re
currently clicking this link.</p>

<p>I think I know how to refactor link-to and LinkView and all that</p>

<p>Goals</p>

<ul>
<li>make linking/routing/active calc logic shareable</li>
<li>make it possible to click a link to make it active before a slow
transition has completed.</li>
<li>support calculating activeness for bootstrap wrapper <code>&lt;li&gt;</code>s and
anything else in general too.</li>
</ul>


<h2>RFCs</h2>

<p>Rust tempered it&#8217;s freewheeling feature additions by requiring RFCs.</p>

<p>https://github.com/rust-lang/rfcs/blob/master/active/0001-rfc-process.md
https://github.com/rust-lang/rfcs/blob/master/active/0039-lifetime-elision.md</p>

<p>Sounds like we&#8217;ll be doing this for Ember.</p>

<h2>Elide</h2>

<blockquote><p>omit (a sound or syllable) when speaking: (as adj. elided) : the indication of elided consonants or vowels.</p></blockquote>

<h2>Variadic</h2>

<p>http://en.wikipedia.org/wiki/Variadic_function</p>

<p>A function that is variadic has an indefinite number of arguments.
<code>.bind</code></p>

<blockquote><p>8:50 PM <spion> bind is variadic and I think it also has to do some stuff with constructors
8:51 PM <spion> (additional arguments can be used for partial application)
8:52 PM <spion> the constructor stuff: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/bind#Bound_functions_used_as_constructors
8:53 PM <spion> (creates significant additional overhead)
8:53 PM <spion> so a simple non-variadic closure implementation of bind has a lot less work to do :P</p></blockquote>

<h2>React forms</h2>

<p>https://github.com/wingspan/wingspan-forms</p>

<p>Powerded by KendoUI</p>

<h2>Reflux</h2>

<p>https://github.com/spoike/refluxjs</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>â•”â•â•â•â•â•â•â•â•â•â•—       â•”â•â•â•â•â•â•â•â•â•—       â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
</span><span class='line'>â•‘ Actions â•‘â”€â”€â”€â”€â”€â”€&gt;â•‘ Stores â•‘â”€â”€â”€â”€â”€â”€&gt;â•‘ View Components â•‘
</span><span class='line'>â•šâ•â•â•â•â•â•â•â•â•â•       â•šâ•â•â•â•â•â•â•â•â•       â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</span><span class='line'>     ^                                      â”‚
</span><span class='line'>     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span></code></pre></td></tr></table></div></figure>


<p>Rationale: http://spoike.ghost.io/deconstructing-reactjss-flux/</p>

<h2>Promixo dedicated</h2>

<p>https://addons.heroku.com/proximo#dedicated</p>

<h2>CIDR: Classless Inter-Domain Routing</h2>

<p>http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing</p>

<p>Classful allocation of IP addresses (pre 1993) defined class A, B, C
network groups split along the 8 bit chunks. Problem is the smallest
allocation (256 addresses, assuming you were allocated something like
123.456.789.XXX) was often too small for companies, whereas the next
step up from that (123.456.XXX.XXX) was generally too huge (65536) for
companies/entities to efficiently take advantage of. SOLUTION: CIDR
blocks and subnet masks.</p>

<blockquote><p>This led to inefficiencies in address use as well as routing because the large number of allocated small (class-C) networks with individual route announcements, being geographically dispersed with little opportunity for route aggregation, created heavy demand on routing equipment.</p></blockquote>

<p>In other words, class C allocations are 123.456.789.XXX allocations,
each containing 256 addresses, with no requirement that they be
geographically grouped, such that routers had to maintain large tables
for very similar looking addresses rather than being able to rely on
some grouping rules to minimize the routing information they had to know
about. But now subnet masking is a thing and blah blah blah I&#8217;m done
learning this shit.</p>

<p>192.168.2.0/24 means that the network is identified by the first 24 bits</p>

<blockquote><p>192.168.100.0/24 represents the given IPv4 address and its associated routing prefix 192.168.100.0, or equivalently, its subnet mask 255.255.255.0 (i.e. 24 &#8220;1&#8221; bits).</p>

<p>the IPv4 block 192.168.100.0/22 represents the 1024 IPv4 addresses from 192.168.100.0 to 192.168.103.255.</p></blockquote>

<h2>TokenEx client-side encryption</h2>

<p>Original misconception:</p>

<ul>
<li>You post directly to TokenEx via AJAX, and they give you an encrypted
value that you can pass to your server and exchange for a token</li>
</ul>


<p>Correction:</p>

<ul>
<li>You only use JSEncrypt to encrypt the PAN via a public key.</li>
</ul>


<p>Wait, I don&#8217;t understand, with tokenizing, if you have a token saved in
the database, then your server, if compromised, could still send data
through to TokenEx, which would proxy it through to whomever.</p>

<h2>Form Factor</h2>

<p>https://www.pcisecuritystandards.org/documents/Mobile_Payment_Security_Guidelines_Merchants_v1.pdf</p>

<blockquote><p>The PCI Security Standards Council charter provides a forum for collaboration across the payment space
to develop security standards and guidance for the protection of payment card data wherever it may be
stored, processed, or transmittedâ€”regardless of the <em>form factor</em> or channel used for payment.</p></blockquote>

<p>the physical size and shape of a piece of computer hardware.</p>

<p>http://en.wikipedia.org/wiki/Mobile_phone_form_factor</p>

<p>or phone.</p>

<p>what a stupid fucking phrase/word/definition.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/08/02/daily-journal/"/>
    <updated>2014-08-02T21:24:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/08/02/daily-journal</id>
    <content type="html"><![CDATA[<h2>NPM is killing me</h2>

<p>Apparently this fixed everything.</p>

<pre><code>npm cache clear &amp;&amp; npm install
</code></pre>

<p>https://www.npmjs.org/doc/cli/npm-cache.html</p>

<p>npm caches everything in <code>npm config get cache</code>, which for me is:</p>

<pre><code>~/.npm
</code></pre>

<p>Folder structure is something like</p>

<pre><code>~/.npm/PACKAGE_NAME/VERSION/
</code></pre>

<p>which contains:</p>

<ul>
<li>.cache.json

<ul>
<li>lots of overlap w the project&#8217;s package.json, with additional
cache-specific things like</li>
<li>etag, shasum</li>
<li>deployment-specific data about the package</li>
</ul>
</li>
<li>package.tgz

<ul>
<li>the original tarball downloaded for this packaage</li>
</ul>
</li>
<li>package/

<ul>
<li>the unzipped tarball</li>
</ul>
</li>
</ul>


<p>In other words</p>

<blockquote><p>Additionally, whenever a registry request is made, a .cache.json file is placed at the corresponding URI, to store the ETag and the requested data. This is stored in {cache}/{hostname}/{path}/.cache.json.</p></blockquote>

<h2>Food Shit</h2>

<p>Pok Pok is a legit ass Thai place I need to check out.</p>

<pre><code>http://pokpokny.com/
</code></pre>

<h2><code>sed</code> to select lines</h2>

<pre><code>$ git branch
  cp-qp
* master
  new-doctitle
  setup-controller-qp
</code></pre>

<p>I wanted to switch to the fourth one without typing
<code>setup-controller-qp</code>. Here&#8217;s how you could do it by using the line
number</p>

<pre><code>$ git branch | sed -n '4p' | xargs git checkout
Switched to branch 'setup-controller-qp'
</code></pre>

<p>Obviously this is just a dumb exercise since it&#8217;s waaay more typing.
This is me practicing.</p>

<p>You can also display multiple lines using a syntax similiar to cut&#8217;s
<code>-f1,2</code> syntax:</p>

<pre><code>$ git branch | sed -n '3,4p' 
  new-doctitle
  setup-controller-qp
</code></pre>

<h2>commissary</h2>

<p>From Orange is the New Black</p>

<blockquote><p>commissary: a restaurant in a movie studio, military base, prison, or other institution.</p></blockquote>

<h2>HRT</h2>

<p><a href="http://en.wikipedia.org/wiki/Hormone_replacement_therapy">Hormone replacement therapy</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/29/daily-journal/"/>
    <updated>2014-07-29T07:50:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/29/daily-journal</id>
    <content type="html"><![CDATA[<h2>tar</h2>

<p>Short for Tape Archives.</p>

<p>Had a tar.xz file, just needed to</p>

<pre><code>tar xf thefile.tar.xz
</code></pre>

<h2>Dexing</h2>

<p>Convert string names to numbers to be referenced within compiled Java
whilst packaging android apps.</p>

<h2>Good Food</h2>

<p>Prince St Cafe on Prince and Mott.</p>

<ul>
<li>Awesome burger</li>
<li>Awesome lamb thing</li>
</ul>


<h2>ls -l</h2>

<p>Was curious about an <code>@</code> sign I saw next to a .txt file, from <code>ls(1)</code>:</p>

<blockquote><p>The Long Format</p>

<pre><code>If the -l option is given, the following information is displayed for
each file: file mode, number of links, owner name, group name, number
of bytes in the file, abbreviated month, day-of-month file was last
modified, hour file last modified, minute file last modified, and the
pathname.  In addition, for each directory whose contents are dis-
played, the total number of 512-byte blocks used by the files in the
directory is displayed on a line by itself, immediately before the
information for the files in the directory.  If the file or directory
has extended attributes, the permissions field printed by the -l
option is followed by a '@' character.  Otherwise, if the file or
directory has extended security information (such as an access control
list), the permissions field printed by the -l option is followed by a
'+' character.
</code></pre></blockquote>

<ul>
<li><code>@</code> extended attributes</li>
<li><code>+</code> extended security info</li>
</ul>


<h2>Interrupted System Call</h2>

<p>http://infohost.nmt.edu/~eweiss/222_book/222_book/0201433079/ch10lev1sec5.html</p>

<p>I&#8217;m getting some shit about foreman and interrupted system calls. So
what is it.</p>

<h2>&#8220;data at the edge&#8221;</h2>

<p>Keeping secure data at the edge of your infrastructure, e.g. using
tokens instead of storing CC&#8217;s in your db.</p>

<h2>PAN (primary account number)</h2>

<p>Bank card number.</p>

<p>http://en.wikipedia.org/wiki/Primary_account_number</p>

<h2>CP (card present)</h2>

<p>e.g AuthorizeNetCP</p>

<p>Cheaper rates if you can prove card present (via CVV).</p>

<h2>TokenEx</h2>

<p>ProcessTransaction</p>

<p>ProcessTransactionWithPAN</p>

<ul>
<li>pass in all the CC data; no</li>
</ul>


<h2>Levenshtein Distance</h2>

<p>The minimum number of single-element operations (add, remove,
substitute) between two sequences. Often used for spell-checking
suggestions.</p>

<p>I was thinking of using it to do an array diffing for React-ish stuff.</p>

<pre><code>Array 1: B C D E F
Array 2: A B C D E
</code></pre>

<p>Clearly the answer to how to get from 1 to 2 is</p>

<pre><code>shift A
delete E
</code></pre>

<p>But how to programmatically detect that?</p>

<h2>Ruby String Substring Shorthand</h2>

<p>https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<p>I can&#8217;t believe I didn&#8217;t know this&#8230;</p>

<pre><code>s = "alex is quite maudlin"
s['quite'] = 'very'
s =&gt; "alex is very maudlin"
</code></pre>

<p>and if the substring isn&#8217;t in there, then</p>

<pre><code>IndexError: string not matched
</code></pre>

<p>http://www.ruby-doc.org/core-2.1.2/String.html#method-i-5B-5D-3D</p>

<h2>JRuby the Hard Parts</h2>

<p>Goal: understand this talk https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<h2>Learn about encodings</h2>

<p>I had to resort to this shit:</p>

<pre><code>line = line.force_encoding("iso-8859-1")
</code></pre>

<p>for a bigass file because I was running into</p>

<pre><code>http://stackoverflow.com/questions/15399530/ruby-match-invalid-byte-sequence-in-utf-8
</code></pre>

<p>Apparently you can open files as a certain encoding. Seems good.</p>

<h2>Auto-inline CSS with Roadie</h2>

<p>https://github.com/Mange/roadie</p>

<p>Useful for supporting a vast array of shitty email clients that require
inline CSS. This wouldn&#8217;t be a problem if web components.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal 2]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal-2/"/>
    <updated>2014-07-28T20:43:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal-2</id>
    <content type="html"><![CDATA[<h2>User and Kernel</h2>

<p>http://blog.codinghorror.com/understanding-user-and-kernel-mode/</p>

<p>Non-idle tasks.</p>

<p>The CPU graph is tasty. Red means kernel.</p>

<p>CPU hardware knows all about kernels n shit. It isn&#8217;t just a software
divide. CPU instructions and certain memory locations can only be
accessed by the kernel, enforced by hardware. User mode makes it so that
only the app crashes, not the entire system.</p>

<p>http://en.wikipedia.org/wiki/Ring_(computer_security)</p>

<p>Interesrserseting.</p>

<p>x86 CPU hardware:</p>

<ul>
<li>0 is kernel</li>
<li>3 is user</li>
</ul>


<p>1 and 2 are device drivers but they&#8217;re not often used. On Windows,
device drivers can be user or kernel mode, mostly to the user, but video
cards are often kernel level since they so perfy. In Vista+, the Windows
Driver Display Model is such that only kernel mode is used for executing
the GPU commands, but the translation from API to GPU now takes place in
userland.</p>

<p>Exceptions fire in kernel land I guess? Sometimes?</p>

<h2>Old Foreman Orphans Sidekiq</h2>

<p>After lots of starts/stops of foreman, I noticed lots of sidekiq
instances with ppid 1. They was orphans. I killed em.</p>

<h2>fspawn</h2>

<p>Refers to the fork+exec approach to spawning a process.</p>

<h2>Daemons</h2>

<p>https://github.com/ghazel/daemons</p>

<p>Library of fun little trinkets.</p>

<ul>
<li>given some-server.rb, let&#8217;s you write a some-server-control.rb</li>
<li>inline the server inside such a daemon (you can still run it
without forking via <code>run</code> command)</li>
<li>manage multiple daemons</li>
<li>Ability to take existing server and daemonize it; you do lose control
over the daemon unless you&#8217;re a <code>ps</code>/<code>kill</code> JOURNEYMAN.

<ul>
<li>this takes advantage of the <code>fork</code> <code>getsid</code></li>
</ul>
</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons.rb#L45-L53</p>

<pre><code># 1.  Forks a child (and exits the parent process, if needed)
# 2.  Becomes a session leader (which detaches the program from
#     the controlling terminal).
# 3.  Forks another child process and exits first child. This prevents
#     the potential of acquiring a controlling terminal.
# 4.  Changes the current working directory to "/".
# 5.  Clears the file creation mask (sets +umask+ to 0000).
# 6.  Closes file descriptors (reopens +STDOUT+ and +STDERR+ to point to a logfile if
#     possible).
</code></pre>

<p>Controlling terminal:</p>

<p>http://www.gnu.org/software/libc/manual/html_node/Controlling-Terminal.html</p>

<blockquote><p>An individual process disconnects from its controlling terminal when it calls setsid to become the leader of a new session.</p></blockquote>

<p>Ah I get it:</p>

<ul>
<li>first fork is to orphan the child, but it&#8217;s still connected to a
controlling terminal/session.</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L201</p>

<p>They actually loop through all known IO files to close file
descriptors using ObjectSpace:</p>

<p>http://www.ruby-doc.org/core-2.1.2/ObjectSpace.html</p>

<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L221</p>

<p>That&#8217;s pretty rad. I guess the GC uses it too.</p>

<h2>.pid file</h2>

<p>It&#8217;s a file in a well known location that contains only the pid of
some running process, usually a daemon. Useful because daemons are often
hard to detect, kinda look like forgotten orphan processes, and there
might be multiple similar ones. But pid files let you look up the pid of
the running process so that you can send it signals.</p>

<h2><code>$0</code> or <code>$PROGRAM_NAME</code></h2>

<p>If you run this script</p>

<pre><code>fork {
  $PROGRAM_NAME = "WAT"
  sleep
}
</code></pre>

<p>then <code>ps | grep WOOT</code> yields</p>

<pre><code>62724 ttys022    0:00.00 WOOT
</code></pre>

<p>Woot wat wat wotasoasdas lol.</p>

<h2><code>pidof</code></h2>

<pre><code>brew install pidof

$ pidof bash
754 1246 1748 2308 2498 5380 20397 23552 26224 26973 48454 79258 81847 5226 5346 5443 5851 10659 25008 26375 27009 52684 88768 88882 18853 19116 19246 20275 20476 21364 43211 52269 52390 52637 54869 54974 58037 58950 59080
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal/"/>
    <updated>2014-07-28T08:16:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal</id>
    <content type="html"><![CDATA[<h2>Them processes</h2>

<p>Kernel</p>

<!--more-->


<ul>
<li>sits on top of hardware, doing things like

<ul>
<li>read/write from filesystem</li>
<li>sending/receiving network data</li>
<li>playing audio</li>
</ul>
</li>
<li>programs don&#8217;t have access to this stuff, only the kernel</li>
</ul>


<p>System call is the barrier b/w userland and kernel.</p>

<p>What about memory? I think userland can read memory.</p>

<p>Common man pages for FreeBSD or Linux</p>

<p><code>wat(2)</code> means section 2 of manual, wat: <code>man 2 wat</code></p>

<p>Can&#8217;t execute code without a process.</p>

<p><code>Process.pid == $$</code> global var in Ruby, from Perl/bash, but
<code>Process.pid</code> is way more obvious, duh.</p>

<p>Processes have parents, identified via <code>ppid</code>, <code>Process.ppid</code>, but not
super often used.</p>

<p>In Unixland, everything is a file.</p>

<p>When opening resources, you&#8217;re given a file descriptor number, unique to
your process, unshareable with unrelated processes. These resources are
closed when you exit process, cept forking.</p>

<p>All Ruby <code>IO</code> objects have a <code>fileno</code>, e.g.</p>

<pre><code>2.0.0-p353 :007 &gt; $stdin.fileno
 =&gt; 0
2.0.0-p353 :007 &gt; $stdout.fileno
 =&gt; 1
2.0.0-p353 :008 &gt; $stderr.fileno
 =&gt; 2
</code></pre>

<p>File descriptors are assigned lowest unused value, and are reusable when
old file handlers are closed.</p>

<p>Streams are lovely, before them, each program had to explicitly handle
different keyboard types, etc, but the stream abstraction unified all of
that.</p>

<p><code>fsync</code> flushes file descriptor state to disk, but disk might reorder
writes. The <code>F_FULLFSYNC</code> will ask the drive to write it immediately and
preserve order, useful for things like databases, see <code>fsync</code></p>

<pre><code> For applications that require tighter guarantees about the integrity of their
 data, Mac OS X provides the F_FULLFSYNC fcntl.  The F_FULLFSYNC fcntl asks the
 drive to flush all buffered data to permanent storage.  Applications, such as
 databases, that require a strict ordering of writes should use F_FULLFSYNC to
 ensure that their data is written in the order they expect.  Please see fcntl(2)
 for more detail.
</code></pre>

<p><code>F_FULLFSYNC</code> probably isn&#8217;t available on everything, possibly mac only.</p>

<p>To find the limit of file descriptors you can do <code>Process.getrlimit(:NOFILE)</code></p>

<p>This translates to <code>getrlimit(2)</code>, control max system resource
consumption. <code>r</code> is resource, <code>NOFILE</code> means &#8220;The maximum number of open
files for this process&#8221;.</p>

<pre><code>2.0.0-p353 :001 &gt; Process.getrlimit(:NOFILE)
 =&gt; [2048, 2048]
    #soft, hard
</code></pre>

<p>Soft means an exception will raise but you can reconfigure. Hard limit
might be reconfigurable by superuser, or if the process has permissions.</p>

<p><code>sysctl</code> lets you get or set kernel state, useful for configuring
system-wide kernel details.</p>

<p><code>EMFILE</code> is too many files open. Testable via</p>

<pre><code>machty.github.com :: ruby -e "Process.setrlimit(:NOFILE, 3); File.open('/dev/null')"
-e:1:in `initialize': Too many open files - /dev/null (Errno::EMFILE)
</code></pre>

<p><code>ulimit</code> is a built in command to control resource usage for this shelll
and any of its children. It&#8217;s different from system wide <code>sysctl</code> stuff.
I can change the result above</p>

<p>So I remember <code>ulimit</code> resets the soft limit. If I set to 2046, then</p>

<pre><code>machty.github.com :: ruby -e "puts Process.getrlimit(:NOFILE)"
2046
2046
</code></pre>

<blockquote><p>(Built-in command) In computing, a shell builtin is a command or a function, called from a shell, that is executed directly in the shell itself, instead of an external executable program which the shell would load and execute. ..</p></blockquote>

<p>Use cases for overriding limits</p>

<ul>
<li>stress-testing utilities (e.g. 5000 simultaneous connections)</li>
<li>limiting resources for 3rd party stuff, removing permissions to change</li>
</ul>


<p>Environment is nothing more than Env vars, key values pairs.
Set by parent, inherited by children.</p>

<pre><code>machty.github.com :: A=lol ruby -e "puts ENV['A']"
lol
</code></pre>

<p>Note that env var assignment on its own shell line sets them for the
rest of the process, but followed by a command only sets them for that
command.</p>

<p>Process names are changeable, e.g. <code>$PROCESS_NAME = "fuckles"</code></p>

<pre><code>  PID TTY           TIME CMD
45874 ttys011    0:00.68 fuckles
</code></pre>

<p>Note that TIME is CPU time.</p>

<p>Ah, <code>time</code> makes sense to me now:</p>

<pre><code>machty.github.com :: time sleep 1

real    0m1.012s
user    0m0.001s
sys     0m0.003s
</code></pre>

<p><code>sleep</code> suspends execution thread, consuming no CPU. I think <code>sys</code> means
system call time, such as telling the pthread to sleep. IT IS ALL MAKING
SENSE.</p>

<p>Processes have exit codes, 0 is successful.</p>

<p>All the ways to exit</p>

<ul>
<li>exit, <code>Kernel#exit</code>, exits w 0 by default but you can pass a code,
runs <code>Kernel#at_exit</code> blocks. <code>exit!</code> does a code 1 and doesn&#8217;t run
exit blocks.</li>
<li>abort accepts a string in ruby, runs exit handlers, returns 1</li>
<li>raised exceptions yield exit code 1 and still raise things.</li>
</ul>


<p>Processes can fork, unless you&#8217;re JRuby. That means Unicorn won&#8217;t work
for JRuby.</p>

<p>Forking copies all memory (or copy on write). File descriptors are also
provided to forked thinger.</p>

<pre><code>2.0.0-p353 :016 &gt; fork { puts Process.pid; puts Process.ppid}
 =&gt; 46054
2.0.0-p353 :017 &gt; 46054
45874
2.0.0-p353 :018 &gt;   Process.pid
 =&gt; 45874
</code></pre>

<p>Parent and child can share file descriptors, open files, sockets, etc.
Because forking is faster than booting up fresh copies of servers&#8230; it
is good&#8230;?</p>

<p>Awesome example:</p>

<pre><code>if fork
  puts "YES"
else
  puts "NO"
end
</code></pre>

<p>Hahaha, don&#8217;t run this in irb though, because you&#8217;ll have two processes
reading from the same $stdin, e.g. your keyboard.</p>

<p>Blockless <code>fork</code> returns twice</p>

<ul>
<li>parent gets child pid</li>
<li>child gets nil</li>
</ul>


<p>Explains this output</p>

<pre><code>ruby -e "cid=fork; puts cid || 'none'"
46650
none
</code></pre>

<p>What about threads? Do thread ids change after forking?</p>

<pre><code>machty.github.com :: ruby -e "puts Thread.current; fork; puts Thread.current"
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
</code></pre>

<p>No it seems they don&#8217;t&#8230; forking really makes everything seem totally
the same. I wonder how that works at the pthread level.</p>

<p>http://pubs.opengroup.org/onlinepubs/009695399/functions/fork.html</p>

<blockquote><p>A process shall be created with a single thread. If a multi-threaded process calls fork(), the new process shall contain a replica of the calling thread and its entire address space, possibly including the states of mutexes and other resources. Consequently, to avoid errors, the child process may only execute async-signal-safe operations until such time as one of the exec functions is called. [THR] [Option Start]  Fork handlers may be established by means of the pthread_atfork() function in order to maintain application invariants across fork() calls.</p></blockquote>

<p>So only a single thread is created, and the kernel knows it&#8217;s a separate
thread, but the forked instance still thinks the address of that thread
is the same as before, even though it&#8217;s obviously a different thread.</p>

<p>Forking allows (but doesn&#8217;t guarantee) a process to run on multiple
cores. If the system is busy the forked processes might all run on the
same CPU.</p>

<p>Forking duplicates memory (assuming no copy-on-write; TODO: learn the
terminology for total memory vs not-yet-copied-on-write memory).
Running out of memory due to over-forking is called a fork bomb.</p>

<p>Forking means orphaning if the parent process finishes before children.</p>

<p>Daemon processes are intentionally orphaned so that they can stay
running forever. Orphaned children can be communicated with via signals.</p>

<p>Fork-and-forget vs remembering child process. <code>Process.wait</code> will wait
for ONE child process to terminate before quitting, and returns the pid
of the child process that terminates. Spawn 3 processes, must wait three
times. <code>wait2</code> returns <code>[pid, status]</code>, so you can get codes n shit.
<code>waitpid</code> and <code>waitpid2</code> wait on specific pids. But they are aliased to
the same thing: `wait</p>

<p>The kernel queues child process return info so that waiting on a process
that has already did will return its shit. That said, waiting on
non-existent children raises <code>ECHILD</code>.</p>

<p>Unicorn forks N times, makes sure the processes are still alive,
restarts if necessary, etc.</p>

<p>If you don&#8217;t do <code>Process.wait</code> though, the kernel will keep on storing
information about exit codes, etc. You either need to <code>wait</code> or <code>detach</code>,
or else you get a zombie process.</p>

<p>http://en.wikipedia.org/wiki/Zombie_process</p>

<p>A Zombie process is a process that has called exit but whose parent
hasn&#8217;t called <code>wait</code> or <code>detach</code>.</p>

<ul>
<li>Zombie: un-reaped, terminated child process</li>
<li>Orphan: still active child process whose parent has died.</li>
</ul>


<p>Orphans get attached to <code>init</code> (or <code>launchd</code> in OS X land), which has a
pid of 1.</p>

<p>Oh man, fork bombs are hilarious: http://en.wikipedia.org/wiki/Fork_bomb</p>

<p>So ppid actually automatically updates:</p>

<pre><code>fork do
  loop do
    puts "(#{Process.pid}, #{Process.ppid})"
    sleep 1
  end
end

sleep 1

abort "k i'm done #{Process.pid}"
</code></pre>

<p>Output:</p>

<pre><code>(47598, 47597)
(47598, 47597)
k i'm done 47597
(47598, 1)
(47598, 1)
</code></pre>

<p>Pretty cool.</p>

<p>Also if you <code>brew install pstree</code> and take a look at that, pid 1 is
<code>launchd</code>.</p>

<p>You can check the status of process and how it changes into a zombie and
then when it gets removed from the process table when we call
<code>Process.wait</code>:</p>

<pre><code>cpid = fork {}
puts `ps -p #{cpid} -o state`
sleep 1
puts `ps -p #{cpid} -o state`
Process.wait
puts `ps -p #{cpid} -o state`
</code></pre>

<p>Yields:</p>

<pre><code>STAT
R+
STAT
Z+
STAT
</code></pre>

<p>Note the last STAT is empty because no such pid; shit is dead.
The <code>+</code> means process is in the foreground process group of its control
terminal.</p>

<p>Note that no memory is allocated to the zombie process itself; just the
slot in the process table is used; zombie processes prevent other
processes from taking their place and reusing their PID. Which is
another thing: a parent process might not want a child pid to be reused
when creating a child pid, so it&#8217;ll create the new child, and THEN
<code>wait</code>/<code>detach</code> on original.</p>

<p><code>Process.detach</code> spins up a thread to <code>wait</code> on a process. Here&#8217;s a
really roundabout way to detach and then wait and get the return value:</p>

<pre><code>t = Process.detach(cpid)
puts `ps -p #{cpid} -o state`
puts t.value
</code></pre>

<p><code>t.join</code> before a <code>t.value</code> is a noop; <code>value</code> must always <code>join</code> in
order to get the value.</p>

<p>Fork-and-forget is rare. <code>Process.detach</code> has no system call equiv; it&#8217;s
just a ruby convenience.</p>

<p>SIGCHLD fires when a child process exits. You can trap it and <code>wait</code> for
that process to finish. Problem is, signal delivery is unreliable; if
you&#8217;re handling a signal and another one comes in, you might not receive
that signal. Solution is to pass a second param to <code>wait</code> to describe
how the kernel should wait for this thing, e.g. <code>Process::WNOHANG</code></p>

<p>Shit is so messy</p>

<pre><code>Process.trap(:CHLD) do
  nil while Process.wait(-1, Process::WNOHANG) rescue Errno::ECHILD
end
</code></pre>

<p>Yes you could unravel but come on.</p>

<p>Signals are async, ignorable, actionable, defaultable. Processes use the
kernel to as an intermediary to send messages.</p>

<pre><code>echo "puts 'lol'" | ruby
</code></pre>

<p>Who knew? It accepts input from stdin. So you can pipe Ruby code to it.
Ctrl-C sends an interrupt. You can trap it and ignore. You can also say
<code>trap(:INT, "IGNORE")</code></p>

<p>It&#8217;s good form in lib code to define a trap, though it&#8217;s possibly to
preserve other people&#8217;s callbacks and call them in yours. But you can&#8217;t
restore default behavior. This is fine if your&#8217;e writing a server
though.</p>

<blockquote><p>USR2 - reexecute the running binary. A separate QUIT should be sent to the original process once the child is verified to be up and running.</p></blockquote>

<p>https://github.com/ice799/memprof does some cool stuff with trapping
signals, printing out useful shits.</p>

<p>This guy is boundlessly smart.</p>

<p>Make a pipe, give someone one end to yell into and the other person the
put their ear up to it. Methinks you see where this is going.</p>

<p>Source and Sink, Writer and Reader. Pipe persists until all associated
descriptors are closed. Half-closed pipes are &#8220;widowed&#8221;. Writing to a
widowed pipe yields <code>SIGPIPE</code>, but widowing it is how the reader gets an
EOF signal. <code>SIGPIPE</code> can be disabled via F_SETNOSIGPIPE in fcntl, which
we saw above in this journal for telling a hard drive to actually
preserve write order.</p>

<p>In Ruby you can pass an encoding which tags the read input with that
encoding.</p>

<p>http://ruby-doc.org/core-2.0/IO.html#method-c-pipe</p>

<pre><code>rd, wr = IO.pipe

if fork
  wr.close # REQUIRED
  puts "Parent got: &lt;#{rd.read}&gt;"
  rd.close
  Process.wait
else
  rd.close # REQUIRED
  puts "Sending message to parent"
  wr.write "Hi Dad"
  wr.close
end
</code></pre>

<p>The <code># REQUIRED</code> closes are there because otherwise the data won&#8217;t
flush, EOF&#8217;s won&#8217;t be called.</p>

<p>So that&#8217;s a neat little primitive, but how is it different than just
using a StringIO? Well, aside from the fact that I don&#8217;t think you can
just progressively write into StringIO as you read from it (maybe you
can), Pipe goes through the kernel; there&#8217;s system calls and overhead.
Check this bitchin benchmark:</p>

<pre><code>require 'benchmark'
require 'stringio'

n = 100000
Benchmark.bm do |x|
  x.report("pipes:") {
    n.times do
      rd, wr = IO.pipe
      wr.write "HELLO"
      wr.close
      raise "wat" unless rd.read == "HELLO"
      rd.close
    end
  }

  x.report("StringIO") {
    n.times do
      s = StringIO.new("HELLO")
      raise "wat" unless s.read == "HELLO"
      s.close
    end
  }
end
</code></pre>

<p>yields</p>

<pre><code>              user     system      total        real
  pipes:  0.630000   0.730000   1.360000 (  1.363994)
StringIO  0.080000   0.000000   0.080000 (  0.077973)
</code></pre>

<p>This is skewed by the fact that you&#8217;re not going to be creating and
dumping pipes all the time, but it just highlights the inner workings of
Pipe: because it involves syscalls, much of the time is spent in
<code>system</code>.</p>

<p>With streams (pipes/TCP sockets), you write to a stream followed by a
delimiter. Newline is the delimiter. Unix sockets are intra machine, and
fast.</p>

<p>Use sockets to communicate in datagrams vs delimited stream chunks. You
still have pairs, but rather than read/write pairs, you just have
bidirectional shits, one of which needs to get closed per process.
Sockets are bidirectional!</p>

<p>http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or
http://wiki.secondlife.com/wiki/Message_Queue_Evaluation_Notes</p>

<p>From http://www.ruby-doc.org/core-2.1.0/IO.html</p>

<blockquote><p>In the example below, the two processes close the ends of the pipe that they are not using. This is not just a cosmetic nicety. The read end of a pipe will not generate an end of file condition if there are any writers with the pipe still open. In the case of the parent process, the rd.read will never return if it does not first issue a wr.close.</p></blockquote>

<p>Fuckles and shittles.</p>

<pre><code>man socketpair
</code></pre>

<p>Thom Ass Tover says:</p>

<p>http://www.thomasstover.com/uds.html</p>

<p>So these sockets are Unix Domain Sockets, or local sockets.</p>

<p>Pipes</p>

<ul>
<li>can be given a name</li>
<li>writing to a full one yields <code>SIGSTOP</code></li>
<li>are faster than Unix domain sockets</li>
<li>require context switches w kernel to use read/write</li>
</ul>


<p>Solaris pipes are special in that they are full duplex, where as on
Linux and BSD you&#8217;d need two pipes for full duplex. fifos are named
pipes. I guess they&#8217;re like files.</p>

<p>http://en.wikipedia.org/wiki/Named_pipe</p>

<p>wow:</p>

<pre><code>mkfifo my_pipe
gzip -9 -c &lt; my_pipe &gt; out.gz &amp;
</code></pre>

<p>So, Matt Daemon.</p>

<p><code>init</code> or <code>launchd</code> has ppid 0 and pid 1.</p>

<p><code>exit if fork</code> will fork and close the parent process.</p>

<p><code>Process.setsid</code> creates a new session. It talks about a process groups
and what not. If you call it, your process becomes</p>

<ul>
<li>session leader of new session</li>
<li>process group leader of new process group</li>
<li>and has no controlling terminal</li>
<li>and becomes the only new thing in the thing</li>
</ul>


<p>returns the new process group ID.</p>

<p>Job control is the way processes are managed by terminal. Process group
id is generally same as process ID. Fork and the process group id will
be the same. If they fork and so on then yeah yeah yeah this is how you
know they all came from the same shit. When you do <code>irb</code> in a terminal
it&#8217;ll set the process group to the pid of the command you run.</p>

<p>This is why interrupting a Ruby script that&#8217;s shelled out to thing will
kill all the things if it gets an interrupt; if it&#8217;s still alive, it&#8217;ll
kill children. It&#8217;s only upon normal exiting that you lose
thisetoisjdoiasj.</p>

<p>Session groups are higher up, a collection of process groups. One
session group: <code>echo "lol" | echo "lol"</code>. EPERM fires if you are already
leader (can only call w children).</p>

<p>Look at http://rubygems.org/gems/daemons</p>

<p><code>exec</code> totally transforms your shit, better fork first.</p>

<pre><code>Thread.new {
  sleep 2
  puts "THIS WILL NEVER PRINT"
}
Thread.new {
  sleep 1
  exec 'ls'
}
</code></pre>

<p>It entirely nukes your process context, including any outstanding
threads. You must escape via a fork.</p>

<p>Ruby&#8217;s <code>exec</code> will close file handles, database connections, etc, before
passing control to the new shit, though native <code>exec</code> calls would leave
them open. Sensible default given <code>echo</code> doesn&#8217;t care about your
database. You might accidentally exec another process that doesn&#8217;t do
anything with a db connection, and it never totally closes. But you can
override this default if you want to pass the fileno to the new process
and keep open that handle when it opens it for reading.</p>

<p>Unlike fork, no memory is shared with the resulting process of an exec.</p>

<p>I am so tired.</p>

<p><code>system</code> returns a true or false. Output barfs to stdout.</p>

<p><code>popen</code> opens a bi-directional pipe; you can write to and read from the
process spawned</p>

<p><code>popen3</code> gives you access to all 3.</p>

<p>Forking means a copy of all the parent process&#8217;s context before
<code>exec</code>-ing something super small like <code>ls</code>, but you can use gems that
wrap <code>posix_spawn(2)</code></p>

<p>https://github.com/rtomayko/posix-spawn</p>

<p>Also check out <code>man vfork</code> for virtual memory friendly forking.</p>

<p>Resque forks for memory management; bloating Ruby tasks tend not to
shrink, so fork makes it possible for forked workers to bloat and
disappear.</p>

<p>http://rubydoc.info/github/defunkt/resque/Resque/Worker</p>

<blockquote><p>A Resque Worker processes jobs. On platforms that support fork(2), the worker will fork off a child to process each job. This ensures a clean slate when beginning the next job and cuts down on gradual memory growth as well as low level failures.</p>

<p>It also ensures workers are always listening to signals from you, their master, and can react accordingly.</p></blockquote>

<p>Preforking, is it cool. haidjasoidjasiodj</p>

<p>What&#8217;s the rules on writing to stdout between multiple processes.
You can do it; there&#8217;s not going to be thread-unsafety, i don&#8217;t think.</p>

<p>http://stackoverflow.com/questions/1326067/how-to-lock-io-shared-by-fork-in-ruby</p>

<p>Preforking has load balancing wins similar to message queuing with
multiple consumers; when a consumer is ready, it just listens for the
same thing. A socket is shared b/w forked processes, and kernel makes
sure only one gets it</p>

<p>I need to understand more about $stdout and buffering and what not. It&#8217;s
not thread safe, but process-safe? syscall-safe?</p>

<ul>
<li>fork-safe if the action in question fits within a single syscall</li>
</ul>


<p>I have no fucking IDEA MY BRAIN IS DEAD.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/26/daily-journal/"/>
    <updated>2014-07-26T15:10:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/26/daily-journal</id>
    <content type="html"><![CDATA[<h2>top</h2>

<blockquote><p>display and update sorted information about processes</p></blockquote>

<p><code>top</code> will display a sampled, updating list of processes, ordered by pid
by default. Order by cpu:</p>

<pre><code>top -o cpu
</code></pre>

<p>Filter by a pid</p>

<pre><code>top -pid 12345
</code></pre>

<p>Show a single sample of the pid and thread number for a given pid</p>

<pre><code>top -l1 -pid 1234 -stats pid,th
</code></pre>

<h2>Spawn 50 ruby threads&#8230;</h2>

<p>and you wind up w 52: <code>Thread.main</code> + the 50 you created + Ruby
housekeeping thread (listening for OS signals and piping them
synchronously to main thread).</p>

<p>Ruby creates legit OS threads, vs <code>_____</code> threads, whatever the
terminology is for threads that live entirely in the code.</p>

<h2>Thread#join</h2>

<p>Yes, you have to call it on a spawned thread so that the main thread
will wait on it before prematurely exiting. But did you know that
exceptions thrown in a spawned thread get re-raised on the main thread
if you do <code>.join</code>?</p>

<p><code>Thread#value</code> joins and returns the last value of the thread.</p>

<p><code>Thread#status</code> returns status for live, dead, erroed, dying threads.</p>

<p><code>Thread.stop</code> puts the thread to sleep and it won&#8217;t wake up until
someone calls <code>wakeup</code> on it</p>

<p><code>Thread.pass</code> hints the OS to schedule another thread, but this may be
ignored by the scheduler.</p>

<p><code>Thread#raise</code> lets you externally fire exceptions within another thread
but should not be used because <code>ensure</code> is busted. <code>Thread#kill</code> does
what you expect but should also be aborted for the same reasons.</p>

<p>Multiple threads mean concurrency; they <em>might</em> mean parallelism. One
CPU switching b/w threads means concurrency but not parallelism;
multiple cores means paralleilism if they&#8217;re both executing.</p>

<p>Code can&#8217;t be parallel, only concurrent. The executation of concurrent
code can be parallel if the scheduler so chooses.</p>

<h2>golang concurrency vs parallelism</h2>

<p>http://concur.rspace.googlecode.com/hg/talk/concur.html#slide-2</p>

<p>Concurrency is defined as:</p>

<blockquote><p>Programming as the composition of independently executing processes</p></blockquote>

<p>not Linux processes, but rather the famously harder to define Process.</p>

<p>Parallelism is</p>

<blockquote><p>Programming as the simultaneous execution of (possibly related) computations.</p>

<p>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable</p></blockquote>

<p>Concurrency facilitates but doesn&#8217;t guarantee parallelism.</p>

<p>Goroutines aren&#8217;t threads; they&#8217;re similar but cheaper, won&#8217;t block
other goroutines, and multiplexed onto OS threads as necessary.</p>

<p>Synchronize via channels. I guess this is like Ruby Queue? Sounds like
you&#8217;d never do someGoroutine.value but rather use the channel primitive.</p>

<h2>ruby concurrency and you</h2>

<p>https://blog.engineyard.com/2011/ruby-concurrency-and-you</p>

<p>Green threads</p>

<ul>
<li>scheduled by VM, rather than underlying OS</li>
<li>pre 1.9 Ruby was this way (MRI)</li>
<li>managed in user space rather than kernel space</li>
</ul>


<p>Test: if i run Ruby 1.8.7 and do a top of new threads, I would expect
the thread count to be only whatever I started with.</p>

<p>BEHOLD, on 1.8.7:</p>

<pre><code>PID    #TH
84752  1
</code></pre>

<p>So old ruby didn&#8217;t even spawn another thread for housekeeping&#8230; I guess
maybe it wasn&#8217;t necessary because it didn&#8217;t have to coordinate the
signals landing at any random currently-active thread? Pretty cool.</p>

<p>I guess green threads are easy to implement in any interpreted language:
in the main loop of the interpreter you can just check if 100ms has gone
by and then move to another other known threads.</p>

<p>Early Java had green threads&#8230; I don&#8217;t know enough about Java to
comment here.</p>

<p>Ruby &lt;1.9 was smart enough to know when one of these threads was blocked
on external data so that it could &#8220;sleep&#8221; until the data arrived:</p>

<blockquote><p>MRI 1.8.7 is quite smart, and knows that when a Thread is waiting for some external event (such as a browser to send an HTTP request), the Thread can be put to sleep and be woken up when data is detected.</p></blockquote>

<p>1.9 uses native threads, but there&#8217;s still a GIL because the non-Ruby
parts of MRI 1.9 aren&#8217;t thread-safe.</p>

<p>MRI 1.9 uses the same technique as MRI 1.8 to improve the situation,
namely the GIL is released if a Thread is waiting on an external
event (normally IO) which improves responsiveness.</p>

<p>Great read:</p>

<p>http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/</p>

<p>Threads are hard, but requests are an extremely clean concurrency
primitive: controllers and the models loaded and views rendered, etc.,
are not shared between threads that are processing requests. It&#8217;s only
if you start using global state that problems arise, but why are you
doing that?</p>

<p>Why the Ruby/Rails thread FUD?</p>

<ul>
<li>Early Rails wasn&#8217;t threadsafe; essentially a mutex around each request</li>
<li>Mongrel explicitly mutexed around its Rails adapter, so even when
<code>threadsafe!</code> was added, you&#8217;d still have zero concurrency in mongrel.</li>
</ul>


<blockquote><p>For safety, Ruby does not allow a context switch while in C code unless the C code explicitly tells the VM that itâ€™s ok to do so.</p></blockquote>

<p>And mysql was poorly written in this case. So mysql would block.</p>

<blockquote><p>A lot of people talk about the GIL (global interpreter lock) in Ruby 1.9 as a death knell for concurrency. For the uninitiated, the GIL disallows multiple CPU cores from running Ruby code simultaneously. That does mean that youâ€™ll need one Ruby process (or thereabouts) per CPU core, but it also means that if your multithreaded code is running correctly, you should need only one process per CPU core. Iâ€™ve heard tales of six or more processes per core. Since itâ€™s possible to fully utilize a CPU with a single process (even in Ruby 1.8), these applications could get a 4-6x improvement in RAM usage (depending on context-switching overhead) by switching to threadsafe mode and using modern drivers for blocking operations.</p></blockquote>

<p>Node vs Ruby Threading:</p>

<p>Yehuda: &#8220;the main difference is that a callback is smaller in size than a stack&#8221;</p>

<p>In other words, the context switch that happens when switching threads
includes copying over an entire stack of the thread you&#8217;re resuming and
some other details I don&#8217;t know of off the top of my head. But with
callbacks, the callbacks have no stack (is this true in Rubyland? maybe
there&#8217;s stack trace information but probably no stack. The only stack
starts from where the callback/block was created, and the same is true w
threads, but the point is that in a thread-per-request model, the stack
goes all the way up to when the request was first received, which can be
a pretty tall stack).</p>

<p>So what about Fibers? They&#8217;re cooperative, but why is their context
switch not a big deal? They have a stack size limit of 4kb. How can I
test this?</p>

<p>Here&#8217;s a nice article:</p>

<p>http://timetobleed.com/fixing-threads-in-ruby-18-a-2-10x-performance-boost/</p>

<p>Seems to suggest that the stack that needs to be copied when context
switching includes interpreter code, which has many local vars and
sometimes the stack is up to 4kb, which is cray cray.</p>

<p>Green threads: pre-emptible userland threads. userland = not kernel
land.</p>

<p>You can hack into the thread-yielding code of old Ruby to allocate
stacks on the heap so that all you have to do to context switch is
change what rsp (pointer to the bottom of the stack) points to. This
means the stack won&#8217;t grow (so you have to pick a sensible size).</p>

<p>Ruby 1.9 performs way better in the benchmarks than his hacks&#8230; why?
&#8220;Thanks. 1.9 uses pthreads which create stacks in a similar manner to
what I did.&#8221; Awesome.</p>

<p>pthreads = POSIX threads</p>

<p>http://timetobleed.com/threading-models-so-many-different-ways-to-get-stuff-done/</p>

<p>Threads models:</p>

<h3>1:1 (native threads)</h3>

<p>One kernel thread for every user thread.</p>

<p>Pros</p>

<ul>
<li>execute threads on different CPUs</li>
<li>threads don&#8217;t block each other</li>
<li>shared memory b/w threads</li>
</ul>


<p>Cons</p>

<ul>
<li>Setup overhead since creating a thread requires a system call (and
those are slow)</li>
<li>Low upper bound on the number of threads that can be created</li>
</ul>


<p><code>pthread_create</code> is the fn that makes the system call to create the
thread.</p>

<h3>1:N (green threads)</h3>

<p>&#8220;lightweight threads&#8221;</p>

<ul>
<li>thread creation, execution, cleanup are cheap</li>
<li>lots of threads can be created</li>
</ul>


<p>Cons</p>

<ul>
<li>kernel doesn&#8217;t know about it, so no parallel execution across CPUs</li>
<li>blocking IO can block all green threads</li>
</ul>


<p>Forking + threading and cross-process communication is one way around
limitations.</p>

<h3>M:N</h3>

<p>Hybrid of above</p>

<ul>
<li>Multi CPUs</li>
<li>Not all threads blocked by blocking system calls</li>
<li>Cheap</li>
</ul>


<p>Cons</p>

<ul>
<li>Really really hard to synchronize userland and kernel scheduler</li>
<li>Green threads will block within same kernel thread</li>
<li>Difficult to maintain</li>
</ul>


<p>1:1 has shown itself to be more performant, but in some cases M:N might
be the right choice.</p>

<p>TODO: read this http://www.akkadia.org/drepper/nptl-design.pdf</p>

<pre><code>b = nil

t = Thread.new do
  b = Fiber.new {
    puts "FIBER"
  }
end

while !b
  # just wait
end

b.resume
</code></pre>

<p>This results in</p>

<pre><code>fiberthread.rb:13:in `resume': fiber called across threads (FiberError)
        from fiberthread.rb:13:in `&lt;main&gt;'
</code></pre>

<p>Of course it would.</p>

<p>Use strace / dtruss to trace sys calls.</p>

<p>Spinlocks are locks that, rather than sleeping, actively busy-wait until
the lock is free. This only makes sense if the wait is expected to be
short, otherwise it might block other threads.</p>

<p>Interesting, from the wiki:</p>

<blockquote><p>Most operating systems (including Solaris, Mac OS X and FreeBSD) use a hybrid approach called &#8220;adaptive mutex&#8221;. The idea is to use a spinlock when trying to access a resource locked by a currently-running thread, but to sleep if the thread is not currently running. (The latter is always the case on single-processor systems.)</p></blockquote>

<p>The idea is that a lock by an active thread is likely to be finished
soon, and since spinlocks avoid the scheduling overhead of a context
switch, then hooray.</p>

<p>Busy-waiting in general means while-looping until some condition is
true. You can even do this in JS:</p>

<pre><code>var end = +new Date() + 1000;
while (+new Date() &lt; end) {}
</code></pre>

<p>So whether Node or EventMachine, the concept is the same: both run on
callbacks.</p>

<p>Realization: I was thinking that I could demonstrate the difference b/w
green threads and OS threads by seeing if a while(true) in a green
thread would yield to others, but the answer is:</p>

<ul>
<li>of course it would yield; each iteration of the while true is
an iteration of the interpreter loop that&#8217;s running commands, so its
timer would fire at that point.</li>
<li>the only time it&#8217;d block is if you called out to a C extension that
looped and didn&#8217;t yield back control.</li>
</ul>


<p>It seems a Fiber&#8217;s 4k stack begins at the point at which it is created.
Hmm. So does it or does it not include interpreter stuff? Well for one
it&#8217;s in the same thread as a requirement.</p>

<p>Reasons why Fibers are faster than threads:</p>

<ul>
<li>limited 4kb stack for quick context switching</li>
<li>no pre-emption means no aggressive/frequent context switching;
context-switch as infrequently as you&#8217;d like.</li>
</ul>


<p>https://github.com/eventmachine/eventmachine/blob/master/docs/old/LIGHTWEIGHT_CONCURRENCY</p>

<p>Lightweight Concurrency generally means</p>

<ul>
<li>putting thread scheduling under the control of your program</li>
</ul>


<blockquote><p>By &#8220;lighter,&#8221; we mean: less
resource-intensive in one or more dimensions, usually including memory and
CPU usage. In general, you turn to LC in the hope of improving the
performance and scalability of your programs.</p></blockquote>

<p>NOTE: race conditions can happen in concurrent environments, even if
parallelism isn&#8217;t there, e.g. preempting</p>

<p>Mac has a max 2048 thread limit.</p>

<p>&#8220;IO Bound&#8221; means your program is mostly bottlenecked by IO, such that
swapping for a faster IO would boost your program performance immensely.</p>

<p>In such a case, going multi-threaded is a no-brainer rather than
serially getting blocked on each slow thing. But if you over do it then
you might just be wasting memory/CPU resources from thread stacks and
context switching that it&#8217;s not justified.</p>

<p>&#8220;CPU bound&#8221; means doubling CPU would mean the job would get done that
much faster.</p>

<p>Quad-core with 4 threads on CPU bound means mega-wins for Rubinius but
obviously not GIL&#8217;d MRI. If you make it 5, then you get the
context-switching overhead.</p>

<p>Rails apps are combo of IO-bound and CPU-bound</p>

<p>IO:</p>

<ul>
<li>Database</li>
<li>Third party APIs</li>
<li>Files read</li>
</ul>


<p>CPU:</p>

<ul>
<li>Rendering templates</li>
<li>Rendering JSON</li>
</ul>


<p>Measure measure measure.</p>

<p>This is comically incorrect:</p>

<pre><code>Mutex.new.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>should be</p>

<pre><code>m = Mutex.new

# ...create thread...

m.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>&#8220;critical section&#8221; refers to the part of your concurrent code that
alters shared data.</p>

<p>Memory Models describe the guarantees made to threads when
reading-from/writing-to memory, which mostly become important to think
about in a multi-threaded settings. The memory model describes how
caching occurs in the registers before actually writing out to memory,
and it describes the scope of compiler/hardware optimizations that can
be made that lead to non-determinant order of memory operations which
can fuck your shit unless you use <code>volatile</code> in Java or explicit mutexes
in Ruby.  Ruby doesn&#8217;t have a memory model spec yet. Java and Go and
others do. I guess Rust nips this in the bud w ownership.</p>

<p>Mutex is a form of a memory barrier, and I think <code>volatile</code> is too.</p>

<p>Livelocking is when <code>try_lock</code>s repeatedly fail, so the threads are
still technically alive but stuck in the same loop.</p>

<p>Best solution is to declare mutex grabbing in the same order via a mutex
hierarchy.</p>

<h2>Signals in ruby</h2>

<p>Rubyz</p>

<pre><code>Signal.trap("USR1") do
  puts "lol handling your custom user handler"
end
puts Process.pid # =&gt; e.g. 12345
</code></pre>

<p>Shellz</p>

<pre><code>kill -s USR1 12345
</code></pre>

<p>So many ways to kill a program:</p>

<ul>
<li>Abort: often self-initiated by <code>abort</code></li>
</ul>


<h2>Difference b/w seg fault and bus error</h2>

<p>http://stackoverflow.com/questions/838540/bus-error-vs-segmentation-fault</p>

<p>On most architectures I&#8217;ve used, the distinction is that:</p>

<ul>
<li>a SEGV is caused when you access memory you&#8217;re not meant to
(e.g., outside of your address space).</li>
<li>a SIGBUS is caused due to alignment issues with the CPU
(e.g., trying to read a long from an address which isn&#8217;t a multiple of 4).</li>
</ul>


<h2>Signals in C</h2>

<p>This is just for fun, but you can set up signal masks and signal
handles and all that fun crap.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

static int gotSignal = 0;

void wat(int s) {
  printf("Got Signal %d", s);
  gotSignal = 1;
}

int main() {
  /* SIGUSR1 == 16 */
  signal(SIGUSR1, &amp;wat);

  pid_t pid = getpid();
  printf("The process id is %d", pid);

  // prevent signal from getting here
  sigset_t s;
  sigaddset(&amp;s, SIGUSR1);
  // uncomment to block the signal from arriving
  //sigprocmask(SIG_BLOCK, &amp;s, NULL);

  while(!gotSignal) {
    printf(".");
    fflush(stdout);
    sleep(1);
  }

  printf("\nDone!\n");
}
</code></pre>

<p>and you can send it usr1 via</p>

<pre><code>kill -s USR1 12345
</code></pre>

<h2>Signals in Node</h2>

<pre><code>var done = false;

process.on("SIGUSR1", function() {
  done = true;
});

console.log("pid: ", process.pid);

var timerId = setInterval(function() {
  if (done) {
    console.log("DONEZO");
    clearInterval(timerId);
  } else {
    process.stdout.write(".");
  }
}, 500);
</code></pre>

<p>Note that SIGUSR1 is reserved by node.js to start the debugger.
The above code will work but if the debugger&#8217;s enabled then that&#8217;ll also
cause it to start.</p>

<p>Seems that signals are often used to start a debugger, or some kind of
debugging operation. Interesting.</p>

<h2>Condition Variables</h2>

<p>A provider and consumer both use the same mutex. Provider locks when
providing an update. Consumer locks when trying to perform an operation,
but internally does a <code>condvar.wait(mutex)</code> with the locked <code>mutex</code> to
unlock until the <code>condvar</code> is <code>signal</code>ed by the provider.</p>

<p>So why wrap the consumer in a while loop rather than an if (see page 104
of storimer)? Because there could be multiple consumers.</p>

<p><code>ConditionVariable#signal</code> wakes up a single thread, <code>ConditionVariable#broadcast</code>
wakes up all threads.</p>

<h2><code>thread_safe</code> gem</h2>

<ul>
<li>ThreadSafe::Array</li>
<li>ThreadSafe::Hash</li>
<li>ThreadSafe::Cache

<ul>
<li>similar to Hash, but insertion order enumeration isn&#8217;t preserved,
which means it can be faster</li>
</ul>
</li>
</ul>


<h2>Immutable = threadsafe</h2>

<p>Read more about it.</p>

<h2>Globals</h2>

<p>The Ruby AST is a global (is it really an AST at that point? is
dynamically adding a method an example of modifying an AST? ASTs are for
parsing, not so much adding/removing methods from a class obj).</p>

<p>Anyway, Kaminari was bitten by this:</p>

<p>https://github.com/amatsuda/kaminari/issues/214</p>

<h2>Thread-locals</h2>

<p>Variables that are global to everything in the current thread but hidden
to everyone else. So you could do</p>

<pre><code>Thread.current[:some_service] = SomeService.new
</code></pre>

<p>which could open a new connection. Connections are nice concurrency
primitives, much like request objects in Rails. But if you have too many
threads, you might hit a max connection limit, so in that case, use
pools, lol.</p>

<p>Pools let you specify max concurrency, which is likely less than the
number of threads that might want to consume it, and then when
requesting access to a thing in a pool, it&#8217;ll block until a slot&#8217;s
available.</p>

<p>See: https://github.com/mperham/connection_pool</p>

<p>mperham is Mr Sidekiq. Mr. Concurrency in general I guess.</p>

<p>Question: is a connection pool the same as a thread pool? Probably not,
connection pool is just a resource pool that is thread-aware, but
doesn&#8217;t constitute individual threads.</p>

<h2>Rubinius Actor</h2>

<p>https://github.com/rubinius/rubinius-actor</p>

<p>Depends on core Rubinius class <code>Channel</code>. TODO: find out why <code>Channel</code>
doesn&#8217;t/can&#8217;t exist in MRI.</p>

<h2>Rubinius Ruby JITting</h2>

<p>Talking to IRC folk: one of the major reasons for Ruby all the way down
or at least Ruby most of the way down is that more of it can be JITted
rather than having the hard C/C++ boundary after which no more
optimizations can be made.</p>

<p>Also, in some benchmarks b/w Rubinius and JRuby and MRI, etc., one thing
that comes up a lot is the suggestion that the tests run for longer so
that the JIT is primed, all the optimizations have been made, etc etc
etc.</p>

<h2>Rails Batches</h2>

<p>http://api.rubyonrails.org/classes/ActiveRecord/Batches.html</p>

<pre><code>Article.find_each do |a|
  a.wat
end
</code></pre>

<p>this internally splits DB queries into batches of 1000 so that you&#8217;re
not instantiating potentially a billion Ruby objects for each row. In
the end you&#8217;ll still allocate the same amount of memory but it can be
GC&#8217;d along the way vs causing an insane spike and possibly crashing your
server.</p>

<h2>Server-sent events</h2>

<p>http://tenderlovemaking.com/2012/07/30/is-it-live.html</p>

<ol>
<li>A stream obj is added to Rails request object, quacks like IO obj.
You can write to it and close it, but it doesn&#8217;t actually stream live
to the client; it buffers, and then flushes.</li>
<li>With <code>ActionController::Live</code>, it&#8217;ll actually stream live.</li>
<li>Some WebServers, like WEBrick will thwart this by buffering the
response until it&#8217;s complete. Unicorn could work, but it&#8217;s meant for
fast responses; anything taking longer than 30s might get terminated.
Rainbows/Puma/Thin would work.</li>
</ol>


<h2>Celluloid</h2>

<p>Transforms method invocations into blocking messages. Precede w <code>async</code>
to prevent blocking (obviously still happens async);</p>

<pre><code>require 'celluloid'

class DoesStuff
  include Celluloid

  attr_accessor :i

  def foo
    # currently this displays
    # one item per second.
    # if you swap comments with
    # the line after it'll wait
    # until the very end to print them all
    # at once because the each at the end
    # will evaluate the "longest" future first
    sleep i
    #sleep (11 - i)
    i
  end
end


futures = []

10.times do |i|
  thing = DoesStuff.new
  thing.i = i

  futures &lt;&lt; thing.future.foo
end


futures.each do |f|
  puts "Completed: #{f.value.i}"
end

sleep
</code></pre>

<p>This is interesting: https://github.com/celluloid/celluloid/wiki/Frequently-Asked-Questions#q-can-i-do-blocking-io-inside-an-actor-or-do-i-have-to-use-celluloidio</p>

<p>It&#8217;s fine to have blocking IO such as waiting for a DB query to return,
or slow HTTP response, but you shouldn&#8217;t have it waiting on
<em>indefinite</em> IO; for that, use Celluloid::IO.</p>

<p>I believe that an actor can&#8217;t be handling multiple messages at the same
time. Wrong! That&#8217;s only if Erlang/Exclusive mode is on, and you have to
be careful about that because it means a higher risk of deadlock:</p>

<p>https://github.com/celluloid/celluloid/wiki/Exclusive</p>

<p>Sidekiq doesn&#8217;t make use of return values a whole lot; rather actors are
expected to send messages back to their &#8220;callers&#8221;.</p>

<p>Accessing localvars is faster than ivars: https://github.com/puma/puma/commit/fb4e23d628ad77c7978b67625d0da0e5b41fd124</p>

<h2>Compare and set (CAS)</h2>

<p>aka check-and-set</p>

<p>For platforms that support it, CAS is a mutex-free approach to
thread-safety</p>

<pre><code>a += 1
</code></pre>

<p>is not thread safe, but</p>

<pre><code>cur = a.value
new_value = cur + 1
if (!a.compare_and_set(cur, new_value)) 
  # try again
end
</code></pre>

<p>is.</p>

<p>Worth pointing out that Redis supports a form of this using WATCH.</p>

<pre><code>MULTI # begin transaction
SET foo lol
SET bar wat
EXEC # execute
</code></pre>

<p>so basically if you do</p>

<pre><code>WATCH someval
MULTI
set someval lol
EXEC
</code></pre>

<p>and someval changed after the MULTI then it will fail.</p>

<p>So why use CAS over a mutex?</p>

<blockquote><p>If the cost of retrying the operation is cheap, or rare, it may be much less expensive than using a lock.</p></blockquote>

<p>Logic checks out.</p>

<pre><code>require 'atomic'
v = Atomic.new(0)
v.update do |current|
  current + 1
end
</code></pre>

<p>This is the shorthand to the idempotent loop with CAS.</p>

<p>Lockless showed mega improvements relative to locking in Rubinius but
not JRuby for some reason.</p>

<p>Hamster is the immutability gem to check out.</p>

<h2>oni</h2>

<p>https://github.com/olery/oni</p>

<p>Uses SQS, look into it because i am such a nooblet.</p>

<h2>SQS</h2>

<p>Uses a visibility timeout after a consumer has started to receive a
message in which time it is hidden from other consumers, and in this
time it should be deleted.</p>

<ul>
<li>Supports GET/POST requests to public URLs, presuming you pass in a
valid signature

<ul>
<li>This means you could fire requests directly to SQS rather than
having to go to a server first&#8230; that is badass.</li>
</ul>
</li>
<li>Reports of scalability problems</li>
</ul>


<p><a href="http://nsono.net/amazon-sqs-vs-rabbitmq/">Alternative: RabbitMQ</a></p>

<ul>
<li>SQS: consumers must poll for messages, and SQS charges by the request,
even if the response is empty.</li>
<li>RabbitMQ supports push</li>
<li>is free and open source</li>
<li>based on erlang</li>
<li>adheres to AMQP (standard for high performance messages queues)</li>
<li>supports durable queues (crash-recoverable, written to disk)</li>
<li>delivered in order unless message requeued</li>
<li>more consistent (much less likely to deliver a message twice unless
the message actually failed)</li>
</ul>


<p>cons</p>

<ul>
<li>not necessarily highly available (because it&#8217;s a server that runs on
whatever instance you wanna put it on, so you have to manage failover,
redundancy, etc, whereas SQS is a system that handles all of that)</li>
<li>this is configurable, but the default is for RabbitMQ to drop messages
if there are no consumers; surprising to SQS folk.</li>
</ul>


<h2>Heartbeats</h2>

<p>https://www.rabbitmq.com/reliability.html</p>

<blockquote><p>In some types of network failure, packet loss can mean that disrupted TCP connections take some time to be detected by the operating system. AMQP offers a heartbeat feature to ensure that the application layer promptly finds out about disrupted connections (and also completely unresponsive peers). Heartbeats also defend against certain network equipment which may terminate &#8220;idle&#8221; TCP connections. In RabbitMQ versions 3.0 and higher, the broker will attempt to negotiate heartbeats by default (although the client can still veto them). Using earlier versions the client must be configured to request heartbeats.</p></blockquote>

<p>Re: &#8216;Heartbeats also defend against certain network equipment which may
terminate &#8220;idle&#8221; TCP connections.&#8217;: I bet that&#8217;s referring to NAT, which
manages a cache of IP translations and will go inactive if nothings been
sent to / received from an IP for a while.</p>

<p>YAY I WAS RIGHT http://stackoverflow.com/questions/865987/do-i-need-to-heartbeat-to-keep-a-tcp-connection-open#comment1713801_866003</p>

<p>So Heartbeats</p>

<ul>
<li>reassure you the connection is alive in some cases where the failure
conditions aren&#8217;t otherwise detectable</li>
<li>keep the NAT state tables warm for your IP</li>
</ul>


<h2>Celluloid::IO</h2>

<p>https://github.com/celluloid/celluloid-io</p>

<p>Provides a different class of Actor that&#8217;s heavier than normal Celluloid
actors, but contains a high performance reactor like EventMachine or
cool.io (todo: check out cool.io). So unlike EventMachine you can have
multiple loops, e.g. one in each actor (resources permitting). (Also,
does EM really force you to just have one?)</p>

<h2>Autoload</h2>

<p>Yes we know it&#8217;s not threadsafe in MRI. Recent JRuby versions make it
thread safe, but just eager load your shits before spawning threads.</p>

<h2>Requests as concurrency unit</h2>

<p>I guess in general you should always look for the concurrency unit; that
domain object that encapsulates all the data you need to get a job done
so that hopefully you&#8217;re not sharing data between threads. Each request
gets handled by its own thread.</p>

<h2>Queue</h2>

<p><code>Queue#pop</code> will suspend a thread until data is in the queue. Like a
mofuggin stream.</p>

<p>Queue is apparently the only thread-safe data structure that ships with
Ruby.</p>

<h2>JRuby</h2>

<p>Foreign function interface</p>

<p>http://en.wikipedia.org/wiki/Foreign_function_interface</p>

<p>Mechanism for languages to invoke routines from other languages.</p>

<p>Write your extension code in Ruby, FFI will call the write C / Java /
whatever stuff. It won&#8217;t even be compiled. I guess it just links into
dynamic libs?</p>

<p>JRuby obviously doesn&#8217;t support C extensions, but FFI extensions will
work.</p>

<p>JRuby</p>

<ul>
<li>has no fork(), since JVMs mostly can&#8217;t safely be forked
(<code>NotImplementedError: fork is not available on this platform</code>)</li>
<li>Fibers are native threads, rather than MRI green threads, which means
you are constrained to native thread overhead/limits.</li>
</ul>


<h2>Rubinius (rbx)</h2>

<ul>
<li>Designed for concurrency, speed.</li>
<li>Rubinius 2.0 has no GIL</li>
<li>All tools written in Ruby, including bytecode VM, compiler,
generational GC, JIT, etc</li>
<li>No continuations (because dependent on callcc, a C thing)</li>
<li>At some point, when dealing with locks and low level things, you&#8217;ll
find C++.</li>
</ul>


<p>http://rubini.us/2011/02/25/why-use-rubinius/</p>

<h2>Ruby Enterprise Edition</h2>

<p>By Phusion. No longer alive.</p>

<ul>
<li>Compatible w 1.8.7</li>
<li>End of Life since 2012</li>
<li>No more work being done, reasons being:

<ul>
<li>Rails 4 no longer supporting 1.8</li>
<li>COW patch accepted on Ruby 2.0</li>
<li>Many Ruby Enterprise Edition patches addressed in 1.9, 2.0</li>
</ul>
</li>
</ul>


<h2>MacRuby</h2>

<p>Implementation of 1.9 Ruby directly on top of Mac OS X core tech, e.g.</p>

<ul>
<li>Obj-C runtime and GC</li>
<li>LLVM compiler infrastructure</li>
</ul>


<h2>Reactive manifesto</h2>

<p>TODO: read this http://www.reactivemanifesto.org/</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/19/daily-journal/"/>
    <updated>2014-07-19T11:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/19/daily-journal</id>
    <content type="html"><![CDATA[<h2>Crank</h2>

<p>Meth.</p>

<p>An eccentric person, esp. one who is obsessed by a particular subject or
theory: when he first started to air his views, they labeled him a
crank | [ as modifier ] : I am used to getting crank calls from
conspiracy theorists.</p>

<h2>Roko&#8217;s modern basilisk</h2>

<p>It&#8217;s happening.</p>

<h2>Transactional UIs</h2>

<p>People build forms. Ember gives you sweet syntax sugar for 2wb.
Not for transactional UI, anything that needs a buffer.</p>

<p>Old mindset: if you need 1wb, just&#8230; don&#8217;t set on the other side of a
2wb.</p>

<p>TODO: ask kris more about the async/sync cocoa observer binding
limitations.</p>

<ul>
<li>Most observers just do something and stop.</li>
<li>And they mostly want to know the last thing they cared about.</li>
</ul>


<p>Bubbling doesn&#8217;t describe actions; actions go wherever. Bubbling only in
route hierarchy.</p>

<p>Services:</p>

<ul>
<li>session/user</li>
<li>timer</li>
<li>websocket</li>
<li>analytics</li>
</ul>


<p>Idea: components provide services to the components the render. They
have a ServiceCertificate</p>

<p>Goal:</p>

<ul>
<li>Try and associate actions with objects.</li>
<li><code>actions</code> themselves can just be passed into the <code>actions</code></li>
</ul>


<h2>Non-dynamic routes</h2>

<pre><code>resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}

resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}
</code></pre>

<p>Initializers vs <code>applicationRoute#beforeModel</code>.</p>

<p>retcon for how to use controllers</p>

<p>asop to data binding</p>

<p>HTMLbars knows what parts of the template are dynamic vs static.</p>

<p>In React, if you have a conditional</p>

<h2>Skunkworks project</h2>

<blockquote><p>A skunkworks project is a project developed by a small and loosely
structured group of people who research and develop a project
primarily for the sake of radical innovation.[1] The terms
originated with Lockheed&#8217;s World War II Skunk Works project.</p></blockquote>

<p>http://en.wikipedia.org/wiki/Skunk_Works</p>

<blockquote><p>The designation &#8220;skunk works&#8221;, or &#8220;skunkworks&#8221;, is widely used
in business, engineering, and technical fields to describe a
group within an organization given a high degree of autonomy
and unhampered by bureaucracy, tasked with working on advanced
or secret projects.</p></blockquote>

<p>Lockheed Martin&#8217;s Skunk Works project made SR-71.</p>

<h2>Project Svelte</h2>

<p>http://www.trustedreviews.com/opinions/android-4-4-kitkat-s-project-svelte-what-it-is-and-why-you-should-care</p>

<blockquote><p>â€˜dogfoodingâ€™ â€“ that is making its employees use and live with their own projects</p></blockquote>

<p>They dogfooded their employees by forcing them to dev on handicapped
phones. Android 4.4 was the result, apparently it was way more
performant.</p>

<h2>RACK_ENV vs RAILS_ENV</h2>

<p><code>Rails.env</code> is decided by <code>RAILS_ENV || RACK_ENV || "development"</code>. It&#8217;s
common to set <code>RACK_ENV</code> which will also set <code>RAILS_ENV</code>, but if you
have any rack middleware that behaves differently in different
environments, you might screw yourself if you&#8217;re using <code>RAILS_ENV</code>.</p>

<h2>wythoughts on blocks</h2>

<p>The reason <code>|i|</code> is ok is for the same reason you can&#8217;t do the following
in Ruby:</p>

<pre><code>a = { |it| wat }
</code></pre>

<p>You have to do</p>

<pre><code>a = proc { |it| wat }
</code></pre>

<p>Case in point you need an fn to save a block.</p>

<h2>mythoughts on mutability</h2>

<p>Can/should we swap POJOs when an observed property changes? Is there any
value to</p>

<pre><code>var pojo = {
  a: {
    b: 123
  }
};

var a = pojo.a;
Ember.set(pojo, 'a.b'
</code></pre>

<h2>ASI: automatic semicolon insertion</h2>

<p>Nuff said.</p>

<h2>old browser disagreements on ws</h2>

<pre><code>[ text ws text]
</code></pre>

<p>cloneNode produces:</p>

<ul>
<li>ie8: 1 node</li>
<li>ie9: 2 nodes</li>
<li>else: 3 nodes</li>
</ul>


<h2>NoScope</h2>

<p>http://www.thecssninja.com/javascript/noscope</p>

<p>tldr NoScope is an old IE categorization of nodes, and NoScope dictates
that innerHTML and cloneNode will strip these els.</p>

<h2>Ropes: DAG of string implementation for FF/Chrome</h2>

<p>http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=181EEF66EB411F4277C009A1D492CF75?doi=10.1.1.14.9450&amp;rep=rep1&amp;type=pdf</p>

<p>Look into this more. Too lazy to read / comment.</p>

<p>How to force Chrome to not use a rope:</p>

<ul>
<li>Less than 12 chars</li>
</ul>


<p>What does it mean to intern strings?</p>

<h2>CSP: Content Security Policy</h2>

<p>http://www.html5rocks.com/en/tutorials/security/content-security-policy/</p>

<h2>String interning</h2>

<pre><code>String.prototype.intern = (function() {
   "use strict";
   var o = {"- ": 0};
   delete o["- "];
   return function() {
       var str = this;
       o[str] = true;
       var ret = Object.keys(o)[0];
       delete o[str];
       return ret;
       try {} finally {}
   };
})();
</code></pre>

<h2>Component pinning</h2>

<p>Associating the re-render with the pre-existing fragment.</p>

<h2>localStorage on iOS Cordova webviews</h2>

<ol>
<li>Run dev, set <code>localStorage.wat = "lol"</code></li>
<li>Stop and re-run the app, and <code>localStorage.wat</code> still is &#8220;lol&#8221;</li>
<li>Delete the app, re-install, still dev, <code>localStorage.wat</code> is undefined</li>
</ol>


<p>I don&#8217;t even have to check&#8230; your app can&#8217;t run in both dev and prod.
You can&#8217;t share userSessions across dev and prod apps. Then again, our
servers could maintain keys for both APNS and APNS_SANDBOX.</p>

<h2>GCM project number vs project ID</h2>

<p>https://developers.google.com/compute/docs/faq#whatisthedifference</p>

<p>You pick project ID, they pick project number. Project number is the
Sender ID you use for GCM.</p>

<h2>Pointer comparisons for such perf</h2>

<pre><code>if (wat === false) {
}
</code></pre>

<p><code>false</code> can be implemented to just refer to a unique memory location,
such that all browsers need to comparison in the above code is <code>wat</code>&#8217;s
memory address against <code>false</code>&#8217;s.</p>

<p>Same goes with</p>

<pre><code>if (wat === undefined) {
}
</code></pre>

<p>just that the presence of <code>foo</code> in <code>cache.foo</code> is ambiguous without
testing <code>foo in cache</code>; might be easier to do <code>cache.foo = UNDEFINED</code>
where</p>

<pre><code>function UNDEFINED() {}
</code></pre>

<p>Sentinel as fuck.</p>

<h2>PushPlugin</h2>

<p>Only starts firing PNs after <code>register</code>. We need a user session to
register, right? Seems weird we can&#8217;t query it for information before
immediately registering&#8230; either way, works fine for us, at least we
killed Zalgo.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/18/daily-journal/"/>
    <updated>2014-07-18T03:50:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/18/daily-journal</id>
    <content type="html"><![CDATA[<h2>Cookies</h2>

<p>What ends up in <code>document.cookie</code>?</p>

<p>Test: kill a previous localhost:5000 server, start a server for a
separate project. Reload the page. Request headers sent include
a transient cookie from the previous server. I bet it was due to
Turbolinks. I was right!</p>

<p>From http://tools.ietf.org/html/rfc6265#section-4.1.1</p>

<blockquote><p> Origin servers MAY send a Set-Cookie response header with any
 response.  User agents MAY ignore Set-Cookie headers contained in
 responses with 100-level status codes but MUST process Set-Cookie
 headers contained in other responses (including responses with 400-
 and 500-level status codes).  An origin server can include multiple
 Set-Cookie header fields in a single response.  The presence of a
 Cookie or a Set-Cookie header field does not preclude HTTP caches
 from storing and reusing a response.</p></blockquote>

<p>So you can send multiple headers with the same key. Makes sense, since
comma separation will conflict with the UTC date (e.g. <code>Aug 12, 2014</code>).</p>

<p>So how do you set multiple cookies in Rack?</p>

<p>Interesting: https://github.com/rack/rack/blob/master/lib/rack/utils.rb#L266</p>

<p>Anyway, split cookies with newlines and Rack will cause this to send two
<code>Set-Cookie</code> headers, which is totally fine.</p>

<p>You can also use <code>set_cookie</code> on <code>Rack::Response</code> if you&#8217;re into that
sort of thing..</p>

<p>I psyched myself out thinking cookies were overwriting each other by doing:</p>

<pre><code>"Set-Cookie" =&gt; "foo\nbar\nbaz"
</code></pre>

<p><code>document.cookie</code> was only revealing <code>baz</code>. But, I&#8217;m a dumb: cookies
need to be key-value pairs, which fixed it.</p>

<p>You can use <code>HttpOnly</code> to prevent JS (and other APIs?) access to the
cookie sent by the server. Makes sense; less likely that&#8217;ll break
something.</p>

<p>Getting <code>document.cookie</code> returns all the cookies available to JS.
Setting it will only set the cookie you provide.</p>

<blockquote><p>Notice that servers can delete cookies by sending the user agent a
new cookie with an Expires attribute with a value in the past.</p></blockquote>

<h2>JavaScript set focus</h2>

<p><code>focus()</code> is a method on input elements. So is <code>blur()</code>.</p>

<p><code>document.activeElement</code> in modern browsers points to the focused
element, which might also include scroll windows.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/document.activeElement</p>

<p>In older browsers, to <code>blur</code> the active element, you&#8217;d have to know what
that element was; there was no way to query. Might be wrong about this.</p>

<h2>React Nested Router</h2>

<p>http://www.youtube.com/watch?v=P6xTa3RRzfA</p>

<ul>
<li>State is just data</li>
<li>Your route is data, e.g. you could render a top-level App component
and tell it what its route is, and render everything a la React,
pretend like you&#8217;re redrawing the whole page.</li>
<li>Rather than switch-statement-based routing, the <code>activeRoute</code> just
gets passed in via <code>props</code> like any other property

<ul>
<li><code>router.match</code> handlers will create all the routes, and pass in a
single <code>activeRoute</code>; every route segment along the way just knows
about with its activeRoute child is, if one exists.</li>
<li>e.g. <code>contact/profile</code>, app.activeRoute = contact,
contact.activeRoute = profile</li>
</ul>
</li>
<li>API

<ul>
<li>Route component

<ul>
<li>handler = a React Class</li>
</ul>
</li>
</ul>
</li>
<li>Differences w Ember

<ul>
<li>No auto-gen &#8216;index&#8217; routes</li>
<li>paths don&#8217;t inherit parent paths

<ul>
<li>this means if you&#8217;re &#8220;overwriting&#8221; a parent dynamic segment, the
dynamic segment must appear <em>somewhere</em> in the child route so you
can actually load that data.

<ul>
<li>AH, the router will detect when children omit ids that their
parents have declared. That&#8217;s nice.</li>
<li>also yells at you if you use the same path in two places.</li>
</ul>
</li>
<li>nice that it lets you have <code>/profile</code> vs <code>/user</code></li>
</ul>
</li>
<li>Ember is less typing, but

<ul>
<li>React makes it easier to share handlers</li>
<li>Overwriting URL is nice when you need it, error checking is nice</li>
</ul>
</li>
</ul>
</li>
<li>So each non leaf handler gets <code>activeRoute</code>, all handlers get all
<code>params</code>.</li>
<li>Refactorability/decoupling:

<ul>
<li>Because route names and paths are fully specified and all params are provided to
each handler, changing the nesting of a route means you don&#8217;t have
to rewrite all your link-tos from &#8220;wat.foo&#8221; to &#8220;foo&#8221;. Then again
if you&#8217;re using resources you don&#8217;t have to do that either.</li>
</ul>
</li>
<li>Question: what about other <code>props</code> you&#8217;d want to pass into a
component?

<ul>
<li>Answer: Route components aren&#8217;t concerned with props other than how
to be a route handler.</li>
</ul>
</li>
</ul>


<p>http://jsbin.com/vukacule/6/edit</p>

<p>It is really cool that you can switch between rendering a route with App
as a handler vs just rendering App. The difference is that, when
route-driven, it gets passed props.</p>

<p>The <code>Route</code> components you use are obviously stateless; all state lives
on the Handlers.</p>

<p>Ah, in React <code>` syntax just means</code>{blah: &#8220;wat&#8221;}` inside
the normal single-curly.</p>

<p>How do Links work? They call transitionTo and there&#8217;s a single URLStore
singleton.</p>

<h2>TLS Replay?</h2>

<p>I had it in my head that man-in-the-middle wasn&#8217;t a problem for TLS but
maybe they could replay the messages? Turns out I am wrong; TLS includes
a sequence mechanism.</p>

<p>That being said, your app might send repeat messages, which demands its
own double checking / application-level sequencing or some other
prevention mechanism.</p>

<h2>chroot</h2>

<p>http://en.wikipedia.org/wiki/Chroot</p>

<p>Learned about this when speculating w Ember Core about how the front
page Rust evaluator works at http://www.rust-lang.org/</p>

<p>It runs a program with the assumption that <code>/</code> is somewhere else, and it
can&#8217;t access it.</p>

<p>Change</p>

<h2>process.nextTick</h2>

<p><code>process</code> doesn&#8217;t exist on the browser, so therefore neither does
<code>nextTick</code>, but you can hack it if you&#8217;re on a browser that has a native
<code>Promise</code> object, since the <a href="http://promisesaplus.com/">spec</a> mentions
that resolution callbacks must happen when the execution context
consists only of platform code.</p>

<blockquote><p>onFulfilled or onRejected must not be called until the execution
context stack contains only platform code. [3.1].</p></blockquote>

<p>So here&#8217;s how you could write nextTick, note that there&#8217;s no need to</p>

<pre><code>var p = Promise.resolve();
function nextTick(cb) {
  p.then(cb);
}
</code></pre>

<h2>Visibility API</h2>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/Guide/User_experience/Using_the_Page_Visibility_API">mdn</a></p>

<p>e.g.</p>

<ul>
<li>pause video when you tab-away</li>
<li>stop requestAnimationFrame</li>
</ul>


<h2>Closing over <code>let i</code></h2>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p>The above code has the gotcha that by the time the <code>fns</code> functions run,
they&#8217;ll all print out <code>10</code>, rather than the value of <code>i</code> when the
closing-over function was created. This is part of the reason why jshint
will yell at you for creating functions in a loop, e.g.</p>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(makeCallback(i));
}

function makeCallback(num) {
  return function() {
    console.log(num);
  }
}
</code></pre>

<p>Then <code>i</code> will be uniquely preserved for each callback.</p>

<p>The es6 <code>let</code> keyword gives you block scope, which includes everything
declared within the for loop. If you just use <code>let</code> in the original
code, you can do</p>

<pre><code>var fns = [];
for (let i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p><code>i</code> doesn&#8217;t get hoisted; rather, each iteration gets its own <code>i</code> value
that gets closed over.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/16/daily-journal/"/>
    <updated>2014-07-16T00:40:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/16/daily-journal</id>
    <content type="html"><![CDATA[<h2>WeakMap</h2>

<p>Use objects as keys. If you lose access to a key, it and its value will
eventually be removed by GC because references to keys are weak. This
also means WeakMaps are non enumerable since GC is non-deterministic and
a key that might exist pre GC might not exist after.</p>

<h2>ES6 Symbols</h2>

<p>They&#8217;re nothing like Ruby symbols.</p>

<p>They&#8217;re used to create unique, non-enumerable, keys that can&#8217;t be
determined publicly unless the symbol is exported. So you could prevent
tampering with a player&#8217;s score by storing the score on the player using
an unshared symbol as the key:</p>

<p>http://tc39wiki.calculist.org/es6/symbols/</p>

<h2>ES6 === Harmony === ES.next</h2>

<p>They&#8217;re all the same thing.</p>

<h2>JS 1.7 vs ES6, etc</h2>

<p><a href="http://ejohn.org/blog/versions-of-javascript/">jeresig clears this up a bit</a></p>

<p>All modern browsers support ECMAScript; JavaScript is a variant of it
that Mozilla&#8217;s largely been adding features to. ES3 === JS 1.5.</p>

<p>So I see <code>let</code> was added to JavaScript 1.7, so why is it now being
described as a new upcoming feature of ES6? Ah, because all browsers
track ECMAScript standards, even if they call their enhanced language in
the browser something else. Mozilla has been blazing ahead and trying
new shit, but other browsers won&#8217;t pick it up until it&#8217;s actually
standardized into ECMAScript.</p>

<p>Why would Microsoft follow ECMAScript? Well, for starters, it delivered
JScript to Ecma back in the day for standardization.</p>

<blockquote><p>The name &#8220;ECMAScript&#8221; was a compromise between the organizations involved in standardizing the language, especially Netscape and Microsoft, whose disputes dominated the early standards sessions.</p></blockquote>

<p>Interesting, and:</p>

<blockquote><p>While both JavaScript and JScript aim to be compatible with ECMAScript, they also provide additional features not described in the ECMA specifications</p></blockquote>

<p>Also, some reason I thought TC39 was part of Mozilla. I see that I am
obviously incorrect: http://www.ecma-international.org/memento/TC39.htm</p>

<p>It&#8217;s Ecma-TC39. The things I don&#8217;t know.</p>

<p>W3C Tag, Ecma-TC39. W3C Tag, Ecma-TC39.</p>

<h2><code>let</code></h2>

<p><code>let</code> behaves like C++ declarations; the obj is only available in the
curlies, or in for loops, or whatever, and there&#8217;s no hoisting. Outside
of the block, the variable is undefined.</p>

<h2>Cloudfront TTL</h2>

<p>TTL lets you specify a min time before CF checks the origin to see if it
has a new version of the file/response. You still need your origin
server&#8217;s Cache-Control headers setup correctly.</p>

<p><a href="http://stackoverflow.com/questions/10621099/what-is-a-ttl-0-in-cloudfront-useful-for">TTL can be 0</a>.
Why? TTL 0 means that it delegates Cache-Control entirely to the origin.
This means CF will always make a GET request w <code>If-Modified-Since</code>
header to let the server return <code>304 Not Modified</code>.</p>

<h2>Drag and Drop</h2>

<p>Draggable elements need to be marked as <code>draggable="true"</code>.</p>

<p>Then listen to the <code>ondragstart</code> event, e.g.
<code>ondragstart="drag(event)"</code>.</p>

<p>And then say what data is associated with the dragged el&#8230;</p>

<pre><code>ev.dataTransfer.setData("Text", ev.target.id);
</code></pre>

<p>This seems strange.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/DataTransfer</p>

<p>It really is a class associated only w drag and drop.</p>

<p>Should probably be reading this rather than fucking w3schools. Why do I
still do that?
https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Drag_and_drop</p>

<p>Ah I get it, you use dataTransfer as part of the mechanism for
dynamically determining drop targets. You have to prevent bubbling
(return false or preventDefault) on droppable targets, and in that fn
they have the option of looking up the data transfer to see if they want
to accept the data from that drag drop.</p>

<p>You can also configure drag drag visual details to indicate copying,
moving, etc. LOL such drag and drop.</p>

<p>Oof apparently it&#8217;s a fucking disaster: http://www.quirksmode.org/blog/archives/2009/09/the_html5_drag.html</p>

<p>Criticisms:</p>

<ul>
<li>7 fucking events, such API surface</li>
<li>&#8220;For the drop event to fire at all, you have to cancel the defaults of both the dragover and the dragenter event.&#8221;</li>
</ul>


<h2>Cordova events: sticky != buffered</h2>

<p>Sticky events (e.g. deviceready) just mean that once fired, they stay in
a fired state. This means you can&#8217;t have multiple events fire if it&#8217;s a
sticky event. I was originally thinking sticky meant all the events were
cached until the first handler was registered.</p>

<p>Ended up making this: https://gist.github.com/machty/e1cc485060f2951aeb6c</p>

<h2>Why <code>-print0</code> in <code>find</code>?</h2>

<p>Often you pipe the results of <code>find</code> into <code>xargs</code> to pass the results of
a <code>find</code> so that some utility can operate on each file found. GOOD
ENGRISH, MATCHNEER.</p>

<p>But since <code>xargs</code> splits based on whitespace by default, this will break
for files with newlines or or spaces in them, so <code>-print0</code> separates
files w null bytes, and <code>-0</code> tells xargs to split via null bytes as
well. Win win win. No difference if you have no files with spaces in
them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Forgotten things]]></title>
    <link href="http://machty.github.com/blog/2014/07/15/forgotten-things/"/>
    <updated>2014-07-15T12:18:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/15/forgotten-things</id>
    <content type="html"><![CDATA[<p>Here&#8217;s a progressively-updated list of things I forget throughout the
day. This is different from the list of things I&#8217;ve learned; that
approach is useful for packing the things into my brain, hopefully; the
purpose of this list is to pack things back in when I forget. And for
now it&#8217;ll just be one giant progressively-updated blog.</p>
]]></content>
  </entry>
  
</feed>
