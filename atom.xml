<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[machty's thoughtz]]></title>
  <link href="http://machty.github.com/atom.xml" rel="self"/>
  <link href="http://machty.github.com/"/>
  <updated>2014-07-29T07:48:38-04:00</updated>
  <id>http://machty.github.com/</id>
  <author>
    <name><![CDATA[Alex Matchneer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Daily Journal 2]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal-2/"/>
    <updated>2014-07-28T20:43:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal-2</id>
    <content type="html"><![CDATA[<h2>User and Kernel</h2>

<p>http://blog.codinghorror.com/understanding-user-and-kernel-mode/</p>

<p>Non-idle tasks.</p>

<p>The CPU graph is tasty. Red means kernel.</p>

<p>CPU hardware knows all about kernels n shit. It isn&#8217;t just a software
divide. CPU instructions and certain memory locations can only be
accessed by the kernel, enforced by hardware. User mode makes it so that
only the app crashes, not the entire system.</p>

<p>http://en.wikipedia.org/wiki/Ring_(computer_security)</p>

<p>Interesrserseting.</p>

<p>x86 CPU hardware:</p>

<ul>
<li>0 is kernel</li>
<li>3 is user</li>
</ul>


<p>1 and 2 are device drivers but they&#8217;re not often used. On Windows,
device drivers can be user or kernel mode, mostly to the user, but video
cards are often kernel level since they so perfy. In Vista+, the Windows
Driver Display Model is such that only kernel mode is used for executing
the GPU commands, but the translation from API to GPU now takes place in
userland.</p>

<p>Exceptions fire in kernel land I guess? Sometimes?</p>

<h2>Old Foreman Orphans Sidekiq</h2>

<p>After lots of starts/stops of foreman, I noticed lots of sidekiq
instances with ppid 1. They was orphans. I killed em.</p>

<h2>fspawn</h2>

<p>Refers to the fork+exec approach to spawning a process.</p>

<h2>Daemons</h2>

<p>https://github.com/ghazel/daemons</p>

<p>Library of fun little trinkets.</p>

<ul>
<li>given some-server.rb, let&#8217;s you write a some-server-control.rb</li>
<li>inline the server inside such a daemon (you can still run it
without forking via <code>run</code> command)</li>
<li>manage multiple daemons</li>
<li>Ability to take existing server and daemonize it; you do lose control
over the daemon unless you&#8217;re a <code>ps</code>/<code>kill</code> JOURNEYMAN.

<ul>
<li>this takes advantage of the <code>fork</code> <code>getsid</code></li>
</ul>
</li>
</ul>


<h2>.pid file</h2>

<p>It&#8217;s a file in a well known location that contains only the pid of
some running process, usually a daemon. Useful because daemons are often
hard to detect, kinda look like forgotten orphan processes, and there
might be multiple similar ones. But pid files let you look up the pid of
the running process so that you can send it signals.</p>

<h2><code>$0</code> or <code>$PROGRAM_NAME</code></h2>

<p>If you run this script</p>

<pre><code>fork {
  $PROGRAM_NAME = "WAT"
  sleep
}
</code></pre>

<p>then <code>ps | grep WOOT</code> yields</p>

<pre><code>62724 ttys022    0:00.00 WOOT
</code></pre>

<p>Woot wat wat wotasoasdas lol.</p>

<h2><code>pidof</code></h2>

<pre><code>brew install pidof

$ pidof bash
754 1246 1748 2308 2498 5380 20397 23552 26224 26973 48454 79258 81847 5226 5346 5443 5851 10659 25008 26375 27009 52684 88768 88882 18853 19116 19246 20275 20476 21364 43211 52269 52390 52637 54869 54974 58037 58950 59080
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/28/daily-journal/"/>
    <updated>2014-07-28T08:16:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/28/daily-journal</id>
    <content type="html"><![CDATA[<h2>Them processes</h2>

<p>Kernel</p>

<!--more-->


<ul>
<li>sits on top of hardware, doing things like

<ul>
<li>read/write from filesystem</li>
<li>sending/receiving network data</li>
<li>playing audio</li>
</ul>
</li>
<li>programs don&#8217;t have access to this stuff, only the kernel</li>
</ul>


<p>System call is the barrier b/w userland and kernel.</p>

<p>What about memory? I think userland can read memory.</p>

<p>Common man pages for FreeBSD or Linux</p>

<p><code>wat(2)</code> means section 2 of manual, wat: <code>man 2 wat</code></p>

<p>Can&#8217;t execute code without a process.</p>

<p><code>Process.pid == $$</code> global var in Ruby, from Perl/bash, but
<code>Process.pid</code> is way more obvious, duh.</p>

<p>Processes have parents, identified via <code>ppid</code>, <code>Process.ppid</code>, but not
super often used.</p>

<p>In Unixland, everything is a file.</p>

<p>When opening resources, you&#8217;re given a file descriptor number, unique to
your process, unshareable with unrelated processes. These resources are
closed when you exit process, cept forking.</p>

<p>All Ruby <code>IO</code> objects have a <code>fileno</code>, e.g.</p>

<pre><code>2.0.0-p353 :007 &gt; $stdin.fileno
 =&gt; 0
2.0.0-p353 :007 &gt; $stdout.fileno
 =&gt; 1
2.0.0-p353 :008 &gt; $stderr.fileno
 =&gt; 2
</code></pre>

<p>File descriptors are assigned lowest unused value, and are reusable when
old file handlers are closed.</p>

<p>Streams are lovely, before them, each program had to explicitly handle
different keyboard types, etc, but the stream abstraction unified all of
that.</p>

<p><code>fsync</code> flushes file descriptor state to disk, but disk might reorder
writes. The <code>F_FULLFSYNC</code> will ask the drive to write it immediately and
preserve order, useful for things like databases, see <code>fsync</code></p>

<pre><code> For applications that require tighter guarantees about the integrity of their
 data, Mac OS X provides the F_FULLFSYNC fcntl.  The F_FULLFSYNC fcntl asks the
 drive to flush all buffered data to permanent storage.  Applications, such as
 databases, that require a strict ordering of writes should use F_FULLFSYNC to
 ensure that their data is written in the order they expect.  Please see fcntl(2)
 for more detail.
</code></pre>

<p><code>F_FULLFSYNC</code> probably isn&#8217;t available on everything, possibly mac only.</p>

<p>To find the limit of file descriptors you can do <code>Process.getrlimit(:NOFILE)</code></p>

<p>This translates to <code>getrlimit(2)</code>, control max system resource
consumption. <code>r</code> is resource, <code>NOFILE</code> means &#8220;The maximum number of open
files for this process&#8221;.</p>

<pre><code>2.0.0-p353 :001 &gt; Process.getrlimit(:NOFILE)
 =&gt; [2048, 2048]
    #soft, hard
</code></pre>

<p>Soft means an exception will raise but you can reconfigure. Hard limit
might be reconfigurable by superuser, or if the process has permissions.</p>

<p><code>sysctl</code> lets you get or set kernel state, useful for configuring
system-wide kernel details.</p>

<p><code>EMFILE</code> is too many files open. Testable via</p>

<pre><code>machty.github.com :: ruby -e "Process.setrlimit(:NOFILE, 3); File.open('/dev/null')"
-e:1:in `initialize': Too many open files - /dev/null (Errno::EMFILE)
</code></pre>

<p><code>ulimit</code> is a built in command to control resource usage for this shelll
and any of its children. It&#8217;s different from system wide <code>sysctl</code> stuff.
I can change the result above</p>

<p>So I remember <code>ulimit</code> resets the soft limit. If I set to 2046, then</p>

<pre><code>machty.github.com :: ruby -e "puts Process.getrlimit(:NOFILE)"
2046
2046
</code></pre>

<blockquote><p>(Built-in command) In computing, a shell builtin is a command or a function, called from a shell, that is executed directly in the shell itself, instead of an external executable program which the shell would load and execute. ..</p></blockquote>

<p>Use cases for overriding limits</p>

<ul>
<li>stress-testing utilities (e.g. 5000 simultaneous connections)</li>
<li>limiting resources for 3rd party stuff, removing permissions to change</li>
</ul>


<p>Environment is nothing more than Env vars, key values pairs.
Set by parent, inherited by children.</p>

<pre><code>machty.github.com :: A=lol ruby -e "puts ENV['A']"
lol
</code></pre>

<p>Note that env var assignment on its own shell line sets them for the
rest of the process, but followed by a command only sets them for that
command.</p>

<p>Process names are changeable, e.g. <code>$PROCESS_NAME = "fuckles"</code></p>

<pre><code>  PID TTY           TIME CMD
45874 ttys011    0:00.68 fuckles
</code></pre>

<p>Note that TIME is CPU time.</p>

<p>Ah, <code>time</code> makes sense to me now:</p>

<pre><code>machty.github.com :: time sleep 1

real    0m1.012s
user    0m0.001s
sys     0m0.003s
</code></pre>

<p><code>sleep</code> suspends execution thread, consuming no CPU. I think <code>sys</code> means
system call time, such as telling the pthread to sleep. IT IS ALL MAKING
SENSE.</p>

<p>Processes have exit codes, 0 is successful.</p>

<p>All the ways to exit</p>

<ul>
<li>exit, <code>Kernel#exit</code>, exits w 0 by default but you can pass a code,
runs <code>Kernel#at_exit</code> blocks. <code>exit!</code> does a code 1 and doesn&#8217;t run
exit blocks.</li>
<li>abort accepts a string in ruby, runs exit handlers, returns 1</li>
<li>raised exceptions yield exit code 1 and still raise things.</li>
</ul>


<p>Processes can fork, unless you&#8217;re JRuby. That means Unicorn won&#8217;t work
for JRuby.</p>

<p>Forking copies all memory (or copy on write). File descriptors are also
provided to forked thinger.</p>

<pre><code>2.0.0-p353 :016 &gt; fork { puts Process.pid; puts Process.ppid}
 =&gt; 46054
2.0.0-p353 :017 &gt; 46054
45874
2.0.0-p353 :018 &gt;   Process.pid
 =&gt; 45874
</code></pre>

<p>Parent and child can share file descriptors, open files, sockets, etc.
Because forking is faster than booting up fresh copies of servers&#8230; it
is good&#8230;?</p>

<p>Awesome example:</p>

<pre><code>if fork
  puts "YES"
else
  puts "NO"
end
</code></pre>

<p>Hahaha, don&#8217;t run this in irb though, because you&#8217;ll have two processes
reading from the same $stdin, e.g. your keyboard.</p>

<p>Blockless <code>fork</code> returns twice</p>

<ul>
<li>parent gets child pid</li>
<li>child gets nil</li>
</ul>


<p>Explains this output</p>

<pre><code>ruby -e "cid=fork; puts cid || 'none'"
46650
none
</code></pre>

<p>What about threads? Do thread ids change after forking?</p>

<pre><code>machty.github.com :: ruby -e "puts Thread.current; fork; puts Thread.current"
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
#&lt;Thread:0x007fa7710677a8&gt;
</code></pre>

<p>No it seems they don&#8217;t&#8230; forking really makes everything seem totally
the same. I wonder how that works at the pthread level.</p>

<p>http://pubs.opengroup.org/onlinepubs/009695399/functions/fork.html</p>

<blockquote><p>A process shall be created with a single thread. If a multi-threaded process calls fork(), the new process shall contain a replica of the calling thread and its entire address space, possibly including the states of mutexes and other resources. Consequently, to avoid errors, the child process may only execute async-signal-safe operations until such time as one of the exec functions is called. [THR] [Option Start]  Fork handlers may be established by means of the pthread_atfork() function in order to maintain application invariants across fork() calls.</p></blockquote>

<p>So only a single thread is created, and the kernel knows it&#8217;s a separate
thread, but the forked instance still thinks the address of that thread
is the same as before, even though it&#8217;s obviously a different thread.</p>

<p>Forking allows (but doesn&#8217;t guarantee) a process to run on multiple
cores. If the system is busy the forked processes might all run on the
same CPU.</p>

<p>Forking duplicates memory (assuming no copy-on-write; TODO: learn the
terminology for total memory vs not-yet-copied-on-write memory).
Running out of memory due to over-forking is called a fork bomb.</p>

<p>Forking means orphaning if the parent process finishes before children.</p>

<p>Daemon processes are intentionally orphaned so that they can stay
running forever. Orphaned children can be communicated with via signals.</p>

<p>Fork-and-forget vs remembering child process. <code>Process.wait</code> will wait
for ONE child process to terminate before quitting, and returns the pid
of the child process that terminates. Spawn 3 processes, must wait three
times. <code>wait2</code> returns <code>[pid, status]</code>, so you can get codes n shit.
<code>waitpid</code> and <code>waitpid2</code> wait on specific pids. But they are aliased to
the same thing: `wait</p>

<p>The kernel queues child process return info so that waiting on a process
that has already did will return its shit. That said, waiting on
non-existent children raises <code>ECHILD</code>.</p>

<p>Unicorn forks N times, makes sure the processes are still alive,
restarts if necessary, etc.</p>

<p>If you don&#8217;t do <code>Process.wait</code> though, the kernel will keep on storing
information about exit codes, etc. You either need to <code>wait</code> or <code>detach</code>,
or else you get a zombie process.</p>

<p>http://en.wikipedia.org/wiki/Zombie_process</p>

<p>A Zombie process is a process that has called exit but whose parent
hasn&#8217;t called <code>wait</code> or <code>detach</code>.</p>

<ul>
<li>Zombie: un-reaped, terminated child process</li>
<li>Orphan: still active child process whose parent has died.</li>
</ul>


<p>Orphans get attached to <code>init</code> (or <code>launchd</code> in OS X land), which has a
pid of 1.</p>

<p>Oh man, fork bombs are hilarious: http://en.wikipedia.org/wiki/Fork_bomb</p>

<p>So ppid actually automatically updates:</p>

<pre><code>fork do
  loop do
    puts "(#{Process.pid}, #{Process.ppid})"
    sleep 1
  end
end

sleep 1

abort "k i'm done #{Process.pid}"
</code></pre>

<p>Output:</p>

<pre><code>(47598, 47597)
(47598, 47597)
k i'm done 47597
(47598, 1)
(47598, 1)
</code></pre>

<p>Pretty cool.</p>

<p>Also if you <code>brew install pstree</code> and take a look at that, pid 1 is
<code>launchd</code>.</p>

<p>You can check the status of process and how it changes into a zombie and
then when it gets removed from the process table when we call
<code>Process.wait</code>:</p>

<pre><code>cpid = fork {}
puts `ps -p #{cpid} -o state`
sleep 1
puts `ps -p #{cpid} -o state`
Process.wait
puts `ps -p #{cpid} -o state`
</code></pre>

<p>Yields:</p>

<pre><code>STAT
R+
STAT
Z+
STAT
</code></pre>

<p>Note the last STAT is empty because no such pid; shit is dead.
The <code>+</code> means process is in the foreground process group of its control
terminal.</p>

<p>Note that no memory is allocated to the zombie process itself; just the
slot in the process table is used; zombie processes prevent other
processes from taking their place and reusing their PID. Which is
another thing: a parent process might not want a child pid to be reused
when creating a child pid, so it&#8217;ll create the new child, and THEN
<code>wait</code>/<code>detach</code> on original.</p>

<p><code>Process.detach</code> spins up a thread to <code>wait</code> on a process. Here&#8217;s a
really roundabout way to detach and then wait and get the return value:</p>

<pre><code>t = Process.detach(cpid)
puts `ps -p #{cpid} -o state`
puts t.value
</code></pre>

<p><code>t.join</code> before a <code>t.value</code> is a noop; <code>value</code> must always <code>join</code> in
order to get the value.</p>

<p>Fork-and-forget is rare. <code>Process.detach</code> has no system call equiv; it&#8217;s
just a ruby convenience.</p>

<p>SIGCHLD fires when a child process exits. You can trap it and <code>wait</code> for
that process to finish. Problem is, signal delivery is unreliable; if
you&#8217;re handling a signal and another one comes in, you might not receive
that signal. Solution is to pass a second param to <code>wait</code> to describe
how the kernel should wait for this thing, e.g. <code>Process::WNOHANG</code></p>

<p>Shit is so messy</p>

<pre><code>Process.trap(:CHLD) do
  nil while Process.wait(-1, Process::WNOHANG) rescue Errno::ECHILD
end
</code></pre>

<p>Yes you could unravel but come on.</p>

<p>Signals are async, ignorable, actionable, defaultable. Processes use the
kernel to as an intermediary to send messages.</p>

<pre><code>echo "puts 'lol'" | ruby
</code></pre>

<p>Who knew? It accepts input from stdin. So you can pipe Ruby code to it.
Ctrl-C sends an interrupt. You can trap it and ignore. You can also say
<code>trap(:INT, "IGNORE")</code></p>

<p>It&#8217;s good form in lib code to define a trap, though it&#8217;s possibly to
preserve other people&#8217;s callbacks and call them in yours. But you can&#8217;t
restore default behavior. This is fine if your&#8217;e writing a server
though.</p>

<blockquote><p>USR2 - reexecute the running binary. A separate QUIT should be sent to the original process once the child is verified to be up and running.</p></blockquote>

<p>https://github.com/ice799/memprof does some cool stuff with trapping
signals, printing out useful shits.</p>

<p>This guy is boundlessly smart.</p>

<p>Make a pipe, give someone one end to yell into and the other person the
put their ear up to it. Methinks you see where this is going.</p>

<p>Source and Sink, Writer and Reader. Pipe persists until all associated
descriptors are closed. Half-closed pipes are &#8220;widowed&#8221;. Writing to a
widowed pipe yields <code>SIGPIPE</code>, but widowing it is how the reader gets an
EOF signal. <code>SIGPIPE</code> can be disabled via F_SETNOSIGPIPE in fcntl, which
we saw above in this journal for telling a hard drive to actually
preserve write order.</p>

<p>In Ruby you can pass an encoding which tags the read input with that
encoding.</p>

<p>http://ruby-doc.org/core-2.0/IO.html#method-c-pipe</p>

<pre><code>rd, wr = IO.pipe

if fork
  wr.close # REQUIRED
  puts "Parent got: &lt;#{rd.read}&gt;"
  rd.close
  Process.wait
else
  rd.close # REQUIRED
  puts "Sending message to parent"
  wr.write "Hi Dad"
  wr.close
end
</code></pre>

<p>The <code># REQUIRED</code> closes are there because otherwise the data won&#8217;t
flush, EOF&#8217;s won&#8217;t be called.</p>

<p>So that&#8217;s a neat little primitive, but how is it different than just
using a StringIO? Well, aside from the fact that I don&#8217;t think you can
just progressively write into StringIO as you read from it (maybe you
can), Pipe goes through the kernel; there&#8217;s system calls and overhead.
Check this bitchin benchmark:</p>

<pre><code>require 'benchmark'
require 'stringio'

n = 100000
Benchmark.bm do |x|
  x.report("pipes:") {
    n.times do
      rd, wr = IO.pipe
      wr.write "HELLO"
      wr.close
      raise "wat" unless rd.read == "HELLO"
      rd.close
    end
  }

  x.report("StringIO") {
    n.times do
      s = StringIO.new("HELLO")
      raise "wat" unless s.read == "HELLO"
      s.close
    end
  }
end
</code></pre>

<p>yields</p>

<pre><code>              user     system      total        real
  pipes:  0.630000   0.730000   1.360000 (  1.363994)
StringIO  0.080000   0.000000   0.080000 (  0.077973)
</code></pre>

<p>This is skewed by the fact that you&#8217;re not going to be creating and
dumping pipes all the time, but it just highlights the inner workings of
Pipe: because it involves syscalls, much of the time is spent in
<code>system</code>.</p>

<p>With streams (pipes/TCP sockets), you write to a stream followed by a
delimiter. Newline is the delimiter. Unix sockets are intra machine, and
fast.</p>

<p>Use sockets to communicate in datagrams vs delimited stream chunks. You
still have pairs, but rather than read/write pairs, you just have
bidirectional shits, one of which needs to get closed per process.
Sockets are bidirectional!</p>

<p>http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or
http://wiki.secondlife.com/wiki/Message_Queue_Evaluation_Notes</p>

<p>From http://www.ruby-doc.org/core-2.1.0/IO.html</p>

<blockquote><p>In the example below, the two processes close the ends of the pipe that they are not using. This is not just a cosmetic nicety. The read end of a pipe will not generate an end of file condition if there are any writers with the pipe still open. In the case of the parent process, the rd.read will never return if it does not first issue a wr.close.</p></blockquote>

<p>Fuckles and shittles.</p>

<pre><code>man socketpair
</code></pre>

<p>Thom Ass Tover says:</p>

<p>http://www.thomasstover.com/uds.html</p>

<p>So these sockets are Unix Domain Sockets, or local sockets.</p>

<p>Pipes</p>

<ul>
<li>can be given a name</li>
<li>writing to a full one yields <code>SIGSTOP</code></li>
<li>are faster than Unix domain sockets</li>
<li>require context switches w kernel to use read/write</li>
</ul>


<p>Solaris pipes are special in that they are full duplex, where as on
Linux and BSD you&#8217;d need two pipes for full duplex. fifos are named
pipes. I guess they&#8217;re like files.</p>

<p>http://en.wikipedia.org/wiki/Named_pipe</p>

<p>wow:</p>

<pre><code>mkfifo my_pipe
gzip -9 -c &lt; my_pipe &gt; out.gz &amp;
</code></pre>

<p>So, Matt Daemon.</p>

<p><code>init</code> or <code>launchd</code> has ppid 0 and pid 1.</p>

<p><code>exit if fork</code> will fork and close the parent process.</p>

<p><code>Process.setsid</code> creates a new session. It talks about a process groups
and what not. If you call it, your process becomes</p>

<ul>
<li>session leader of new session</li>
<li>process group leader of new process group</li>
<li>and has no controlling terminal</li>
<li>and becomes the only new thing in the thing</li>
</ul>


<p>returns the new process group ID.</p>

<p>Job control is the way processes are managed by terminal. Process group
id is generally same as process ID. Fork and the process group id will
be the same. If they fork and so on then yeah yeah yeah this is how you
know they all came from the same shit. When you do <code>irb</code> in a terminal
it&#8217;ll set the process group to the pid of the command you run.</p>

<p>This is why interrupting a Ruby script that&#8217;s shelled out to thing will
kill all the things if it gets an interrupt; if it&#8217;s still alive, it&#8217;ll
kill children. It&#8217;s only upon normal exiting that you lose
thisetoisjdoiasj.</p>

<p>Session groups are higher up, a collection of process groups. One
session group: <code>echo "lol" | echo "lol"</code>. EPERM fires if you are already
leader (can only call w children).</p>

<p>Look at http://rubygems.org/gems/daemons</p>

<p><code>exec</code> totally transforms your shit, better fork first.</p>

<pre><code>Thread.new {
  sleep 2
  puts "THIS WILL NEVER PRINT"
}
Thread.new {
  sleep 1
  exec 'ls'
}
</code></pre>

<p>It entirely nukes your process context, including any outstanding
threads. You must escape via a fork.</p>

<p>Ruby&#8217;s <code>exec</code> will close file handles, database connections, etc, before
passing control to the new shit, though native <code>exec</code> calls would leave
them open. Sensible default given <code>echo</code> doesn&#8217;t care about your
database. You might accidentally exec another process that doesn&#8217;t do
anything with a db connection, and it never totally closes. But you can
override this default if you want to pass the fileno to the new process
and keep open that handle when it opens it for reading.</p>

<p>Unlike fork, no memory is shared with the resulting process of an exec.</p>

<p>I am so tired.</p>

<p><code>system</code> returns a true or false. Output barfs to stdout.</p>

<p><code>popen</code> opens a bi-directional pipe; you can write to and read from the
process spawned</p>

<p><code>popen3</code> gives you access to all 3.</p>

<p>Forking means a copy of all the parent process&#8217;s context before
<code>exec</code>-ing something super small like <code>ls</code>, but you can use gems that
wrap <code>posix_spawn(2)</code></p>

<p>https://github.com/rtomayko/posix-spawn</p>

<p>Also check out <code>man vfork</code> for virtual memory friendly forking.</p>

<p>Resque forks for memory management; bloating Ruby tasks tend not to
shrink, so fork makes it possible for forked workers to bloat and
disappear.</p>

<p>http://rubydoc.info/github/defunkt/resque/Resque/Worker</p>

<blockquote><p>A Resque Worker processes jobs. On platforms that support fork(2), the worker will fork off a child to process each job. This ensures a clean slate when beginning the next job and cuts down on gradual memory growth as well as low level failures.</p>

<p>It also ensures workers are always listening to signals from you, their master, and can react accordingly.</p></blockquote>

<p>Preforking, is it cool. haidjasoidjasiodj</p>

<p>What&#8217;s the rules on writing to stdout between multiple processes.
You can do it; there&#8217;s not going to be thread-unsafety, i don&#8217;t think.</p>

<p>http://stackoverflow.com/questions/1326067/how-to-lock-io-shared-by-fork-in-ruby</p>

<p>Preforking has load balancing wins similar to message queuing with
multiple consumers; when a consumer is ready, it just listens for the
same thing. A socket is shared b/w forked processes, and kernel makes
sure only one gets it</p>

<p>I need to understand more about $stdout and buffering and what not. It&#8217;s
not thread safe, but process-safe? syscall-safe?</p>

<ul>
<li>fork-safe if the action in question fits within a single syscall</li>
</ul>


<p>I have no fucking IDEA MY BRAIN IS DEAD.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/26/daily-journal/"/>
    <updated>2014-07-26T15:10:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/26/daily-journal</id>
    <content type="html"><![CDATA[<h2>top</h2>

<blockquote><p>display and update sorted information about processes</p></blockquote>

<p><code>top</code> will display a sampled, updating list of processes, ordered by pid
by default. Order by cpu:</p>

<pre><code>top -o cpu
</code></pre>

<p>Filter by a pid</p>

<pre><code>top -pid 12345
</code></pre>

<p>Show a single sample of the pid and thread number for a given pid</p>

<pre><code>top -l1 -pid 1234 -stats pid,th
</code></pre>

<h2>Spawn 50 ruby threads&#8230;</h2>

<p>and you wind up w 52: <code>Thread.main</code> + the 50 you created + Ruby
housekeeping thread (listening for OS signals and piping them
synchronously to main thread).</p>

<p>Ruby creates legit OS threads, vs <code>_____</code> threads, whatever the
terminology is for threads that live entirely in the code.</p>

<h2>Thread#join</h2>

<p>Yes, you have to call it on a spawned thread so that the main thread
will wait on it before prematurely exiting. But did you know that
exceptions thrown in a spawned thread get re-raised on the main thread
if you do <code>.join</code>?</p>

<p><code>Thread#value</code> joins and returns the last value of the thread.</p>

<p><code>Thread#status</code> returns status for live, dead, erroed, dying threads.</p>

<p><code>Thread.stop</code> puts the thread to sleep and it won&#8217;t wake up until
someone calls <code>wakeup</code> on it</p>

<p><code>Thread.pass</code> hints the OS to schedule another thread, but this may be
ignored by the scheduler.</p>

<p><code>Thread#raise</code> lets you externally fire exceptions within another thread
but should not be used because <code>ensure</code> is busted. <code>Thread#kill</code> does
what you expect but should also be aborted for the same reasons.</p>

<p>Multiple threads mean concurrency; they <em>might</em> mean parallelism. One
CPU switching b/w threads means concurrency but not parallelism;
multiple cores means paralleilism if they&#8217;re both executing.</p>

<p>Code can&#8217;t be parallel, only concurrent. The executation of concurrent
code can be parallel if the scheduler so chooses.</p>

<h2>golang concurrency vs parallelism</h2>

<p>http://concur.rspace.googlecode.com/hg/talk/concur.html#slide-2</p>

<p>Concurrency is defined as:</p>

<blockquote><p>Programming as the composition of independently executing processes</p></blockquote>

<p>not Linux processes, but rather the famously harder to define Process.</p>

<p>Parallelism is</p>

<blockquote><p>Programming as the simultaneous execution of (possibly related) computations.</p>

<p>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable</p></blockquote>

<p>Concurrency facilitates but doesn&#8217;t guarantee parallelism.</p>

<p>Goroutines aren&#8217;t threads; they&#8217;re similar but cheaper, won&#8217;t block
other goroutines, and multiplexed onto OS threads as necessary.</p>

<p>Synchronize via channels. I guess this is like Ruby Queue? Sounds like
you&#8217;d never do someGoroutine.value but rather use the channel primitive.</p>

<h2>ruby concurrency and you</h2>

<p>https://blog.engineyard.com/2011/ruby-concurrency-and-you</p>

<p>Green threads</p>

<ul>
<li>scheduled by VM, rather than underlying OS</li>
<li>pre 1.9 Ruby was this way (MRI)</li>
<li>managed in user space rather than kernel space</li>
</ul>


<p>Test: if i run Ruby 1.8.7 and do a top of new threads, I would expect
the thread count to be only whatever I started with.</p>

<p>BEHOLD, on 1.8.7:</p>

<pre><code>PID    #TH
84752  1
</code></pre>

<p>So old ruby didn&#8217;t even spawn another thread for housekeeping&#8230; I guess
maybe it wasn&#8217;t necessary because it didn&#8217;t have to coordinate the
signals landing at any random currently-active thread? Pretty cool.</p>

<p>I guess green threads are easy to implement in any interpreted language:
in the main loop of the interpreter you can just check if 100ms has gone
by and then move to another other known threads.</p>

<p>Early Java had green threads&#8230; I don&#8217;t know enough about Java to
comment here.</p>

<p>Ruby &lt;1.9 was smart enough to know when one of these threads was blocked
on external data so that it could &#8220;sleep&#8221; until the data arrived:</p>

<blockquote><p>MRI 1.8.7 is quite smart, and knows that when a Thread is waiting for some external event (such as a browser to send an HTTP request), the Thread can be put to sleep and be woken up when data is detected.</p></blockquote>

<p>1.9 uses native threads, but there&#8217;s still a GIL because the non-Ruby
parts of MRI 1.9 aren&#8217;t thread-safe.</p>

<p>MRI 1.9 uses the same technique as MRI 1.8 to improve the situation,
namely the GIL is released if a Thread is waiting on an external
event (normally IO) which improves responsiveness.</p>

<p>Great read:</p>

<p>http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/</p>

<p>Threads are hard, but requests are an extremely clean concurrency
primitive: controllers and the models loaded and views rendered, etc.,
are not shared between threads that are processing requests. It&#8217;s only
if you start using global state that problems arise, but why are you
doing that?</p>

<p>Why the Ruby/Rails thread FUD?</p>

<ul>
<li>Early Rails wasn&#8217;t threadsafe; essentially a mutex around each request</li>
<li>Mongrel explicitly mutexed around its Rails adapter, so even when
<code>threadsafe!</code> was added, you&#8217;d still have zero concurrency in mongrel.</li>
</ul>


<blockquote><p>For safety, Ruby does not allow a context switch while in C code unless the C code explicitly tells the VM that it’s ok to do so.</p></blockquote>

<p>And mysql was poorly written in this case. So mysql would block.</p>

<blockquote><p>A lot of people talk about the GIL (global interpreter lock) in Ruby 1.9 as a death knell for concurrency. For the uninitiated, the GIL disallows multiple CPU cores from running Ruby code simultaneously. That does mean that you’ll need one Ruby process (or thereabouts) per CPU core, but it also means that if your multithreaded code is running correctly, you should need only one process per CPU core. I’ve heard tales of six or more processes per core. Since it’s possible to fully utilize a CPU with a single process (even in Ruby 1.8), these applications could get a 4-6x improvement in RAM usage (depending on context-switching overhead) by switching to threadsafe mode and using modern drivers for blocking operations.</p></blockquote>

<p>Node vs Ruby Threading:</p>

<p>Yehuda: &#8220;the main difference is that a callback is smaller in size than a stack&#8221;</p>

<p>In other words, the context switch that happens when switching threads
includes copying over an entire stack of the thread you&#8217;re resuming and
some other details I don&#8217;t know of off the top of my head. But with
callbacks, the callbacks have no stack (is this true in Rubyland? maybe
there&#8217;s stack trace information but probably no stack. The only stack
starts from where the callback/block was created, and the same is true w
threads, but the point is that in a thread-per-request model, the stack
goes all the way up to when the request was first received, which can be
a pretty tall stack).</p>

<p>So what about Fibers? They&#8217;re cooperative, but why is their context
switch not a big deal? They have a stack size limit of 4kb. How can I
test this?</p>

<p>Here&#8217;s a nice article:</p>

<p>http://timetobleed.com/fixing-threads-in-ruby-18-a-2-10x-performance-boost/</p>

<p>Seems to suggest that the stack that needs to be copied when context
switching includes interpreter code, which has many local vars and
sometimes the stack is up to 4kb, which is cray cray.</p>

<p>Green threads: pre-emptible userland threads. userland = not kernel
land.</p>

<p>You can hack into the thread-yielding code of old Ruby to allocate
stacks on the heap so that all you have to do to context switch is
change what rsp (pointer to the bottom of the stack) points to. This
means the stack won&#8217;t grow (so you have to pick a sensible size).</p>

<p>Ruby 1.9 performs way better in the benchmarks than his hacks&#8230; why?
&#8220;Thanks. 1.9 uses pthreads which create stacks in a similar manner to
what I did.&#8221; Awesome.</p>

<p>pthreads = POSIX threads</p>

<p>http://timetobleed.com/threading-models-so-many-different-ways-to-get-stuff-done/</p>

<p>Threads models:</p>

<h3>1:1 (native threads)</h3>

<p>One kernel thread for every user thread.</p>

<p>Pros</p>

<ul>
<li>execute threads on different CPUs</li>
<li>threads don&#8217;t block each other</li>
<li>shared memory b/w threads</li>
</ul>


<p>Cons</p>

<ul>
<li>Setup overhead since creating a thread requires a system call (and
those are slow)</li>
<li>Low upper bound on the number of threads that can be created</li>
</ul>


<p><code>pthread_create</code> is the fn that makes the system call to create the
thread.</p>

<h3>1:N (green threads)</h3>

<p>&#8220;lightweight threads&#8221;</p>

<ul>
<li>thread creation, execution, cleanup are cheap</li>
<li>lots of threads can be created</li>
</ul>


<p>Cons</p>

<ul>
<li>kernel doesn&#8217;t know about it, so no parallel execution across CPUs</li>
<li>blocking IO can block all green threads</li>
</ul>


<p>Forking + threading and cross-process communication is one way around
limitations.</p>

<h3>M:N</h3>

<p>Hybrid of above</p>

<ul>
<li>Multi CPUs</li>
<li>Not all threads blocked by blocking system calls</li>
<li>Cheap</li>
</ul>


<p>Cons</p>

<ul>
<li>Really really hard to synchronize userland and kernel scheduler</li>
<li>Green threads will block within same kernel thread</li>
<li>Difficult to maintain</li>
</ul>


<p>1:1 has shown itself to be more performant, but in some cases M:N might
be the right choice.</p>

<p>TODO: read this http://www.akkadia.org/drepper/nptl-design.pdf</p>

<pre><code>b = nil

t = Thread.new do
  b = Fiber.new {
    puts "FIBER"
  }
end

while !b
  # just wait
end

b.resume
</code></pre>

<p>This results in</p>

<pre><code>fiberthread.rb:13:in `resume': fiber called across threads (FiberError)
        from fiberthread.rb:13:in `&lt;main&gt;'
</code></pre>

<p>Of course it would.</p>

<p>Use strace / dtruss to trace sys calls.</p>

<p>Spinlocks are locks that, rather than sleeping, actively busy-wait until
the lock is free. This only makes sense if the wait is expected to be
short, otherwise it might block other threads.</p>

<p>Interesting, from the wiki:</p>

<blockquote><p>Most operating systems (including Solaris, Mac OS X and FreeBSD) use a hybrid approach called &#8220;adaptive mutex&#8221;. The idea is to use a spinlock when trying to access a resource locked by a currently-running thread, but to sleep if the thread is not currently running. (The latter is always the case on single-processor systems.)</p></blockquote>

<p>The idea is that a lock by an active thread is likely to be finished
soon, and since spinlocks avoid the scheduling overhead of a context
switch, then hooray.</p>

<p>Busy-waiting in general means while-looping until some condition is
true. You can even do this in JS:</p>

<pre><code>var end = +new Date() + 1000;
while (+new Date() &lt; end) {}
</code></pre>

<p>So whether Node or EventMachine, the concept is the same: both run on
callbacks.</p>

<p>Realization: I was thinking that I could demonstrate the difference b/w
green threads and OS threads by seeing if a while(true) in a green
thread would yield to others, but the answer is:</p>

<ul>
<li>of course it would yield; each iteration of the while true is
an iteration of the interpreter loop that&#8217;s running commands, so its
timer would fire at that point.</li>
<li>the only time it&#8217;d block is if you called out to a C extension that
looped and didn&#8217;t yield back control.</li>
</ul>


<p>It seems a Fiber&#8217;s 4k stack begins at the point at which it is created.
Hmm. So does it or does it not include interpreter stuff? Well for one
it&#8217;s in the same thread as a requirement.</p>

<p>Reasons why Fibers are faster than threads:</p>

<ul>
<li>limited 4kb stack for quick context switching</li>
<li>no pre-emption means no aggressive/frequent context switching;
context-switch as infrequently as you&#8217;d like.</li>
</ul>


<p>https://github.com/eventmachine/eventmachine/blob/master/docs/old/LIGHTWEIGHT_CONCURRENCY</p>

<p>Lightweight Concurrency generally means</p>

<ul>
<li>putting thread scheduling under the control of your program</li>
</ul>


<blockquote><p>By &#8220;lighter,&#8221; we mean: less
resource-intensive in one or more dimensions, usually including memory and
CPU usage. In general, you turn to LC in the hope of improving the
performance and scalability of your programs.</p></blockquote>

<p>NOTE: race conditions can happen in concurrent environments, even if
parallelism isn&#8217;t there, e.g. preempting</p>

<p>Mac has a max 2048 thread limit.</p>

<p>&#8220;IO Bound&#8221; means your program is mostly bottlenecked by IO, such that
swapping for a faster IO would boost your program performance immensely.</p>

<p>In such a case, going multi-threaded is a no-brainer rather than
serially getting blocked on each slow thing. But if you over do it then
you might just be wasting memory/CPU resources from thread stacks and
context switching that it&#8217;s not justified.</p>

<p>&#8220;CPU bound&#8221; means doubling CPU would mean the job would get done that
much faster.</p>

<p>Quad-core with 4 threads on CPU bound means mega-wins for Rubinius but
obviously not GIL&#8217;d MRI. If you make it 5, then you get the
context-switching overhead.</p>

<p>Rails apps are combo of IO-bound and CPU-bound</p>

<p>IO:</p>

<ul>
<li>Database</li>
<li>Third party APIs</li>
<li>Files read</li>
</ul>


<p>CPU:</p>

<ul>
<li>Rendering templates</li>
<li>Rendering JSON</li>
</ul>


<p>Measure measure measure.</p>

<p>This is comically incorrect:</p>

<pre><code>Mutex.new.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>should be</p>

<pre><code>m = Mutex.new

# ...create thread...

m.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>&#8220;critical section&#8221; refers to the part of your concurrent code that
alters shared data.</p>

<p>Memory Models describe the guarantees made to threads when
reading-from/writing-to memory, which mostly become important to think
about in a multi-threaded settings. The memory model describes how
caching occurs in the registers before actually writing out to memory,
and it describes the scope of compiler/hardware optimizations that can
be made that lead to non-determinant order of memory operations which
can fuck your shit unless you use <code>volatile</code> in Java or explicit mutexes
in Ruby.  Ruby doesn&#8217;t have a memory model spec yet. Java and Go and
others do. I guess Rust nips this in the bud w ownership.</p>

<p>Mutex is a form of a memory barrier, and I think <code>volatile</code> is too.</p>

<p>Livelocking is when <code>try_lock</code>s repeatedly fail, so the threads are
still technically alive but stuck in the same loop.</p>

<p>Best solution is to declare mutex grabbing in the same order via a mutex
hierarchy.</p>

<h2>Signals in ruby</h2>

<p>Rubyz</p>

<pre><code>Signal.trap("USR1") do
  puts "lol handling your custom user handler"
end
puts Process.pid # =&gt; e.g. 12345
</code></pre>

<p>Shellz</p>

<pre><code>kill -s USR1 12345
</code></pre>

<p>So many ways to kill a program:</p>

<ul>
<li>Abort: often self-initiated by <code>abort</code></li>
</ul>


<h2>Difference b/w seg fault and bus error</h2>

<p>http://stackoverflow.com/questions/838540/bus-error-vs-segmentation-fault</p>

<p>On most architectures I&#8217;ve used, the distinction is that:</p>

<ul>
<li>a SEGV is caused when you access memory you&#8217;re not meant to
(e.g., outside of your address space).</li>
<li>a SIGBUS is caused due to alignment issues with the CPU
(e.g., trying to read a long from an address which isn&#8217;t a multiple of 4).</li>
</ul>


<h2>Signals in C</h2>

<p>This is just for fun, but you can set up signal masks and signal
handles and all that fun crap.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

static int gotSignal = 0;

void wat(int s) {
  printf("Got Signal %d", s);
  gotSignal = 1;
}

int main() {
  /* SIGUSR1 == 16 */
  signal(SIGUSR1, &amp;wat);

  pid_t pid = getpid();
  printf("The process id is %d", pid);

  // prevent signal from getting here
  sigset_t s;
  sigaddset(&amp;s, SIGUSR1);
  // uncomment to block the signal from arriving
  //sigprocmask(SIG_BLOCK, &amp;s, NULL);

  while(!gotSignal) {
    printf(".");
    fflush(stdout);
    sleep(1);
  }

  printf("\nDone!\n");
}
</code></pre>

<p>and you can send it usr1 via</p>

<pre><code>kill -s USR1 12345
</code></pre>

<h2>Signals in Node</h2>

<pre><code>var done = false;

process.on("SIGUSR1", function() {
  done = true;
});

console.log("pid: ", process.pid);

var timerId = setInterval(function() {
  if (done) {
    console.log("DONEZO");
    clearInterval(timerId);
  } else {
    process.stdout.write(".");
  }
}, 500);
</code></pre>

<p>Note that SIGUSR1 is reserved by node.js to start the debugger.
The above code will work but if the debugger&#8217;s enabled then that&#8217;ll also
cause it to start.</p>

<p>Seems that signals are often used to start a debugger, or some kind of
debugging operation. Interesting.</p>

<h2>Condition Variables</h2>

<p>A provider and consumer both use the same mutex. Provider locks when
providing an update. Consumer locks when trying to perform an operation,
but internally does a <code>condvar.wait(mutex)</code> with the locked <code>mutex</code> to
unlock until the <code>condvar</code> is <code>signal</code>ed by the provider.</p>

<p>So why wrap the consumer in a while loop rather than an if (see page 104
of storimer)? Because there could be multiple consumers.</p>

<p><code>ConditionVariable#signal</code> wakes up a single thread, <code>ConditionVariable#broadcast</code>
wakes up all threads.</p>

<h2><code>thread_safe</code> gem</h2>

<ul>
<li>ThreadSafe::Array</li>
<li>ThreadSafe::Hash</li>
<li>ThreadSafe::Cache

<ul>
<li>similar to Hash, but insertion order enumeration isn&#8217;t preserved,
which means it can be faster</li>
</ul>
</li>
</ul>


<h2>Immutable = threadsafe</h2>

<p>Read more about it.</p>

<h2>Globals</h2>

<p>The Ruby AST is a global (is it really an AST at that point? is
dynamically adding a method an example of modifying an AST? ASTs are for
parsing, not so much adding/removing methods from a class obj).</p>

<p>Anyway, Kaminari was bitten by this:</p>

<p>https://github.com/amatsuda/kaminari/issues/214</p>

<h2>Thread-locals</h2>

<p>Variables that are global to everything in the current thread but hidden
to everyone else. So you could do</p>

<pre><code>Thread.current[:some_service] = SomeService.new
</code></pre>

<p>which could open a new connection. Connections are nice concurrency
primitives, much like request objects in Rails. But if you have too many
threads, you might hit a max connection limit, so in that case, use
pools, lol.</p>

<p>Pools let you specify max concurrency, which is likely less than the
number of threads that might want to consume it, and then when
requesting access to a thing in a pool, it&#8217;ll block until a slot&#8217;s
available.</p>

<p>See: https://github.com/mperham/connection_pool</p>

<p>mperham is Mr Sidekiq. Mr. Concurrency in general I guess.</p>

<p>Question: is a connection pool the same as a thread pool? Probably not,
connection pool is just a resource pool that is thread-aware, but
doesn&#8217;t constitute individual threads.</p>

<h2>Rubinius Actor</h2>

<p>https://github.com/rubinius/rubinius-actor</p>

<p>Depends on core Rubinius class <code>Channel</code>. TODO: find out why <code>Channel</code>
doesn&#8217;t/can&#8217;t exist in MRI.</p>

<h2>Rubinius Ruby JITting</h2>

<p>Talking to IRC folk: one of the major reasons for Ruby all the way down
or at least Ruby most of the way down is that more of it can be JITted
rather than having the hard C/C++ boundary after which no more
optimizations can be made.</p>

<p>Also, in some benchmarks b/w Rubinius and JRuby and MRI, etc., one thing
that comes up a lot is the suggestion that the tests run for longer so
that the JIT is primed, all the optimizations have been made, etc etc
etc.</p>

<h2>Rails Batches</h2>

<p>http://api.rubyonrails.org/classes/ActiveRecord/Batches.html</p>

<pre><code>Article.find_each do |a|
  a.wat
end
</code></pre>

<p>this internally splits DB queries into batches of 1000 so that you&#8217;re
not instantiating potentially a billion Ruby objects for each row. In
the end you&#8217;ll still allocate the same amount of memory but it can be
GC&#8217;d along the way vs causing an insane spike and possibly crashing your
server.</p>

<h2>Server-sent events</h2>

<p>http://tenderlovemaking.com/2012/07/30/is-it-live.html</p>

<ol>
<li>A stream obj is added to Rails request object, quacks like IO obj.
You can write to it and close it, but it doesn&#8217;t actually stream live
to the client; it buffers, and then flushes.</li>
<li>With <code>ActionController::Live</code>, it&#8217;ll actually stream live.</li>
<li>Some WebServers, like WEBrick will thwart this by buffering the
response until it&#8217;s complete. Unicorn could work, but it&#8217;s meant for
fast responses; anything taking longer than 30s might get terminated.
Rainbows/Puma/Thin would work.</li>
</ol>


<h2>Celluloid</h2>

<p>Transforms method invocations into blocking messages. Precede w <code>async</code>
to prevent blocking (obviously still happens async);</p>

<pre><code>require 'celluloid'

class DoesStuff
  include Celluloid

  attr_accessor :i

  def foo
    # currently this displays
    # one item per second.
    # if you swap comments with
    # the line after it'll wait
    # until the very end to print them all
    # at once because the each at the end
    # will evaluate the "longest" future first
    sleep i
    #sleep (11 - i)
    i
  end
end


futures = []

10.times do |i|
  thing = DoesStuff.new
  thing.i = i

  futures &lt;&lt; thing.future.foo
end


futures.each do |f|
  puts "Completed: #{f.value.i}"
end

sleep
</code></pre>

<p>This is interesting: https://github.com/celluloid/celluloid/wiki/Frequently-Asked-Questions#q-can-i-do-blocking-io-inside-an-actor-or-do-i-have-to-use-celluloidio</p>

<p>It&#8217;s fine to have blocking IO such as waiting for a DB query to return,
or slow HTTP response, but you shouldn&#8217;t have it waiting on
<em>indefinite</em> IO; for that, use Celluloid::IO.</p>

<p>I believe that an actor can&#8217;t be handling multiple messages at the same
time. Wrong! That&#8217;s only if Erlang/Exclusive mode is on, and you have to
be careful about that because it means a higher risk of deadlock:</p>

<p>https://github.com/celluloid/celluloid/wiki/Exclusive</p>

<p>Sidekiq doesn&#8217;t make use of return values a whole lot; rather actors are
expected to send messages back to their &#8220;callers&#8221;.</p>

<p>Accessing localvars is faster than ivars: https://github.com/puma/puma/commit/fb4e23d628ad77c7978b67625d0da0e5b41fd124</p>

<h2>Compare and set (CAS)</h2>

<p>aka check-and-set</p>

<p>For platforms that support it, CAS is a mutex-free approach to
thread-safety</p>

<pre><code>a += 1
</code></pre>

<p>is not thread safe, but</p>

<pre><code>cur = a.value
new_value = cur + 1
if (!a.compare_and_set(cur, new_value)) 
  # try again
end
</code></pre>

<p>is.</p>

<p>Worth pointing out that Redis supports a form of this using WATCH.</p>

<pre><code>MULTI # begin transaction
SET foo lol
SET bar wat
EXEC # execute
</code></pre>

<p>so basically if you do</p>

<pre><code>WATCH someval
MULTI
set someval lol
EXEC
</code></pre>

<p>and someval changed after the MULTI then it will fail.</p>

<p>So why use CAS over a mutex?</p>

<blockquote><p>If the cost of retrying the operation is cheap, or rare, it may be much less expensive than using a lock.</p></blockquote>

<p>Logic checks out.</p>

<pre><code>require 'atomic'
v = Atomic.new(0)
v.update do |current|
  current + 1
end
</code></pre>

<p>This is the shorthand to the idempotent loop with CAS.</p>

<p>Lockless showed mega improvements relative to locking in Rubinius but
not JRuby for some reason.</p>

<p>Hamster is the immutability gem to check out.</p>

<h2>oni</h2>

<p>https://github.com/olery/oni</p>

<p>Uses SQS, look into it because i am such a nooblet.</p>

<h2>SQS</h2>

<p>Uses a visibility timeout after a consumer has started to receive a
message in which time it is hidden from other consumers, and in this
time it should be deleted.</p>

<ul>
<li>Supports GET/POST requests to public URLs, presuming you pass in a
valid signature

<ul>
<li>This means you could fire requests directly to SQS rather than
having to go to a server first&#8230; that is badass.</li>
</ul>
</li>
<li>Reports of scalability problems</li>
</ul>


<p><a href="http://nsono.net/amazon-sqs-vs-rabbitmq/">Alternative: RabbitMQ</a></p>

<ul>
<li>SQS: consumers must poll for messages, and SQS charges by the request,
even if the response is empty.</li>
<li>RabbitMQ supports push</li>
<li>is free and open source</li>
<li>based on erlang</li>
<li>adheres to AMQP (standard for high performance messages queues)</li>
<li>supports durable queues (crash-recoverable, written to disk)</li>
<li>delivered in order unless message requeued</li>
<li>more consistent (much less likely to deliver a message twice unless
the message actually failed)</li>
</ul>


<p>cons</p>

<ul>
<li>not necessarily highly available (because it&#8217;s a server that runs on
whatever instance you wanna put it on, so you have to manage failover,
redundancy, etc, whereas SQS is a system that handles all of that)</li>
<li>this is configurable, but the default is for RabbitMQ to drop messages
if there are no consumers; surprising to SQS folk.</li>
</ul>


<h2>Heartbeats</h2>

<p>https://www.rabbitmq.com/reliability.html</p>

<blockquote><p>In some types of network failure, packet loss can mean that disrupted TCP connections take some time to be detected by the operating system. AMQP offers a heartbeat feature to ensure that the application layer promptly finds out about disrupted connections (and also completely unresponsive peers). Heartbeats also defend against certain network equipment which may terminate &#8220;idle&#8221; TCP connections. In RabbitMQ versions 3.0 and higher, the broker will attempt to negotiate heartbeats by default (although the client can still veto them). Using earlier versions the client must be configured to request heartbeats.</p></blockquote>

<p>Re: &#8216;Heartbeats also defend against certain network equipment which may
terminate &#8220;idle&#8221; TCP connections.&#8217;: I bet that&#8217;s referring to NAT, which
manages a cache of IP translations and will go inactive if nothings been
sent to / received from an IP for a while.</p>

<p>YAY I WAS RIGHT http://stackoverflow.com/questions/865987/do-i-need-to-heartbeat-to-keep-a-tcp-connection-open#comment1713801_866003</p>

<p>So Heartbeats</p>

<ul>
<li>reassure you the connection is alive in some cases where the failure
conditions aren&#8217;t otherwise detectable</li>
<li>keep the NAT state tables warm for your IP</li>
</ul>


<h2>Celluloid::IO</h2>

<p>https://github.com/celluloid/celluloid-io</p>

<p>Provides a different class of Actor that&#8217;s heavier than normal Celluloid
actors, but contains a high performance reactor like EventMachine or
cool.io (todo: check out cool.io). So unlike EventMachine you can have
multiple loops, e.g. one in each actor (resources permitting). (Also,
does EM really force you to just have one?)</p>

<h2>Autoload</h2>

<p>Yes we know it&#8217;s not threadsafe in MRI. Recent JRuby versions make it
thread safe, but just eager load your shits before spawning threads.</p>

<h2>Requests as concurrency unit</h2>

<p>I guess in general you should always look for the concurrency unit; that
domain object that encapsulates all the data you need to get a job done
so that hopefully you&#8217;re not sharing data between threads. Each request
gets handled by its own thread.</p>

<h2>Queue</h2>

<p><code>Queue#pop</code> will suspend a thread until data is in the queue. Like a
mofuggin stream.</p>

<p>Queue is apparently the only thread-safe data structure that ships with
Ruby.</p>

<h2>JRuby</h2>

<p>Foreign function interface</p>

<p>http://en.wikipedia.org/wiki/Foreign_function_interface</p>

<p>Mechanism for languages to invoke routines from other languages.</p>

<p>Write your extension code in Ruby, FFI will call the write C / Java /
whatever stuff. It won&#8217;t even be compiled. I guess it just links into
dynamic libs?</p>

<p>JRuby obviously doesn&#8217;t support C extensions, but FFI extensions will
work.</p>

<p>JRuby</p>

<ul>
<li>has no fork(), since JVMs mostly can&#8217;t safely be forked
(<code>NotImplementedError: fork is not available on this platform</code>)</li>
<li>Fibers are native threads, rather than MRI green threads, which means
you are constrained to native thread overhead/limits.</li>
</ul>


<h2>Rubinius (rbx)</h2>

<ul>
<li>Designed for concurrency, speed.</li>
<li>Rubinius 2.0 has no GIL</li>
<li>All tools written in Ruby, including bytecode VM, compiler,
generational GC, JIT, etc</li>
<li>No continuations (because dependent on callcc, a C thing)</li>
<li>At some point, when dealing with locks and low level things, you&#8217;ll
find C++.</li>
</ul>


<p>http://rubini.us/2011/02/25/why-use-rubinius/</p>

<h2>Ruby Enterprise Edition</h2>

<p>By Phusion. No longer alive.</p>

<ul>
<li>Compatible w 1.8.7</li>
<li>End of Life since 2012</li>
<li>No more work being done, reasons being:

<ul>
<li>Rails 4 no longer supporting 1.8</li>
<li>COW patch accepted on Ruby 2.0</li>
<li>Many Ruby Enterprise Edition patches addressed in 1.9, 2.0</li>
</ul>
</li>
</ul>


<h2>MacRuby</h2>

<p>Implementation of 1.9 Ruby directly on top of Mac OS X core tech, e.g.</p>

<ul>
<li>Obj-C runtime and GC</li>
<li>LLVM compiler infrastructure</li>
</ul>


<h2>Reactive manifesto</h2>

<p>TODO: read this http://www.reactivemanifesto.org/</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/19/daily-journal/"/>
    <updated>2014-07-19T11:30:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/19/daily-journal</id>
    <content type="html"><![CDATA[<h2>Crank</h2>

<p>Meth.</p>

<p>An eccentric person, esp. one who is obsessed by a particular subject or
theory: when he first started to air his views, they labeled him a
crank | [ as modifier ] : I am used to getting crank calls from
conspiracy theorists.</p>

<h2>Roko&#8217;s modern basilisk</h2>

<p>It&#8217;s happening.</p>

<h2>Transactional UIs</h2>

<p>People build forms. Ember gives you sweet syntax sugar for 2wb.
Not for transactional UI, anything that needs a buffer.</p>

<p>Old mindset: if you need 1wb, just&#8230; don&#8217;t set on the other side of a
2wb.</p>

<p>TODO: ask kris more about the async/sync cocoa observer binding
limitations.</p>

<ul>
<li>Most observers just do something and stop.</li>
<li>And they mostly want to know the last thing they cared about.</li>
</ul>


<p>Bubbling doesn&#8217;t describe actions; actions go wherever. Bubbling only in
route hierarchy.</p>

<p>Services:</p>

<ul>
<li>session/user</li>
<li>timer</li>
<li>websocket</li>
<li>analytics</li>
</ul>


<p>Idea: components provide services to the components the render. They
have a ServiceCertificate</p>

<p>Goal:</p>

<ul>
<li>Try and associate actions with objects.</li>
<li><code>actions</code> themselves can just be passed into the <code>actions</code></li>
</ul>


<h2>Non-dynamic routes</h2>

<pre><code>resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}

resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}
</code></pre>

<p>Initializers vs <code>applicationRoute#beforeModel</code>.</p>

<p>retcon for how to use controllers</p>

<p>asop to data binding</p>

<p>HTMLbars knows what parts of the template are dynamic vs static.</p>

<p>In React, if you have a conditional</p>

<h2>Skunkworks project</h2>

<blockquote><p>A skunkworks project is a project developed by a small and loosely
structured group of people who research and develop a project
primarily for the sake of radical innovation.[1] The terms
originated with Lockheed&#8217;s World War II Skunk Works project.</p></blockquote>

<p>http://en.wikipedia.org/wiki/Skunk_Works</p>

<blockquote><p>The designation &#8220;skunk works&#8221;, or &#8220;skunkworks&#8221;, is widely used
in business, engineering, and technical fields to describe a
group within an organization given a high degree of autonomy
and unhampered by bureaucracy, tasked with working on advanced
or secret projects.</p></blockquote>

<p>Lockheed Martin&#8217;s Skunk Works project made SR-71.</p>

<h2>Project Svelte</h2>

<p>http://www.trustedreviews.com/opinions/android-4-4-kitkat-s-project-svelte-what-it-is-and-why-you-should-care</p>

<blockquote><p>‘dogfooding’ – that is making its employees use and live with their own projects</p></blockquote>

<p>They dogfooded their employees by forcing them to dev on handicapped
phones. Android 4.4 was the result, apparently it was way more
performant.</p>

<h2>RACK_ENV vs RAILS_ENV</h2>

<p><code>Rails.env</code> is decided by <code>RAILS_ENV || RACK_ENV || "development"</code>. It&#8217;s
common to set <code>RACK_ENV</code> which will also set <code>RAILS_ENV</code>, but if you
have any rack middleware that behaves differently in different
environments, you might screw yourself if you&#8217;re using <code>RAILS_ENV</code>.</p>

<h2>wythoughts on blocks</h2>

<p>The reason <code>|i|</code> is ok is for the same reason you can&#8217;t do the following
in Ruby:</p>

<pre><code>a = { |it| wat }
</code></pre>

<p>You have to do</p>

<pre><code>a = proc { |it| wat }
</code></pre>

<p>Case in point you need an fn to save a block.</p>

<h2>mythoughts on mutability</h2>

<p>Can/should we swap POJOs when an observed property changes? Is there any
value to</p>

<pre><code>var pojo = {
  a: {
    b: 123
  }
};

var a = pojo.a;
Ember.set(pojo, 'a.b'
</code></pre>

<h2>ASI: automatic semicolon insertion</h2>

<p>Nuff said.</p>

<h2>old browser disagreements on ws</h2>

<pre><code>[ text ws text]
</code></pre>

<p>cloneNode produces:</p>

<ul>
<li>ie8: 1 node</li>
<li>ie9: 2 nodes</li>
<li>else: 3 nodes</li>
</ul>


<h2>NoScope</h2>

<p>http://www.thecssninja.com/javascript/noscope</p>

<p>tldr NoScope is an old IE categorization of nodes, and NoScope dictates
that innerHTML and cloneNode will strip these els.</p>

<h2>Ropes: DAG of string implementation for FF/Chrome</h2>

<p>http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=181EEF66EB411F4277C009A1D492CF75?doi=10.1.1.14.9450&amp;rep=rep1&amp;type=pdf</p>

<p>Look into this more. Too lazy to read / comment.</p>

<p>How to force Chrome to not use a rope:</p>

<ul>
<li>Less than 12 chars</li>
</ul>


<p>What does it mean to intern strings?</p>

<h2>CSP: Content Security Policy</h2>

<p>http://www.html5rocks.com/en/tutorials/security/content-security-policy/</p>

<h2>String interning</h2>

<pre><code>String.prototype.intern = (function() {
   "use strict";
   var o = {"- ": 0};
   delete o["- "];
   return function() {
       var str = this;
       o[str] = true;
       var ret = Object.keys(o)[0];
       delete o[str];
       return ret;
       try {} finally {}
   };
})();
</code></pre>

<h2>Component pinning</h2>

<p>Associating the re-render with the pre-existing fragment.</p>

<h2>localStorage on iOS Cordova webviews</h2>

<ol>
<li>Run dev, set <code>localStorage.wat = "lol"</code></li>
<li>Stop and re-run the app, and <code>localStorage.wat</code> still is &#8220;lol&#8221;</li>
<li>Delete the app, re-install, still dev, <code>localStorage.wat</code> is undefined</li>
</ol>


<p>I don&#8217;t even have to check&#8230; your app can&#8217;t run in both dev and prod.
You can&#8217;t share userSessions across dev and prod apps. Then again, our
servers could maintain keys for both APNS and APNS_SANDBOX.</p>

<h2>GCM project number vs project ID</h2>

<p>https://developers.google.com/compute/docs/faq#whatisthedifference</p>

<p>You pick project ID, they pick project number. Project number is the
Sender ID you use for GCM.</p>

<h2>Pointer comparisons for such perf</h2>

<pre><code>if (wat === false) {
}
</code></pre>

<p><code>false</code> can be implemented to just refer to a unique memory location,
such that all browsers need to comparison in the above code is <code>wat</code>&#8217;s
memory address against <code>false</code>&#8217;s.</p>

<p>Same goes with</p>

<pre><code>if (wat === undefined) {
}
</code></pre>

<p>just that the presence of <code>foo</code> in <code>cache.foo</code> is ambiguous without
testing <code>foo in cache</code>; might be easier to do <code>cache.foo = UNDEFINED</code>
where</p>

<pre><code>function UNDEFINED() {}
</code></pre>

<p>Sentinel as fuck.</p>

<h2>PushPlugin</h2>

<p>Only starts firing PNs after <code>register</code>. We need a user session to
register, right? Seems weird we can&#8217;t query it for information before
immediately registering&#8230; either way, works fine for us, at least we
killed Zalgo.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/18/daily-journal/"/>
    <updated>2014-07-18T03:50:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/18/daily-journal</id>
    <content type="html"><![CDATA[<h2>Cookies</h2>

<p>What ends up in <code>document.cookie</code>?</p>

<p>Test: kill a previous localhost:5000 server, start a server for a
separate project. Reload the page. Request headers sent include
a transient cookie from the previous server. I bet it was due to
Turbolinks. I was right!</p>

<p>From http://tools.ietf.org/html/rfc6265#section-4.1.1</p>

<blockquote><p> Origin servers MAY send a Set-Cookie response header with any
 response.  User agents MAY ignore Set-Cookie headers contained in
 responses with 100-level status codes but MUST process Set-Cookie
 headers contained in other responses (including responses with 400-
 and 500-level status codes).  An origin server can include multiple
 Set-Cookie header fields in a single response.  The presence of a
 Cookie or a Set-Cookie header field does not preclude HTTP caches
 from storing and reusing a response.</p></blockquote>

<p>So you can send multiple headers with the same key. Makes sense, since
comma separation will conflict with the UTC date (e.g. <code>Aug 12, 2014</code>).</p>

<p>So how do you set multiple cookies in Rack?</p>

<p>Interesting: https://github.com/rack/rack/blob/master/lib/rack/utils.rb#L266</p>

<p>Anyway, split cookies with newlines and Rack will cause this to send two
<code>Set-Cookie</code> headers, which is totally fine.</p>

<p>You can also use <code>set_cookie</code> on <code>Rack::Response</code> if you&#8217;re into that
sort of thing..</p>

<p>I psyched myself out thinking cookies were overwriting each other by doing:</p>

<pre><code>"Set-Cookie" =&gt; "foo\nbar\nbaz"
</code></pre>

<p><code>document.cookie</code> was only revealing <code>baz</code>. But, I&#8217;m a dumb: cookies
need to be key-value pairs, which fixed it.</p>

<p>You can use <code>HttpOnly</code> to prevent JS (and other APIs?) access to the
cookie sent by the server. Makes sense; less likely that&#8217;ll break
something.</p>

<p>Getting <code>document.cookie</code> returns all the cookies available to JS.
Setting it will only set the cookie you provide.</p>

<blockquote><p>Notice that servers can delete cookies by sending the user agent a
new cookie with an Expires attribute with a value in the past.</p></blockquote>

<h2>JavaScript set focus</h2>

<p><code>focus()</code> is a method on input elements. So is <code>blur()</code>.</p>

<p><code>document.activeElement</code> in modern browsers points to the focused
element, which might also include scroll windows.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/document.activeElement</p>

<p>In older browsers, to <code>blur</code> the active element, you&#8217;d have to know what
that element was; there was no way to query. Might be wrong about this.</p>

<h2>React Nested Router</h2>

<p>http://www.youtube.com/watch?v=P6xTa3RRzfA</p>

<ul>
<li>State is just data</li>
<li>Your route is data, e.g. you could render a top-level App component
and tell it what its route is, and render everything a la React,
pretend like you&#8217;re redrawing the whole page.</li>
<li>Rather than switch-statement-based routing, the <code>activeRoute</code> just
gets passed in via <code>props</code> like any other property

<ul>
<li><code>router.match</code> handlers will create all the routes, and pass in a
single <code>activeRoute</code>; every route segment along the way just knows
about with its activeRoute child is, if one exists.</li>
<li>e.g. <code>contact/profile</code>, app.activeRoute = contact,
contact.activeRoute = profile</li>
</ul>
</li>
<li>API

<ul>
<li>Route component

<ul>
<li>handler = a React Class</li>
</ul>
</li>
</ul>
</li>
<li>Differences w Ember

<ul>
<li>No auto-gen &#8216;index&#8217; routes</li>
<li>paths don&#8217;t inherit parent paths

<ul>
<li>this means if you&#8217;re &#8220;overwriting&#8221; a parent dynamic segment, the
dynamic segment must appear <em>somewhere</em> in the child route so you
can actually load that data.

<ul>
<li>AH, the router will detect when children omit ids that their
parents have declared. That&#8217;s nice.</li>
<li>also yells at you if you use the same path in two places.</li>
</ul>
</li>
<li>nice that it lets you have <code>/profile</code> vs <code>/user</code></li>
</ul>
</li>
<li>Ember is less typing, but

<ul>
<li>React makes it easier to share handlers</li>
<li>Overwriting URL is nice when you need it, error checking is nice</li>
</ul>
</li>
</ul>
</li>
<li>So each non leaf handler gets <code>activeRoute</code>, all handlers get all
<code>params</code>.</li>
<li>Refactorability/decoupling:

<ul>
<li>Because route names and paths are fully specified and all params are provided to
each handler, changing the nesting of a route means you don&#8217;t have
to rewrite all your link-tos from &#8220;wat.foo&#8221; to &#8220;foo&#8221;. Then again
if you&#8217;re using resources you don&#8217;t have to do that either.</li>
</ul>
</li>
<li>Question: what about other <code>props</code> you&#8217;d want to pass into a
component?

<ul>
<li>Answer: Route components aren&#8217;t concerned with props other than how
to be a route handler.</li>
</ul>
</li>
</ul>


<p>http://jsbin.com/vukacule/6/edit</p>

<p>It is really cool that you can switch between rendering a route with App
as a handler vs just rendering App. The difference is that, when
route-driven, it gets passed props.</p>

<p>The <code>Route</code> components you use are obviously stateless; all state lives
on the Handlers.</p>

<p>Ah, in React <code>` syntax just means</code>{blah: &#8220;wat&#8221;}` inside
the normal single-curly.</p>

<p>How do Links work? They call transitionTo and there&#8217;s a single URLStore
singleton.</p>

<h2>TLS Replay?</h2>

<p>I had it in my head that man-in-the-middle wasn&#8217;t a problem for TLS but
maybe they could replay the messages? Turns out I am wrong; TLS includes
a sequence mechanism.</p>

<p>That being said, your app might send repeat messages, which demands its
own double checking / application-level sequencing or some other
prevention mechanism.</p>

<h2>chroot</h2>

<p>http://en.wikipedia.org/wiki/Chroot</p>

<p>Learned about this when speculating w Ember Core about how the front
page Rust evaluator works at http://www.rust-lang.org/</p>

<p>It runs a program with the assumption that <code>/</code> is somewhere else, and it
can&#8217;t access it.</p>

<p>Change</p>

<h2>process.nextTick</h2>

<p><code>process</code> doesn&#8217;t exist on the browser, so therefore neither does
<code>nextTick</code>, but you can hack it if you&#8217;re on a browser that has a native
<code>Promise</code> object, since the <a href="http://promisesaplus.com/">spec</a> mentions
that resolution callbacks must happen when the execution context
consists only of platform code.</p>

<blockquote><p>onFulfilled or onRejected must not be called until the execution
context stack contains only platform code. [3.1].</p></blockquote>

<p>So here&#8217;s how you could write nextTick, note that there&#8217;s no need to</p>

<pre><code>var p = Promise.resolve();
function nextTick(cb) {
  p.then(cb);
}
</code></pre>

<h2>Visibility API</h2>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/Guide/User_experience/Using_the_Page_Visibility_API">mdn</a></p>

<p>e.g.</p>

<ul>
<li>pause video when you tab-away</li>
<li>stop requestAnimationFrame</li>
</ul>


<h2>Closing over <code>let i</code></h2>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p>The above code has the gotcha that by the time the <code>fns</code> functions run,
they&#8217;ll all print out <code>10</code>, rather than the value of <code>i</code> when the
closing-over function was created. This is part of the reason why jshint
will yell at you for creating functions in a loop, e.g.</p>

<pre><code>var fns = [];
for (var i = 0; i &lt; 10; ++i) {
  fns.push(makeCallback(i));
}

function makeCallback(num) {
  return function() {
    console.log(num);
  }
}
</code></pre>

<p>Then <code>i</code> will be uniquely preserved for each callback.</p>

<p>The es6 <code>let</code> keyword gives you block scope, which includes everything
declared within the for loop. If you just use <code>let</code> in the original
code, you can do</p>

<pre><code>var fns = [];
for (let i = 0; i &lt; 10; ++i) {
  fns.push(function() {
    console.log(i);
  });
}
</code></pre>

<p><code>i</code> doesn&#8217;t get hoisted; rather, each iteration gets its own <code>i</code> value
that gets closed over.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/16/daily-journal/"/>
    <updated>2014-07-16T00:40:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/16/daily-journal</id>
    <content type="html"><![CDATA[<h2>WeakMap</h2>

<p>Use objects as keys. If you lose access to a key, it and its value will
eventually be removed by GC because references to keys are weak. This
also means WeakMaps are non enumerable since GC is non-deterministic and
a key that might exist pre GC might not exist after.</p>

<h2>ES6 Symbols</h2>

<p>They&#8217;re nothing like Ruby symbols.</p>

<p>They&#8217;re used to create unique, non-enumerable, keys that can&#8217;t be
determined publicly unless the symbol is exported. So you could prevent
tampering with a player&#8217;s score by storing the score on the player using
an unshared symbol as the key:</p>

<p>http://tc39wiki.calculist.org/es6/symbols/</p>

<h2>ES6 === Harmony === ES.next</h2>

<p>They&#8217;re all the same thing.</p>

<h2>JS 1.7 vs ES6, etc</h2>

<p><a href="http://ejohn.org/blog/versions-of-javascript/">jeresig clears this up a bit</a></p>

<p>All modern browsers support ECMAScript; JavaScript is a variant of it
that Mozilla&#8217;s largely been adding features to. ES3 === JS 1.5.</p>

<p>So I see <code>let</code> was added to JavaScript 1.7, so why is it now being
described as a new upcoming feature of ES6? Ah, because all browsers
track ECMAScript standards, even if they call their enhanced language in
the browser something else. Mozilla has been blazing ahead and trying
new shit, but other browsers won&#8217;t pick it up until it&#8217;s actually
standardized into ECMAScript.</p>

<p>Why would Microsoft follow ECMAScript? Well, for starters, it delivered
JScript to Ecma back in the day for standardization.</p>

<blockquote><p>The name &#8220;ECMAScript&#8221; was a compromise between the organizations involved in standardizing the language, especially Netscape and Microsoft, whose disputes dominated the early standards sessions.</p></blockquote>

<p>Interesting, and:</p>

<blockquote><p>While both JavaScript and JScript aim to be compatible with ECMAScript, they also provide additional features not described in the ECMA specifications</p></blockquote>

<p>Also, some reason I thought TC39 was part of Mozilla. I see that I am
obviously incorrect: http://www.ecma-international.org/memento/TC39.htm</p>

<p>It&#8217;s Ecma-TC39. The things I don&#8217;t know.</p>

<p>W3C Tag, Ecma-TC39. W3C Tag, Ecma-TC39.</p>

<h2><code>let</code></h2>

<p><code>let</code> behaves like C++ declarations; the obj is only available in the
curlies, or in for loops, or whatever, and there&#8217;s no hoisting. Outside
of the block, the variable is undefined.</p>

<h2>Cloudfront TTL</h2>

<p>TTL lets you specify a min time before CF checks the origin to see if it
has a new version of the file/response. You still need your origin
server&#8217;s Cache-Control headers setup correctly.</p>

<p><a href="http://stackoverflow.com/questions/10621099/what-is-a-ttl-0-in-cloudfront-useful-for">TTL can be 0</a>.
Why? TTL 0 means that it delegates Cache-Control entirely to the origin.
This means CF will always make a GET request w <code>If-Modified-Since</code>
header to let the server return <code>304 Not Modified</code>.</p>

<h2>Drag and Drop</h2>

<p>Draggable elements need to be marked as <code>draggable="true"</code>.</p>

<p>Then listen to the <code>ondragstart</code> event, e.g.
<code>ondragstart="drag(event)"</code>.</p>

<p>And then say what data is associated with the dragged el&#8230;</p>

<pre><code>ev.dataTransfer.setData("Text", ev.target.id);
</code></pre>

<p>This seems strange.</p>

<p>https://developer.mozilla.org/en-US/docs/Web/API/DataTransfer</p>

<p>It really is a class associated only w drag and drop.</p>

<p>Should probably be reading this rather than fucking w3schools. Why do I
still do that?
https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Drag_and_drop</p>

<p>Ah I get it, you use dataTransfer as part of the mechanism for
dynamically determining drop targets. You have to prevent bubbling
(return false or preventDefault) on droppable targets, and in that fn
they have the option of looking up the data transfer to see if they want
to accept the data from that drag drop.</p>

<p>You can also configure drag drag visual details to indicate copying,
moving, etc. LOL such drag and drop.</p>

<p>Oof apparently it&#8217;s a fucking disaster: http://www.quirksmode.org/blog/archives/2009/09/the_html5_drag.html</p>

<p>Criticisms:</p>

<ul>
<li>7 fucking events, such API surface</li>
<li>&#8220;For the drop event to fire at all, you have to cancel the defaults of both the dragover and the dragenter event.&#8221;</li>
</ul>


<h2>Cordova events: sticky != buffered</h2>

<p>Sticky events (e.g. deviceready) just mean that once fired, they stay in
a fired state. This means you can&#8217;t have multiple events fire if it&#8217;s a
sticky event. I was originally thinking sticky meant all the events were
cached until the first handler was registered.</p>

<p>Ended up making this: https://gist.github.com/machty/e1cc485060f2951aeb6c</p>

<h2>Why <code>-print0</code> in <code>find</code>?</h2>

<p>Often you pipe the results of <code>find</code> into <code>xargs</code> to pass the results of
a <code>find</code> so that some utility can operate on each file found. GOOD
ENGRISH, MATCHNEER.</p>

<p>But since <code>xargs</code> splits based on whitespace by default, this will break
for files with newlines or or spaces in them, so <code>-print0</code> separates
files w null bytes, and <code>-0</code> tells xargs to split via null bytes as
well. Win win win. No difference if you have no files with spaces in
them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Forgotten things]]></title>
    <link href="http://machty.github.com/blog/2014/07/15/forgotten-things/"/>
    <updated>2014-07-15T12:18:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/15/forgotten-things</id>
    <content type="html"><![CDATA[<p>Here&#8217;s a progressively-updated list of things I forget throughout the
day. This is different from the list of things I&#8217;ve learned; that
approach is useful for packing the things into my brain, hopefully; the
purpose of this list is to pack things back in when I forget. And for
now it&#8217;ll just be one giant progressively-updated blog.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/14/daily-journal/"/>
    <updated>2014-07-14T09:33:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/14/daily-journal</id>
    <content type="html"><![CDATA[<h2>Website Push != Push Notifications</h2>

<p>So when you&#8217;re rummaging through the Apple Dev Portal, don&#8217;t confuse the
two and generate the wrong certs. K?</p>

<h2>WWDC 2011 video on UIViewController Containment</h2>

<pre><code>https://developer.apple.com/videos/wwdc/2011/
</code></pre>

<p>First off, WWDC stands for the Apple World-Wide Developer Conference.</p>

<h2>Why view controllers</h2>

<ul>
<li>Make it easy to make high quality apps</li>
<li>Reusable</li>
</ul>


<p>A View Controller just a Controller. Mediates model data with many
views. View controllers maintain entire hierarchies of views. They&#8217;re
heavyweight, meant to manage a &#8220;screenful of content&#8221;. Often packaged
with a model, e.g.</p>

<ul>
<li>TweetViewController</li>
<li>ImagePickerController</li>
</ul>


<p>View Controllers are social, meant to connect to each other. They push
and pop each other, etc. They talk to each other a lot.</p>

<p>The &#8220;manage a screenful of content&#8221;:</p>

<p>View Controllers anticipate being presented in different ways. More
accurately: they should maintain a unit of content. Only
<code>rootViewController</code> manages a &#8220;screenful of content&#8221;, specifically the
<code>rootViewController</code> property of the window object. Knows how to forward
rotation events, decides overall layout.</p>

<p>How to use View Controllers</p>

<ul>
<li>subclass UIViewController</li>
<li>associate VC w view hierarchy</li>
<li>override callbacks</li>
</ul>


<p>Apperance callbacks: viewWillAppear, viewDidAppear, etc
Rotation callbacks: viewWillRotate, etc</p>

<p>ViewControllers manage an entire view hierarchy. Not just one to one
with a view.</p>

<p>View Controller Containers, a tale of Two Hierarchies: view hierarchies
and view controller hierarchies.</p>

<p>Container controllers</p>

<ul>
<li>responsible for parent child relationships

<ul>
<li>API like <code>initWithRootViewController</code> implies parent-child in nav
controller</li>
<li>split view controllers lets you set view controller children.</li>
</ul>
</li>
</ul>


<p>Controller container api</p>

<ul>
<li>addChildViewController

<ul>
<li>not meant to be called by anyone but its own implementation; don&#8217;t
call it on other controllers, basically</li>
</ul>
</li>
<li>remoteFromParentViewController

<ul>
<li>^^ ditto</li>
</ul>
</li>
<li>childViewControllers array</li>
<li>callbacks

<ul>
<li>willMoveToParentViewController</li>
<li>didMoveToParentViewController</li>
</ul>
</li>
</ul>


<p>Shouldn&#8217;t be able to walk up view hierarchy and totally skip over a
parent view controller: UIViewControllerHierarchyInconsistencyException,
prevents you from manually adding views into the wrong view controller
hierarchy.</p>

<p>When are appearance callbacks called?</p>

<p>viewWillAppear etc has nothing to do w addChildViewController, which has
nothing to do w view appearance.</p>

<p>viewWillAppear just means it&#8217;s in the window view hiearchy, but doesn&#8217;t
mean it&#8217;s actually visible (same w viewDidAppear).</p>

<p>TODO: what is view layoutSubviews?</p>

<p>viewDidAppear after the view added to viewHierarchy. Called after
layoutSubviews.</p>

<p>When implementing transitions, you have to implement
didTransitionToBlahBlah, one of the options is <code>animations</code> lambda.</p>

<p>VS Layout callbacks:</p>

<ul>
<li>viewWillLayoutSubviews&#8230;</li>
</ul>


<p>Presentation and Dismissal of VCs</p>

<p>set presentation style and then do presentViewController</p>

<p>Can also present VCs by direct subview manipulation.</p>

<pre><code>[root.someView addSubview: vc.view]
</code></pre>

<p>But this is bad form; better to make the VC a child of the root VC. VC
knows where subviews should go rather than the ass backwards way.</p>

<p>When to create a custom view controller container?</p>

<ul>
<li>Hopefully you don&#8217;t need to, so think twice first</li>
<li>Aesthetics</li>
<li>Custom app flows</li>
<li>Your app manipulates view hiearchy directly</li>
</ul>


<p>Use case: make split view show up in both landscape and portrait: no
need to make custom VC because now there&#8217;s API to just better configure
split view.</p>

<p>View controllers know themselves if they&#8217;re moving to or from parent
view controllers within viewWillAppear and viewDidAppear by checking:</p>

<pre><code>// used in viewDid/WillAppear
- (BOOL)isMovingToParentViewController;

// used in viewDid/WillDisappear
- (BOOL)isMovingFromParentViewController;

- isBeingPresented;
- isBeingDismissed;
</code></pre>

<p>Lol:</p>

<pre><code>- (BOOL) automaticallyForwardAppearanceAndRotationMethodsToChildViewControllers;
</code></pre>

<h2>RFC</h2>

<p>RFC&#8217;s (Request for Comments):</p>

<blockquote><p>Memos in the Requests for Comments (RFC) document series contain technical and organizational notes about the Internet</p></blockquote>

<p>http://www.ietf.org/about/</p>

<p>So many standards organizations. How am I supposed to keep this separate
from IEEE?</p>

<p>Anyway, RFCs are docs produced by IETF. I don&#8217;t think anyone else
(notable) produces docs called RFCs.</p>

<h2>Push Notifications</h2>

<p>Two levels of trust involved in publishing a push notifications:</p>

<h3>Connection Trust</h3>

<ul>
<li>Provider-side: provider proves it is an authorized provider that
Apple&#8217;s agreed to publish notifications for</li>
<li>Device-side: APNs must validate the connection is a with a legit
device</li>
</ul>


<h3>Token Trust</h3>

<p>Establishes certainty that messages are routed correctly; a provider
shouldn&#8217;t be able to send messages to random iPhones.</p>

<ul>
<li>APNs gives device a token</li>
<li>Devices gives it to provider</li>
<li>Provider uses it when publishing to APNs</li>
<li>APNs uses it to route back to device</li>
</ul>


<p>A <code>device token</code> is not a device <code>UDID</code>; aside from being a totally
different string, it is conceptually different in that it identifies not
only the unique device, but the application the Push Notification is
delivered to.</p>

<p>Maybe that&#8217;s what&#8217;s confusing: don&#8217;t call it a <code>device token</code>, call
it&#8230; an app-token? I get confused by the easiest things.</p>

<h3>Providers must maintain persistent connection</h3>

<p>If you want to send a notification through APNS (and GCM),
you must maintain a persistent connection to the server. In other words,
you can&#8217;t just connect-sendmessage-disconnect a la HTTP, which makes
push notifications inconvenient for Rails-y architectures without
using Sidekiq/Resque to reuse a persistent connection.</p>

<p>I both:</p>

<ol>
<li>failed to realize that this was a requirement for a while and</li>
<li>failed to understand why</li>
</ol>


<p>The best justification for this architecture that I can determine from
the docs and people I&#8217;ve talked to is that constantly
connecting/disconnecting to what is a high-performance, low-latency,
distributed system would be a colossal waste of resources and a latency
hit. An app capable of notifications is essentially a stream that APNS
consumes, and might be sending thousands of messages, so either way
they&#8217;d at least need to support a persistent connection for performance
reasons, and if they&#8217;re going to support that, why bother supporting
an obviously deficient connect/disconnect-based server interaction.</p>

<p>How many other services can be considered consumers of your stream?</p>

<h3>Service-to-Device Connection Trust</h3>

<p>Device identity is established via TLS peer-to-peer auth (internally;
iOS devs don&#8217;t need to implement this).</p>

<ul>
<li>Device TLS auths w APNs</li>
<li>APNs returns certificate, which it validates</li>
<li>Device sends device certificate to APNs</li>
<li>APNs valiates device certificate</li>
</ul>


<p>So I guess this prevents:</p>

<ul>
<li>an iPhone mimicker pretending to be something it&#8217;s not</li>
<li>an APNs ripoff pretending to be something it&#8217;s not</li>
</ul>


<h3>Provider-to-APNS connection trust</h3>

<p>Same process as above, just w provider (your server) and APNS.</p>

<p>A connection to APNs can only serve a single application, identified by
the topic (bundle ID) specified in the certificate, presumably the
one you generate in the online dev console. Also, APNs has a certificate
revocation list; if a provider is on that list, it&#8217;s connection will be
refused/closed. I think this would happen if you didn&#8217;t implement a
persistent connection to APNs but rather treated it like HTTP and kept
closing/opening the connection.</p>

<h3>Token Generation and Dispersal / token trust</h3>

<p>Jesus christ why don&#8217;t I just RTFM? It solves all the problems. Ah yes,
arm-chair ADD.</p>

<ul>
<li>Application asks system to register</li>
<li>System (iOS) forwards this to APNs</li>
<li>APNs generates device token using info in the certficate (presumably
the one established as described above) and encrypts it, and sends
back the encrypted token</li>
<li>App gets the encrypted key as an <code>NSData</code>, and must send it to the
provider in hexidecimal format</li>
</ul>


<p>This guarantees that only APNs generated the token used for routing
(since it&#8217;s encrypted by some private key within APNs). This token can
only be used for the device that originally connected to receive
notifications.</p>

<h3>Trust components</h3>

<p>e.g. keys/certificates you need to create/provide to APNs for all of
this shit to work:</p>

<ul>
<li><p>Provider</p>

<ul>
<li>unique provider certificate and private key for validating
connection to APNs</li>
<li>certificate identifies a topic that the provide can publish to (the
app&#8217;s bundle id).</li>
<li>Provider provides device token.</li>
<li>Provider can additionally validate that it&#8217;s talking to APNs using
the public server certificate provide&#8230; at connection time?</li>
</ul>
</li>
<li><p>Device</p>

<ul>
<li>obvious stuff already covered</li>
</ul>
</li>
</ul>


<p>Note: &#8220;topic&#8221; today is literally the bundle ID of the app. A certificate
identifies which apps it&#8217;s allowed to broadcast notifications to via
this topic. Maybe in the future, topics can refer to multiple apps?
Right now it&#8217;s coupled to bundle ID, in the future, this could be a
configurable thing&#8230; multiple apps could subscribe to the same topic?
This is all bullshit atm but what I think based on their terminology.
It&#8217;s really just a really constrained pub-sub, where apps can&#8217;t
subscribe to message channels other than the one that uniquely
identifies their app+device tuple.</p>

<h3>Coalescing</h3>

<p>APNs is last-write wins in that that in the case of multiple
notifications, only the last one will be stored-forwarded to the app.
This isn&#8217;t to say they coalesce within your device (validated by the
fact that you&#8217;ll see multiple messages from IRCCloud rather than a
single one saying &#8220;new messages available&#8221;), but specifically refers to
the storage of messages undeliverable because the client app&#8217;s turned
off. GCM gives you more fine-grained control over this.</p>

<h3>Summary</h3>

<p>So, given that I&#8217;ve been fighting this bullshit, realizations:</p>

<p>I need to stop revoking/re-creating the APNs app certificate generated
in the Apple Dev console. It&#8217;s not like it&#8217;s tied to some private/public
key or anything.</p>

<h2>Difference b/w .pem and .cer, etc</h2>

<p>I had to run this to convert .cer to .pem</p>

<pre><code>openssl x509 -in aps_development.cer -inform DER -out aps_development.pem
</code></pre>

<h3>X.509</h3>

<pre><code>http://en.wikipedia.org/wiki/X.509
</code></pre>

<p>X.509 is an ITU-T (Telecommunication Standardization Sector)
standard that describes certificate generation, revocation, and other
utilities. <code>openssl</code> just happens to support x509 certificate
generation.</p>

<p>Remember: x509 means one thing: certificates. If you see x509 in the
wild, it&#8217;s probably talking about certificates. x509 certificates.
Certificates.</p>

<p>x509 is unlike PGP in that it maintains a hierarchical chain of
certificate signers, each validated by the previous, with a root CA
(Certificate Authority) starting the chain. PGP relies (or at least
originally relied on) a Web of Trust.</p>

<h3>PEM</h3>

<p><code>---BEGIN CERTIFICATE---</code> and <code>---END CERTIFICATE---</code>.</p>

<p>Can contain multiple certificate and even the prviate key. &#8220;The private
key&#8221;? Which private key? Answer: the one that&#8217;s automatically generated
by Keychain Access and similar utilities when you create a Certificate
Signing Request (CSR).</p>

<p><a href="http://stackoverflow.com/a/7947362/914123">See here</a></p>

<p>TODO: can you even use an existing public/private key? Probably, but
possibly less secure:</p>

<p><a href="http://en.wikipedia.org/wiki/Certificate_signing_request">Read the wiki, you dingus</a></p>

<h2>PKCS</h2>

<p>(public key cryptography standards) created by RSA Security in the 90s.
It&#8217;s a family of standards relating to cryptography.</p>

<p>PCKS 1 is a standard, PCKS 9 is a standard, PCKS 12 is a standard.</p>

<p>Exporting multiple cryptography shits in a single file falls under the
PKCS 12 standard. PKCS 12 also handles bundling all the members of a
CHAIN OF TRUST.</p>

<blockquote><p>It is commonly used to bundle a private key with its X.509 certificate or to bundle all the members of a chain of trust.</p></blockquote>

<p>Makes sense, must be a common thing. Apple obviously does that. AWS SNS
expects you to upload a <code>.p12</code> that it splits into a cert and priv key.</p>

<p>File name extension is <code>.p12</code> (which I&#8217;ve seen) or <code>.pfx</code> which I&#8217;ve
not.</p>

<p><a href="http://en.wikipedia.org/wiki/PKCS_12">Wiki</a></p>

<p>So if I understand correctly, the purpose of certificate is so that you
can encrypt data, and anyone who wants to validate that you are who you
say you are can look up the certificate chain.</p>

<p>You create a pub/priv key pair, create a CSR with it, and then the
approving authority gives you a certificate that you can hand to other
people. The certificate can be used to validate that whatever you
encrypted with your (still unshared and totally) private key, can be
guaranteed to have originated from you. Without certification, you&#8217;re
just some entity with a pub/priv key pair&#8230; and&#8230; I don&#8217;t know, need
to read up more on the implications of this. Amazing how hard this stuff
is.</p>

<p>Anyway, <code>pkcs12</code> is the <code>openssl</code> file utility for creating/parsing
pkcs12 file.</p>

<h2><code>man</code> page sections</h2>

<p>Valid:</p>

<pre><code>man crontab
man 1 crontab # equiv to above
man -s 1 crontab # equiv to above
man 5 crontab 
man -s 5 crontab # equiv to above
</code></pre>

<p>Invalid:</p>

<pre><code>man 2 crontab # No entry for crontab in section 2 of the manual
man 3 crontab # ditto
man 4 crontab # ditto
</code></pre>

<p>Why would it have pages 1 and 5 but not 2-4?</p>

<p><a href="http://en.wikipedia.org/wiki/Man_page">Ahhhh!</a></p>

<p>Turns out there are sections (that vary by platform):</p>

<pre><code>1   General commands
2   System calls
3   Library functions, covering in particular the C standard library
4   Special files (usually devices, those found in /dev) and drivers
5   File formats and conventions
6   Games and screensavers
7   Miscellanea
8   System administration commands and daemons
</code></pre>

<p><code>crontab</code> has no system calls, lib fns, special files, but it does have
general commands and file formats.</p>

<p><code>man</code> isn&#8217;t just unix commands, but also lib, system calls, C functions,
etc.</p>

<p>These sections also handle cases when unrelated concepts have the same
name&#8230; there might be an <code>exit</code> C fn (there is) and an <code>exit</code> terminal
command.</p>

<p>This explains the wording here:</p>

<pre><code>No entry for printf in section 4 of the manual
</code></pre>

<p>You don&#8217;t look up the <code>printf</code> page, and then its section 4
subsection&#8230; rather, you look up entries in a section of <code>man</code>.</p>

<p>That&#8217;s the same reason it&#8217;s <code>man 3 printf</code> rather than <code>man printf 3</code></p>

<p>God, such an obvious thing I never understood/remembered.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/13/daily-journal/"/>
    <updated>2014-07-13T15:18:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/13/daily-journal</id>
    <content type="html"><![CDATA[<h2>HTML is an API, getAttribute</h2>

<p>HTML is just a string of characters that get converted into DOM. You can
also create DOM via the JavaScript DOM API. Seems like an obvious thing
I guess but it just clicked for me.</p>

<p>What&#8217;s an attribute? It&#8217;s any key-value pair (or occasional boolean)
within an open tag.</p>

<pre><code>&lt;div id="lol" snaggletooth="blorg"&gt;&lt;/div&gt;
</code></pre>

<p><code>id</code> and <code>snaggletooth</code> are attributes. During HTML parsing, the browser
will convert this isn&#8217;t an HTML element (which is a node). HTML elements
have a fixed set of <em>properties</em>. All the <em>attributes</em> you provide in
your HTML that map to known properties will set the values of those
properties, hence <code>.id</code> gets set to &#8220;lol&#8221;, but <code>.snaggletooth</code> would
yield <code>undefined</code>, because that&#8217;s obviously not a real property name.</p>

<p>http://jsbin.com/bejog/1/edit</p>

<p>This also explains why you can set an <code>&lt;input&gt;</code>&#8217;s value to &#8220;wat&#8221;, then
type in a new value in the input field, and <code>getAttribute("value")</code> will
still yield <code>"wat"</code> even though <code>inputElement.value</code> will equal whatever
you typed in.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/08/daily-journal/"/>
    <updated>2014-07-08T14:31:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/08/daily-journal</id>
    <content type="html"><![CDATA[<p>This blog left intentionally blank. There are flashcards about browser
networking attached to it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/05/daily-journal/"/>
    <updated>2014-07-05T16:44:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/05/daily-journal</id>
    <content type="html"><![CDATA[<h2>Bandwidth</h2>

<p>Grigorik&#8217;s book confused me when he switched from the bits/second
definition of bandwidth to the more signal processing definition.</p>

<pre><code>http://en.wikipedia.org/wiki/Bandwidth_(computing)
vs
http://en.wikipedia.org/wiki/Bandwidth_(signal_processing)
</code></pre>

<p>Computing bandwidth refers to bits/s. Signal bandwidth is the difference
in the max and min Hz that you transmit on.</p>

<p>This is interesting:</p>

<blockquote><p>A key characteristic of bandwidth is that any band of a given width can
carry the same amount of information, regardless of where that band is
located in the frequency spectrum. For example, a 3 kHz band
can carry a telephone conversation whether that band is at baseband
(as in a POTS telephone line) or modulated to some higher frequency.</p></blockquote>

<p>My understanding of this is that regardless of the modulation alphabet
you use, modulation will always cause a signal to vary between a
minimumm and maximum frequency, which determines the bandwidth of a
signal. For example, transmitting a &#8220;01&#8221; might mean squeezing the waves
together tightly until the next &#8220;letter&#8221; to transmit, and the tightest
those waves are squeezed determines the maximum frequency, while &#8220;10&#8221;
might might loosening the waves, and other letters could be some
combination of the two, but the key thing here is that bandwidth
determines the min and max frequencies that those waves can compress
or expand to; any more and you might be interfering with someone else&#8217;s
band.</p>

<!-- more -->


<p>And as to the ability to transmit the same amount of information, I
don&#8217;t understand that; I&#8217;ll have to read up on that a bit more.</p>

<h2>allocWithZone</h2>

<p>Cocoa&#8217;s <code>alloc</code> method calls <code>allocWithZone</code> zone with some sensible
default. The whole point of <code>allocWithZone</code> is to allow you to
explicitly specify which memory zone an object lives in, allowing you to
put related objects into the same zone so as to avoid thrashing.</p>

<p>NOTE: <code>allocWithZone</code> is old school, and as memory becomes cheap and
approaches to memory management improve, the zone passed in becomes
ignored, particularly with ARC.</p>

<p>Also, if any instance vars need to be <code>alloc</code>d, they should be done
within the same zone, or else you&#8217;re defeating the whole purpose of zone
allocation (then again, ARC ignores this, so&#8230;). Anyway, you can do
things like <code>self.label = [[NSString allocFromZone:[self zone]] initWithString:@"balls"]</code></p>

<h2>Designated Initializer</h2>

<p>In Cocoa, the designated initializer is the one initializer in a class
that all others defer to perform the full initialization of an object.
As such, it&#8217;s usually the one with the most arguments, and other
initializers will usually choose sensible defaults to pass to the
designated initializer.</p>

<p>Designated Initializers in subclasses must call the Designated
Initializers in its superclass.</p>

<p>NOTE: sometimes a class might have multiple Designated Initializers,
e.g. NSCell.</p>

<p>Drawback: having to know what the Designated Initializer is for a given
class&#8230; yeah, that sucks.</p>

<h2>Two-Stage Creation</h2>

<p>e.g. <code>[[Thing alloc] init]</code></p>

<ol>
<li>Assign implicit <code>self</code> local var to <code>[super init]</code>, which might
return something other than <code>self</code> where alloc fails or singleton
pattern returns another instance.</li>
<li>If <code>self</code> not nil, continue to perform initialization.</li>
</ol>


<p>Step 2 is extremely defensive and possibly overkill, but nil is a valid
return value for initializers so you have to watch out for it. Aren&#8217;t
nils awesome?</p>

<h2><code>self</code> and <code>cmd</code></h2>

<p>These are the two implicit variables provided within a method
invocation.</p>

<ol>
<li><code>self</code> is the instance, durr</li>
<li><code>_cmd</code> is the message received that caused the method to be run</li>
</ol>


<p>Question: what happens if you don&#8217;t assign <code>self</code>? Does it actually make
a difference outside of the method? Is it a reference or just a value
used within the method?</p>

<h2>ARC</h2>

<p>Automatic Reference Counting: been around since Mac OS X 10.5, but if
you&#8217;re writing a class with ARC, all consumers must also be using ARC
(but it&#8217;s possible for ARC to consume non-ARC). Hence, it&#8217;s important to
understand old school memory management.</p>

<h2><code>dealloc</code> and <code>finalize</code></h2>

<p>No-ARC:</p>

<p><code>dealloc</code> called automatically (don&#8217;t call it yourself) when reference count down
to 0.</p>

<p>ARC:</p>

<p><code>finalize</code> called instead of <code>dealloc</code>, but often doesn&#8217;t need to be
implemented unless any non-ARC objects were alloc&#8217;d that need to be
manually released, or some file handles need to be closed, etc.</p>

<h2><code>stringWithString</code> vs <code>[alloc] initWithString</code></h2>

<p><code>autorelease</code> is called within these convenience methods like
<code>stringWithString</code>, but not called with the <code>alloc</code> + <code>init</code> pattern.
<code>autorelease</code> is often idiomatically meant for temporary vars.
You must call <code>retain</code> on something that&#8217;s autoreleased if you want to
hold on to it.</p>

<p>One drawback to the convenience methods is that their allocation is
hard-wired to their initialization; you can&#8217;t swap the approach to
allocation, or pick zones or anything like that.</p>

<h2><code>drawRect</code> and <code>setNeedsDisplay</code></h2>

<p><code>drawRect</code> is a template method which you&#8217;re never supposed to call
yourself; if you&#8217;re tempted to use it, chances are you want
<code>setNeedsDisplay</code> instead.</p>

<h2>Template Methods vs Delagate</h2>

<p>Template Methods as an approach to customizing/overriding a super
class&#8217;s default behavior in a subclass result in tight coupling to the
super class. Also, if you need to override lots of different unrelated
behaviors in a superclass, likely the super class should have been
designed to use Delegates instead.</p>

<h2><code>NSClassFromString</code> =~ <code>const_get</code></h2>

<p>Objective-C&#8217;s runtime supports class lookup from strings via
<code>NSClassFromString</code>. I had no idea. And like in Ruby, Objective C
classes are objects as well.</p>

<h2>NSBundle</h2>

<p>Makes use of NSClassFromString (or some variety of it?) to look up
classes in a bundle. Can either use <code>+classNamed</code> if you know the class,
or <code>+principalClass</code>, which uses the class defined in the Bundle&#8217;s
plist.</p>

<h2>Obj-C Categories =~ <code>reopen</code></h2>

<pre><code>@interface Horseshit (SomeCategory)
- (void)newMethod;
@end

@implementation Horseshit (SomeCategory)
- (void)newMethod
{
  // stuff
}
@end
</code></pre>

<p>This can be used to reopen classes, which, like <code>Module#reopen</code> in Ruby,
is inherited by subclasses as well.</p>

<p>This is familiar:</p>

<blockquote><p>but there is no good way to force exist- ing compiled code to
return instances of your subclass instead of instances of NSMutableArray.</p></blockquote>

<p>The same gotcha is true for Ruby, where you can&#8217;t trivially subclass
<code>Array</code> without running into the often undesirable behavior of methodsl
like <code>#map</code> returning an instance of <code>Array</code>, rather than your subclass.</p>

<p>The Ruby approach to this (credit to Avdi Grimm), is something like</p>

<pre><code>require 'forwardable'
class MyArray
  include Enumerable
  extend Forwardable

  def initialize
    @a = []
  end

  def_delegators :@a, :each, :&lt;&lt;
end

a = MyArray.new
a &lt;&lt; 123
a.map { |i| i*2 } # =&gt; [246] # works because Enumerable#map uses #each
</code></pre>

<p>But in the case of <code>NSMutableArray</code>, since you&#8217;d have to override a
great many methods in a subclass of <code>NSMutableArray</code> to return instances
of your subclass, it might just make more sense to reopen
<code>NSMutableArray</code> by declaring a new category, and just throw methods
onto that; that way, these methods will still return their hard-wired
<code>NSMutableArray</code> instances, but they&#8217;ll have the new methods that you
were tempted to put on an <code>NSMutableArray</code> subclass. A little sucky but
hey that&#8217;s framework code.</p>

<h3>Categories for Framework Division</h3>

<p>Kinda like how Ember progressively reopens ControllerMixin and other
classes in the various <code>ember-xxx</code> libraries that get combined into the
final complete Ember package, Cocoa uses categories to &#8220;reopen&#8221; certain
classes as libraries/frameworks are added. For instance,
<code>NSAttributedString</code> exists in Cocoa Foundation and can be used in
non-graphical contexts, but once Application Kit is added, categories
that included string-drawing logic are added to <code>NSAttributedString</code>.</p>

<p>Reserving judgement as to whether it makes sense to keep dumping code
into <code>NSAttributedString</code> vs adding utility classes that know how to
draw <code>NSAttributedString</code>s.</p>

<h2>(Informal) Protocols</h2>

<p>A formal protocol, or just protocol, is a language construct in Obj-C
that is used to declare methods than an object must implement in order
to work in certain scenarios. The compiler can guarantee that a protocol
is adhered to and will throw errors (warnings?) if not.</p>

<p>An <em>informal protocol</em> is a protocol where no compiler time checks are
made to make sure an object/class actually implements the methods in the
informal protocol. Informal protocols are implemented as categories of
<code>NSObject</code> (which means virtually all classes inherit those informal
protocol methods), but Cocoa will often only provide an interface to
these categories, but no implementation; the compiler doesn&#8217;t check
this, so lots of Cocoa classes use runtime checks to see if these
methods have been implemented on an object before sending such a
message.</p>

<p>One of the crappiest parts about informal protocols is that you have to
know, when subclassing, whether a super class provides an implementation
of an informal protocol method. If you just do <code>[super method]</code> and
<code>method</code> doesn&#8217;t exist, then boom. The safest way around this if you
don&#8217;t have the original source code is a run-time check, a la</p>

<pre><code>if ([Superclass instancesRespondToSelector:@selector(method)]) {
  [super method];
}
// more crap
</code></pre>

<p>Additionally, you could just stub out all the methods that Apple
&#8220;forgot&#8221; to implement via a new NSObject category, but this</p>

<ol>
<li>Overrides the method definitions for classes that <em>do</em> provide an
implementation</li>
<li>Might interfere with runtime logic that checks if a method is
implemented and performs some additional logic if it is.</li>
</ol>


<p>But mean that just seems to scream with mega design flaws.
Tell-don&#8217;t-ask, much?</p>

<blockquote><p>it’s a best practice to provide a default implementation for each
method you declare in your informal protocol.</p></blockquote>

<p>If that&#8217;s the case, then why not just do a normal ol category? Answer:
because the key difference w informal protocols is that they&#8217;re declared
on <code>NSObject</code>, so any object/class has the option of providing it.</p>

<p>Note that Obj-C 2.0 (Mac OS X 10.5) provides <code>@required</code> and <code>@optional</code>
keywords in plain ol protocols to allow informal protocol semantics on
formal protocols.</p>

<h2>Category (and reopen) gotchas</h2>

<ol>
<li>Collisions are more likely when reopening is the norm</li>
<li>Apple (or whatever vendor) might add methods in future versions that
clash with the ones you&#8217;ve added</li>
<li>Replacing methods means you have to be very careful to duplicate all
of the effects of a method (but why do methods have so much logic in
them in the first place?). Replacing should kinda be a last resort.</li>
</ol>


<p>If you&#8217;re going to extend Cocoa classes, it&#8217;s wise to use a prefix.</p>

<p>One nice convention is when you&#8217;re extending NSArray with your custom
Wat category, you could throw it in a file named <code>NSArray+Wat.h</code>.</p>

<h2>Anonymous type: <code>id</code></h2>

<p>Unlike C++ and Java (et al), knowing the receiver type of a message is
not a requirement and can be deferred until runtime. This supports duck
typing. Bark bark.</p>

<p>Selectors can be dynamically constructed from strings as run-time. (But
beware of standard security issues surrounding code injection.)</p>

<p><code>id</code> as a type says nothing more than &#8220;this object can receive
messages&#8221;. An <code>id</code> var can point to <code>nil</code> (as opposed to <code>NULL</code>), which
evaluates to zero. Also, sending messages to <code>nil</code> is NOT an error, and
returns <code>nil</code>.</p>

<p><code>id</code> can be an alternative to forward class declaration, but obviously
the tradeoff is that you&#8217;re giving the compiler less information to use
for catching errors/typos.</p>

<p>Unrecognized messages/methods are warnings rather than errors because
sometimes the compiler cannot guarantee that the object definitely
cannot respond to a message.</p>

<p>Two ways to do a runtime check to see if an object/class responds to a
selector:</p>

<pre><code>[SomeClass instancesRespondToSelector:@selector(method)]
[instance respondsToSelector:(SEL)aSelector]
</code></pre>

<p>Check if an <code>id</code> is an instance of some class via</p>

<pre><code>[someIdVar isKindOfClass:[NSArray class]]
</code></pre>

<p>What about <code>nil</code>? I guess it&#8217;ll always return falsy (<code>nil</code>) for all
selectors, so <code>isKindOfClass</code> would correctly return falsy.</p>

<p>There is also a <code>conformsToProtocol</code> selector. In addition to a
<code>NSObject</code> class, there is an <code>NSObject</code> protocol&#8230; why? How is it
useful? Dunno.</p>

<p>You can use anonymous types scoped to protocols so that you can get all
those lovely compiler warnings you expect, e.g.:</p>

<pre><code>id &lt;MyDumbProtocol&gt; wat = something;
[wat someMessage]
</code></pre>

<p>If you catch yourself doing this a bunch:</p>

<pre><code>id &lt;MyDumbProtocol, NSObject&gt; woot;
</code></pre>

<p>then maybe consider having MyDumbProtocol inherit from NSObject.</p>

<p>Of note: the presence of an anonymous type prevents the need for generic
programming features, like C++ templates. Then again you could just
store everything as a void pointer, right? But then in C++ you have to
do address translation in some cases. I think. I forget.</p>

<h2>NSEnumerator</h2>

<p>Simple interface:</p>

<ul>
<li>nextObject: call until nil</li>
<li>allObjects: returns an array of all remaining untraversed items;
nextObject guaranteed to be nil after calling this</li>
</ul>


<p>NSEnumerators retain the underlying container until traversal is
complete so that it&#8217;s not dealloc&#8217;d mid-traversal.</p>

<p>Unsafe to modify collection mid-traversal.</p>

<p>Common example:</p>

<pre><code>id instance;
NSEnumerator *enumerator = [myCollection objectEnumerator]; while (instance = [enumerator nextObject])
{
  // do something with instance 
}
</code></pre>

<p>Fast enumeration:</p>

<pre><code>id instance;
for (instance in myCollection) {
  // do something with instance 
}
// or, alternatively:
for (id instance2 in myCollection) {
  // do something with instance2 
}
</code></pre>

<p>An object needs to support Fast Enumeration to be used in a for-in loop.
Enumerators themselves support fast enumeration, so you can do:</p>

<pre><code>id instance;
for (instance in [myArrayInstance reverseObjectEnumerator]) {
  // do something with instance 
}
</code></pre>

<p>Internal Enumeration is like <code>each</code> in Ruby, where the iteration is
internal to the collection or enumerator. Cocoa offers:</p>

<pre><code>- (void)makeObjectsPerformSelector:(SEL)aSelector
- (void)makeObjectsPerformSelector:(SEL)aSelector withObject:(id)anObject
</code></pre>

<h2>Objective-C runtime files</h2>

<p>Explore <code>/usr/include/objc/*.h</code> for fun and profit.</p>

<h2>Selectors</h2>

<pre><code>SEL aSelector = @selector(myDumbMethod);
</code></pre>

<p>NSObject has the following method for running <code>aSelector</code> later:</p>

<pre><code>-(id)performSelector:(SEL)aSelector
</code></pre>

<p>Interchangeable:</p>

<pre><code>id result1 = [someObject update];
id result2 = [someObject performSelector:@selector(update)];
id result3 = [someObject performSelector:aSelector];
</code></pre>

<p>Get a SEL from a String:</p>

<pre><code>SEL NSSelectorFromString(NSString *)
</code></pre>

<p>Passing an arg to performSelector</p>

<pre><code>- (id)performSelector:(SEL)aSelector withObject:(id)anObject
</code></pre>

<p>Need to use NSInvocation if</p>

<ul>
<li>more than one arg</li>
<li>non object arg</li>
<li>returns non-object value</li>
</ul>


<p>Perform a method async&#8230;?</p>

<pre><code>- (void)performSelector:(SEL)aSelector withObject:(id)anArgument afterDelay:(NSTimeInterval)delay
</code></pre>

<p>This schedules the event to fire via NSRunLoop, which only guarantees
that it won&#8217;t fire before <code>delay</code>, but you might catch it mid slow
operation and it won&#8217;t fire til after that&#8217;s done. Obvious parallels to
Ember&#8217;s Backburner.js.</p>

<p>Async performs are cancelable via <code>cancelPreviousPerformRequestsWithTarget</code>.</p>

<p><code>NSRunLoop</code> runs in different modes which govern which sources of input
are read by the loop; async schedules are put in to <code>NSDefaultRunLoopMode</code>, and
the run loop might not be in that mode, which would cause that to be
ignored. Interesting, will need to follow up on that. Maybe that&#8217;s
because there are different threads? And you can set up the different
threads to listen for different events? And a performSelector afterDelay
is just like any other events, like user tapped something, etc.</p>

<h2>Implementation of Obj-C message sending</h2>

<p>First off, a <code>runtime</code> is any collection of functions/functionality that
comes with the compiled language and is depended upon to perform certain
tasks at runtime. That was a shitty definition. A runtime is any
collection of functionality you need at runtime that comes with the
language you&#8217;re using. Handlebars has a runtime; even though your
templates are precompiled, they all depend on shared functionality that
lives within the Handlebars runtime that must be present to actually
render a template. I knew that, kinda, but it just clicked as a generic
concept. JVM is a runtime. C++ has a runtime.</p>

<p>Two most important C functions:</p>

<pre><code>id objc_msgSend(id self, SEL op, ...);
id objc_msgSendSuper(struct objc_super *super, SEL op, ...);
</code></pre>

<p>These fns search for a handling method on the receiver.</p>

<p>Here&#8217;s the typedef for a C function pointer of a method that responds to
a selector:</p>

<pre><code>typedef id (*IMP)(id self, SEL _cmd, ...);
// e.g.:
IMP fn = &amp;someFn;
// i think this is valid C, I forget.
</code></pre>

<p>The search for the method on the receiver is slow, but the result is
cached on the receiver class so future lookups are fast.</p>

<p>You can convert a message send into a C fn pointer via:</p>

<pre><code>- (IMP)methodForSelector:(SEL)aSelector;
+ (IMP)instanceMethodForSelector:(SEL)aSelector;
</code></pre>

<p>The late binding provided by all of the above makes it possible for
other threads to schedule operations on the main thread via super
convenient methods like</p>

<pre><code>- (void)performSelectorOnMainThread:(SEL)aSelector withObject:(id)arg waitUntilDone:(BOOL)wait
- (void)performSelectorOnMainThread:(SEL)aSelector withObject:(id)arg waitUntilDone:(BOOL)wait modes:(NSArray * )array
</code></pre>

<h2>Accessors</h2>

<p>Some obvious general benefits mixed w Cocoa-specific:</p>

<ul>
<li>Uniform access principle: flexibility to switch from simple instance
variable storage to some other complex logic. In Ember this like how
you can effortlessly switch between a raw value property and a
computed property and any consuming code won&#8217;t need to change if it
has been using <code>.get()</code> from the start.</li>
<li>Facilitate Cocoa&#8217;s non-ARC memory maintenance</li>
<li>Facilitate Cocoa Key-value coding and observation</li>
<li>Facilitate special logic when (re)-connecting Interface Builder outlets.</li>
</ul>


<p>Naming conventions: if you&#8217;re returning a value, just name the getter
the name of the property (i.e. not prefixed with &#8220;get&#8221;):</p>

<pre><code>- (float) interestRate 
{
  return interestRate;
}
</code></pre>

<p>If you&#8217;re returning by reference (via pointers), prefix with get:</p>

<pre><code>- (void)getInterestRate:(float * )aFloatPtr {
  if(NULL != aFloatPtr) {
    *aFloatPtr = interestRate; 
  }
}
</code></pre>

<p>Apparently this is seldom-used, hence there&#8217;s not many <code>get</code> methods in
Cocoa, but common in some cases where size of array returned is not
known ahead of time, or there are more than one &#8220;return&#8221; values, e.g.:</p>

<pre><code>-(void)getRed:(CGFloat *)red green:(CGFloat *)green blue:(CGFloat *)blue alpha:(CGFloat *)alpha
</code></pre>

<p>Setters are obviously prefixed by set</p>

<pre><code>- (void)setInterestRate:(float)aRate 
{
  interestRate = aRate; 
}
</code></pre>

<p>They make a good point about debugging utility:</p>

<blockquote><p>During debugging, if a property has an incorrect or suspicious value,
a debugger break-point set within the implementation of an accessor
halts execution whenever the property is changed and helps track
down how and why the value is being changed incorrectly.</p></blockquote>

<p>This isn&#8217;t super easy to do in Ember as a general capability unless it&#8217;s
one of the rare cases where you&#8217;re writing a getter-setter computed
property&#8230; maybe we can do something in ember-inspector that hooks into
ember-metal?</p>

<h2>Thread safety + Memory Management</h2>

<p>Thread safety w memory management: consider the following:</p>

<pre><code>- (NSString * ) aString {
  return _myString ;
}
</code></pre>

<p>An obvious getter that returns an NSString instance var. But lets say
there are two threads, where Thread A is retrieving <code>aString</code> and
intends to <code>retain</code> it, and Thread B releases the object that <code>aString</code>
lives on, thus causing it to be deallocated. In this case, there&#8217;s a
race condition in multi-threaded environments:</p>

<pre><code>A: NSString * str = [alexObject aString];
B: [alexObject release]; 
B: // ref count is now 0, dealloc occurs
B: // _myString gets `release`d and dealloc'd because ref count is 0
A: [str retain];
A: // BOOM. can't `retain` a dealloc'd obj
</code></pre>

<p>Realization: the &#8220;intending to <em>retain</em>&#8221; distinction isn&#8217;t so important;
more important is &#8220;intending to use in any way&#8221;; sending a message to a
suddenly dealloc&#8217;d obj is going to break, it&#8217;s just that the obvious way
to prevent dealloc is to immediately <code>retain</code> the return value of a
getter, but then you&#8217;re still exposed to the race condition above. So
the retain needs to happen in the getter, a la:</p>

<pre><code>- (NSString * )title {
  id result;

  // Lock
  result = [[_myTitle retain] autorelease];
  // Unlock

  return result; 
}
</code></pre>

<p>Makes sense, but I need to learn about when autorelease actually fires
its release&#8230; this would cause issues if the autorelease just happened
at the end of a thread&#8217;s run loop, since another thread might not have
had time to use/retain an obj before the other thread released it at the
end of its run loop. AH CRUCIAL MISTAKE: I was some reason thinking that
the getting would happen in one thread and that retaining of that return
value would happen in another thread; no, all of that happens on one
thread, and autorelease, assuming my assumptions about the run loop are
correct, will always correctly fire after the code that called the
getter had a chance to use/retain its return value.</p>

<p>So actually, it sounds like consumers of getters don&#8217;t need to call
<code>retain</code> unless they really intend to hold on to that value beyond the
end of the run loop.</p>

<pre><code>- (void)setTitle:(NSString * ) aTitle {
 ￼[aTitle retain];
</code></pre>

<p>  ￼￼￼￼[ _myTitle release];</p>

<pre><code>  _myTitle = aTitle; 
}
</code></pre>

<p>So if you had no locks on the above getters and setters, there&#8217;d be a
race condition where <code>[_myTitle release]</code> and <code>[_myTitle retain]</code> are
called at the same time, release happens first, and then <code>retain</code> gets
called on a dealloc&#8217;d my obj. So really you&#8217;d need</p>

<pre><code>- (void)setTitle:(NSString * ) aTitle {
 ￼[aTitle retain];

  // Lock
</code></pre>

<p>  ￼￼￼￼[ _myTitle release];</p>

<pre><code>  _myTitle = aTitle; 
  // Unlock
}
</code></pre>

<p>The above handles all the following cases:</p>

<ul>
<li>changing a value from nil to aTitle</li>
<li>changing a value from somethingElse to aTitle</li>
<li>changing a value from aTitle to aTitle</li>
<li>changing a value from somethingElse to nil</li>
<li>changing a value from nil to nil</li>
</ul>


<p>This is due to the precise ordering of retains/release and assignment,
as well as the fact that sending messages to <code>nil</code> is harmless so long
as you don&#8217;t count on the return value.</p>

<p>Hmm, I&#8217;m told that the following is actually the correct answer, but I&#8217;m
not sure why:</p>

<pre><code>- (void)setTitle:(NSString * )aTitle {
  id oldValue; 
  [aTitle retain];

  // Lock
  oldValue = _myTitle; 
  _myTitle = aTitle; 
  // Unlock

  [oldValue release]; 
}
</code></pre>

<h2>NSKeyValueCoding</h2>

<p>An informal protocol. Allows properties to be read/written by string
name.</p>

<h2>Archiving / Unarchiving</h2>

<p>Objects can be (de)serialized into a binary format (or XML) and back,
and Cocoa handles all the issues of cross-platform byte ordering and 32
vs 64 bit, etc, issues that normally crop up when you try to store in
binary (apparently though it doesn&#8217;t have to handle big/little-endian
issues?).</p>

<p>When Archiving, an object can conditionally or unconditionally
reference another obj; if unconditional, force the object to be stored;
if conditional, only store the object if something else has declared it
as unconditional, and if not, when unarchived, that object will be
<code>nil</code>.</p>

<p>So in Cocoa, a View knows about its subviews, but little to nothing about
its parent view, so it conditionally references its parentView, and
unconditionally references child views.</p>

<p>To archive an object:</p>

<pre><code>[NSKeyedArchiver archivedDataWithRootObject:someObject];
+(NSData *)archivedDataWithRootObject:(id)rootObject
</code></pre>

<p><code>rootObject</code> conforms to <code>NSCoding</code> protocol, and is sent a message to
unconditionally archive itself, causing the chain reaction that
ultimately archives the whole thing and returns <code>NSData</code> that can be
written to a file.</p>

<p><code>NSUserDefaults</code> is the standard way of storing user preferences, but
it only supports storing <code>NSData</code>, <code>NSString</code>, and a few others&#8230; how
to encode something like an <code>NSColor</code>? Answer: &#8220;reopen&#8221; <code>NSUserDefaults</code>
by adding a custom category to it that defines <code>setColor</code> and
<code>colorForKey</code> to use <code>NSKeyedArchiver</code> to archive and unarchive to the
color to and from an <code>NSData</code>, which <em>can</em> be stored in UserDefaults.</p>

<p>To implement <code>NSCoder</code> protocol, implement:</p>

<pre><code>- (void)encodeWithCoder:(NSCoder * )coder
- (id)initWithCoder:(NSCoder * )
</code></pre>

<p>To encode/decode arbitrary C structs/unions:</p>

<blockquote><p>Either wrap the unsupported data types in objects that conform to the
NSCoding protocol and then encode those objects, or break the data
types down to supported components like int and float and encode
the individual components.</p></blockquote>

<p>Cocoa supports object substitution when encoding. I don&#8217;t know what it&#8217;s
used for, need to research more.</p>

<p><code>-awakeFromNib</code> is almost like a <code>didInsertElement</code>, or rather an
<code>afterRender</code> callback called on an object after all the objects in the
archive have been unpacked, so you have the guarantee when the hook is
called that all <code>IBOutlet</code>s are connected.</p>

<p>&#8220;Simulation&#8221; mode in Interface Builder encodes and decodes all objects
to simulate the real thang.</p>

<p>A <code>.nib</code> specificies a File Owner that will &#8220;own&#8221; the objects decoded
from the <code>.nib</code>. The owner object also receives an <code>awakeFromNib</code>
anytime a <code>.nib</code> is unarchived with that file as the owner. Obviously
this means you can associate a <code>.nib</code> with whichever owner you want (not
sure if you can do this dynamically?), and a single owner can own (be
associated with) multiple <code>.nib</code>s. That&#8217;s kinda rad.</p>

<h2>Copying</h2>

<p>Some things don&#8217;t make sense to be copied, like singletons e.g.
<code>NSApplication</code>, which is meant to contain a single connection to OS X&#8217;s
Quartz window server.</p>

<p><code>NSCopying</code> in Cocoa is meant to produce shallow copies. One approach
for deep copies, if everything adheres to <code>NSCoding</code> protocol, is to
archive and then unarchive.</p>

<p>On mutability: Cocoa provides lots of immutable classes, like <code>NSString</code>
and <code>NSArray</code>. Why? Issues surrounding concurrency come to mind, e.g. if
you can only create new modifies versions of a string rather than
modify the string, then threads will each have their own copies of
strings to fart around with rather than have to manage complex locking
procedures when making changes to the thing.</p>

<p>But the other thing to realize is that immutable objects can be shared,
and passed by reference without fear of someone mucking with them.
Multiple objects can &#8220;own&#8221; the same immutable object. Maybe this will
help me remember:</p>

<blockquote><p>Everyone owns immutable objects</p></blockquote>

<p>or</p>

<blockquote><p>There is no tragedy of the commons with immutable objects</p></blockquote>

<p><code>NSCopying</code> returns immutable copies, but there&#8217;s also
<code>NSMutableCopying</code>.</p>

<p>If you&#8217;re implementing copy on an immutable object, it&#8217;s as easy as:</p>

<pre><code>- (id)copyWithZone:(NSZone * )aZone 
{
  return [self retain]; 
}
</code></pre>

<p>Optimal as fuck.</p>

<p>There is no formal <code>NSDeepCopying</code> protocol, but you can make your own
<code>deepCopy</code> method using Archiving and Unarchiving.</p>

<p><code>NSDictionary</code> copies objects used as keys, so those need to conform to
<code>NSCopying</code>.</p>

<p>In Obj-C 2.0, it&#8217;s common to have a public interface with <code>readonly</code>
properties, only to have an anonymous category class extension redefine
them as <code>readwrite</code> so that they are mutable within the implementation
but immutable to the public.</p>

<blockquote><p>The compiler allows redeclarations to replace readonly with readwrite,
but no other attributes of the property can be changed in a redeclaration.</p></blockquote>

<p>So you could change something from</p>

<pre><code>@property (readonly, retain) NSString *word;
</code></pre>

<p>to</p>

<pre><code>@property (readwrite, retain) NSString *word;
</code></pre>

<p><code>retain</code> means setters retain their args rather than copy them.</p>

<p>Note that <code>assign</code> is the default among <code>assign</code>, <code>copy</code>, or <code>retain</code>,
so the following are equivalent:</p>

<pre><code>@property (readonly, assign)
@property (readonly)
</code></pre>

<p>But the Obj-C 2.0 compiler will warn you if you use the default <code>assign</code> for a
property that adheres to <code>NSCopying</code>.</p>

<h2>Strong and Weak pointers</h2>

<p>Obj-C 2.0 supports <code>__strong</code> and <code>__weak</code> pointers. Presumably that
means <code>__strong</code> pointers can &#8220;own&#8221; the referenced object and increase
its retain count, while <code>__weak</code> pointer can only refer to an object but
have no ownership. It probably circumvents cycles. And it probably
implies that there&#8217;s no mark and sweep phase? Is that true? There&#8217;s no
weak reference in JavaScript, but maybe there&#8217;s some other use case.
Mark and Sweep gets rid of the need for strong and weak pointers in the
case of handling circular dependencies, but are there use cases beyond
that? I guess there are, if you want to say &#8220;let this weak pointer
reference this thing that might disappear at any point.&#8221; That could
exist even if mark and sweep were used&#8230; right? Yeah, it could. It just
means that the sweeper wouldn&#8217;t traverse weak pointers.</p>

<p>So weak pointers can make sense in mark and sweep or reference counting.</p>

<p>But mark and sweep is better at cycles and don&#8217;t require manual cycle
breaking before garbage can be collected.</p>

<h2>Singletons</h2>

<p>Given Obj-C classes are objects, why use instances over class objects?</p>

<p>Answer: rewriting all the references to the superclass when you
subclass. Class object or no, you&#8217;re treating it as an instance, and
tightly coupling to that instance. Also, I don&#8217;t really know enough
about how class objects work, but can you also inherit/override methods
with class objects the same way? Well, you can&#8217;t store a pointer to a
class object without it looking really weird, right? Like:</p>

<pre><code>id foo = [NSObject class];
[foo classMethod];
</code></pre>

<p>Is there a more specific type than <code>id</code> that lets you store classes?
Dunno. Point is: you could get in the habit of storing pointers to class
objects but using the factory pattern to avoid initializing them, and so
long as the interface the same you would have maintained loose coupling.
But this is no different than just saying Obj-C supports duck-typing so
your factory could return anything that conforms to whatever
informal informal protocol you&#8217;re conforming to.</p>

<p>So to sum it up: the main reason not to do this is it becomes really
really confusing what you&#8217;re trying to accomplish and subclassing
becomes extremely convoluted.</p>

<p>The Cocoa pattern is to have a class object encapsulate access to the
singleton instance and have the singleton encapsulate all the stuff
unique to what that object is doing. Derp.</p>

<p><code>+sharedInstance</code> is usually the name of the singleton accessor.</p>

<pre><code>+ (MySingleton * )sharedInstance {
  static MySingleton *myInstance = nil; 
  if (!myInstance) {
    myInstance = [[[self class] alloc] init];
  }
 ￼return myInstance; 
}
</code></pre>

<p>Note the <code>[[self class] alloc]</code>, rather than <code>[MySingleton alloc]</code>. This
lets you subclass and defer the alloc to which subclass you&#8217;re using it.
You can choose the subclass that locks in in an app ready hook by doing</p>

<pre><code>[MySingletonSubclass sharedInstance];
</code></pre>

<p>But you&#8217;d have to be careful that this ran before anyone else called
<code>[MySingleton sharedInstance]</code>, which is the API anywhere else in your
code. This parallels to Ember requiring that you&#8217;ve registered/injected
everything before your first lookup. Both feel kinda jank.</p>

<p>Also, obviously this won&#8217;t work for <code>NSApplication</code> singleton because
it&#8217;s created before your code even runs; to handle that, you have to set
the Principal Class in the XCode info panel when the application target
is selected, whatever that means. This actually writes through to the
Info.plist file. You could rewrite the above code to similarly look up
<code>infoDictionary</code> in <code>mainBundle</code> and choose which class to init.</p>

<p>Prediction: this code isn&#8217;t thread-safe, right?</p>

<pre><code>Thread A: [MySingleton sharedInstance]
          if (!myInstance) {
Thread B: [MySingleton sharedInstance]
          if (!myInstance) {
            myInstance = ALLOC INIT STUFF;
Thread A:   myInstance = ALLOC INIT STUFF;
</code></pre>

<p>Boom. Needs moar mutex.</p>

<p>There&#8217;s also <code>alloc</code> and <code>allocWithZone</code> and a bunch of others and use a
<code>hiddenAlloc</code> not defined in the public interface. It&#8217;s really messy and
error-prone. Kinda like a lot of Cocoa?</p>

<p>But if you&#8217;re using a singleton in Interface Builder (I guess this just
means referencing it as a File Owner?) you have to preserve normal alloc
and init semantics, so you end up having <code>alloc</code> return sharedInstance
and adding code to <code>init</code> to make sure it only inits once.</p>

<p>Singleton examples:</p>

<ul>
<li><code>NSApplication</code>: maintains Quartz window server connection. Apparently
it receives and distributes events via First Responder pattern. That&#8217;s
rad. Event delegation, or something else? What does it mean?</li>
<li><code>NSWorkStation</code>: encapsulates connection to Finder and underlying file
system</li>
<li><code>NSFontManager</code>: maintains per-font singleton flyweights</li>
<li>and friends</li>
</ul>


<p><code>+new</code> is old school Obj-C, deprecated as eff, and not to be used in
Cocoa.</p>

<p>Some classic Cocoa singletons became instances over time as their
assumptions changed, like <code>NSPrintPanel</code> and <code>NSPageLayout</code>. Be careful
about your assumptions, then?</p>

<h2>Random: parallel b/w calculus and OO?</h2>

<p>The relationship between an instance and a class object could be
described as an integral relative to its derivative.</p>

<pre><code>derivative(class) = instance
integral(instance) = class + C
</code></pre>

<p>where <code>C</code> is all the methods declared on an object&#8217;s singleton class.</p>

<p>What&#8217;s the derivative of an instance? Often it&#8217;s 0.</p>

<h2>Notifications / Observers / Run loop scheduling</h2>

<p>This is like Evented in Ember, except that the observer state lives in a
global <code>NSNotificationManager</code> in Cocoa whereas it lives on instance
meta in Ember. The Ember benefit is that testing becomes easier when you
don&#8217;t have to remember to flush a global instance. It also means
you don&#8217;t have to remember to teardown observers when you destroy an
object, observer or observee (I think; need to verify this).</p>

<p>Notifications are synchronous, so be mindful of performance implications
when complex interactions are involved. You can asyncify by doing a</p>

<pre><code>[self performSelector:@selector(doSlowAssShit:) 
      withObject:[aNotification object]
      afterDelay:0.0f];
</code></pre>

<p>I wonder if the 0.0f performs in the same run loop or not? In Ember, I
remember making the change so that Ember.run.later would guarantee
running on a separate run loop.</p>

<p>For more complex async messaging, you can use <code>NSNotificationQueue</code>,
which handles the async-ness, and then posts notifications later, after
which point it&#8217;s back in sync-land.</p>

<p>Oo oo oo:</p>

<blockquote><p>The NSPostASAP style directs the queue to post the notification
at the beginning of the next run loop iteration and is effectively
identical to the -performSelector:withObject:afterDelay:</p></blockquote>

<p>So afterDelay 0.0f forces onto the next run loop iteration.</p>

<p>Three styles of async flags for a notification queue&#8217;s
<code>-enqueueNotification</code>:</p>

<ul>
<li>NSPostASAP: same as afterDelay:0.0f approach above</li>
<li>NSPostWhenIdle: runs when run loop is ideal, e.g. no user input events
or other things.</li>
<li>NSPostNow: post the notification immediately and synchronously. Will
still perform <code>NSNotificationQueue</code>-specific coalescing if there are
other events with NSPostASAP or NSPostWhenIdle whose args match. This
is like Ember.run.once except that it works cross run loop, whereas
Ember.run.once only guarantees once-ness within a run loop.</li>
</ul>


<p>So far I don&#8217;t think I&#8217;ve seen an example of enqueuing and action to the
same run loop&#8230; or maybe there was something earlier.</p>

<p>Cocoa lets you describe how once-ness coalesces via the following
<code>coalesceFlags</code> masks:</p>

<ul>
<li>NSNotificationNoCoalescing: same as Ember.run.schedule. No coalescing occurs</li>
<li>NSNotificationCoalescingOnName: coalesce if notification names match</li>
<li>NSNotificationCoalescingOnSender: <code>postNotification</code> includes a string
<code>sender</code>, which Ember doesn&#8217;t have, but this flag will cause events to
coalesce on sender.</li>
</ul>


<p>Ember doesn&#8217;t let you specify coalesce options for <code>run.once</code>. It will
coalesce on action names, and replace any args present on a previously
scheduled action with the same name.</p>

<p>Since NSRunLoop supports multiple modes of operations (which I still
don&#8217;t understand), you can also specify run loop modes in <code>forModes</code>.</p>

<p><code>NSDistributedNotificationCenter</code> lets you post inter-process
notifications. Other apps must <code>addObserver</code> to register to receive them
of course. You can control suspended app behaviors, etc etc etc.</p>

<p>One downside about framework notifications is that you end up posting
notifications that no one may ever use, or you might not post a crucial
one that people would love to have, and there&#8217;s a performance cost to
un-judicious use.</p>

<p>Notifications are similar to delegates, except that delegates are meant
to be the sole receiver/manager of these events.</p>

<h2>Delegation</h2>

<p>Delegation is a benefit over subclassing and overriding hooks (Template
Pattern) because subclass-superclass coupling is bad, and it&#8217;s also
hardwired at compile time whereas you can switch delegates dynamically
at runtime.</p>

<p>Another way to think about it is that sometimes model/controller state
dictate constraints on the view layer, e.g. <code>NSWindow</code> sizing and what
not, but subclassing <code>NSWindow</code> to pollute it with model/controller
concerns would break the separation of concerns. Delegates obviously do
this to some degree, but this breakage, if it can be considered that,
is way more encapsulated.</p>

<p><code>setDelegate</code> should only assign an instance variable but not retain it;
an object doesn&#8217;t own its delegate, but a delegate knows about the
object. This avoids cycles and makes conceptual sense. Delegate objects
are responsible sending <code>setDelegate:nil</code> to all the objects it stands
in for upon <code>dealloc</code>.</p>

<p>Data Sources are like delegates, but provides data rather than
responding to a change.</p>

<p><code>NSOutlineView</code> and <code>NSTableView</code> use a data source.</p>

<h2>UIKit is iOS-only!</h2>

<p>UIKit is iOS only (Cocoa Touch), dweebleton. Apparently UIKit is based on
<code>Application Kit</code>.</p>

<pre><code>Cocoa:ApplicationKit::CocoaTouch:UIKit
</code></pre>

<h2>Prefix.pch for globally used framework headers</h2>

<p>Save on typing by adding an <code>import</code> to <code>YourApp-Prefix.pch</code>, which
literally prepends it to every Objective-C source file in your proj.</p>

<p>Also, <code>.pch</code> means Pre-Compile Header.</p>

<h2>View Hierarchy</h2>

<p>Non-opaque views let clicks through. Like <code>pointer-events</code> in CSS land.</p>

<p>Each view tracks two rectangles:</p>

<ul>
<li>bounds: always <code>0,0</code> origin unless reset at some point (there&#8217;s a
method to use this, apparently scrollview uses it).</li>
<li>frame: the box within the parent view&#8217;s coord system.</li>
</ul>


<p>Scaling is supported, resetting the origin (which affects bounds) is
supported. There are methods for translating between coord systems.</p>

<p>TODO: finish this bitchass book.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/07/01/daily-journal/"/>
    <updated>2014-07-01T10:03:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/07/01/daily-journal</id>
    <content type="html"><![CDATA[<h2>window vs document events</h2>

<p><code>window</code> and <code>document</code> have different events. Duh.</p>

<p><code>window</code>:</p>

<ul>
<li>resize</li>
</ul>


<p><code>document</code>:</p>

<ul>
<li>DOMContentLoaded</li>
</ul>


<p>Breakdown of events and their originators:</p>

<p>https://developer.mozilla.org/en-US/docs/Web/Events</p>

<p>Fun fact: DOMContentLoaded is considered a DOM mutation event.</p>

<h2>Treat stubbed cordova as its own platform</h2>

<p>I&#8217;m doing a Phonegap/Cordova app and it&#8217;s been tricky settling on a
pattern for stubbing out the cordova library when I&#8217;m just running in
Chrome or anywhere not in the actual native cordova wrapper, and I think
I found the final solution: clone https://github.com/apache/cordova-js,
define a new platform with a fake exec, have the fake exec look up some
stubbed handlers that you can define in your app, (e.g.
<code>window._stubbedCordovaHandlers[blahblah]</code>) and basically leave it up to
your app to stub out all the native plugin services/actions. The effect
of all of this is that your index.html always loads a cordova.js (which
has some other conveniences like stick event handlers, pub sub channels,
etc) but you don&#8217;t have to have a bunch of conditionals asking whether
this is a stubbed version of the app or not.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/06/29/daily-journal/"/>
    <updated>2014-06-29T19:29:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/06/29/daily-journal</id>
    <content type="html"><![CDATA[<h2>DAS thangs</h2>

<p>Ctrl-Z suspends a task, but you can resume a task via <code>%1</code> or <code>%2</code>, etc,
referencing the number next to the job as displayed in <code>jobs</code>:</p>

<pre><code>[1]- suspended bleh
[2]+ suspended lol
[3]  suspended lol
</code></pre>

<p>You can also do <code>%-</code> and <code>%+</code>.</p>

<h3>Inline loops</h3>

<pre><code>while true; do echo "wat"; sleep 1; done
</code></pre>

<p>ctrl-z to suspend, <code>bg</code> to convert a suspended job to a background job.</p>

<p>Open the output of a command in <code>vim</code>: <code>echo woot | view -</code></p>

<ul>
<li><code>view</code> is a <code>vim -R</code> alias that opens in read-only mode</li>
<li><code>-</code> option reads the file from stdin</li>
</ul>


<p>The man page for <code>vim</code> / <code>view</code> mentions that commands are read from
stderror. So how would we run a command that reads input from stdin and
commands from stderr? TODO: this.</p>

<pre><code>machty.github.com :: &lt;(echo "wat")
-bash: /dev/fd/63: Permission denied
machty.github.com :: echo &lt;(echo "wat")
/dev/fd/63
</code></pre>

<p><code>&lt;()</code> will run a command and put its output in a file descriptor which
is file-like enough to work as an input to most commands. Gary&#8217;s example
is the &#8220;diff of diffs&#8221;, which is mostly useful to see if two branches
(e.g. one rebased and the other not) have the same content.</p>

<pre><code>diff -u &lt;(git diff master~5..master~1) &lt;(git diff master~4..master)
</code></pre>

<p>Can diff google com and fr, e.g.</p>

<pre><code>diff &lt;(curl www.google.com | tidy) &lt;(curl www.google.fr | tidy) | view -
</code></pre>

<p>This is stupidly cool. Another use case is diffing localhost w deployed
site.</p>

<h2>subterfuge</h2>

<p>I thought this word was a synonym for &#8220;plasma&#8221;, as in the liquid-y
filler part of blood that&#8217;s revealed when you spin blood in a
centrifuge. I think the centrifuge&#8217;s involvement in that tripped me up.</p>

<p>http://www.merriam-webster.com/dictionary/subterfuge</p>

<p>It actually just means</p>

<ul>
<li>deceit used in order to achieve one&#8217;s goal</li>
</ul>


<h2>Cordova My Mac 64-bit</h2>

<p>This was the only thing showing up after I changed the project name in
config.xml away from what I&#8217;d had it as when I first generated the iOS
platform. Remember this crap; I&#8217;m sure I&#8217;ll have to fight it again.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Social Media Triggers]]></title>
    <link href="http://machty.github.com/blog/2014/06/29/social-media-triggers/"/>
    <updated>2014-06-29T19:00:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/06/29/social-media-triggers</id>
    <content type="html"><![CDATA[<p>I&#8217;ve enjoyed about a week away from Twitter, and hope to prolong this
hiatus. Twitter isn&#8217;t consistent with a lot of the lifestyle
changes I&#8217;ve been nagging myself to make. Twitter is snack drawer
positioned arms-reach away from the bed of someone trying to maintain a
diet. It&#8217;s a total trigger for me to retrogress into class clown attention
whore behavior I&#8217;ve been exhibiting since I was 5. So I&#8217;m on a break.</p>

<p>Twitter encourages me to project a public facade of empty-headed
buffoonery fueled by zany sarcasm and Photoshop. The last few months,
I&#8217;ve had various opportunities to meet in person people who only know me
by this facade, and it&#8217;s draining and depressing to keep it up in
person.</p>

<p>So I&#8217;m on a break. I&#8217;ve rediscovered distraction-free boredom. And it&#8217;s
been glorious. I play music again. I sing. When I get frustrated in my
endeavors to improve at my hobbies or my crafts, I have one less
mindless outlet distracting me away from pushing through the difficult
moments. Maybe I&#8217;ll return to Twitter when I have an album to promote.
Or something worth talking about.</p>

<p>This is where I&#8217;m supposed to apologize for a serious post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/06/20/daily-journal/"/>
    <updated>2014-06-20T10:44:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/06/20/daily-journal</id>
    <content type="html"><![CDATA[<h2>Push Notifications</h2>

<p>Apple uses APNS (Apple Push Notification Service) and Android uses
GCM (Google Cloud Message). Compare/contrast:</p>

<p>Apple:
- Max payload size: 256 bytes
- When the app is inactive:
  - Read <code>aps</code> hash:</p>

<pre><code>- Display `alert`
- Play `sound`
- Update app's `badge` number
</code></pre>

<p>Android
- Max payload size: 4096 bytes
- Has no <code>badge</code> option
- Supports <code>collapse_key</code> to collapse identical messages, like &#8220;New
  Mail&#8221; messages, which only need to be responded to once, and require
  only one server fetch.</p>

<p>About payload size: this includes all the JSON padding. The smallest
message is an empty message, represented by the following payload:</p>

<pre><code>{"aps":{"alert":""}}
</code></pre>

<p>This is 20 chars/bytes, meaning you have 236 bytes left for a message.
But push notification payloads often include a badge number, and an
alert to play.</p>

<p>Source: <a href="http://stackoverflow.com/a/6308462/914123">this lovely SO</a></p>

<p><a href="https://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Chapters/ApplePushService.html">From the docs</a>:</p>

<blockquote><p>If the target application isn’t running when the notification
arrives, the alert message, sound, or badge value is played or
shown. If the application is running, the system delivers the
notification to the application delegate as an NSDictionary
object. The dictionary contains the corresponding Cocoa
property-list objects (plus NSNull).</p></blockquote>

<h2>DAS: Boundaries</h2>

<p>https://www.destroyallsoftware.com/talks/boundaries</p>

<p>Integration tests a scam because:
- if 50 conditionals in your app, 2<sup>50</sup> paths, and no way to
- as code grows, time of each test grows (due to more setup, DB stuff,
  etc)</p>

<h2><code>after_commit</code></h2>

<p>This is a hook available within <code>ActiveRecord::Base</code> subclasses
that let you run some code post-transaction. I was confused by this
because a lot of the examples made it seem like you could just
run a method called <code>after_commit</code> in controller code or something,
but nay.</p>

<p>Controller code isn&#8217;t run in a transaction; transactions are only
automatic within <code>.save</code>.</p>

<h2>Sidekiq serializers params via JSON.dump</h2>

<p>This answers my question as to whether symbolized keys are preserved
when passing hash args to a Sidekiq worker: JSON.dump turns string
keys into symbols.</p>

<h2>Difference between <code>Fiber#resume</code> and <code>transfer</code></h2>

<p>Both will transfer control to the fiber you call it on; the difference
is that if that new fiber calls yield, it</p>

<pre><code>f0 
  f1.resume
    Fiber.yield
</code></pre>

<p>FUCK! i don&#8217;t know. TODO come back to this.</p>

<p>Followup: transfer transfers control to another Fiber. The transfer-er
doesn&#8217;t necessarily expect to get returned to, so if the transfer-ee
yields, it&#8217;ll yield the value back to whoever spawned the transfer-er,
rather than return control back to the transfer-er. It&#8217;s mega fucking
confusing.</p>

<p>Also, you have to <code>require 'fiber'</code> to even use this shit.</p>

<h2>~~2.5 in js</h2>

<pre><code>~~2.5  // 2
~~2    //-3
~~-4.2 // 4
</code></pre>

<p>Removes everything to the right of the decimal point, so it&#8217;s like
Math.floor except Math.floor doesn&#8217;t remove stuff to the right of the
decimal point for negative numbers.</p>

<h2><code>void</code> operator</h2>

<p><code>void 0</code> or <code>void(0)</code> evaluates the expression and then returns
undefined. So I could do <code>void (anyNumberOfBullshits())</code> and it&#8217;d be
undefined. Compared to just writing undefined, it:</p>

<ul>
<li>works even if <code>undefined</code> (a variable) has been redefined</li>
<li>is shorter than writing <code>undefined</code></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/06/03/daily-journal/"/>
    <updated>2014-06-03T11:57:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/06/03/daily-journal</id>
    <content type="html"><![CDATA[<h3><code>&lt;base&gt;</code> tag</h3>

<p>From <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base">MDN</a>:</p>

<blockquote><p>The HTML Base Element (<code>&lt;base&gt;</code>) specifies the base URL to use for
all relative URLs contained within a document. There is maximum
one <code>&lt;base&gt;</code> element in a document.</p></blockquote>

<p>You can also specify the target for all links in the base tag. Crazy?</p>

<p>http://jsbin.com/tedik/1/edit</p>

<p>Note that it also supports values like &#8220;../&#8221;, which is how I got my
ember-cli tests.html to work when I got rid of the base url config.</p>

<h3>bootleg</h3>

<blockquote><p>(esp. of liquor, computer software, or recordings) made,
distributed, or sold illegally: bootleg cassettes | bootleg whiskey.</p></blockquote>

<h3>Ember proto CPs</h3>

<p>You can get the proto of an Ember class via <code>Klass.proto()</code> and
you can even invoke its CPs, but where are they cached? Answer: on the
meta of the prototype, and invoking the CP on an instance of that class
will not reuse that cache but rather use its own instance cache.</p>

<p>http://emberjs.jsbin.com/ucanam/5351/edit</p>

<p>Later realization: <em>obviously</em> it had to work this way. What, would all
instances just magically share the proto cached CP value? That&#8217;s
idiotic.</p>

<h3>CrossWalk</h3>

<p>Like Cordova but you get your own browser runtime, so no platform
browser discrepancies.</p>

<p>https://crosswalk-project.org/#documentation/about</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/05/31/daily-journal/"/>
    <updated>2014-05-31T13:03:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/05/31/daily-journal</id>
    <content type="html"><![CDATA[<h3>Git relative revisions</h3>

<pre><code>git checkout 08h398se~1 
</code></pre>

<h3>Lazy CPs stripped down examples</h3>

<p>Observing a CP requires consuming it with a get
before its observers will fire upon change:</p>

<p>http://emberjs.jsbin.com/ucanam/5200/edit</p>

<p>But, for some reason, future changes to that property
don&#8217;t fire that observer:</p>

<p>http://emberjs.jsbin.com/ucanam/5203/edit</p>

<p>This is because firing the observer tears down the chain
nodes unless they&#8217;re activated again by future gets:</p>

<p>http://emberjs.jsbin.com/ucanam/5204/edit</p>

<p>But firing the observer tears down the chain
nodes, so future fires also need to be preceded by
a get to make the observer alive again:</p>

<p>http://emberjs.jsbin.com/ucanam/5201/edit</p>

<p>http://emberjs.jsbin.com/ucanam/5198/edit</p>

<pre><code>// CRUCIAL REALIZATION!!!! THIS IS HOW OBSERVERS
// STAY LIVE IN VIEWS; RE-RENDERED METAMORPH TEMPLATES
// CALL .get() to get the LATEST VALUE OF THE FUCK.
// BUT GENERALLY SPEAKING YOU JUST NEED TO CALL .GET()
// ON THE THING TO MAKE IT ALIVE AGAIN!
http://emberjs.jsbin.com/ucanam/5208/edit



/*
Ember.addObserver(pojo, 'foo', function() {
  console.log('foo observer fired');
});
*/



// These additional changes
// don't fire the fooAlias
// observer, unless we continue
// consuming (uncomment the stuff)
//Ember.get(pojo, 'fooAlias');
Ember.set(pojo, 'foo', 7);
//Ember.get(pojo, 'fooAlias');
Ember.set(pojo, 'foo', 8);
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ember Meta]]></title>
    <link href="http://machty.github.com/blog/2014/05/31/ember-meta/"/>
    <updated>2014-05-31T07:27:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/05/31/ember-meta</id>
    <content type="html"><![CDATA[<h3>Ember Meta</h3>

<p><em>This will start off in my typical meandering daily journal form and
hopefully evolve into something good enough for an ARCHITECTURE.md</em></p>

<p>Ember&#8217;s internals make heavy use of meta objects, which are generated
and attached to objects in order to keep track of bindings, computed
properties, observers, and all sorts of other things evolving Ember magic.</p>

<h4><code>EMPTY_META</code></h4>

<p><code>EMPTY_META</code> is a default, empty meta object that represents an object
with no observers, bindings, or computed properties.</p>

<p><code>Ember.meta</code> is the function that takes an object and returns its meta
object; asking Ember.meta for a read-only meta object for a POJO
will return <code>Ember.EMPTY_META</code></p>

<pre><code>Ember.meta({}, false) === Ember.EMPTY_META // true

http://emberjs.jsbin.com/ucanam/5173/edit
</code></pre>

<p>This is an optimization that lets us pretend as if every object in
Emberland had a meta object, simplifying our binding/observer algorithms
while not wastefully generating meta objects for objects that don&#8217;t need
their own separate copies. It&#8217;s a form of copy-on-write.</p>

<pre><code>var pojo = {
  foo: 'wat'
};

console.assert(Ember.meta(pojo, false) === Ember.EMPTY_META);

// Add a computed property, which requires writing to meta.
Ember.defineProperty(pojo, 'fooAlias', Ember.computed.alias('foo'));

console.assert(Ember.get(pojo, 'foo') === 'wat');

var newMeta = Ember.meta(pojo, false)

console.assert(newMeta !== Ember.EMPTY_META);

// http://emberjs.jsbin.com/ucanam/5176/edit
</code></pre>

<h4><code>META_DESC</code></h4>

<p>This is the ES5 descriptor for the property stashed on an object that
points to its meta object:</p>

<pre><code>{
  writable: true,
  configurable: false,
  enumerable: false,
  value: null
};
</code></pre>

<p>This makes the property non-enumerable, which is why the meta object
won&#8217;t show up when iterating over an object with <code>for..in</code>.</p>

<h4>Meta obj structure</h4>

<p><code>EMPTY_META</code> is just <code>new Meta(null)</code>, and here&#8217;s the meta structure:</p>

<pre><code>Meta.prototype = {
  // Set to {} by constructor

    // dictionary of all Ember.Descriptor properties
    // defined on for the obj, e.g computed properties
    descs: null,    

    // dictionary of properties on the object that are
    // being observed, where the key is the observed
    // property name and the value is the number of
    // active observers of this property.
    // e.g. meta.watching.foo === 2 means that two
    // observers are watching obj.foo for changes.
    watching: null,

    // TODO
    cache: null,

    // TODO
    cacheMeta: null,

    // The owner of this meta object; important to keep track
    // of because when prototypal inheritance is involved, a
    // child object will initially point to the same meta obj
    // as its prototype, even though they should have separate
    // meta obj. `Ember.meta()` detects this by checking to see
    // if meta.source equals the passed in object, and if not,
    // it generates a new meta object
    source: null,

  // Left as null by constructor
  deps: null,
  listeners: null,
  mixins: null,
  bindings: null,
  chains: null,
  chainWatchers: null,
  values: null,

  // The prototype of source
  //   meta.proto.isPrototypeOf(meta.source) // true


  proto: null
};

//    ret = o_create(ret);
//    ret.descs     = o_create(ret.descs);

// why is this o_create? 
// if proto.foo is being watched, and obj.foo is overwritten
// to some other value, then it's definitely disconnected at
// that point, right? Even if it's not overwritten, if you have
// 
// proto = {
// }
// 
//    ret.watching  = o_create(ret.watching);
//    ret.cache     = {};
//    ret.cacheMeta = {};
//    ret.source    = obj;

// TODO: categorize this realization
// removeDependentKeys calls iterDeps, which loops
// over deps[propName] &gt; 0,
// and then the cp.didChange method decrements
// the deps in the meta in removeDependentKeys();
// this method is called in two places:
// - didChange()
// - teardown()
// 
// note that it doesn't do this for non-cacheables CPs.
</code></pre>

<p>If CP#didChange removes dependent keys, who adds it back in template situations?
The view that was installed will call get() on that CP, and .get() on a cacheable property will call addDependentKeys</p>

<p>So the rule is that if you want an observer be/stay alive, you need to
call get on that changed prop. AH HA.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/05/28/daily-journal/"/>
    <updated>2014-05-28T15:42:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/05/28/daily-journal</id>
    <content type="html"><![CDATA[<h3>Rubymotion</h3>

<p>The next version will support Android. Ruby on Android. By PHH.</p>

<p>http://blog.rubymotion.com/post/87048665656/rubymotion-3-0-sneak-peek-android-support</p>

<h3>Magnet Link</h3>

<p><a href="http://en.wikipedia.org/wiki/Magnet_uri">Wikipedia</a></p>

<p>e.g. for all my illegal torrent downloads</p>

<pre><code>magnet:?xt=urn:btih:7O4OWESOQIXMYWY6U36MXWRICAUDB2OU&amp;dn=Louie.S04E05.HDTV.x264-LOL&amp;tr=udp://tracker.openbittorrent.com:80&amp;tr=udp://tracker.publicbt.com:80&amp;tr=udp://tracker.istole.it:80&amp;tr=udp://open.demonii.com:80&amp;tr=udp://tracker.coppersurfer.tk:80
</code></pre>

<ul>
<li>&#8220;de facto&#8221; standard; no official spec</li>
<li>The scheme is &#8220;magnet&#8221;, even though there&#8217;s not &#8220;magnent&#8221; protocol in
the way &#8220;http&#8221; is a scheme that refers to the Hyper Text Transfer
Protocol.</li>
<li>URI has target file&#8217;s contents built into hash; anyone with the file
can generate the URL without needing to refer to a central authority.
This makes search results guaranteed; the server either has the thing
you&#8217;re looking for or it doesn&#8217;t, and if you&#8217;d, say, like to continue
downloading the latest episode of Louie from a source, you could
search by content hash rather than by &#8220;Louie S04E07&#8221; which might yield
a bunch of different encodings and other things you don&#8217;t actually
want.</li>
<li>magnet URIs have no <a href="http://en.wikipedia.org/wiki/URI_scheme#Generic_syntax">hierarchical part</a>,
but rather immediately begin with a query param.</li>
<li><code>xt</code> query param refers to &#8220;exact topic&#8221;; this is followed by the hash
type, such as sha1, or in the example above, &#8220;btih&#8221;, which is a SHA1
hash of a BitTorrent Info Hash (TODO: write about bittorrent meta)</li>
<li><code>dn</code> = display name, e.g. <code>Louie.S04E05.HDTV.x264-LOL</code></li>
<li><code>tr</code> = tracker url for bittorrent downloads; note in the above sample
magnet URL <code>tr</code> appears multiple types; wiki suggests appending an
incrementing <code>.N</code> to query param keys, but I guess that&#8217;s not a
requirement.</li>
</ul>


<blockquote><p>The Pirate Bay migrated from .torrent files to magnet URI in February 2012. This migration made the storage footprint of The Pirate Bay exceptionally small. A user demonstrated that the total size of The Pirate Bay magnets would be approximately 90MB of compressed data.[2]</p></blockquote>

<h3>STOMP</h3>

<p><a href="http://en.wikipedia.org/wiki/Streaming_Text_Oriented_Messaging_Protocol">Wikipedia</a></p>

<p>Streaming Text Oriented Messaging Protocol: protocol designed for
working with Message-Oriented Middleware (MOM). It&#8217;s language-agnostic,
so you could have a Ruby STOMP client talking to a Java STOMP server,
etc.</p>

<p>Go figure the Ruby Server that I found depends on EventMachine. How
could it not? I should probably figure out how servers queue up
requests. Is that the job of Thin/Mongrel/Unicorn?</p>

<h3>Ember overwriting get-only computed properties</h3>

<p>Best explained in a <a href="http://emberjs.jsbin.com/ucanam/5139/edit">JSBin</a>.</p>

<p>Setting a computed property that is get-only (which is determined
by the fact that the supplied function has an arity of &lt;= 1) will
overwrite that CP with whatever static value you&#8217;re setting it to.</p>

<p>Relevant
<a href="https://github.com/emberjs/ember.js/blob/master/packages/ember-metal/lib/computed.js#L490-L492">Ember</a>
<a href="https://github.com/emberjs/ember.js/blob/master/packages/ember-metal/lib/computed.js#L1224-L1228">links</a></p>

<h3>Defeaturify doesn&#8217;t get run before Ember API docs get generated</h3>

<p>This is probably the least timeless thing I could write about.</p>

<h3>Drop permissions in a server setting</h3>

<p>It&#8217;s an OS requirement that running a server on port 80 requires root
permissions, which means you need to be logged in as root or running
sudo to start up a server on port 80, but it can be risky to leave a
server running with full permissions, so it&#8217;s common practice to <em>drop
permissions</em> after the server has been start up.</p>

<p>I stumbled upon this concept while reading
<a href="https://github.com/ruby/ruby/blob/trunk/lib/webrick.rb#L14-L15">WEBrick code</a>:</p>

<pre><code># WEBrick also includes tools for daemonizing a process and starting a process
# at a higher privilege level and dropping permissions.
</code></pre>

<h3>Michael McKean</h3>

<p><img src="http://f.cl.ly/items/0x23191Z3K1J0M0Z1e3D/coneheads03.jpg" alt="Michael McKean" /></p>

<p>A total hateable 90s &#8220;that guy&#8221;.</p>

<h3>Ruby Fiber-local variables</h3>

<p><code>Thread#[]</code> is <a href="http://www.ruby-doc.org/core-2.1.1/Thread.html#method-i-5B-5D">a thing</a></p>

<p>It&#8217;s an accessor for fiber-local variables. What does that mean? It
means even though you&#8217;re saying <code>Thread.current[:a]</code>, which looks as if
you&#8217;re grabbing <code>a</code> as tied to the current thread, it&#8217;ll actually be
grabbing <code>a</code> from the currently active Fiber within that Thread, which
is a little misleading (and obviously wasn&#8217;t a problem before Fibers
were a thing in 1.9.2).</p>

<p>Example:</p>

<pre><code>Thread.new {
  Thread.current[:a] = "lol"
  Fiber.new {
    puts "in new fiber: #{Thread.current[:a]}"
  }.resume
  puts "in original fiber: #{Thread.current[:a]}"
}.join
</code></pre>

<p>This prints</p>

<pre><code>in new fiber:
in original fiber: lol
</code></pre>

<h3>Thread#join</h3>

<p>I knew this but I&#8217;m forgetful.</p>

<p>The following program prints &#8220;DONE&#8221; and exits:</p>

<pre><code>Thread.new {
  sleep 1
  puts "OMG"
}
puts "DONE"
</code></pre>

<p>The following program waits a second, prints &#8220;OMG&#8221;, prints &#8220;DONE&#8221; and quits:</p>

<pre><code>Thread.new {
  sleep 1
  puts "OMG"
}.join
puts "DONE"
</code></pre>

<p><code>Thread#join</code> pauses the current thread until the <code>.join</code>d thread
completes. Dur.</p>

<h3>Rack Request Store</h3>

<p><a href="https://github.com/steveklabnik/request_store">GitHub</a></p>

<p>Apparently <code>Thread.current</code> is already well known as common storage
place for global state for whichever thread you&#8217;re on (which is safer
than sharing/clobbering some truly global var shared b/w threads). The
problem is that servers don&#8217;t agree on Thread re-use:</p>

<pre><code>def index
  Thread.current[:counter] ||= 0
  Thread.current[:counter] += 1
  render :text =&gt; Thread.current[:counter]
end
</code></pre>

<blockquote><p>If we ran this on MRI with Webrick, you&#8217;d get 1 as output, every time. But if you run it with Thin, you get 1, then 2, then 3&#8230;</p></blockquote>

<p>Presumably that&#8217;s because WEBrick spawns a new thread for every request
while Thin reuses threads. (TODO: confirm this?)</p>

<p>So anyway, Rack RequestStore is a thread-local storage mechanism that
gets cleared at the beginning of every web request. The functioning code
is literally no more than:</p>

<pre><code>module RequestStore
  def self.store
    Thread.current[:request_store] ||= {}
  end

  def self.clear!
    Thread.current[:request_store] = {}
  end
end
</code></pre>

<p>and</p>

<pre><code>module RequestStore
  class Middleware
    def initialize(app)
      @app = app
    end

    def call(env)
      RequestStore.clear!
      @app.call(env)
    end
  end
end
</code></pre>

<p>and then you&#8217;d write in your app code:</p>

<pre><code>def index
  RequestStore.store[:foo] ||= 0
  RequestStore.store[:foo] += 1
  render :text =&gt; RequestStore.store[:foo]
end
</code></pre>

<p>so you still have to use <code>||=</code> to initialize values but you have the
guarantee that a previous value doesn&#8217;t stick around.</p>

<h3>Deadlock detected</h3>

<pre><code>1.9.3p484 :004 &gt; Thread.current.join
fatal: deadlock detected
</code></pre>

<p>Dur.</p>

<h3>POSIX: Portable Operating System Interface</h3>

<p>I had no idea what this was. It always &#8220;the thing that has something to
do with linux/unix and has opinions about utilities that you might find
both on linux and Mac OS&#8221;.</p>

<p>It&#8217;s a family of standards specified by the IEEE, specifically IEEE
1003. Linux, UNIX, and Mac OS X are POSIX-compliant, I believe, but what
does that mean?</p>

<p><a href="http://stackoverflow.com/questions/1780599/i-never-really-understood-what-is-posix">good SO question</a></p>

<p><a href="http://pubs.opengroup.org/onlinepubs/9699919799/">Readable POSIX Standard</a></p>

<p>The C programming language was standardized by POSIX, also BSD variant
exists.</p>

<h3>Difference b/w linux and unix</h3>

<p><a href="http://www.cyberciti.biz/faq/what-is-the-difference-between-linux-and-unix/">Source</a></p>

<p>UNIX is a copyrighted name; most UNIX system sare commercial in nature.
Open Group holds UNIX trademark.</p>

<p>Linux is a UNIX clone created by Linus Torvalds and aims for POSIX
compliance.</p>

<p>Linux is just a kernel; everything else that goes into a Linux distro is
GUI systems and GNU utilities, filled in by third parties, whereas with
a UNIX OS, everything comes from a single source/vendor so it&#8217;s
considered a &#8220;complete operating system&#8221;.</p>

<p>Linux is free, redistributable under GNU licenses. Most UNIX-like
systems not free, w OpenSolaris as exception. But some Linux systems
are accompanied by Linux support, consultancy, bug fixing, and training
for additional fees, e.g. Redhat.</p>

<p>Some UNIX OS&#8217;s</p>

<ul>
<li>HP-UX</li>
<li>IBM AIX</li>
<li>Sun Solaris</li>
<li>Mac OS X (the X emphasizes relation w UNIX)</li>
<li>IRIX</li>
</ul>


<p>Some Linux Distributions</p>

<ul>
<li>Redhat Enterprise Linux</li>
<li>Fedora Linux</li>
<li>Debian Linux</li>
<li>Suse Enterprise Linux</li>
<li>Ubuntu Linux</li>
</ul>


<p>Commonalities b/w Unix and Linux</p>

<ul>
<li>GUI, file, windows manager</li>
<li>Shells (ksh, csh, bash)</li>
<li>Various office apps (open office)</li>
<li>Development tools (perl, php, python, GNU C/C++ compilers)</li>
<li>POSIX interface (wat? i guess this means both are POSIX compliant)</li>
</ul>


<p><a href="http://en.wikipedia.org/wiki/File:Unix_history.svg">Unix History graphic</a></p>

<h3>IEEE: Institute of Electrical and Electronics Engineers</h3>

<p>A professional association with corp office in NYC, dedicated to
technical advancement and excellence. Known for their conferences,
educational activities, and in particular their standards development.</p>

<p>How do they make money? Let&#8217;s look at their
<a href="http://sites.ieee.org/annualreport/files/2013/10/IEEE-2012-Annual-Report-Full.pdf">annual report</a>.</p>

<p>Members pay dues. Full year membership is $187. They have 429,000
members. Membership bolsters your tech career, I guess. Hear about
conferences n shit.</p>

<p>$406M in revenue, mostly in periodicals and conferences, then
membership, then standards, then other things.</p>

<p>So how do they make money off of standards? Someone approaches them and
says &#8220;hey you usually do a good job on this stuff; we&#8217;ll pay you to help
out on these standards?&#8221;</p>

<p><a href="http://standards.ieee.org/develop/process.html">what a nice resource</a></p>

<blockquote><p>The development of a new standard is typically triggered by a formal request, submitted to an SDO (Standards Development Organization) by a Sponsoring Body (individual or entity, such as an industry society) for review and evaluation. The SDO mandates, oversees, and helps facilitate the process for standards development. The Sponsor for the standards project assumes responsibility for the respective area of standards development, including the organization of the standards development team and its activities.</p></blockquote>

<p><a href="http://standards.ieee.org/develop/projstart.html">then there&#8217;s this</a></p>

<ul>
<li>An idea or concept needs to be standardized</li>
<li>Sponsorship organization comes along to coalesce the ideas of
individuals and to financially back the standardization process.</li>
</ul>


<p>What are some of their most &#8220;popular&#8221; standards? These are based on the
Wikipedia search autocomplete of &#8220;IEEE &#8220;:</p>

<ul>
<li>IEEE 802.11: MAC (media access control) and physical layer (PHY) specs
for implementing wireless LAN (WLAN) in certain frequency bands. IEEE
802 is the</li>
<li>IEEE 802.11g-2003 et al: enhancements to the original spec, expanding
to other frequencies.</li>
<li>IEEE 1394: FireWire</li>
<li>IEEE 1003: POSIX</li>
</ul>


<p>&#8220;IEEE 802&#8221; refers to the family of standards dealing with LAN. Different
suffixes refer to different standards (rather than versions of
standards).</p>

<p>Also, when an amendment comes out, e.g. 802.11g-2003, it is
revoked when fully incorporated into the main standard, but
manufacturers will still refer to the amendment code as a means to
concisely advertise a product&#8217;s capability:</p>

<blockquote><p>While each amendment is officially revoked when it is incorporated in the latest version of the standard, the corporate world tends to market to the revisions because they concisely denote capabilities of their products. As a result, in the market place, each revision tends to become its own standard.</p></blockquote>

<h3>Pass a return value to &#8220;break&#8221; in Ruby</h3>

<p><img src="http://f.cl.ly/items/0Q311t0Y1R2v1O29081u/Image%202014-05-29%20at%2011.51.58%20AM.png" alt="twitter convo" /></p>

<pre><code>[1,2,3].map { |i| break "shit" } # =&gt; "shit"
</code></pre>

<p>More generally:</p>

<pre><code>def foo
  yield
  "shit"
end

foo { break "naw" } # =&gt; "naw"
</code></pre>

<p><code>break x</code> means &#8220;force the method that yielded me to return x&#8221;.</p>

<h3>Ruby Garbage Collection</h3>

<p>Phrasing from <a href="http://samsaffron.com/archive/2014/04/08/ruby-2-1-garbage-collection-ready-for-production">this article</a></p>

<p>Ruby 2.0: collect GC every 8MB; too small for most Rails apps
Ruby 2.1: Revised to have defaults make sense for both script and web apps</p>

<p>Specifically, expand GC limit every time limit hit, with ceilings.</p>

<p>But there was a 2.1 bug fixed in 2.1.1. In addition, there&#8217;s still a
&#8220;memory doubling&#8221; issue under 2.1.1 due to the generational GC added to
2.1.</p>

<p>The gist of generational GC is that:</p>

<ul>
<li>Oftentimes, an allocated piece of memory is transient; it&#8217;s used once
and immediately its consumer lets go of it, and it can be released
back to the system</li>
<li>Objects that survive a first sweep are statistically likely to
maintain in use for a long time, so it doesn&#8217;t make sense to
constantly sweep these objects in every GC pass.</li>
<li>So separate garbage collection into two generations, old and new.
New-gen allocations get moved to old-gen if they survive the first
sweep, and old-gen sweeps (major GC events) happen way less
frequently.</li>
</ul>


<p>This apparently made Ruby 2.1 10x faster on average. But according to
this article, the 2.1 algo was too simplistic for web apps since web
apps perform lots of &#8220;medium&#8221; allocations (allocations that survive a
first sweep but can thereafter very quickly be swept up), e.g. most
(all?) allocations will take place during a web request, so if a GC hits
in the middle of a request, a lot of new-gen allocations will be moved
to old-gen, even though much of the new-genners could be cleaned up at
the end of the request.</p>

<p>Bad side effects:</p>

<ul>
<li>Major GC events run more often (triggered by oldgen growth)</li>
<li>Oldgen grows beyond what we need (saturated by medium-gen)</li>
</ul>


<p>.NET and Java use 3 generations, gen0 survivors go to gen1, then gen1 to
gen2, where they remain.</p>

<p>The planned (and I guess implemented at this point) refactor is to
requires that objects will have to survive 2 minor GCs to be promoted to
oldgen, therefore, if no more than 1 minor GC runs during a request,
heaps will stay at optimal sizes. Slated for 2.2 release (not yet
released).</p>

<p>BTW, RSS refers to &#8220;resident set size&#8221;, the portion of a process&#8217;s
memory that is held in RAM, as in &#8216;in residence&#8217;. If it weren&#8217;t in
residence, it might be in swap or in filesystem.</p>

<p>So the Ruby algo is called <code>RGenGC</code>.</p>

<h3>Bitmap marking</h3>

<p><a href="http://patshaughnessy.net/2012/3/23/why-you-should-be-excited-about-garbage-collection-in-ruby-2-0">source</a></p>

<p>In MRI, lots data stored as metadata + RValue, e.g. &#8220;abc&#8221; stored as an
RString which is flags + &#8220;abc&#8221; stored on an RValue heap with lots of
other strings.</p>

<pre><code>[a,b,c,s,o,m,e,o,t,h,e,r,s,t,r,i,n,g]
</code></pre>

<p>Fun fact: your ruby code itself is converted into RValue structures as
it is parsed and converted into byte code.</p>

<p>GC is run when we&#8217;re out of RValue storage, loop over references an set
<code>FL_MARK</code> to mark the obj. Then leftover unmarked freeable objs are
collected into a singly-linked list, which will then be used for future
RValue allocs. If a heap (collection of RValue pointers) can&#8217;t free up
any more space, and additional heap is alloc&#8217;d.</p>

<h4>Copy-on-Write optimization</h4>

<p>(brought to you by POSIX, right? or BSD? TODO: nail this down)</p>

<p>Linux/UNIX/UNIX-like systems have COW (copy on write). Semantically, a
fork of a process means copying all of memory from starting process. But
a full copy doesn&#8217;t actually need to happen until one of the proces
writes.</p>

<p>Presumably this same thing happens if it&#8217;s the parent process that
writes to COW data, right? How does that work? Are they both considered
child processes? TODO!!!</p>

<p>But before bitmap sweeping, COW didn&#8217;t work for Ruby, because Ruby&#8217;s GC
involves writing to <code>FL_MARK</code> to mark a piece of data as referenced by
some other thing, and this sets off the OS&#8217;s copy-on-write behavior;
writing to <code>FL_MARK</code> looks like any other kind of memory write and the
OS doesn&#8217;t know the difference.</p>

<p>(note: <a href="http://www.rubyenterpriseedition.com/">Ruby Enterprise Edition</a>
fixed this, if you&#8217;re interested)</p>

<p>The MRI fix came with replacing <code>FL_MARK</code> with a bitmap of marked
values. It&#8217;s not a 2D bit map, it just means bits mapped to RValue
heap array elements. Obviously the bitmaps themselves are heavily
modified so they&#8217;ll definitely be fully copied, but they&#8217;re small so no
biggie.</p>

<p>Heaps now must be &#8220;aligned&#8221; with their maps, so we can&#8217;t just use boring
ol malloc, but rather <code>posix_memalign</code> to alloc something that
presumably doesn&#8217;t align with a word.</p>

<h3>Enumerable Lazy</h3>

<p>This is in 2.0. You don&#8217;t want to use it all the time for performance
reasons (the construction of all the intermediate blocks outweighs the
cost of evaluating some array you might not entirely consume), but it
allows you to do things like:</p>

<pre><code>require 'prime'
Prime.lazy.select {|x| x % 4 == 3 }.take(10).to_a
</code></pre>

<p><a href="http://railsware.com/blog/2012/03/13/ruby-2-0-enumerablelazy/">Read more</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Journal]]></title>
    <link href="http://machty.github.com/blog/2014/05/26/daily-journal/"/>
    <updated>2014-05-26T13:17:00-04:00</updated>
    <id>http://machty.github.com/blog/2014/05/26/daily-journal</id>
    <content type="html"><![CDATA[<h3>EIP: Notes</h3>

<p>Consider reading <em>Data and Reality</em> by William Kent.</p>

<p>Semantic dissonance is ironed out by shared database schema; each app is
forced to conform its data to that schema before saving to that
database.</p>

<p>Coming up with unified schemas that meet the needs of multiple
applications is extremely difficult, and there are political
considerations; the delay of a flagship product so that a shared
database can be adhered to often leads to splitting.</p>

<h4>RPI: Remote Procedure Invocation</h4>

<h4>Web Service / WSDL</h4>

<p>Seems like I come across this term enough without actually knowing how
it&#8217;s specifically defined; presumably a REST API is a kind of web
service, but what&#8217;s the official definition?</p>

<p><a href="http://en.wikipedia.org/wiki/Web_service">Wikipedia says</a>:</p>

<blockquote><p>A Web service is a method of communication between two electronic devices
over a network. It is a software function provided at a network address
over the web with the service always on as in the concept of utility computing.</p></blockquote>

<p>A web service allows two software systems to interact with each other
over the internet. You can interact with a web service so long as you
have its publicly available address.</p>

<p>Rules for communication between web services are defined in WSDLs (Web
Services Description Language). A searchable dictionary of discoverable
WSDLs is a UDDI (Universal Description, Discovery and Integration).
Interacting with these services often involves using the SOAP protocol
(Simple Object Access Protocol), an XML format for structuring messages
for web services.</p>

<h4>Messaging</h4>

<p>Senders don&#8217;t just barf information into a messaging cloud but rather
adds this information to a particular Message Channel, likewise w
receivers who must explicitly specify Message Channels.</p>

<p>Channels are &#8220;logical addresses&#8221; which hide implementation details of
how the underlying messaging system actually delivers these messages.</p>

<p>It&#8217;s often possible but rare for channels to be dynamically created at
runtime; receivers would also need to know to look for such a channel,
so channels are usually decided by deploy time (apparently there are
exceptions?).</p>

<p>In Java et all, <code>new MessageQueue</code> won&#8217;t actually create a new channel,
but will just create a wrapper for a channel pre-defined in
administrative tools.</p>

<p>Channel names are generally boring ol alphanumeric names like
<code>MyChannel</code>, but hierarchical conventions exist to, e.g.
<code>BlahCorp/Prod/OrderProcessing/NewOrders</code>.</p>

<p>Two types of Message Channels: - <em>Point-to-Point</em> and
<em>Publish-Subscribe Channels</em>.</p>

<p>From the application dev&#8217;s perspective, there are a few different types
of messages:</p>

<ul>
<li>Command Message: invoke a procedure in another app</li>
<li>Document Message: pass data to another app</li>
<li>Event Message: notify another app of a change in this app</li>
<li>Request-Reply: receiver should send back a response</li>
</ul>


<p>A SOAP message is a <em>Message</em>, but it itself could be wrapped in another
outer message. Recursive, babeh.</p>

<h3>Git: detached HEAD state</h3>

<p><code>HEAD</code> is a reference to the currently checked-out commit. Usually it
points to a branch you have checked out, but if you try and check out a
specific commit, tag, or remote branch, you&#8217;ll go into detached HEAD
state.</p>

<p>Don&#8217;t call it &#8220;headless&#8221; state; you&#8217;re probably mixing terminology with
headless webkit or something, like I did; there&#8217;s no &#8220;headless&#8221; state
in Git, you always have a HEAD, but if it&#8217;s detached, it means you&#8217;re
not tied to a branch any more.</p>

<p>So <code>HEAD</code> always refers to the currently checkout out commit, which is
why if you run <code>git checkout HEAD~1</code> many times in a row, you&#8217;ll be
rewinding to a previous commit every time you run it rather than
repeatedly checking out the tip of the current branch minus one, which is what I
originally thought. Also, there is no &#8220;current branch&#8221; once you&#8217;re run
<code>git checkout HEAD~1</code>; the commit you&#8217;ve checked out could be an
ancestor in many different branches, so if you want to re-attach, you
have to be explicit.</p>

<h3>Filters and Pipes</h3>

<p>A pipe connects filters. A filter is a single purpose component that can
be reused. Filters have an input pipe and output pipe, and don&#8217;t
generally have knowledge of where the output pipe is pointing.</p>

<p>Why is it called a pipe and not a channel? Because a channel is named,
and anyone pushing or pulling from it is doing so according to some
logical intent, whereas filters are way dumber.</p>

<p>Filters can/should be implement via an abstract pipe interface, so that
all filtering could potentially happen within one machine, but at any
point the pipe could be turned into a full on Message Channel that might
go to some other machine.</p>

<p>Filters lend themselves nicely to testability as individually testable components.</p>

<p>Filters connected via async channels in their own processes/threads also
allow for higher throughput for typical pipeline reasons; 3 messages
that come in at the same time that need to be decrypted, authenticated,
and deduped can begin w the decryptor, which, once finished with the
first, can move on to the next. Assembly line style.</p>

<p>Parallelizing filters works best if the filter is stateless, e.g.
de-dupe would be a challenge to parallelize since it depends stores
previous messages to check for dupes, and wouldn&#8217;t function unless that
storage was shared.</p>

<h3>Message Router</h3>

<ul>
<li>Doesn&#8217;t modify message contents</li>
<li>Only decides destination message</li>
<li>Message Routers are meant to decouple, but if list of destinations
changes often, Router might become coupled bottleneck, in which case
it&#8217;s better to let recipients (i.e. that which Router would output to)
decide which messages they&#8217;re interested in, i.e. Pub Sub channel.</li>
<li><em>Predictive routing</em> means putting control in Message Router; <em>reactive
routing</em> means Pub Sub.</li>
</ul>


<p>Decoupling is nice but comes at the expense of reasonability about the
system; harder to see a flow.</p>

<p>Brainless router: single input, single output; meant as a stub for when
we&#8217;re pretty sure we&#8217;ll want a more intelligent router later.</p>

<p>Content-based router: decides where to go based on message content.</p>

<p>Context-based routers: decide where to go based on environmental
conditions, e.g. load-balancing, test, failover.</p>

<p>Failover: switching to redundant / standby system automatically if
primary one fails.</p>

<p>Note that some Message Channels come with their own form of load balancing
if Competing Consumers are consuming off the channel as fast as they
can, but Message Routers have the benefit of being able to use more
complicated logic, which a Competing Consumer free-for-all would not be
able to make use of.</p>

<p>Routers can connect to Control Bus to live-update decision criteria
without requiring code change.</p>

<p>Routers play in important role in Message Broker pattern, which is the
integration equivalent to the Mediator GoF pattern.</p>

<h3>EDI: Electronic Data Interchange</h3>

<p>Source: EIP, using EDI 850 Purchase Order as an example.</p>

<p><a href="http://en.wikipedia.org/wiki/Electronic_data_interchange">Wikipedia</a></p>

<p>Electronic communication system that provides standards for exchanging
data via any electronic means.</p>

<p>Origins: military logistics</p>

<p>ERP: Enterprise Resource Planning</p>

<h3>Why HTTP isn&#8217;t a transport layer</h3>

<p><a href="http://restpatterns.org/Articles/Why_HTTP_Isn't_A_Transport_Protocol">Source</a></p>

<p>So many things to dissect. I&#8217;m sad I still don&#8217;t have this shit stuck in
my brain. Gosh damn.</p>

<p>Alright, what&#8217;s a transport layer? TCP&#8217;s a transport layer. It&#8217;s
concerned with getting data from A to B and doesn&#8217;t care about the
format of the data. UDP is also one, but doesn&#8217;t guarantee delivery,
packet order, etc.</p>

<p>HTTP (Hypertext Transfer Protocol) is an application-layer protocol.</p>

<p>Good explanation of layers:</p>

<pre><code>http://en.wikipedia.org/wiki/File:Internet_layering.svg
</code></pre>

<p>IP is the Internet layer, the addressing layer that describes how
different systems can access each other.</p>

<p>Blah blah blah. Anyway, armed with this knowledge, what does it mean for
HTTP to even be considered a transport protocol?</p>

<p>Some people expand HTTP to Hypertext <em>Transport</em> Protocol, which is NOT
the same as the actual correct <em>Transfer</em> protocol.  It&#8217;s not transport,
it&#8217;s transfer, you dummy.</p>

<p>Subtle differences between transfer and transport:</p>

<ul>
<li>Transport as agnostically carrying something from A to B</li>
<li>Transfer pays attention to the content of what&#8217;s being transferred.</li>
</ul>


<p>That&#8217;s why HTTP offers so many different verbs (GET POST PUT PATCH
DELETE CONNECT OPTIONS HEAD) and status codes. You&#8217;d only need to GET/PUT and 200/500/400
(success, server failure, client failure) if HTTP were a transport
protocol, but the fact that it has all these expressive differences in
intent implies it&#8217;s most of an application/transfer layer.</p>

<p>OK, so well done, article, but terrible job at explaining exactly <em>who</em>
is using HTTP as a transport layer protocol and how and what the cut off
is. I still don&#8217;t know.</p>

<p>Oh I get it, from the wiki article an example SOAP message:</p>

<pre><code>POST /InStock HTTP/1.1
Host: www.example.org
Content-Type: application/soap+xml; charset=utf-8
Content-Length: 299
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"

&lt;?xml version="1.0"?&gt;
&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope"&gt;
  &lt;soap:Header&gt;
  &lt;/soap:Header&gt;
  &lt;soap:Body&gt;
    &lt;m:GetStockPrice xmlns:m="http://www.example.org/stock"&gt;
      &lt;m:StockName&gt;IBM&lt;/m:StockName&gt;
    &lt;/m:GetStockPrice&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
</code></pre>

<p>So in this case there is a SOAP message that itself adheres to an XML
schema, but in most cases it is transported within the body of an HTTP
request. So it uses HTTP as its transport layer. A SOAP message <em>could</em>
be transported over TCP socket, but it&#8217;s generally done over HTTP.</p>

<p>I&#8217;ve resolved my confusion: for any given message format, a message
needs to be transported. SOAP is a message format, and it just so
happens to be wrapped in HTTP. You could wrap a message in many
different layers which might be intended as application layers, each one
treating its wrapper as a transport layer.</p>

<p>SOAP is shitty for caching because resources are not a first class
consideration in the way they are for REST. HTTP headers and resource
URLs provide information that lends itself nicely to caching.</p>

<h3>ActiveX!!!</h3>

<p>I never really knew what this was. It implies security risk and
executable code within Internet Explorer. But wat it be?</p>

<p><a href="http://en.wikipedia.org/wiki/ActiveX">Wikipedia</a></p>

<p>It&#8217;s a Microsoft framework, picking up where Component Object Model
(COM) left off. It enabled extra features in Internet Explorer but made
it easy for malicious dicks to run code that was automatically
downloaded from an <code>OBJECT</code> tag.</p>

<p>There&#8217;s a word that keeps on getting thrown around: control. An ActiveX
control. What kind of shitty name is that? Is that like the short-lived
Ember.Control? What a control is?</p>

<blockquote><p>ActiveX controls are essentially pieces of software and have access to your entire computer if you opt to install and run them.</p>

<p>An object in a window or dialog box. Examples of controls include push-buttons, scroll bars, radio buttons, and pull-down menus.</p>

<p>ActiveX controls are small programs, sometimes also called &#8220;add-ons,&#8221; used on the Internet. They can make browsing more enjoyable by allowing animation or they can help with tasks such as installing security updates at Windows Update.</p>

<p>These are objects that are like small programs or &#8220;applets&#8221; and a number of Microsoft programs like Office and Internet Explorer (IE) are designed to be able to interact with them. An example is a spell checker. Since Word comes with a spell checker, other Microsoft programs such as Outlook Express can make use of it. In fact, any program with the appropriate interface can use this spell checker.</p></blockquote>

<p>So they&#8217;re plugins / addons. Sometimes they&#8217;ve visible, other times
they&#8217;re hidden. But they were originally used to enhance the
functionality of Internet Explorer to view things like PDFs and
Macromedia Flash. So basically, ActiveX controls are components that
could be reused in many different settings. Building blocks. Yesterday&#8217;s
technology: tomorrow.</p>

<blockquote><p>ActiveX controls are actually not Internet Explorer-only. They also work in other Microsoft applications, such as Microsoft Office.</p></blockquote>

<p>ActiveX increases the attack surface by malicious dicks; even a
well-intentioned but carelessly implemented ActiveX control could
open the door to hackery, such as the Java ActiveX control.</p>

<h3>XSL: Extensible Stylesheet Language</h3>

<h3>document.implementation</h3>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/document.implementation">MDN</a></p>

<p>Returns a DOMImplementation object associated with the current document.</p>

<p><code>document.implementation.createDocument(namespaceURI, qualifiedNameStr, documentType)</code>
creates an XML doc.</p>

<ul>
<li><code>namespaceURI</code>, e.g. &#8216;http://www.w3.org/1999/xhtml&#8217;</li>
<li><code>qualifiedNameStr</code>: qualified name of the document to be created,
which is an optional prefix + the local root element name; if you&#8217;re
creating an html document, you&#8217;ll provide &#8216;html&#8217; because that&#8217;s the
root element name of an html doc.</li>
<li><code>documentType</code>, optional, often just null</li>
</ul>


<p>Many examples use Document.load to load xml data, but it&#8217;s not part of
the <a href="http://www.w3.org/TR/2004/REC-DOM-Level-3-LS-20040407/">Load and Save</a>
spec any more, or it is, but Load and Save is really old?</p>

<p>This spec is/was</p>

<blockquote><p>a platform- and language-neutral interface that allows programs and scripts to dynamically load the content of an XML document into a DOM document and serialize a DOM document into an XML document</p></blockquote>

<h3>Level N</h3>

<p>DOM Level 3 wtf does it mean? I guess it just means a more complex
layering on top of a previous level. Additional levels enhance and
expand scope, while versions are meant to refine, fix issues, etc,
limited to that scope. As DOM Levels increase, features are added that
don&#8217;t conflict with lower DOM features but just add more stuff on top.
So you can just use DOM Level 1 features and never touch anything above,
but those above Levels will never thwart DOM Level 1.</p>

<ul>
<li>DOM Level 0: pre-specification DOM API, e.g. IE3</li>
<li>DOM Level 1: (1998) full specification for HTML/XML doc, partly
implemented by IE5</li>
<li>DOM Level 2: (late 2000) added <code>getElementById</code> and an event model</li>
<li>DOM Level 3: (late 2004) added XPath and keyboard event handling and
support for serializing docs as XML (?)</li>
<li>DOM Level 4: currently being developed, last call working draft
released in Feb 2014.</li>
</ul>


<p>The terminology used as that DOM Level 3 is the latest &#8220;release&#8221;. But
not to be confused with versions&#8230; presumably each level has its own
version.</p>

<h3>Events</h3>

<p>Informed by this <a href="http://en.wikipedia.org/wiki/DOM_Events#DOM_Level_0">Wikipedia article</a></p>

<p>DOM event handling has evolved over the years.</p>

<h4>DOM Level 0 events</h4>

<p>(DOM Level 0 meaning pre-spec DOM).</p>

<ul>
<li>inline, e.g. <code>onclick="alert('shit'); return false;"</code>, which
essentially gets invoked as
<code>(function() { alert('shit'); return false; }).call(clickedElement)</code></li>
<li>traditional; event handlers can be added/removed by script, but only
one event handler could be registered; <code>node.onclick = handler</code>,
<code>node.onclick = newHandler;</code>, etc.</li>
</ul>


<p>Did you know that <code>document.onclick = someFn</code> still works? Ridiculous!</p>

<h4>DOM Level 2 events</h4>

<p><code>addEventListener</code>, <code>removeEventListener</code>, <code>dispatchEvent</code>, along with
<code>stopPropagation</code> and <code>preventDefault</code>.</p>

<p>Fun fact: I thought the third param to addEventListener was some
ActionScript-y thing about weak references, but it&#8217;s actually
<code>useCapture</code>. Capture events occur starting from the root of the DOM
(document) and move toward the event target; any capture event listeners
registered in that direct line will be invokved first and have the
opportunity to <code>stopPropagation</code>.</p>

<p>Fun fact; the ancestor chain of bubbling events is determined before the
event is fired, so that any DOM modifications that happen
(e.g. moving the EventTarget to some other part of the DOM) within an
event handler doesn&#8217;t affect the predetermined chain.</p>

<p><code>event.target</code> refers to the <code>EventTarget</code>; this is the receiver of the
event</p>

<h4>Event Delegation</h4>

<p>From <a href="http://learn.jquery.com/events/event-delegation/">learn.jquery.com</a>:</p>

<blockquote><p>Event delegation allows us to attach a single event listener, to a parent element, that will fire for all descendants matching a selector, whether those descendants exist now or are added in the future.</p></blockquote>

<p>If this feature didn&#8217;t exist, then you would have to do a lot more
manual adding and removing of event handlers as DOM elements were added
and removed, whereas delegation allows you to define an event handler on
a parent node that only fires when the event passes through a child
described by a selector, e.g.</p>

<pre><code>$('#table').on('click', 'td', function() { });
</code></pre>

<p>One of jQuery&#8217;s original APIs for event delegation was <code>.live</code>, e.g.
<code>$('a').live(...)</code>, but this had some issues:</p>

<ul>
<li>The selector eagerly fired when it didn&#8217;t to (perf)</li>
<li>Chaining methods didn&#8217;t work, which is a surprising and bad API,
e.g. $(&#8216;a&#8217;).find(&#8216;p&#8217;).live(&#8216;click&#8217;);</li>
<li><code>.live()</code> events always attached to <code>document</code>, which means events
take the longest and slowest path before being handled, e.g. a click
on an <code>a</code> tag 20 levels deep in the DOM needs to go all the way
through those 20 levels before being handled.</li>
<li><code>click</code> doesn&#8217;t bubble to <code>document</code> on iOS so <code>live</code> can&#8217;t work
without other workarounds, e.g. (cursor:pointer), natively clickable
elements, etc</li>
<li>stopPropagation doesn&#8217;t work since event already propagated to
<code>document</code> by the time <code>live</code> logic fires</li>
<li><code>.live</code> interacted weird with other methods, e.g. <code>$(document).off()</code>
would disable <code>live</code> handlers, even though <code>live</code> selector seemed to
imply some other magic.</li>
</ul>


<p>That&#8217;s why things shifted to <code>delegate</code> and eventually <code>on</code>, which hits
the sweet spot.</p>

<pre><code>`$('#root').on('click', 'a', handler)`
</code></pre>

<p>Benefits of this approach include:</p>

<ul>
<li>&#8216;a&#8217; isn&#8217;t unnecessarily queried up front</li>
<li>Chaining will work as expect (i.e. continued modifications to <code>#root</code>)</li>
<li>No longer throw everything on <code>document</code></li>
<li>Explicit syntax suggests workarounds for iOS</li>
</ul>


<h4>Historical shit</h4>

<p><a href="http://www.quirksmode.org/js/events_order.html">source: quirksmode</a></p>

<p>Netscape 4 had capture only.</p>

<p>Microsoft had bubble only.</p>

<p>jQuery provides event bubbling for all, along with event delegation,
which <em>depends</em> on event bubbling in order to work (the italics are
probably overkill; if you have event capture you can implement event
bubbling&#8230; even if you didn&#8217;t have event capture, you can walk the tree
and implement yourself).</p>

<p>Proof that you can implement it yourself:</p>

<p>http://jsbin.com/tofop/1/edit</p>

<p>Just loop over parentNode until you get there.</p>

<p>jQuery never provided an API for event capturing because it&#8217;s not
possible on old IE. I guess it&#8217;s possible, but you&#8217;d have to introduce
some async-ness, which would probably break other assumptions. So for
IE6, which only supported bubbling, if you wanted something like</p>

<pre><code>$('a').capture('click', handler);
</code></pre>

<p>you would have to first manually walk the tree up to the document,
then refire a fake event back to the target, calling any capture
handlers,</p>

<p>So if all you had was Netscape</p>

<p>Ember depends on jQuery for event delegation. This will probably go away
soon.</p>

<h3>What&#8217;s wrong w iOS anyway?</h3>

<p>Non-native click events don&#8217;t bubble up to document unless</p>

<ul>
<li>the clicked thing is a native clickable, e.g. link or button</li>
<li>the clicked thing has a handler explicitly attached to it, e.g.
onclick= attr or addEventListener on that thing.</li>
<li><a href="http://jsbin.com/xuwuvu/1/edit">example</a></li>
</ul>


<h3>W3C: World Wide Web Consortium</h3>

<p>The standards organization founded and led by Tim Berners-Lee.</p>

<p>W3C TAG is the Technical Architecture Group in charge of documenting and
building consensus around principles of Web architecture. People whose
names my dumb brain should remember on the TAG:</p>

<ul>
<li>Yehuda Katz</li>
<li>Domenic Denicola</li>
<li>David Herman</li>
</ul>


<p>Not to be confused with TC39, which standardizes ECMAScript. Membership
can be determined by those present in the
<a href="https://github.com/rwaldron/tc39-notes/blob/master/es6/2014-04/apr-9.md">meeting notes</a></p>

<p>So W3C Tag reviews things like
<a href="https://dvcs.w3.org/hg/quota/raw-file/tip/Overview.html">quote management</a>
APIs and stuff that browsers need to expose, and TC39 handles language
features for ECMAScript.</p>

<h3>XSLT</h3>

<p>OMG so many dumb things to learn. Here&#8217;s a
<a href="http://jsbin.com/davew/1/edit">JSBin</a> for farting around w
XSLT transformations. Kinda reminds me of <code>&lt;content select="asd"&gt;</code> in
Web Components land, though probably way more complicated.</p>
]]></content>
  </entry>
  
</feed>
