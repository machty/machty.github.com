
<!DOCTYPE HTML>
<html>
<head>
	<script data-cfasync="false" type="text/javascript" src="//use.typekit.net/axj3cfp.js"></script>
	<script data-cfasync="false" type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<meta charset="utf-8">
	<title>Ember.js, random thoughts, journal  | machty's thoughtz</title>

<meta name="author" content="Alex Matchneer"> 

<meta name="description" content="I'm on Ember core and contribute to lots of stuff prefixed with "Em"."> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="machty's thoughtz" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script type="text/javascript" src="/javascripts/jquery.fancybox.pack.js"></script>

<script language="Javascript" type="text/javascript">
$(document).ready(
  function() {
    (function($) {
      $(".fancybox[data-content-id]").each(function() {
        this.href = $(this).data('content-id');
      });
      $(".fancybox").fancybox({
        beforeLoad: function() {
          var el, 
              id = $(this.element).data('title-id');

          if (id) {
            el = $('#' + id);

            if (el.length) {
              this.title = el.html();
            }
          }
          if ($(this).data('content')) {
            this.content = $(this).data('content');
          }
        },
        helpers: {
          title: {
            type: 'inside'
          }
        }
      });
    })(jQuery);
  }
);
</script>

	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">machty's thoughtz</a></h1>
<h4>Ember.js, random thoughts, journal</h4>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:machty.github.com">
			</form>
		</div>
	</div>
</nav>


</header>

	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/10/faily-burnhole/">
		
			Faily Burnhole</a>
	</h2>
	<div class="entry-content">
		<h2>(postgres) Transactions</h2>

<p>http://www.postgresql.org/docs/8.3/static/tutorial-transactions.html</p>

<ul>
<li>group sequence of SQL into atomic (all-or-nothing) operations</li>
<li>useful for preventing invalid state of a crash occurs in the middle of
a sequence of queries</li>
<li>also, transactions are isolated from each other; one in-progress
transaction won&#8217;t see the partially complete transaction process of
another</li>
<li>postgres implicitly wraps every statement in a transaction block if
you haven&#8217;t.</li>
<li>transaction is <code>BEGIN</code> followed by <code>COMMIT</code> or <code>ROLLBACK</code>.</li>
<li>savepoints allow for finer granularity:

<ul>
<li><code>BEGIN</code></li>
<li><code>UPDATE ...</code></li>
<li><code>SAVEPOINT wat</code></li>
<li><code>UPDATE ...</code></li>
<li><code>ROLLBACK TO wat</code></li>
<li><code>UPDATE ...</code></li>
<li><code>COMMIT</code></li>
</ul>
</li>
</ul>


<p>So how can I use this for nested world environments&#8230;</p>

<h2>Sharing raised error with <code>ensure</code> block</h2>

<p>Saw a Ruby thing I hadn&#8217;t seen before at
https://github.com/rails/rails/blob/master/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb#L186-L205</p>

<p>Basically, a <code>rescue</code> must precede an optional <code>ensure</code> block, but whats
cool is that the error caught be the rescue block is available to the
<code>ensure</code> block. Stripped down, the basic construct is</p>

<pre><code>def wat
  do_something_that_might_fail
  rescue Exception =&gt; e
    # do some error handling
  ensure
    # do generic stuff
    if e
      # continue to do some error handling
    end
end
</code></pre>

<h2>ramdisk + ember-cli</h2>

<p>tmpfs is a form of ramdisk. ramdisk is just a general purpose term for
when a virtual file system is provided but the data just lives on memory
rather than hard disk.</p>

<p>Some questions I need to answer:</p>

<ul>
<li>are there different rules about paging when you create a ramdisk? Does
it prevent its own memory from paging to disk any more than other
processes&#8217; virtual memory?</li>
<li>can you control paging in general? (other than going out of your way
to regularly read memory)</li>
</ul>


<p>My ember-cli builds for a decently complex project are about 2s, which
is waaaay better than the 20s they were a month ago. But I can get my 2s
down to 1s my mounting a ramdisk and symlinking my tmp folder to it:</p>

<pre><code>diskutil erasevolume HFS+ 'RAM Disk' `hdiutil attach -nomount ram://8388608`
rm -rf tmp
mkdir /Volumes/RAM\ Disk/tmp
ln -s /Volumes/RAM\ Disk/tmp tmp
</code></pre>

<h2>Photoshop and tmpfs</h2>

<p>http://www.tekrevue.com/tip/how-to-create-a-4gbs-ram-disk-in-mac-os-x/#comment-904649071</p>

<p>This comment speaks of the diminishing returns of using a ramdisk as
scratch space for Photoshop now that Photoshop is 64bit.</p>

<p>If your system is 32bit, it means running processes can only access
virtual mem addresses from 0 to 2<sup>32-1</sup> (0xFFFFFFFF or 4294967293).
On 64 bit systems, that max address is doubled to 0xFFFFFFFFFFFFFFFF, or
1.84 * 10<sup>19.</sup> If you had more than 4gig of RAM on a 32bit system, each
process would still be limited to a max of 4gig memory usage simply due
to the fact that it can&#8217;t reference memory addresses higher than 4gig.
But Photoshop often needs more than 4gig, so what&#8217;s the solution?
Scratch disks.</p>

<p>Scratch disks are like virtual memory implemented in user space. If you
need to store more temporary data than you can put into memory, just
throw it on scratch disk. The problem is that scratch disks</p>

<p>I could totally be bullshitting right now. I could be wrong. But seems
right? Less wrong?</p>

<h2>ln</h2>

<p>I never remember the argument order for <code>ln</code>.</p>

<p>It is FUCKING LEFTWARD. The thing you create on the right points to the
thing on the left.</p>

<pre><code>ln EXISTING_THING LINK

&lt;-------------
</code></pre>

<p>The thing that confused me was that i kept thinking <code>-s</code> was an option
that accepted an argument. It is not! It&#8217;s just an argless option. <code>ln</code>
always has the format of new thing on right points to left. NEVER
FORGOT.</p>

<h2>Dockyard&#8217;s fixtory</h2>

<p>https://github.com/dockyard/fixtory</p>

<p>Convenient way to populate groups of fixtures, maintain references to
the created instances, etc.</p>

<h2>Execute/search permission</h2>

<p>http://content.hccfl.edu/pollock/AUnix1/FilePermissions.htm</p>

<p>Directories have different levels of &#8220;readability&#8221; based on their read /
execute flags. A file record within a directory has a name and an inode.</p>

<p>You can read names of files in a directory (<code>ls</code>) if you have read
permissions on that directory, and permissions denied if not.</p>

<pre><code>$ ls wat
lol
$ chmod -r wat
$ ls wat
ls: wat: Permission denied
</code></pre>

<p>If you want to access the inode in any way, like to read file
attributes (permissions et al), or to read its contents, you&#8217;ll need
execute (search) permissions on the directory.</p>

<pre><code>$ chmod +r wat
$ chmod -x wat
$ ls wat
lol
$ ls -l wat
ls: wat: Permission denied
$ ls -i wat
ls: wat: Permission denied
$ cat wat/lol
cat: wat/lol: Permission denied
$ chmod +x wat
$ ls wat
lol
</code></pre>

<p>Then of course you need file read permissions to access the contents.</p>

<p>So if you&#8217;re using absolute file paths, every directory along the way
needs execute (search) permissions. But in the unusual case that you&#8217;re
able to <code>cd</code> into a directory (thus setting the process&#8217;s current
working directory, something the kernel tracks to control where relative
file lookups occur from) before a parent directory&#8217;s read permissions
are revoked, you&#8217;re grandfathered in if you&#8217;re using relative file perms
from that point on, unless of course the path you provide steps out and
in again.</p>

<pre><code>$ chmod -x ..
$ cat ../inner/woot
../inner/woot: Permission denied
$ chmod +x ..
$ cat ../inner/woot
lol
</code></pre>

<p>Basically, there&#8217;s no concept of deeper and deeper folders, just
following pointers (<code>..</code> and <code>.</code> included), and pointers have permissions
that must be adhered to in order to traverse them.</p>

<h2>dev id and inode</h2>

<p>Device id + inode uniquely identify a file across all file systems.</p>

<p>If the file itself is a special device file, the inode for that file
contains the major/minor id of the device.</p>

<h2><code>utimes(2)</code> for manually changing access/modify timestamps</h2>

<p>You can change the last modified time and last accessed time of a file.
One use case is how <code>tar</code> and <code>unzip</code> preserve the original timestamps
of archived files when they are unarchived.</p>

<p><code>ctime</code> is changed to now when you run <code>utimes</code>.</p>

<h2>group ID of newly created files</h2>

<p>This is governed by 1. how you&#8217;ve configured the file system and 2.
whether set-group-id is set on parent directory.</p>

<p>I think this is one of the rare cases where set-group-id is meaningfully
used on files rather than directories.</p>

<h2>File deletion doesn&#8217;t require file permissions</h2>

<p>You can delete a file without having any permissions on it, since all
you&#8217;re doing is modifying a parent directory.</p>

<h2>Why not have slashes for directories by default?</h2>

<pre><code>$ ls
inner   lol
$ ls -F
inner/  lol
</code></pre>

<p>Wouldn&#8217;t that slash on <code>inner/</code> be convenient to always display?
Why isn&#8217;t that a default?</p>

<p>Answer: because knowing whether a file is a normal file or a directory
requires execute/search permissions on the directory that file lives in.
You can list file/directory names with next to no permissions, but once
you start looking at inode information (such as whether a file is a
normal file or a directory), you&#8217;ll need search/execute perms, and the
default behavior of <code>ls</code> is much less likely to get permission denied
errors.</p>

<p>So thinketh I. Could be wrong.</p>

<h2>Accessing files w/o read perms</h2>

<p>Even if a directory has no read permissions, if it has execute
permissions, then files inside can still be accessed, but their names
must be known ahead of time since you won&#8217;t be able to list the file
names in that directory.</p>

<p>Seems crazy, but useful for when you have a public directory and don&#8217;t
want to list all the contents.</p>

<p>I guess this also means it&#8217;s not possible to hide a single
file/directory within a directory that has read permissions; i.e. if you
can list one file in a directory, you can list them all.</p>

<p>Neat tidbit: there is (was?) a process accounting flag ASU that&#8217;s set if
the process made use of superuser privileges, and the kernel will only
check superuser permissions last in case it can&#8217;t get privileges any
other way than so that it can avoid unnecessarily setting ASU.</p>

<p>It&#8217;s possible to wind up in a situation where an owner has less access
than a group s/he belongs to, due to the fact that the kernel
permissions algorithm will stop once it finds a matching user or group;
it won&#8217;t try to find read (etc) permissions in all matching permission
bits, it&#8217;ll just check the first set of bits it matches.</p>

<p>ACLs (Access Control Lists) allow for per-user and per-group file permissions.</p>

<h2>Sticky bit</h2>

<p>Used to be a signal for a process to stay in swap, now it&#8217;s a signal
set on directories that, when set, prevents non owners and non write
accessors from being able to delete files they don&#8217;t own.</p>

<h2>umask</h2>

<p>A mask, attached to a process, that negates certain permissions.</p>

<h2>EA: extended attrs</h2>

<p>User EAs can only be applied to files and folders, because</p>

<ul>
<li>symlinks have no meaningful permissions, which means anyone in the
world could clutter symlink w EAs if it were possible</li>
</ul>


<h2>executable permissions</h2>

<p>If no one has executable permissions on a file, then not even <code>sudo</code> can
get it to run as such.</p>

<pre><code>$ chmod -x exe
$ ./exe
-bash: ./exe: Permission denied
$ sudo ./exe
sudo: ./exe: command not found
$ chmod o+x ./exe
$ sudo ./exe
wat
</code></pre>

<p>I guess another way of thinking about it is that a file isn&#8217;t an
executable if no one has permissions to it.</p>

<h2>Processes, cwd, directories, etc</h2>

<p>Kernel tracks two attributes on running processes:</p>

<ul>
<li>root: the point from which absolute paths are looked up. Most
processes have <code>/</code></li>
<li>cwd: the directory from which relative paths are looked up</li>
</ul>


<p>(you can use <code>chroot</code> to change the root directory for a process)</p>

<p>A directory is different from a file in that 1) it is specially marked
as a directory in its inode attrs (remember this is why <code>ls -F</code>
requires execute permissions on the parent directory), and 2)
its contents are a table of filenames (read perms) and inodes
(execute/search perms).</p>

<p>You can&#8217;t use <code>read</code> on a directory, you must use other system calls,
hence <code>cat: wat: Is a directory</code>. Basically, the kernel restricts you to
certain syscalls to modify the directory; you can&#8217;t <code>read</code> / <code>write</code> it
the way you would a normal file. The error that gets thrown is <code>EISDIR</code>.</p>

<h2>inode table</h2>

<p>A filesystem has a root inode table that inode entries in directories
will refer to. The root inode table has the following features:</p>

<ul>
<li>index 0 is unused since a 0 is how directory inodes signal that an
entry is unused</li>
<li>index 1 tracks bad blocks on the disk</li>
<li><p>index 2 is <code>/</code></p>

<p>  $ ls -di /
  2 /</p></li>
</ul>


<p>Woot woot! This stuff is so awesome.</p>

<p>So it&#8217;s in this shared inode table that perms are stored. So if you hard
link, any changes to the permissions of one link affects the other:</p>

<pre><code>permstest :: touch shit1 &amp;&amp; ln shit1 shit2
permstest :: ls -l shit*
-rw-r--r--  2 machty  staff  0 Oct 14 10:40 shit1
-rw-r--r--  2 machty  staff  0 Oct 14 10:40 shit2
permstest :: chmod -rwx shit1
permstest :: ls -l shit*
----------  2 machty  staff  0 Oct 14 10:40 shit1
----------  2 machty  staff  0 Oct 14 10:40 shit2
</code></pre>

<p>TODO: Is this the same w ACLs permissions?</p>

<p>Hardlinks not supported by MS VFAT, but yes to NTFS.</p>

<p>inodes don&#8217;t have filenames&#8230; that&#8217;s only in the directory&#8217;s table;
remember that gzip and gunzip (and some other utilities) share the same
inode, and depending on <code>argv[0]</code>, do different things:</p>

<pre><code>$ ls -i `which gunzip` `which gzip`
343041 /usr/bin/gunzip  343041 /usr/bin/gzip
</code></pre>

<p>The <code>rm</code> algorithm is simple: decrement the inode counter, and if 0,
then deallocate. Reference counting, bitchez.</p>

<p>Based on the above layout, you can&#8217;t (easily) get the filename of an
open file, because multiple files might point to that inode, not to
mention that even if you wanted to loop through the file system&#8217;s inode
table, you still wouldn&#8217;t have the file name, just a matching inode
number.</p>

<p>Hardlinks can&#8217;t be created cross-file-system (since they&#8217;re just inode
numbers. symlinks can handle this though).</p>

<p>Hardlinks can&#8217;t (cept Mac due to Time Machine shit) link to directories
due to circular dependencies (e.g. a nested folder hardlinking to an
ancestor folder).</p>

<p>Symlinks can be displayed with trailing <code>@</code> via <code>ls -F</code>. They don&#8217;t bump
the inode counter. They can be created to point to nothing, or can have
their target files deleted (dangling). Like all the other extra data
displayed by <code>ls -F</code>, search perms are needed on the parent directory.
Symlinks have a symlink file type stored in the inode.</p>

<p>Tools are smart enough to avoid cirular dependencies when symlinks link
to directories, because they actually can know they&#8217;re dealing with a
symlink; a multi-hardlink doesn&#8217;t look any different than anything else.</p>

<pre><code>$ ln -s ./circle ./circle
$ ./circle
-bash: ./circle: Too many levels of symbolic links
</code></pre>

<p>For long ass symlinks (> 60 bytes), a data block (where file data is
normally stored) is used to store the target link. But lots of file
systems (<code>ext2</code>+ et al) have an optimization where if the target is less
than 60 bytes, the target is written right into the inode structure
where the data block pointers are usually kept. I tried reproducing this
with a test case of a bunch of <code>stat</code> syscalls on a small-target symlink
and a 60+ byte symlink and it didn&#8217;t make a difference, but that could
just be due to disk cache on behalf of the kernel; the kernel kept the
inode data in RAM so it was just as fast, but if the cache was cold then
symlink lookups should be a lot faster.</p>

<h2>unlinks don&#8217;t complete while files are open</h2>

<p>If there are open file descriptors, an unlinked file won&#8217;t be totally
deleted. Hence the common practice to create and unlink a temporary file
so that you&#8217;re guaranteed when the handle closes, the file will be
totally deleted. This also makes it possible to happily unlink a file
and not worry whether someone else is using it&#8230; but don&#8217;t we sometimes
get file-in-use errors, like &#8220;can&#8217;t delete this file since it&#8217;s being
used be process X&#8221; stuff? Ah, you can delete a file out from under
someone else. They might still save it if they&#8217;ve buffered the data
(think Vim&#8217;s OMG THE FILE NO LONGER EXISTS warning).</p>

<h2>NTFS vs FAT32</h2>

<p>Windows 7 prefers NTFS. Earlier versions prefer FAT. FAT doesn&#8217;t have
security-related features (I&#8217;m guessing permissions?). FAT was
originally designed for floppies, and then used on hard drives. It&#8217;s
still often used for thumb drives.</p>

<h2>Transducers</h2>

<p>http://blog.cognitect.com/blog/2014/8/6/transducers-are-coming</p>

<p>http://jlongster.com/Transducers.js&#8211;A-JavaScript-Library-for-Transformation-of-Data</p>

<p>God damn it. Guess I have to learn a new thing.</p>

<h2>Reentrant</h2>

<p><a href="wiki">http://en.wikipedia.org/wiki/Reentrancy_(computing)</a></p>

<p>Reentrancy means the function can be interrupted and re-entered without
harm. Actually I think more accurately it means it can be re-entered,
even within the same thread, without causing issue. A function can be
threadsafe and not re-entrant. e.g.</p>

<pre><code>trap :INT do
  puts "int"
end
Process.kill :INT, Process.pid
puts "boom"
</code></pre>

<p>This yields a <code>deadlock; recursive locking (ThreadError)</code> every time,
the same that would happen if you tried to double lock a mutex within
the same thread. The reason is that <code>puts</code> calls <code>write</code>, and <code>write</code>
mutexes around Ruby&#8217;s IO buffer. The signal handler doesn&#8217;t get called
synchronously at <code>Process.kill</code>, but for whatever reason, the kernel
decides to fire the signal handler during <code>write</code> in <code>puts "boom"</code>,
after the write mutex has already been locked. Then the signal handler
runs, tries to the do the same lock, and BOOM. Weird shit. But proof
that <code>puts</code> and <code>write</code> aren&#8217;t re-entrant even though they&#8217;re thread
safe. If you did <code>$stdout.sync = true</code>, they would be reentrant though
and the above error would go away.</p>

<h2>Process cwd</h2>

<p>Hmmm a process&#8217;s cwd does contain a pathname to the cwd; I thought it&#8217;d
just be some kind of inode pointer and not know the name? That said, the
beginning of the path is truncated if there&#8217;s not enough space, though
this is probably rare. That said, you can <code>readlink</code> the symlink at
<code>/proc/PID/cwd</code> (this doesn&#8217;t exist on Mac though).</p>

<h2><code>chroot</code> jail</h2>

<ul>
<li>FTP uses this so that anonymous users can&#8217;t just browse the whole
system</li>
<li>Linux doesn&#8217;t have hard-linked directories, but some UNIX varieties
do, and a hardlink outside of a <code>chroot</code> jail will compromise the jail</li>
<li>Most programs can&#8217;t run in <code>chroot</code> jail because they rely on
dynamically linked libraries, and the link targets are often absolute
and expect <code>/usr</code> to live.</li>
</ul>


<h2>Symlink perfs</h2>

<p>I was enouraged by the fact that on ext2+, symlinks whose targets are
less than 60 chars long get written into the inode rather than into a
separate data block (it&#8217;s basically written where the data block
pointers are usually saved, which amounts to ~60 bytes). Sooo I did a
quick benchmark to see if ember-cli would benefit, and alas (and go
figure?) 60 char perfs that apply to ext2 (and 3 and 4) don&#8217;t apply to
OS X&#8217;s HFS+.</p>

<p>I ran a test creating 100,000 symlinks, one where each symlink target
was 59 chars, and another with 60, and the difference is dramatic:</p>

<pre><code>Linux, ext4, 60 char symlink, 100,000

real    0m19.642s
user    0m0.468s
sys     0m3.988s

Linux, ext4, 59 char symlink, 100,000

real    0m2.005s
user    0m0.360s
sys     0m1.436s
</code></pre>

<p>I&#8217;m sad, because most ember-cli / broccoli symlinks are above the 60
limit, and this would have brought us some insane perfs, but alas alas
alas, most people do ember-cli work on OS X, not Linux. Oh god damn
well.</p>

<h2>ARS Technica on why HFS+ blows</h2>

<p>http://arstechnica.com/apple/2011/07/mac-os-x-10-7/12/#file-system</p>

<ul>
<li>HFS is from 1985</li>
<li>HFS+ (aka Mac OS Extended) released in 1998.</li>
<li>OS X (2001) unfortunately kept HFS+ around even though it sucks</li>
</ul>


<p>So yusuck:</p>

<ul>
<li>16 bit processing resolution in Mac&#8217;s implementation (Motorola 68000
hangover). Not really sure what this means, not sure why if the data
is 32+ bit why 16 is the resolution? So many things I don&#8217;t know.</li>
<li>Time resolution of HFS+ is only a second, shitty for file timing logic
in <code>make</code>, et al. Most modern fs&#8217;s have nanosecond resolution.</li>
<li>Global file lock on metadata; only one process can write to a file at a time. NOPE
that&#8217;s obviously incorrect. It means only one process can update the
file system at a time&#8230; I don&#8217;t understand? Can&#8217;t add multiple files to
a directory at the same time? Metadata?</li>
<li><p>No sparse files. The following ruby code will instantly eat a gig on
HFS+. On ext2 you could still use that gig space for other files, and
intermediate blocks would only be allocated as needed:</p>

<p>  File.open(&#8216;bigassfile_DELETE_ME&#8217;, &#8216;w&#8217;) do |f|</p>

<pre><code>f.seek(1000000000)
f.puts('l')
</code></pre>

<p>  end</p></li>
</ul>


<p>Result: Finder reports -=1gig of freespace, as expected (if there are no
sparse files). Weird though: <code>ls -l</code> reports only 87 block usage; I
would have expected a lot more give the fact that the file system is
allegedly allocating a bunch of zeroes? ANSWER: I think it&#8217;s because OS
X uses a VFS that pretends to support sparse files over HFS+, which
doesn&#8217;t, but I need to confirm this.</p>

<ul>
<li>Hard links to directories is supported, which is kinda weird.
Internally it works by hiding them in hidden a hidden directory (my
guess is to avoid cycles?)</li>
<li>No concern about data integrity. Easy for meta data to get corrupted.
Report showed that ~30% of HFS+ systems had mismatched checksum. Data
loss likely.</li>
</ul>


<h2>Endianness</h2>

<p>Not to be confused with &#8220;bit-endianness&#8221;, the atomic unit Endianness
as people normally talk about it is the byte, rather than the order of
bits. Endianness is concerned with the byte order in a &#8220;word&#8221; (the unit
of a CPU processing, e.g. 32 bit machine vs 64 bit machine refers to the
word size and has implications on the size limits of integers, memory
addresses, etc.). Whether the most significant bits appear at the
beginning or end of a word is the endianness, big-endian or
little-endian. You have to care about this stuff if you&#8217;re manually
converting bytestreams between different systems with different
endianness. Some processors are bi-endian.</p>

<h2>POODLE attack</h2>

<p>https://tools.ietf.org/html/draft-ietf-tls-downgrade-scsv-00</p>

<p>SSL 3.0 preceded TLS 1.0 and has vulnerabilities that allow an attacker
to see plaintext communication. Some clients go beyond the TLS handshake
specifications and will fall back to SSL 3.0 if a TLS handshake fails in
order to support the case where they&#8217;re talking to a legacy ass server
that runs SSL 3.0. A man in the middle can fuck with a handshake,
causing it to fail, and causing the TLS client to try communication with
SSL 3.0, and many servers supporting legacy SSL 3.0 will just happily
fall back to that, exposing the connection to SSL 3.0&#8217;s weaknesses.</p>

<p>The solution is for clients falling back to SSL 3.0 to send a backwards
compatible cipher suggestion that newer patched servers will look out
for and will treat as a signal that &#8220;this SSL 3.0 connection attempt is
only a fallback, and you shouldn&#8217;t accept this and start speaking in
3.0&#8221;. Legacy servers will just see it as a suggested cipher that they
don&#8217;t understand and will just choose another cipher that they do, and
continue communicating in their legacy 3.0 way. Case in point: upgrade
your servers.</p>

<p>The name for the patch is the TLS Signaling Cipher Suite Value (SCSV).</p>

<h2>inotify config</h2>

<p>On Linux you can configure aspects of <code>inotify</code> by writing values in to
various files in <code>/proc/sys/fs/inotify</code>. Question: why this format of
config? Why a single value in each? Why not <code>sysctl</code>?</p>

<h2>ssh escape char</h2>

<p><code>~</code> at the beginning of a line is an ssh escape char; if your connection
is hung, you can do <code>~.</code> (at the beginning of a line; you can force this
by pressing enter) and that&#8217;ll disconnect.</p>

<pre><code>Supported escape sequences:
 ~.   - terminate connection (and any multiplexed sessions)
 ~B   - send a BREAK to the remote system
 ~C   - open a command line
 ~R   - request rekey
 ~V/v - decrease/increase verbosity (LogLevel)
 ~^Z  - suspend ssh
 ~#   - list forwarded connections
 ~&amp;   - background ssh (when waiting for connections to terminate)
 ~?   - this message
 ~~   - send the escape character by typing it twice
</code></pre>

<p>Mmmm command line, this seems interesting if you&#8217;re using ssh for
proxying:</p>

<pre><code> ~C      Open command line.  Currently this allows the addition of port for-
         wardings using the -L, -R and -D options (see above).  It also
         allows the cancellation of existing port-forwardings with
         -KL[bind_address:]port for local, -KR[bind_address:]port for remote
         and -KD[bind_address:]port for dynamic port-forwardings.  !command
         allows the user to execute a local command if the PermitLocalCommand
         option is enabled in ssh_config(5).  Basic help is available, using
         the -h option.
</code></pre>

<h2>Signals</h2>

<p>Signals are sync; between generation and delivery, they are pending.
Most often sent immediately if running, or once it&#8217;s next scheduled to
run. Signals can be temporarily blocked by signal masks til the process
is ready to handle them (to prevent rude interruptions). Signals can
yield the following reponse from processes:</p>

<ul>
<li>ignore: kernel never tells process about it</li>
<li>terminate: &#8220;abnormal&#8221; (non <code>exit</code>) termination</li>
<li>core dump and terminate: core dump is image of virtual memory</li>
<li>stop execution (suspend)</li>
<li>resume execution</li>
</ul>


<p>I guess the thing I&#8217;ve learned here is that by setting signal masks,
you&#8217;re telling the kernel ahead of time what should happen when signals
are sent to this process, rather than setting some process-level
handlers that server as callbacks when these signals arrive;
particularly ignore &#8211; I thought it&#8217;d still make it to some low level
library in the process, but sounds like it&#8217;s rather just the kernel
knowing ahead of time not to even send it.</p>

<p>You can&#8217;t tell a signal that doesn&#8217;t by default terminate/core dump to
terminate/core dump, but you can install a signal handler and then call
<code>abort()</code> or whatever to send yourself a signal that <em>will</em> cause such a
thing to happen.</p>

<p>On Linux you can look up a process&#8217;s signal mask via <code>/proc/PID/status</code>.
You can also use <code>ps -p $$ -o sigmask,sig</code> to get info about signal
masks.</p>

<p><code>SEGV</code> means segmentation violation.</p>

<p><code>SIGBUS</code> is like <code>SIGSEGV</code> but in very particular situations, such as
reading past the end of a memory mapped file. BUS is hipster SEGV.</p>

<p>Send signals with <code>kill</code> (whose name is a hangover from a time in which
most if not all signals terminated a process). Different <code>pid</code> values do
different things:</p>

<ul>
<li>positive: send signal to pid</li>
<li><code>0</code>: send signal to processing group of calling process, including
calling process</li>
<li><code>&lt; -1</code>: send signal to process group dilineated by the absolute value of
the supplied pid</li>
<li><code>-1</code>: send to all processes you have permission to send to, excluding
<code>init</code>/<code>launchd</code> (pid 1) and the calling process. AKA broadcast
signals.</li>
</ul>


<p><code>init</code>/<code>launchd</code> can only be sent signals for which it has signal
handlers, to prevent accidental killing of this precious process.</p>

<p><code>CAP_KILL</code> is the privilege that allows a process to send a signal to
whatever.</p>

<p><code>SIG_CONT</code> is special in that it can be sent by unprivileged processes
to any process in the same session to allow for job-control shells to
restart stopped jobs that have changed their user IDs.</p>

<p>Null signal 0 can be used to test if a process exists and we can send a
signal to it. Of course you might troll yourself given that pids are
recycled.</p>

<p>Plain ol (non-realtime) signals don&#8217;t queue; they just internally set a
bit in the kernel and fire next time that process runs. This is why
multiple signals fired very quickly might get coalesced into one</p>

<h2>How to check if process is still running</h2>

<ul>
<li>(for child processes) <code>wait</code></li>
<li>semaphores and exclusive file locks; if you know a process locks a
file, and you can acquire the lock or semaphore, you know it must be
dead. I&#8217;m guessing pidfiles work this way?</li>
<li><code>stat</code> <code>/proc/PID</code>.</li>
<li>IPC sockets go dead, etc</li>
</ul>


<h2>async-signal-safe</h2>

<p>A function is async-signal-safe if</p>

<ol>
<li>it&#8217;s reentrant</li>
<li>it can&#8217;t be interrupted by signal handler</li>
</ol>


<p>Signal handlers should ideally only call async-signal-safe functions.
Note that if you have a signal handler installed for multiple signals,
or if you have <code>SA_NODEFER</code>, a handler function might get simultaneously
and might not be reentrant relative to itself if it mucks with globals,
even if the main app code doesn&#8217;t touch those globals.</p>

<p>In C-land (and Java) you can use the volatile keyword to prevent
variables from living in registers, or at least guaranteeing that a
write to a variable goes all the way to memory, which is an important
guarantee for when threads share and write to a global variable.</p>

<p>In JRuby, the Atomic gem is useful as a lock-free test-and-set way of
performing an update to a value, and detecting/retrying if someone else
interrupted your operation.</p>

<p>http://moonbase.rydia.net/mental/blog/programming/atomic-operations-in-ruby.html</p>

<p>Parallelism is moronically hard.</p>

<h2>Signal handler recovery</h2>

<p>You can do <code>setjmp</code> and <code>longjmp</code>&#8230; cray crqy.</p>

<p>When the kernel runs a handler, it adds a bit to the <code>sa_mask</code> and then
removes it when handler returns, so if you <code>longjmp</code>, you need to make
sure to unset it. (Presumably NODEFER prevents this bit from being set,
allowing the handler to be called multiple times?)</p>

<h2>Signal Stack</h2>

<p>Processes have a signal stack separate from the regular stack for
running signal handlers. You can use <code>sigaltstack</code> to change it to some
preallocated region, useful for when you want to catch SIGSEGV on a
stack overflow (which means there&#8217;s no more room on the process stack
for a signal frame/stack).</p>

<h2>Interrupted syscalls</h2>

<p>Blocking reads are syscalls, and if a signal hits an app during such a
syscall, when the signal handler returns and normal process flow
continues, that syscall will yield an <code>EINTR</code>. In Ruby this results in a
<code>Interrupt &lt; SignalException &lt; Exception</code> being raised. So you have to
jump through some hoops, put things in loops, to handle/ignore <code>EINTR</code>
on blocking syscalls. Orrr you can use <code>SA_RESTART</code> when establishing
signal handlers w <code>sigaction</code> so that the kernel automatically restarts
interrupted syscalls post signal handler.</p>

<p>Just realized something: on Ruby, if you don&#8217;t trap a (non-terminating)
signal handle, it&#8217;ll fire as an exception that you can caught. That&#8217;s
crazy. This must mean Ruby internally traps all trappable signals and
then checks them against any registered trap handlers in Rubyland.</p>

<h2>Framework blackboxing</h2>

<p>Exceptions in blackboxed frameworks don&#8217;t pause. So you can add
blackboxed frameworks in Chrome inspector options to ignore a framework
that keeps throwing shit. Probably other thins too; TODO: research!</p>

<h2>Cryptonomicomicon</h2>

<p>Page 17.</p>

<p>lambent: glowing, gleaming, or flickering with a soft radiance</p>

<p>gnomon: the projecting piece on a sundial that shows the time by the
position of its shadow.</p>

<h2>Why <code>sysctl</code>?</h2>

<p>In my Linux learnings I was curious as to why some settings seemed to be
stored in files while others seemed to be stored via separate utilities
like <code>sysctl</code>. Turns out <code>sysctl</code> is just a wrapper around <code>/proc/sys</code>,
and the setting variable names e.g. <code>a.b.c.d</code> would map to
<code>/proc/sys/a/b/c/d</code> and the setting would be the contents of that file.</p>

<p>So as far as global structures go, I know about:</p>

<ul>
<li>Environment variables</li>
<li>Shell variables (basically non-exported env vars, don&#8217;t get shared
with child processes).</li>
<li>Shell settings (e.g. ulimit, a per-shell set of defaults used when
invoking child processes <em>from that shell</em>; it&#8217;s not like you&#8217;re
setting system-wide settings when you set <code>ulimit</code>)</li>
<li><code>procfs</code></li>
<li>Probably lots more file based stuff I&#8217;m not thinking of. If it&#8217;s
really system-wide global stuff, it must live in a file somewhere,
right? Everything is a file?</li>
</ul>


<h2><code>TASK_UNINTERRUPTIBLE</code></h2>

<p>A risky process state, usually for operations that are quick to
complete, like waiting for a syscall to finish flushing data to disk,
but if there&#8217;s some issue, NFS or kernel bug, it might result in a hung
task that cannot be killed without a system restart. Another state,
<code>TASK_KILLABLE</code>, was added to prevent this, and it was first applied to
hung NFS.</p>

<h2>Hardware signals</h2>

<p>Linux force-delivers hardware signals even if they&#8217;re set to ignore.
Returning from a signal handler means undefined behavior because likely
the machine instruction that caused the interrupt is going to be
retried, likely causing an infinite loop. You need to <code>_exit</code> (because
<code>exit</code> flushes stdio buffers which might be locked and cause problems,
not to mention that <code>exit</code> fires <code>onexit</code> hooks) or do a <code>siglongjmp</code> to
guarantee that you&#8217;re skipping over the broke ass machine instruction.</p>

<h2>Timers</h2>

<p>3 types of timers per process: real (wall clock), virtual (user CPU),
and profile (user+kernel).</p>

<p>You can set timers on read operations by omitting <code>SA_RESTART</code> from the
<code>SIGALRM</code> registration.</p>

<h2><code>sleep</code></h2>

<p>This could be implemented otherwise with <code>sigsuspend()</code> (which allows
you to specify a temporary signal mask and block until a signal arrives
to wake it up).</p>

<p>You can use <code>sleep</code>, or <code>nanosleep</code>. <code>nanosleep</code> is limited by
resolution of software clock which uses units of time called jiffies&#8230;?
Jiffies are the amount of time the kernel lets a process execute, in HZ.
For a long time it was 100 HZ. So a jiffy was 1% of a second, or 10ms.
That seems crazy big! Maybe not? But if video games wanna run at 60 fps,
and they have to share the CPU with other things, they&#8217;re gonna need
larger jiffy. Because if the video game is alternating with only a
single other process (and in real life it should be many other
processes), then it couldn&#8217;t achieve more than 50 fps. Soooo sounds like
there&#8217;s something I don&#8217;t understand. The Jiffies did get smaller.</p>

<h2>SSLMate</h2>

<p>Buy SSL certs from your terminal. Why the fuck not?</p>

<p>https://sslmate.com/</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-10T10:24:00-04:00" pubdate data-updated="true">Oct 10<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/06/crowley-journal/">
		
			Crowley Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Comptroller</h2>

<p>Basically the CFO of public institutions. In charge of audits,
accountability, etc.</p>

<h2>Fetch remote branch</h2>

<p>http://stackoverflow.com/questions/945654/git-checkout-on-a-remote-branch-does-not-work</p>

<p>I was burned by this.</p>

<p>Basically, I had <code>origin</code> in the <code>+fetch</code> section when I wanted the new
branch in there</p>

<pre><code>fetch = +refs/heads/*:refs/remotes/origin/*
</code></pre>

<p>TODO: understand this fetch crap. I still don&#8217;t grok it.</p>

<h2>Amazon SES</h2>

<p>http://aws.amazon.com/ses/</p>

<p>Simple Email Service.</p>

<h2>Bash run last command substitute</h2>

<pre><code>$ ls lol
ls: wat: No such file or directory
$ ^wat^lol
ls lol
ls: lol: No such file or directory
</code></pre>

<h2>Harp. What is it?</h2>

<p>I don&#8217;t know. You tell me.</p>

<p>http://harpjs.com/</p>

<p>Static web server with built in preprocessing.</p>

<p>https://github.com/silentrob/harp-editor</p>

<h2>Candy kid</h2>

<p><img src="http://kandipatterns.com/images/kandikids.jpg" alt="" /></p>

<h2>Lissajous curve</h2>

<p>http://en.wikipedia.org/wiki/Lissajous_curve</p>

<pre><code>x=A\sin(at+\delta),\quad y=B\sin(bt),
</code></pre>

<p>Family of curves that seem bounded by a (-1,-1)x(1,1) box. What am I
doing with my life.</p>

<p>Source: cryptonomicon, bumble bee doing Lissajous across the ceiling.</p>

<h2>CSS history theft</h2>

<p>http://lcamtuf.coredump.cx/css_calc/?utm_source=html5weekly&amp;utm_medium=email</p>

<ul>
<li>Til mid 2010, a crappy site could use the <code>:visited</code> pseudo class to
render a bunch of URLs and then check the url to see if the <code>:visited</code>
styles were applied.</li>
<li>this loophole was closed by only letting specify color attributes, and
prevent color lookup via <code>getComputedStyle</code>.</li>
<li>loophole remains open for clicking a single URL, which doesn&#8217;t scale
too well.</li>
</ul>


<h2>Milquetoast</h2>

<p>Based on comic cartoon character Caspar Milquetoast, a timid, weak-willed old man,
whose namesake is breakfast comfort food consisting of toast and a white
milk-based sauce.</p>

<p>Millhouse is milqtoast, kinda, but more dweeby. Edward Norton in Fight
Club is milquetoast.</p>

<h2>Gone Girl</h2>

<p>I should see it. Once book, now David Fincher movie that makes people
not want to get married.</p>

<h2>504 Gateway Timeout</h2>

<p>Never knew what this meant, but this can be returned by an intermediary
or proxy server that doesn&#8217;t get a timely response from a backend server
it&#8217;s talking to in order to prepare a response to the client. DOS&#8217;d
servers might see this, wherein their nginx/whatever reverse proxy can
handle the load just fine, but the backend server is inundated and can&#8217;t
keep up with the load.</p>

<h2>Cairns</h2>

<p>City in far north of Queensland, Australia. Scuba.</p>

<h2>FastCGI</h2>

<p>http://en.wikipedia.org/wiki/FastCGI</p>

<p>CGI applications are processes spun up by a web server to handle an
incoming request. Unscalable since spinning up processes all the time
takes a toll on the OS, not to mention that there&#8217;s no way to do
resource sharing (DB connection sharing, in-memory caching (because
the process dies at the end of request)).</p>

<p>With FastCGI, there&#8217;s a persisting FastCGI server that owns all of the
CGI programs, and webservers interact with FastCGI via a binary protocol
(over a socket (local) or TCP connection (remote)).</p>

<p>This decoupling also allows smaller components to be restarted (rather
than having to restart the entire web server).</p>

<p><code>mod_php</code> is another answer to this problem, which takes the approach to
embedding the PHP interpreter inside Apache itself. But each Apache
child then needs to load the interpreter. FastCGI is better on memory
and not constrained to Apache (nginx implements it).</p>

<p>TODO: reverse proxy rails configuration vs Rails attached to FastCGI.</p>

<h2>Copy as curl</h2>

<p>You can copy a resource request made by Chrome as a curl command.</p>

<h2>HAR format</h2>

<p>You can save network requests (request data/headers and response etc) as
a HAR files from the Chrome debugger.</p>

<p>Stands for &#8220;HTTP ARchive&#8221;:
http://www.softwareishard.com/blog/har-12-spec/</p>

<p>HARs are JSON documents containing</p>

<h2>bcrypt stretches</h2>

<p><code>Devise.stretches</code> controls the internal bcrypt stretching amount for
bcrypt password hashing. When <code>RACK_ENV=test</code>, <code>Devise.stretches</code> is 1,
else it is 10 (or some higher number).</p>

<p>Increasing stretches drastically increases the CPU time required for
hashing passwords, which seems like an obvious anti-perf except for the
nice fact that if you&#8217;re server&#8217;s being bombed by a dictionary attack,
which sequentially tries to hash many passwords, the attack will be
thwarted by just how long the server takes to hash the password.</p>

<p>http://en.wikipedia.org/wiki/Key_stretching</p>

<h2>ActiveRecord connection pooling</h2>

<p>http://blog.plataformatec.com.br/2011/12/three-tips-to-improve-the-performance-of-your-test-suite/</p>

<p>Connection pools allow for connection reuse (rather than, say, the
shitty alternative of opening/closing a connection for every query).
The ActiveRecord connection pool has the additional stipulation that
connections are not shared between threads. This makes sense, since
otherwise if you had a multithreaded Rails application and connections
were shared between threads, then only one thread at a time could be
querying the database, and locking would occur, making shit slow.</p>

<p>So by letting each thread have its own connection to a shared resource,
threads won&#8217;t get blocked on each other. Happy fucking day.</p>

<h2>Rails dbconsole</h2>

<p>http://guides.rubyonrails.org/command_line.html#rails-dbconsole</p>

<pre><code>rails dbconsole
# or
rails db
</code></pre>

<h2>dRuby</h2>

<p>COBRA for Ruby basically.</p>

<p>http://www.ruby-doc.org/stdlib-1.9.3/libdoc/drb/rdoc/DRb.html</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-06T21:15:00-04:00" pubdate data-updated="true">Oct 6<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/01/smelly-journal/">
		
			Smelly Journal</a>
	</h2>
	<div class="entry-content">
		<h2>TCP/UDP/Sockets/wat</h2>

<p>What&#8217;s a socket?  Depends on who you ask.</p>

<p>The <a href="file:///Users/machty/code/machty.github.com/rfc793.html">TCP RFC</a>
defines a &#8220;socket&#8221; as an IP address (supplied in IP packet) combined
with a port (supplied in the TCP packet). So a &#8220;socket&#8221; is
(IP,PORT). Socket + Socket = Connection. Hence, in this sense, you can
use the same socket for multiple connections.</p>

<blockquote><p>To allow for many processes within a single Host to use TCP
communication facilities simultaneously, the TCP provides a set of
addresses or ports within each host.  Concatenated with the network
and host addresses from the internet communication layer, this forms
a socket.  A pair of sockets uniquely identifies each connection.
That is, a socket may be simultaneously used in multiple
connections.</p></blockquote>

<ul>
<li>Socket: an operating system abstraction referring to a communication
endpoint. You can read from it. You can write to it.</li>
<li>Note that raw sockets don&#8217;t have ports (ports are a UDP/TCP concept).</li>
</ul>


<h2>Built-ins aren&#8217;t sudo-able</h2>

<pre><code>sudo: cd: command not found
</code></pre>

<p>:). Makes sense. You either need to use absolute paths or <code>sudo bash</code>.</p>

<h2>Switch into another user</h2>

<pre><code>sudo su - machty
</code></pre>

<h2>socket bind vs listen vs accept</h2>

<p>Why so many steps? What does each one do?</p>

<h3>Bind</h3>

<p>Registers a socket with the kernel. Even if you do nothing with that
socket, once you bind, anyone else who tries will get an EADDRINUSE.
This code gets an EADDRINUSE every time.</p>

<pre><code>require 'socket'
def wat
  socket = Socket.new(:INET, :STREAM)
  addr = Socket.pack_sockaddr_in(4485, '0.0.0.0')

  socket.bind(addr)
end

fork { wat }
wat
Process.wait
</code></pre>

<p>If the socket had been created, then a new file descriptor pointing to
the same socket could be used by the forked child process, but you can&#8217;t
just create a totally separate one that points to the same already-bound
port.</p>

<h3>Listen</h3>

<p><code>listen()</code> indicates a &#8220;willingness to accept incoming connections&#8221;.
You provide <code>listen</code> with a <code>backlog</code> integer referring to the max
number of queued connections allowed before you ECONNREFUSED.</p>

<p>It&#8217;s separate from <code>bind</code> because maybe you want to grab a port right at
application start, but you still need to do some thing before you know
a) whether to actually start listening or b) how big the queue size
should be.</p>

<p>It&#8217;s separate from <code>accept</code> because <code>accept</code> kind of a dead end as far
as application initialization goes; once you start <code>accept</code>ing, you must
be all set up and fine with the fact that you&#8217;ll be blocked on IO.</p>

<p>SOMAXCONN is the max backlog number. Probably best to just set
<code>listen</code>&#8217;s backlog to that number. If you&#8217;ve got people queued up for
connections, you should probably be fixing whatever&#8217;s causing the wait.</p>

<h3>Accept</h3>

<p><code>accept</code> will block.</p>

<p>So basically here&#8217;s what happens if you try to connect to a server
that&#8217;s ran through the following steps (followed by a sleep unless
<code>accept</code> is called):</p>

<ul>
<li>no <code>bind</code>: ECONNREFUSED</li>
<li><code>bind</code>: client blocks. If you kill the server, ECONNREFUSED</li>
<li><code>listen</code>: client blocks, reports a successful connection (which means
that <code>listen</code> makes the kernel start accepting connections even if no
one&#8217;s accepting&#8230; this makes sense since at this point we&#8217;ve provided
the kernel a max queue size)</li>
</ul>


<p>If a connection comes in, the kernel will do the handshake, but the
connection will remain in the queue and future connection attempts won&#8217;t
get the handshake until the first one is <code>accept</code>ed.</p>

<p>Does that make sense? The alternative would be the kernel not responding
to the handshake until <code>accept</code>, which seems like a major performance
hit.</p>

<h2>Elastic Beanstalk</h2>

<p>Tries to do what Heroku does. Apparently a clunkier CLI. But neato
features.</p>

<h2>Kernel buffers</h2>

<p>C and Ruby provide buffering on top of a kernel buffers. Why not just
have one buffer? Because the kernel definitely needs to provide
buffering in general so that you can get the perfs for free. But
application specific stuff can benefit from buffering on top of the
kernel&#8217;s defaults, but unfortunately the system calls are megaslow.</p>

<p>Kernel maintains a kernel thread that makes sure that nothing remains
unflushed for more than 30 seconds and will flush things.</p>

<p>You can <code>fadvise</code> the kernel about how reads/writes are likely to
occur so that it can select the best strategy for what you&#8217;re doing.</p>

<p>There&#8217;s an <code>madvise</code> memory equivalent. Wouldn&#8217;t you just write your own
allocator at that point? Guess I should probably learn my shit.</p>

<p>Different types of strategies:</p>

<ul>
<li>NORMAL: no special patterns to report, default kernel behavior.
Read-ahead buffer set to 128k.</li>
<li>SEQUENTIAL: you&#8217;re gonna be reading from lower to higher offsets.
Large files, streaming large music files, blah blah blah, etc., on
linux this yields read-ahead window size 2x the default.</li>
<li>RANDOM: scattershot reads, hence read-ahead is likely a waste, hence
it is disabled.</li>
<li>WILLNEED: notify kernel that you&#8217;ll need a segment of memory soon, so
kernel loads it into the buffer cache (redundant much?). Memory
presurre from other processes might eject these buffers from the
cache, so it&#8217;s good to make sure you <code>read</code> soonish after this
fadvise.</li>
<li>WONTNEED: flush a region if possible</li>
<li>NOREUSE: WILLNEED + WONTNEED, basically. You only expect to read the
region once.</li>
</ul>


<h2>Unzip a curled tar</h2>

<pre><code>curl https://opensource.apple.com/tarballs/bash/bash-92.tar.gz | tar zxf -
</code></pre>

<p>Pretty amazing.</p>

<h2><code>O_DIRECT</code>: bypass the buffer cache</h2>

<p>Often this means slower performance, but if you reaaaally know what
you&#8217;re doing, you can use it. If you use <code>O_DIRECT</code>, here&#8217;s what you
lose:</p>

<ul>
<li>sensible read-aheads</li>
<li>sharing buffers between processes using the same files</li>
<li>other things</li>
</ul>


<p>Database software probably wants <code>O_DIRECT</code> because databases have
unique IO requirements, maintain their own caches, etc.</p>

<p>You have to start paying attention to things like alignment
restrictions. The databuffer must begin on a memory boundary that is a
multiple of block size. I guess that means you have to shift things in
memory before writing to disk. File offset must also be multiple of
block size. Length of data transferred must also be multiple. Else
<code>EINVAL</code>.</p>

<h2>Write-ahead log</h2>

<p>http://en.wikipedia.org/wiki/Write-ahead_logging</p>

<p>Postgres et al use this to provide atomicity / durability. With WAL, all
modifications are written to a log before applied. Redo/undo information
is written to the log.</p>

<p>http://en.wikipedia.org/wiki/Point-in-time_recovery</p>

<p>Restore a previous state in time. Time Machine is OS X is an example of
this (also why they allow directory hard-linking).</p>

<h2>Virtual devices and device files</h2>

<p>Expose universal IO API.</p>

<p>There are character devices like TTYs which can handle a character at a
time, and there are block devices, which can handle IO in (often 512b)
blocks.</p>

<p>Use <code>mknod</code> for making device files. Used to be used for other things,
now it&#8217;s just device files.</p>

<p><code>ls -l</code> displays major or minor number of special device fields in place
of the size (from <code>man ls</code>)</p>

<pre><code> If the file is a character special or block special file, the major and
 minor device numbers for the file are displayed in the size field. 
</code></pre>

<h2>Cryptonomicomicon</h2>

<p>Words.</p>

<p><a href="http://en.wikipedia.org/wiki/Coolie">Coolie</a>: a laborer from Southern
China, Indian subcontinent, Phillipines or Indonesia. Nowadays a
racial slur for people of Asian descent (mostly in South African
vernacular). Etymology not agreed upon, could be from an Urdu word for
&#8220;slave&#8221; or in reference to the Koli, or a Tamil word that meant payment
for work. Coolie trade pretty much was like slave trade, with indentured
servitude, etc. In Crypto they&#8217;re the workers who trade various Shanghai
banks silver-backed paper money in for silver, transporting large boxes
of currency hanging from bamboo sticks.</p>

<p><a href="http://en.wikipedia.org/wiki/Claque">Claque</a>: people paid to applaud
(or heckle) a performance. Basically, real-time proto-laugh tracks,
originating from France. There were laughers (Rieurs), criers
(Pleureurs), ticklers (Chatouilleurs, who kept the audience in high
spirits), and encore-ers (bisseurs). North Korea&#8217;s got lots of claquers.
Entrenched claque-masters also extorted money from performers in
exchange for not booing their performance. Fucking dickweeds.</p>

<p>Swabbie: &#8220;a member of the navy, typically one who is of low rank.&#8221;</p>

<p>Estuary (esturial): the tidal mouth of a large river, where the tide
meets the stream.</p>

<h2>Number authorities</h2>

<p>Kinda like the IANA and port numbers, there&#8217;s a Linux
http://www.lanana.org for controlling things like major version numbers
for device files.</p>

<h2>Silicon Valley</h2>

<p>Turns out I never knew where it was: it&#8217;s the southern portion of the
San Francisco bay area.</p>

<h2>Disk Partitions</h2>

<p>Hard disks have platters, platters have tracks of data, split into
sectors, split into physical blocks.</p>

<p>Platters > data > sectors > blocks.</p>

<p>Blocks are the smallest unit of data a driver can read/write. They&#8217;re
usually 512 bytes.</p>

<p>Disk partitions are treated by the kernel as separate devices in
<code>/dev</code>.</p>

<p>Partitions might consist of</p>

<ul>
<li>a file system</li>
<li>totally raw data (some databases do this)</li>
<li>swap area used by kernel for VM</li>
</ul>


<p>File system on disk is composed of</p>

<ul>
<li>Boot block: how to boot the OS</li>
<li>Superblock: single block saying:

<ul>
<li>size of inode table</li>
<li>logical block size (always a multiple of physical block)</li>
<li>size of the system in logical blocks</li>
</ul>
</li>
<li>inode table / ilist</li>
<li>data blocks</li>
</ul>


<p><code>ext2</code> is special in that it breaks down data blocks into block groups
and prepends a copy of the super block to each to minimize seeks.</p>

<p><code>ls -li</code> shows inode number in first column. inodes contain:</p>

<ul>
<li>file type</li>
<li>owner</li>
<li>group</li>
<li>access perms</li>
<li>timestamps

<ul>
<li>last access</li>
<li>last mod</li>
<li>last status change</li>
<li>(but not a created at? WEIRD. must be a linux thing; mac has this)</li>
</ul>
</li>
<li>number of hardlinks</li>
<li>size of file in bytes</li>
<li>number of blocks allocated (might be less than expected due to holes)</li>
<li>pointers to blocks</li>
</ul>


<p>Note that there is a tradeoff between fragmenting freespace into small
chunks that are too small to use vs fragmenting data blocks so that all
free small chunks can be used.</p>

<p>ext2 has 15 pointers, 12 of which are data block pointers, the next
which points to a block of pointers, the next which points to a an array
of block pointers, and then a tertiary one for large fucking files.</p>

<p>This (using blocks for inode indirection) allows for fixed size
of inode table.</p>

<h2>TLDP</h2>

<p>The Linux Documentation Project</p>

<blockquote><p>LDP is a loosely knit team of volunteers who provide documentation for many aspects of Linux. There are several forms of documentation: Guides, HOWTOs, man pages, and FAQs.</p></blockquote>

<p>That&#8217;s nice.</p>

<h2>McRouter</h2>

<p>https://www.youtube.com/watch?v=EYhcumt8YyI</p>

<p>A &#8220;memcache protocol router, for scaling memcache deployments&#8221;.</p>

<p>Two forms of caching at facebook:</p>

<ul>
<li>demand-filled cache

<ul>
<li>fetch from memcache with key. if not there, fetch from db, then set
memcache w key. all of this logic on webserver</li>
</ul>
</li>
<li>read-through / write-through cache

<ul>
<li>TAO system; query TAO, and if it&#8217;s not there, <em>it</em> fetches from DB
on your behalf</li>
</ul>
</li>
</ul>


<p>Both share the following in common: two orders of magnitude more reads
than writes.</p>

<p>Cache becomes bottleneck, extremely crucial or whole site fails.</p>

<p>Having inconsistent implementations of memcache libs might result in
data loss. So, anyway, McRouter to the rescue. It:</p>

<ul>
<li>is a proxy between memcache client and server (adheres to same ol API,
makes for good drop-in replacement)</li>
<li>also an embedded mode for low latency</li>
<li>a load balancer</li>
<li><a href="http://en.wikipedia.org/wiki/Consistent_hashing">consistent hashing</a>
(where hash table resizes minimize the amount of remapping:

<ul>
<li>Consistent hashing maps objects to the same cache machine, as
far as possible. It means when a cache machine is added,
it takes its share of objects from all the other cache
machines and when it is removed, its objects are shared
between the remaining machines.</li>
</ul>
</li>
<li>connection pooling (presumably this means connections are maintained
by mcrouter to the memcache instances and loaned out when mcrouter
clients make queries, rather than slowly reopening connections each
time)</li>
<li>Server pools&#8230; I guess this means multiple instances of McRouter?</li>
<li>Automatic failover</li>
<li>Cold cache warmup</li>
<li>Broadcast operations</li>
<li>Replicated Data Sets</li>
</ul>


<p>Connection Pooling:</p>

<p>Application threads share McRouter&#8217;s N connections to the memcache
instances, rather then each thread creating N connections resulting in
<code>N*T</code> total connections.</p>

<p>Heterogeneous workloads:</p>

<p>Prefixed keys get routed to specific memcache instances, I guess, rather
than having them all on the same things getting clobbered by others.</p>

<p>Automatic failover:</p>

<p>Normal server, fail over to backup when error returned, timeout,
ECONNREFUSED, etc, with probing to see when it can be reconnected.</p>

<p>Twitter <code>twemproxy</code> is similar to McRouter.</p>

<h4>Reddit infrastructure</h4>

<ul>
<li>AWS</li>
<li>170-300 servers daily (scales in peak hours)</li>
<li>73 cache nodes with 1TB memory</li>
<li>App code fragile-y uses memcache</li>
</ul>


<h4>Reddit Scaling Issues</h4>

<p>AWS constantly releases lovely new instance types, but Reddit can&#8217;t just
hop onto them without testing them out.</p>

<h2>NTFS</h2>

<p>New Technology File System, as in, Windows NT.</p>

<h2>VFS</h2>

<p>Virtual File System: the unified kernel abstraction, providing familiar
things like <code>read()</code>, <code>write()</code>, etc.</p>

<h2>Journaling</h2>

<p>If an OS running ext2 crashes, you need to run <code>fsck</code> (filesystem check)
to make sure inode entries point to real things, etc., else you run the
risk of breaking more shiznittletons.</p>

<p>Journaling FS&#8217;s imply basic database transactions. All intended metadata
writes are written to a journal file first before they&#8217;re performed, and
if the operation is interrupted by a crash, recovery is quick. Actually,
could just be metadata or full on everything data.</p>

<h2>OS X</h2>

<p>Macs use something called HFS Plus, or Mac OS Extended.</p>

<ul>
<li>lots of metadata</li>
<li><p>case-preserving though case-insensitive</p>

<p>  machty.github.com :: cat woot
  lol
  machty.github.com :: cat WOOT
  lol</p></li>
<li><p>journaling</p></li>
</ul>


<h2>mount</h2>

<p><code>mount</code> and <code>unmount</code> will attach a file system to a specified
directory.</p>

<p>KEEP IN MIND DINGUS this &#8220;mount&#8221; concept is all over the place. Mount
routes. Mount external thing blah.</p>

<p><code>unmount2</code> is <code>unmount</code> with flags.</p>

<p>You can mount in multiple mount points.</p>

<pre><code>mount /dev/sdva123 /dumbness
</code></pre>

<p>A device is not accessible as a file system until you mount it. You
couldn&#8217;t just do <code>cd /dev/sdva123</code>. You have to mount it first.</p>

<p>Just realized something: the EBS provided to your EC2 instance could be
formatted into any file system. FUCK IT let&#8217;s do ext4.</p>

<p>mounts can be stacked on top of the same mount point. This makes it
possible to migrate off of an old mount; old processes maintain their
file handles on the old mount, new processes use the new fs, and
eventually you can retire the old mounted fs that&#8217;s not at the top of
the stack. Kinda nifty, weird as it sounds.</p>

<h2>Basic <code>cat</code> shit</h2>

<p>If you want to type some random shit into a new file, do</p>

<pre><code>cat &gt; lolz
</code></pre>

<p>and then you can type into cat&#8217;s STDIN and then Control D to signal EOF.</p>

<h2>kitchen sink of disk utils</h2>

<p>What&#8217;s the difference between all these shits?</p>

<ul>
<li>fdisk: manipulate disk partition table</li>
<li>df: report file system disk space usage</li>
<li>mkfs: build a linux filesystem</li>
</ul>


<h2>tmpfs</h2>

<p>Virtual memory file system. But the thing about virtual memory is that
unused portions might get paged to a swap file on the disk&#8230; so it&#8217;s
not just strictly memory.</p>

<pre><code>sudo mkdir ./wat
sudo mount -t tmpfs StupidName ./wat
</code></pre>

<p><code>tmpfs</code> doesn&#8217;t exist on Mac OS X though some other form probably does.</p>

<p>It&#8217;s used to speed up applications like compilers that make heavy use of
<code>/tmp</code>.</p>

<p><code>tmpfs</code> has also had other use cases, such as implementing shared
memory (System V) and the <code>glibc</code> implementation of POSIX shared memory
and POSIX semaphores.</p>

<h2>Ableton Live</h2>

<ul>
<li>Opt-shift-B: hide Browser</li>
</ul>


<p>Arrangement view is the classic multi track view. You can disable
portions of the mixer that you don&#8217;t care about.</p>

<ul>
<li>IO (opt + command + i): input/output for this track

<ul>
<li>Input type (device, e.g. M-Audio Whatchufuck)</li>
<li>Input channel (devices often have multiple)</li>
<li>Monitoring (radio button basically)

<ul>
<li>In (enable monitoring of input)</li>
<li>Auto (only enable when track is armed - not just when actively
recording)</li>
<li>Off</li>
</ul>
</li>
</ul>
</li>
<li>Delay (no shortcut)

<ul>
<li>delay/predelay to compensate for device/hardware/whatever latency</li>
</ul>
</li>
<li>Mixer (opt + command + m)

<ul>
<li>Activate/deactivate (mute) the track</li>
</ul>
</li>
<li>Return tracks

<ul>
<li>Note that if you tab into clip view (?) then the R button splits
into S and R.</li>
</ul>
</li>
</ul>


<p>Note the master track at the bottom. The Preview/Cue volume controls the
metrononme. Not sure what else Cue refers to&#8230;</p>

<p>Count-in is attached to the metronome menu.</p>

<p>Opt+unfold (triangle button) to unfold all them shits.</p>

<p>You can arm multiple tracks with command+click.</p>

<p>Impulse is an Ableton instrument. Instrument Racks are combinations of
the Impulse instrument with certain pre-saved audio effects.</p>

<h3>Quantize</h3>

<p>This doesn&#8217;t seem to refer to individual notes in a midi recording but
rather for playback between clips; when you press the play button by a
clip, it doesn&#8217;t immediately play unless you have it turned off (which
can result in crazy timing issues). Also, even if you Command-0 to turn
it off and get shit out of sync, if you Command-9 back to one bar and
play a new track, it&#8217;ll make sure it starts in sync with the metronome
(what else could it be? clips don&#8217;t have meter, just a length).</p>

<p>Ah but if you do want per note quantization you can do it a) while
recording, by going to Edit > Record Quantization.</p>

<p>Then if you already recorded something unquantized, you can Command-U.</p>

<h3>Recording clips</h3>

<p>If you create an empty clip, that clip has a size, as all do, so you&#8217;ll
be recording within a loop.</p>

<p>Whereas if you pressed the slot&#8217;s record button, there would be no fixed
length until you stopped recording. The Notes menu associated with that
clip (which has length info) doesn&#8217;t even appear until after the new
recording is finished. How grand!</p>

<h3>Looping</h3>

<ul>
<li>One-indexing: the quickly set things to the beginning of a clip, you
do 1 tab 1 tab 1, not 0 tab 0 tab 0 which&#8217;ll normalize to -1. But
lengths can have zero. 2 0 0 means two measures.</li>
<li>Known trick: 0 0 16 will normalize into 1. If it&#8217;s more convenient to
think in terms of odd meters, this could be useful&#8230; INSTANT
MESHUGGAH.</li>
<li>When loop enabled, normal end is meaningless. When loop disabled, all
loop info is useless. (Though these details still seem to be
displayed.</li>
</ul>


<p>Place insert markers just by clicking the grid.</p>

<p>You can manually copy and paste or you could DuplLoop. DuplLoop also
conveniently works such that if you duplicate into notes you&#8217;ve already
written, they&#8217;re overwritten, rather than dubbed or something cray cray.</p>

<h3>Hotswapping</h3>

<p>Constrasted with double-clicking a new instrument in the Browser,
hotswapping seems to:</p>

<ul>
<li>preserve the rest of the devices you might have attached to the
instrument you&#8217;re hotswapping.</li>
<li>open the browser to the current devices folder; relevant for quickly
finding the thing you want to switch out.</li>
</ul>


<p>Weird that they make such a big deal out of it (do they, or am i just
saying).</p>

<h2>SHIT IS EBS BACKED, DUMMY</h2>

<p>Root device type: ebs</p>

<p>Root device: <code>/dev/xvda</code></p>

<p><code>#NotAllEC2InstancesStartOffWithEphemeralStorage</code></p>

<h2>Helicopter parent</h2>

<p>http://en.wikipedia.org/wiki/Helicopter_parent</p>

<p>A hovery overbearing parent who&#8217;s still around even when kids have gone
to college.</p>

<p>Thought it might mean when you&#8217;re a parent who drops in every so often,
or drops in on other kids. Nope.</p>

<h2>Geocoder can&#8217;t have radiuses be stored on the row</h2>

<p>The bounding box is calculated before the SQL is fired&#8230; then again
there&#8217;s all sorts of sin/cos shit going on, but all to translate into
something that can be compared against that box.</p>

<h2>College</h2>

<p>http://www.nytimes.com/2014/05/18/magazine/who-gets-to-graduate.html</p>

<p>Community College:</p>

<p>Means different things depending on the country, but in America it
usually means a two-year public institution, often granting certificates
and associate&#8217;s degrees (two-year degrees).</p>

<p>Dropout rate is apparently 40%, and if you include community college
dropouts, we&#8217;re the worst other than Hungary.</p>

<p>Rich kids are more likely to graduate (90% of the upper quartile of
income), whereas 25% of the lower half will expect to graduate by 24.</p>

<p>College students who scored the same on standardized tests still have
educational outcomes (graduation rates) that correlate with family
wealth.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-01T08:29:00-04:00" pubdate data-updated="true">Oct 1<span>st</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/09/27/daily-shnurgle/">
		
			Daily Shnurgle</a>
	</h2>
	<div class="entry-content">
		<h2>lseek</h2>

<p>&#8220;long&#8221; (int) seek. There used to just be a <code>seek</code> that took a smaller
int.</p>

<p>You can seek past EOF and the kernel will be fine with it; reads yield 0
and set EOF flag, but writing will cause a &#8220;file hole&#8221; to exist, wherein
null bytes are returned but aren&#8217;t actually written to disk until
someone writes into the hole.</p>

<pre><code>File.open("seektestfile", "r+") do |f|
  f.write("begin")
  f.seek(10, IO::SEEK_SET)
  f.write("end")
end
</code></pre>

<p>Then open <code>seektestfile</code> in vim to see the null bytes. Pretty rad. But
again keep in mind that those null bytes aren&#8217;t actually there on disk
(well actually I guess it&#8217;s up to the kernel to figure out whether the
hole is large enough to warrant the overhead of splitting into a
different block; some file systems don&#8217;t offer file holes at all).</p>

<p>A file is just a collection of allocated disk blocks. No guarantee their
in the same order. But you could use <code>posix_fallocate</code> to reserve
multiple blocks even if you&#8217;re writing to different places in it to make
sure that future writes will succeed rather than risk some other
application filling a hole and blah.</p>

<p>How many bytes in a block/sector in OS X? <code>diskutil info /</code> reveals
(among other things):</p>

<pre><code>Device Block Size:        512 Bytes
</code></pre>

<p>That&#8217;s the hardware block size, which can be different than the file system
block size (the fs block size must of course be >= device block size).</p>

<p>The <code>stat</code> command tells you information about files, like their size n
shit. It has a format option which is like printf. You could be like
<code>stat -f "hello world"</code> and &#8220;hello world&#8221; would be the output, having
run <code>lstat</code> on STDIN and printing out no actual information about it.</p>

<p><code>ioctl</code> is useful for special-cased IO scenarios, like controlling a
terminal device special file. You pass it an op code which determines
what the remaining parameters are.</p>

<h2>syscalls and atomicity</h2>

<p>Examples of system calls that accept flags to ease race condition pain:</p>

<ol>
<li><code>O_EXCL</code> when opening a file throws an error if it already exists;
otherwise you&#8217;d have to try and open it (to see if it exists), and
then try to create it if it doesn&#8217;t, in which time another process
could have come in and created it. <code>O_EXCL</code> guarantees that if the
open succeeds, that process is the owner of the new file.</li>
<li><code>O_APPEND</code> opens a file AND moves its pointer to the end in one shot,
otherwise two processes trying to append might clobber each other
between their <code>seek</code> and <code>write</code>s. Some systems like NFS don&#8217;t
support it and are prone to this race condition. WRONG. I wrote the
wrong thing. <code>O_APPEND</code> actually works by opening the file, flagging
it in such a way that all writes also atomically include an EOF seek.
If <code>O_APPEND</code> worked the way I first described (an <code>open</code> + a
<code>seek</code>), the race condition described could still happen.</li>
</ol>


<h2>File descriptors vs open files</h2>

<p>You can have multiple file descriptors point to the same open file. This
for example happens automatically every time you fork a program (its FDs
get dup&#8217;d).</p>

<p>The kernel maintains</p>

<ul>
<li>a per-process table of descriptors

<ul>
<li>close-on-exec flag</li>
<li>reference to the system-wide open file description</li>
</ul>
</li>
<li>a system-wide table of open file descriptions (the open file table)

<ul>
<li>current file offset (from reads/writes/seeks)</li>
<li>status flags from when the file was open()ed (read-only, etc)</li>
<li>reference to the i-node</li>
</ul>
</li>
<li>file system i-node table</li>
</ul>


<p>Note that there&#8217;s an on-disk i-node and an in-memory i-node that has a
lot more information about locks and other kernel-specific things that only make sense
to open files rather than just static files living on a disk somewhere.</p>

<p><code>fork</code>ing and UNIX domain sockets are two (of many? maybe?) ways for two
processes to have a file descriptor that points to the same system wide
descriptions.</p>

<p>I originally thought the file offset was stored per descriptor, but
apparently it lives in the shared description record? Only one way to
find out:</p>

<pre><code>File.open('shareddesctest.txt', 'w') do |f|
  if fork
    # parent
    f.seek(1, IO::SEEK_SET)
    Process.wait
  else
    # child
    sleep 1
    f.write "wat"
  end
end
</code></pre>

<p>If I open vim, I see <code>^@wat</code>, which means in fact the offset is shared:
parent seeks to offset 1, child waits for this to happen, and then
writes to a file descriptor it hasn&#8217;t touched yet, and it starts writing
at where the parent <code>seek</code>ed to. So indeed offsets are stored in the
shared system-level open file description.</p>

<h2>Redirection and dup2</h2>

<p><code>./a.out &gt; wat 2&gt;&amp;1</code> will pipe both STDOUT and STDERR into the <code>wat</code>
file, using a single system-level file description. How does this work?
Pretty hilariously-jankly.</p>

<ul>
<li>File descriptors are just integers (stdout=1, stderr=2)</li>
<li>To redirect stderr to stdout, you have to duplicate stdout&#8217;s file
descriptor but make sure that that final descriptor has a value of 2,
so that code that writes to stderr (2) is unaffected and will
successfully keeping writing to the newly redirected stream.</li>
<li>File descriptor integers are reused; the various syscalls that
allocate file descriptors always choose the smallest unused file
descriptor int.</li>
<li>So you could 1. close stderr and 2. dup stdout, and this would work,
but not if stdin (0) had already been closed, since the new handle
would take the lower value 0. LOL.</li>
<li>So you have to use <code>dup2</code>, which lets you specify the number of the
file descriptor you&#8217;d like to allocate. Which is what shells with
stream redirection support. :)</li>
</ul>


<p>Duping FDs can also be done w <code>fcntl</code> and <code>F_DUPFD</code>.</p>

<h2>IO at specific offset</h2>

<p>Good for concurrent processes in some cases, you can use <code>pread</code> and
<code>pwrite</code> to perform IO at a specific offset without modifying the file
pointer.</p>

<p>A single syscall is way more performant than multiple ones, hence the
value in <code>pread</code> and friends. You also sidestep certain race conditions.
Then again the time to do IO often dwarfs syscall overhead.</p>

<h2>Scatter IO</h2>

<p><code>readv</code> reads a contiguous chunk of data from a file descriptor and
distributes into multiple buffers supplied to the syscall. <code>writev</code>
writes a contiguous chunk of data to the file.</p>

<p>This avoids certain race conditions, allows you to combine multiple
reads/writes.</p>

<h2><code>/dev/fd</code></h2>

<p>Virtual directory of file descriptors, e.g. 0, 1, 2 (stdin, stdout,
stderr, and some others). Useful for passing a command line utility a
filename when you really want it to read from stdin, e.g.</p>

<pre><code>echo 'wat' | diff /dev/fd/0 olderwat
</code></pre>

<p>Note that you could also do process substitution:</p>

<pre><code>diff &lt;(echo 'wat') olderwat
</code></pre>

<p>which has the same effect but creates a new descriptor rather than
reusing the stdin descriptor.</p>

<p>Note that these process subsitution file handles also live in <code>/dev/fd</code>:</p>

<pre><code>echo &lt;(echo wat) 
# /dev/fd/63
</code></pre>

<h2>&#8220;Header Search Paths&#8221; vs &#8220;User Header Search Paths&#8221;</h2>

<p>User: <code>#include "wat.h"</code>
Non-user: <code>#include &lt;wat.h&gt;</code></p>

<h2>Process vs Program</h2>

<p>A Process is an instance of a Program. A Program is a description of how
to construct a Process.</p>

<p>Program consists of:</p>

<ul>
<li>Binary format ID: describes the format of the executable.</li>
<li>Machine code</li>
<li>Program entry point address; address to <code>int main</code>, or something that
quickly calls <code>int main</code>.</li>
<li>data (constants, default starting values)</li>
<li>symbol/relocation tables: locations and names of functions, for
debugging purposes but also dynamic linking</li>
<li>shared libs: list of dynamic libs for run time linking</li>
</ul>


<p>A process has an initialized data segment and uninitialized data
segment. The former contains all starting values for a program, hence
it&#8217;s stored in disk space, whereas uninitialized data gets initialized
at process start up through a more dynamic process and hence the space
it occupies doesn&#8217;t need to be stored on disk. Uninitialized data gets
zeroed out.</p>

<ul>
<li>Program break: the &#8220;top&#8221; of the heap</li>
</ul>


<p>Application Binary Interface (ABI) set of rules for what registers are
set, etc., when interacting with some low-level service, like the
kernel. SUSv3 standardizes this API so that you&#8217;re using a higher level
than some ultra low level API.</p>

<h2>Locality of reference</h2>

<p>In regards to memory access and optimizations based thereupon.</p>

<ul>
<li>spatial locality: tendency for memory accesses to be near recent
memory accesses (e.g. traversing a data structure, sequential
execution of code)</li>
<li>temporal locality: tendency to access a recently accessed location
(e.g. a loop)</li>
</ul>


<p>This is part of what makes virtual memory possible; it&#8217;s largely pretty
rare to suddenly need to access a non-resident page.</p>

<p>Each process has a page table, which maps pages to their physical RAM
locations. If you access a page that&#8217;s not in RAM, then page fault
occurs (kernel takes over).</p>

<p>Not all virtual memory address regions have a corresponding page, in
which case, SIGSEGV.</p>

<p>The range of valid virtual addresses changes as the stack grows and more
stuff is allocated on the heap (malloc). Also when you run <code>mmap</code>.</p>

<p>Virtual memory requires hardware support, specifically a Paged Memory
Management Unit, which needs to be smart enough to do address
translating but also notify the kernel of page faults.</p>

<p>VM keeps memory isolated between processes unless you really really want
to share: <code>shmget</code> and <code>mmap</code> let you do this as a means of
Inter-Process Communication. It works by having page table entries point
to the same region of RAM, allowing for the different process page table
entries to have different permissions, e.g. one process might have read
access but other has write access to the same page frame in physical
memory.</p>

<p>There&#8217;s a per-process kernel stack which maps to kernel RAM and is
therefore inaccessible when not in kernel mode. This is used for syscall
stacks. I need to read more about this; why can&#8217;t there be a system-wide
kernel stack shared between processes? Isn&#8217;t only one process going to
be in kernel mode at any given time? Maybe not&#8230; if multiple processes
are blocked on IO, does that mean they&#8217;re all in kernel mode? TODO: come
back to dis shiz.</p>

<h2>argv argc</h2>

<p><code>argv[0]</code> is the process name which can be used to switch the behavior
of multiple commands that all point to the same executable.
<code>gzip/gunzip/etc</code> is an example of this. <code>ls -lai</code> yields:</p>

<pre><code>343041 -rwxr-xr-x  4 root  wheel  43200 Oct 31  2013 /usr/bin/gzip
343041 -rwxr-xr-x  4 root  wheel  43200 Oct 31  2013 /usr/bin/gunzip
</code></pre>

<p>Same inode 343041. Here&#8217;s all of em (<code>find /usr/bin -inum 343041</code>):</p>

<pre><code>/usr/bin/gunzip
/usr/bin/gzcat
/usr/bin/gzip
/usr/bin/zcat
</code></pre>

<p>Apparently there&#8217;s no easy way to find all the files that link to an
inode (the above was simple only because they all happened to be in the
same directory).</p>

<p>Note that you can&#8217;t hard-link directories.</p>

<p>Short of stashing global vars, you can&#8217;t access argv and argc (Ruby
facilitates this for you though), unless you&#8217;re willing to do some
non-portable stuff.</p>

<pre><code>kernel
argv,environ
stack
...
heap
uninitialized data
initialized data
text (program code)
...?
</code></pre>

<p><code>argv</code> lives right above the stack.</p>

<h2>env vars</h2>

<p>If you just do</p>

<pre><code>wat=lol
</code></pre>

<p>that sets a shell variable, not strictly an env var tied to the shell
process that gets with children. Functionally, it&#8217;s an environment var
that doesn&#8217;t get passed to children when forked.</p>

<p>You could then put it into the process env via</p>

<pre><code>export wat
</code></pre>

<p>or in one shot</p>

<pre><code>export wat=lol
</code></pre>

<p>You can set a child processes env var (without polluting parent shell
variable list or environment vars) via</p>

<pre><code>wat=lol somecommand
</code></pre>

<p>in which case ARGC for somecommand will be 0. If you did</p>

<pre><code>somecommand wat=lol
</code></pre>

<p>ARGC would be 1, and ARGV[1] would be &#8220;wat=lol&#8221; rather than an env var.</p>

<p>Order of env vars is implementation specific; you don&#8217;t want to rely on
this shiznittletons.</p>

<h2>Streams and LazyValue</h2>

<p>LazyValue is coming to Ember along with HTMLbars. LazyValues are a kind
of / relative of Observables, with the unique feature that they avoid
the back pressure of pushing values into the stream by merely replacing
the current value and notifying an end consumer that the stream has been
invalidated, letting the final consumer decide when it should consume
and actually flush the lazy value through all of its transformations.</p>

<p>I was wondering what the technical term for a stream that doesn&#8217;t mind
&#8220;dropping&#8221; &#8220;samples&#8221; before it has a chance to consume the latest value.
Apparently the word for that is a &#8220;signal&#8221;&#8230;?</p>

<h2>brk and sbrk</h2>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;

int main() {
  void *curBrk;

  for (int i = 0; i &lt; 1; ++i) {
    curBrk = sbrk(0);
    printf("brk is %p\n", curBrk);
  }

  return 0;
}
</code></pre>

<p>brk sets the brk lowest address of a process&#8217;s data segment
(uninitialized) to addr.</p>

<p>These are mad deprecated. Use malloc. Malloc will grow the heap for you
rather than making you set the break. <code>free</code> won&#8217;t shrink the break but
rather just return a chunk to the free list. Why?</p>

<ul>
<li>most frees are in the middle of the heap (as opposed to the edge,
where shrinking the break makes sense)</li>
<li>syscalls are expensive</li>
</ul>


<p>Mac OS X specifics: just from a few experiments I can verify that the
stack grows downward, the break is really small, but malloc seems to be
producing pointer values much closer to the stack than the break. What
gives? No idea.</p>

<p><code>free(NULL)</code> is a noop. <code>malloc(NULL)</code> might return a small piece of
memory that can be freed.</p>

<p><code>malloc</code> scans the free list for something >= the required amount. If >
than the required amount, the free block is split. Different
implementations might be first-fit or best-fit. If nothing found, <code>sbrk</code>
is called to increase it, by some multiple of the virtual memory page
size.</p>

<p><code>free</code> knows the size of the block to free because malloc sneakishly
inserts the length at the beginning of a chunk of allocated memory.</p>

<p>Wow, the algorithm for free and malloc is pretty awesome.</p>

<p>Let&#8217;s see nothing&#8217;s been allocated on the heap. Your free list is a
single element doubly-link list</p>

<pre><code>|Length of Block|prevBlock*|nextBlock*|empty space|
</code></pre>

<p>Then you <code>malloc(4)</code>. It&#8217;ll start at the beginning of that list, see
that <code>4</code> is less than the length of the block, and then it&#8217;ll split that
block. Hmm, so the pointer to the free list needs to remain the same&#8230;
so either malloc&#8217;d block could get put at the end, length of block is
decremented. Yeah that&#8217;s probably how it works.</p>

<p>TL;DR: the free list is a doubly-linked list whose nodes are stored in
the same chunk of memory that&#8217;ll be distributed when mallocs occur. I
always wondered where the &#8220;free list&#8221; lived&#8230; it seemed like one of
those problems where it&#8217;d be mallocs all the way down, but this is
a pretty elegant solution, but it also explains how quickly shit can go
haywire if you accidentally futz with freed values.</p>

<p>The specific algorithm can vary; glibc uses a boundary tag approach,
wherein an allocated chunk includes size of previous chunk, size of
current chunk, and then user space, then size of chunk.</p>

<p>So how are SIGSEGVs detected on double-frees?</p>

<p>http://www.opensource.apple.com/source/Libc/Libc-594.1.4/gen/malloc.c</p>

<p>I think Apple&#8217;s version of malloc tracks allocated blocks (rather than
just a free list). So it&#8217;ll loop through that list and make sure it&#8217;s
actually in there. I think glibc see does something else, where it loops
through the free list to see if it&#8217;s already in there? Or some other
efficient thing using the boundaries stored in adjacent blocks? Unsure.</p>

<p><code>alloca</code> lets you dynamically allocate on the stack by moving the stack
frame pointer downward. It gets &#8220;collected&#8221; one you return from the
function. Not standardized but most systems have it? It&#8217;s useful if
you&#8217;re actually writing a program that necessitates <code>longjump</code> since
heap-allocated memory in the stack frames you&#8217;re skipping over can&#8217;t
possibly be freed, but you get the &#8220;free&#8221; for free if it was allocated
via <code>alloca</code>. That being said, you probably shouldn&#8217;t use it. :)</p>

<h2>Users and Groups</h2>

<p>You can have multiple usernames/passwords map to the same UID. This
means multiple users can be granted the exact same privileges by nature
of them literally being distinguishable by username but not UID.</p>

<p><code>wheel</code> comes from the phrase &#8220;big wheel&#8221; (&#8220;she&#8217;s a big wheel at
Microsoft&#8221;), it refers to a group with admin privileges. <code>admin</code> is
also one such group. <code>root</code> is a member of both:</p>

<pre><code>wheel:*:0:root
admin:*:80:root
</code></pre>

<p>On Mac OpenDirectory is used instead; you can see all of the
<code>/etc/group</code> groups in Directory Utility. <code>wheel</code> is System Group,
<code>admin</code> is Administrators, and there&#8217;s a bunch of other ones specific to
applications, which seem to be prefixed via underscore blah blah blah
who cares.</p>

<h2>groups, permissions</h2>

<p>A process with effective user ID of 0 is a <em>privileged process</em>.</p>

<p>A process starts off with a real user and group ID and can change its
effective user and group ID.</p>

<p>Processes that don&#8217;t start off with the privileges they need can be
granted the ability to set their effective user and group ids, but only
to the owner or group, e.g. I, user <code>peon</code>, can execute <code>a.out</code> (if it
has <code>a+x</code> perms) and have <code>a.out</code> grant itself the permissions that its
owner has.</p>

<pre><code>machty.github.com :: ls -la wat
-rw-r--r--  1 machty  staff  0 Sep 28 09:23 wat
machty.github.com :: chmod u+s wat
machty.github.com :: ls -la wat
-rwSr--r--  1 machty  staff  0 Sep 28 09:23 wat
</code></pre>

<p>The capital <code>S</code> means set-user-id-able but non-executable (this is rare
and maybe useless?). If I do <code>chmod u+x wat</code> it becomes:</p>

<pre><code>-rwsr--r--  1 machty  staff  0 Sep 28 09:23 wat
</code></pre>

<p>If I set group, it&#8217;d be the next column of bits.</p>

<p>Note that there&#8217;s no setUID call that the process has to make to enter
this mode; rather, the bit causes the kernel to set the effective user
or group ID once the process begins to run.</p>

<p>Here&#8217;s all the <code>/usr/bin</code>s that have set-user-id</p>

<pre><code>machty.github.com :: ls -la /usr/bin | grep '^...[Ss]'
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 at
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 atq
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 atrm
-r-sr-xr-x     4 root   wheel     75648 Mar 10  2014 batch
-rwsr-xr-x     1 root   wheel     35136 Oct 31  2013 crontab
-rws--x--x     1 root   wheel     23008 Oct 31  2013 ipcs
-r-sr-xr-x     1 root   wheel     68240 Mar 10  2014 login
-r-sr-xr-x     1 root   wheel     44416 Mar 10  2014 newgrp
-r-sr-xr-x     1 root   wheel     19664 Oct 31  2013 quota
-r-sr-xr-x     1 root   wheel     20720 Mar 10  2014 rlogin
-r-sr-xr-x     1 root   wheel     19856 Mar 10  2014 rsh
-rwsr-xr-x     1 root   wheel     21488 Oct 31  2013 su
-r-s--x--x     1 root   wheel    164896 Oct 31  2013 sudo
-r-sr-xr-x     1 root   wheel     83856 Oct 31  2013 top
</code></pre>

<p>and all the set-group-ids</p>

<pre><code>machty.github.com :: ls -la /usr/bin | grep '^......[Ss]'
-rwxr-sr-x     1 root   mail      24640 Oct 31  2013 lockfile
-rwxr-sr-x     1 root   mail      84656 Oct 31  2013 procmail
-r-xr-sr-x     1 root   tty       20832 Mar 10  2014 wall
-r-xr-sr-x     1 root   tty       19920 Oct 31  2013 write
</code></pre>

<p><code>wall</code> writes some nonsense to everyone&#8217;s terminal: <code>echo wat | wall</code>.</p>

<p>Processes have the ability to switch in and out of their set-uids and
set-group ids. In other words, a program might have its set-uid enabled
(and its owner is root), but it&#8217;s bad/unsafe practice to let a program
just run in root mode the whole time; rather, it should only switch into
root mode when doing stuff that requires privileges, and then switch
back.</p>

<p>In Linux there&#8217;s also the concept of file-system IDs and groupd IDs,
which follow effective ID/group except when <code>setfsuid</code> and <code>setfsfid</code>
are called. But they&#8217;re seldom used. They only exist to cover use cases
of <code>NFS</code>.</p>

<h2>Ruby Base64</h2>

<pre><code>require 'base64'
Base64.encode64("borf") # =&gt; "Ym9yZg==\n"
Base64.strict_encode64("borf") # =&gt; "Ym9yZg=="
</code></pre>

<ul>
<li><code>encode64</code> implements the base64 referenced in
<a href="https://www.ietf.org/rfc/rfc2045.txt">IETF 2045</a>,
the RFC on Multipurpose Internet Mail Extensions (MIME).</li>
<li><code>strict_encode64</code> implements the base64 specified
in <a href="http://tools.ietf.org/html/rfc4648">IETF 4648</a>, which
goes into more detail, gets rid of the newlines</li>
</ul>


<p>I used to have to do <code>gsub(/\n/, "")</code> after encoding to get Ruby&#8217;s
<code>encode64</code> to be compatible with some other that was more picky about
Base64.</p>

<p>Also, I was wondering why the <code>==</code> exist. Base64 converts any bytestream
to a 64 bit alphabet. In other words, 2<sup>6</sup> characters. Consider the
following random 3 byte stream:</p>

<pre><code>01011010 00001111 10101111
</code></pre>

<p>We&#8217;re used to thinking of them split by 8 bits, but a base64 character
can only account for 6 bits, so you&#8217;d actually think of it like:</p>

<pre><code>010110 100000 111110 101111
</code></pre>

<p>This explains why encoding as base 64 has a 4/3 size overhead, an
important consideration before willy nilly encoding a bunch of giant
assets at base 64.</p>

<p>It also explains why encoding strings whose lengths aren&#8217;t a multiple of
3 end up adding <code>=</code> padding (&#8220;borf&#8221; => &#8220;Ym9yZg==\n&#8221;).</p>

<h2><code>ls -d</code></h2>

<p>e.g. <code>ls -ld somedir</code> to show the directory entry rather than expanding
it and listing all of its files.</p>

<h2>Y2K for epoch 32 bit = year 2038</h2>

<p>The epoch + 32 bit signed int max = year 2038.</p>

<h2>Service Workers</h2>

<p>http://www.w3.org/TR/service-workers/#motivations</p>

<p>https://github.com/slightlyoff/ServiceWorker/blob/master/explainer.md</p>

<p>Alex Russell&#8217;s been working on this. It&#8217;s a huge improvement over the
declarative app cache. A ServiceWorker is a WebWorker that can get
installed on page load, and then once installed, is consulted on future
page loads, even if there isn&#8217;t any internet.</p>

<blockquote><p>Documents live out their whole lives using the ServiceWorker they start with.</p></blockquote>

<p>This means if no service worker existed at initial doc download, then
installing a ServiceWorker on the first load means the ServiceWorker
will have to completely sit out for the lifetime of that page. It&#8217;s only
on feature reload where it might get consulted. This slightly off
behavior results in:</p>

<ul>
<li>better fallback for unsupporting browsers</li>
<li>makes sure that people write good URLs whether using ServiceWorkers
or not</li>
<li>Zalgo issues with pages suddenly switching in and out of being managed
by a ServiceWorker</li>
</ul>


<p>Other things of note:</p>

<ul>
<li>ServiceWorkers can die, be aborted, be restarted</li>
<li>So don&#8217;t write them to be stateful.</li>
<li>Or if so, use IndexedDB. (If ServiceWorkers are available, IndexedDB
is available)</li>
</ul>


<h2><code>od</code>: octal decimal dumps</h2>

<pre><code>echo "a" | od

0000000    005141
0000002
</code></pre>

<p>I&#8217;d expect just one stupid byte, why are there multiples?</p>

<p>Oh duh because <code>echo</code> includes a newline.</p>

<pre><code>echo -n "a" | od 

0000000    000141
0000001
</code></pre>

<p>Wat.</p>

<pre><code>echo -n "aa" | od
0000000    060541
0000002
</code></pre>

<p>Oh right, this is an octal dump. Here&#8217;s binary</p>

<pre><code>echo -n "aa" | od -b
0000000   141 141
0000002
</code></pre>

<p>Makes more sense. The leftmost column is just a row indicator.
At some point it&#8217;ll wrap, and you always look at the last one for an
indicator of the length thus far.</p>

<pre><code>echo -n "big ass set of bytes" | od -b
0000000   142 151 147 040 141 163 163 040 163 145 164 040 157 146 040 142
0000020   171 164 145 163
0000024
</code></pre>

<p>See? It wraps automagically.</p>

<h2>cwd</h2>

<p>Processes have <code>cwd</code>s. They&#8217;re the starting point for filename lookups.
A shell&#8217;s current directory is that shell&#8217;s <code>cwd</code>. You can use
<code>getcwd(3)</code> to get the current one.</p>

<p>What&#8217;s the difference between <code>pwd</code> and <code>cwd</code>? <code>pwd</code> is a command that
stands for Print Working Directory. It prints the <code>cwd</code>. But it does so
with the <code>PWD</code></p>

<p><code>$PWD</code> is an env var you can check. <code>$OLDPWD</code> is set when you <code>cd</code> and
<code>cd -</code> uses it.</p>

<p>Soooo I believe the answer to everything is this: the kernel knows about
<code>cwd</code>, but doesn&#8217;t track the absolute path to it in string form; it&#8217;s
just a pointer, which is all it needs in conjunction with relative file
paths to locate and open/create/unlink files, etc.</p>

<p>Shells on the other hand provide a convenience built-in <code>pwd</code> and
expose/manage the <code>$PWD</code> var (et al) to provide a string.</p>

<h2>Hard-linking directories.</h2>

<p>Forbidden in most things, allowed in Mac OS X; twas responsible for
the data loss bug in Broccoli, since <code>rm -rf</code> ing a directory would
follow that link and kill shit.</p>

<p>Why does Mac allow it? Apparently it&#8217;s used in Time Machine. If a
directory hasn&#8217;t changed, a new snapshot can just point to the same
directory inode without duplicating it.</p>

<p>Great explanation: http://stackoverflow.com/a/4707231/914123</p>

<p>By the way <code>ln</code> and <code>link</code> are the same executable:</p>

<pre><code>$ ls -lai `which link`
11551 -rwxr-xr-x  2 root  wheel  14976 Oct 31  2013 /bin/link
$ ls -lai `which ln`
11551 -rwxr-xr-x  2 root  wheel  14976 Oct 31  2013 /bin/ln
</code></pre>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-09-27T09:29:00-04:00" pubdate data-updated="true">Sep 27<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/09/23/daily-snaggletooth/">
		
			Daily Snaggletooth</a>
	</h2>
	<div class="entry-content">
		<h2>Nginx Heroku Buildpack</h2>

<p>https://github.com/ryandotsmith/nginx-buildpack</p>

<blockquote><p>Some application servers (e.g. Ruby&#8217;s Unicorn) halt progress when
dealing with network I/O.</p></blockquote>

<p>This was confusing at first but I think it just means that since
Heroku&#8217;s router only buffers headers and not the entire request, it&#8217;s
possible that a slow client with a large payload will hog a unicorn
worker due to a slow blocking <code>read()</code>, in which time that worker isn&#8217;t
available to process other requests.</p>

<p>The proposed nginx buildpack solution is to put nginx in front of an
IO-bound (and poorly designed/optimized) server and buffer the entire
request and not engage the app server until all the data is there, and
then it can barf the entire request into the app server in one shot,
minimizing blocking IO.</p>

<p>In general though Unicorn is non-ideal in the following cases:</p>

<ul>
<li>Slow client and/or large payload</li>
<li>The app server is internally IO-bound and makes, say, lots of long
slow 3rd party API requests, because in that time it&#8217;s blocking
requests that otherwise could have been handled in a less IO-bound
setting</li>
</ul>


<h2>TTL: Time to Live</h2>

<p>http://en.wikipedia.org/wiki/Time_to_live#IP_packets</p>

<p>Some reason I always pronounced &#8220;live&#8221; as a-live. Rather than the verb
&#8220;live&#8221;. Why? I don&#8217;t know. Time to Live (verb) makes way more sense. How
much time it has to live, rather than, how much time until it is live.
Ridiculous.</p>

<ul>
<li>IP: a per-gateway decrementing value (as opposed to a unit of time).
In other words: IP TTL is max hop.</li>
<li>DNS: time in seconds that a DNS record can be cached. Low values tax
authoritative name servers. Higher values risk staleness. 86400 (24
hours) is common. Before a DNS change, DNS admins might change to a
lower number in advance. QUESTION: why would I, selfish DNS admin, not
just choose a TTL of 1 all the time? Presumable answer: DNS is another
roundtrip unless cached; I might be making my application slower.
Additionally, if DNS goes down (probably rare?), my clients can
still use
<code>#networking</code> validates my presumable answer.</li>
</ul>


<h2>HTTPSAP</h2>

<p>HTTPS Ain&#8217;t a Protocol. It&#8217;s just HTTP layered over TLS, an encrypted
transport layer.</p>

<h2>Resetting Wifi of Remote Mac server</h2>

<p>Heh, this worked</p>

<pre><code>#!/bin/bash

networksetup -setairportpower en1 off
sleep 10
networksetup -setairportpower en1 on
</code></pre>

<p>Run via <code>nohup ./thisdumbscript &amp;</code>.</p>

<p>SSH will be unresponsive for 10+ seconds and then recover. The Magic of
the INTERNET!</p>

<h2>WebSockets and proxy servers</h2>

<p>http://www.infoq.com/articles/Web-Sockets-Proxy-Servers</p>

<p>Websockets work on port 80 and 443:</p>

<blockquote><p>HTML5 Web Sockets do not require new hardware to be installed, or new ports to be opened on corporate networks&#8211;two things that would stop the adoption of any new protocol dead in its tracks.</p></blockquote>

<p>Transparent proxy server: let&#8217;s stuff through, might manipulate content?</p>

<h2>BOSH: Bidirectional-streams Over Synchronous HTTP</h2>

<p>http://en.wikipedia.org/wiki/BOSH</p>

<p>Isn&#8217;t this just long polling? It&#8217;s long polling with the assurance that
immediately after receiving a &#8220;push&#8221;, the client makes a new long-lived
request on the same keep-alive connection. And it can make no more than
one connection whenever it needs to send data. Why does this have its
own stupid name?</p>

<h2>SSH Tunneling</h2>

<p>First off, you can just execute commands like</p>

<pre><code>ssh machty@whatever.com ls
</code></pre>

<p>and assuming I&#8217;ve already done the keygen stuff, that&#8217;ll log in, run
<code>ls</code>, and output the result of that.</p>

<p>But you can use <code>ssh</code> to spin up a local server that makes your SSH
connection act as a proxy to some other IP/port, map that to a local
port, and then connect other things through to that local port.</p>

<p>If I did</p>

<pre><code>ssh machty@wat.com -L 8080:somesite.com:80
</code></pre>

<p>Then I could do</p>

<pre><code>curl localhost:8080
</code></pre>

<p>and then see the contents of somesite.com as a request originating from
the wat.com server I &#8220;logged&#8221; into. (Except that most sites don&#8217;t
respond the way you&#8217;d like if <code>Host</code> and other headers are incorrect).</p>

<h2>What is my public IP?</h2>

<p>You need some third party to tell your your public IP after all the NAT
traversals. You shouldn&#8217;t use this for super sensitive stuff (it&#8217;s
possible the 3rd party server was compromised and maaaaybe there&#8217;s some
exploit if you use this fake IP for some internal thing?).</p>

<p>But this worked for me:</p>

<pre><code>curl icanhazip.com
</code></pre>

<p>Someone on SO suggested this: http://www.moanmyip.com/</p>

<p>I can&#8217;t believe that exists.</p>

<h2>SOCKS proxy</h2>

<p>https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-tunneling-on-a-vps</p>

<p>http://en.wikipedia.org/wiki/SOCKS</p>

<p>With a SOCKS proxy</p>

<h2>tcptraceroute</h2>

<p>Instead of ICMP ECHO packets, which often get filtered out at some point
by some asshole proxy along the way to the destination, tcptraceroute
uses TCP SYN packets instead. What&#8217;s that you say? Don&#8217;t we still need
the incrementing TTL that ICMP uses? TRICK QUESTION: TTL is an octet in
the IP packet, which wraps TCP/UDP/ICMP. So <code>tcptraceroute</code> still uses
TTL. It&#8217;s also nice enough to send a TCP RST (reset) package if the the
destination responds with a SYN|ACK so that you don&#8217;t leave it in a
connection-half-opened state (normally you&#8217;re supposed to send an ACK
and then start sending application data).</p>

<p>Interesting: you need root privileges to run tcptraceroute. Why? Because
the custom SYN packets it creates requires root privileges, probably to
prevent non-privileged users from doing malicious things with packets.
I&#8217;d be curious to know exactly where that takes place though.</p>

<h2>IP packets have no port</h2>

<p>Why? Because ports map to applications, a concept which IP packets don&#8217;t
care about; they&#8217;re all about getting messages to an address. Leave it
to the UDP/TCP packets to provide a source and destination</p>

<p>So hmmm how does ICMP traceroute work? How do the ECHO&#8217;d packets know to
come back to that specific traceroute command?</p>

<h2>ICMP</h2>

<ul>
<li>No port</li>
</ul>


<p>There&#8217;s a single ICMP socket apparently?</p>

<p>https://www.cs.utah.edu/~swalton/listings/sockets/programs/part4/chap18/ping.c</p>

<pre><code>/*
 * pr_pack --
 *  Print out the packet, if it came from us.  This logic is necessary
 * because ALL readers of the ICMP socket get a copy of ALL ICMP packets
 * which arrive ('tis only fair).  This permits multiple copies of this
 * program to be run without having intermingled output (or statistics!).
 */
</code></pre>

<ul>
<li>ident = getpid() &amp; 0xFFFF;

<ul>
<li>this is how a pong that returns is identified as originating from a
pong.</li>
</ul>
</li>
</ul>


<p>Anyway here&#8217;s a little Ruby program you can run with <code>sudo</code>
that&#8217;ll open a raw socket and print a Base64&#8217;d ping packet if you
<code>ping localhost</code>.</p>

<pre><code>require 'socket'
require 'base64'

rsock = Socket.open(:INET, :RAW)

loop do
  s = rsock.recv(1024)
  enc = Base64.encode64(s)
  puts enc
end
</code></pre>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-09-23T11:18:00-04:00" pubdate data-updated="true">Sep 23<span>rd</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/09/20/daily-juggernaut/">
		
			Daily Juggernaut</a>
	</h2>
	<div class="entry-content">
		<h2>Rust is a &#8220;Systems&#8221; programming language</h2>

<p>Seems vague. You can use it for games (<code>#rust-gamedev</code> or
<code>/r/rust_gamedev</code>). What does systems mean?</p>

<p><code>#rust</code> tells me more vague stuff, but basically:</p>

<ul>
<li>Rust doesn&#8217;t impose garbage collection, so you maintain fine-grained
control over memory in that regard</li>
<li>Rust integrates nicely with C</li>
</ul>


<p>These features are often compared with Go. Go has GC. Go apparently
doesn&#8217;t integrate as nicely with C (not sure how true this is, need to
dig in). Apparently Go used to advertise itself as systems, then they
stopped, and Rust adopted that term to make it clear how it is different
from the oft-compared Go.</p>

<h2><code>source</code> and <code>export</code></h2>

<p>I always knew the <code>source</code> command as the command you use when you want
to run a script with a bunch of <code>export</code> definitions, but all it really
means is that <code>source</code> doesn&#8217;t actually make new process but just runs
the code in the source file as shell commands. As such, it means that
any environment vars set in the sourced command don&#8217;t get set in a
separate child process that dies and forgets set vars.</p>

<p><code>export</code> makes sure that an env var gets passed to child processes. Just
setting an env var without <code>export</code> won&#8217;t mark it to be shared with
child processes.</p>

<p>You can verify all of this by <code>source</code>ing a script with a long <code>sleep</code>
and then checking <code>ps</code> to verify that <code>sleep</code> is a direct child of
<code>bash</code>; there&#8217;s no intermediate process running that execution.</p>

<h2>prey project</h2>

<p>Protect your devices from theft:</p>

<p>https://preyproject.com/</p>

<p>TODO: look into this shit.</p>

<h2>awesome cheese</h2>

<p>Stompetoren Grand Cru. With Effie&#8217;s Homemade Oatcakes.</p>

<p>So fucking good.</p>

<p>http://bedfordcheeseshop.com/products/stompetoren-gouda-grand-cru</p>

<h2>Why is CORS disabled for XHR but not a 3rd party post?</h2>

<p>CSRF is still a thing, but falls outside of CORS because CORS intends to
make JavaScript-initiated requests safe. Then again didn&#8217;t
Chrome/Mozilla just make fonts CORS-y?</p>

<h2>Access-Control-Allow-Origin</h2>

<p>I&#8217;d get this error in devtools console whenever my Rails code errored
out during an XHR request:</p>

<pre><code>XMLHttpRequest cannot load http://localhost:5000/wat
No 'Access-Control-Allow-Origin' header is present on the requested resource.
Origin 'http://localhost:4200' is therefore not allowed access. 
</code></pre>

<p>It&#8217;s misleading since I have CORS set up correctly, but apparently not
for erroring requests? Basically, using XMLHTTPRequest (ajax) is going
to set the <code>Origin</code> request header, which flags the server to send back
CORS headers. If the browser doesn&#8217;t see those CORS headers, or the
provided ones don&#8217;t match / grant proper permissions, then the XHR
request will fail.</p>

<p>So basically I have an error in my server code I need to fix. Maybe it&#8217;s
good that CORS fails upon error? Because if not, then I might be opening
up some third party door that&#8217;s sniffing my site due via erroneous
requets? I can&#8217;t really see it but maybe.</p>

<h2>Why won&#8217;t my dumbass server work?</h2>

<p>Scenario: I have a remote Minecraft server. It runs from a persistent
tmux session so that I can log in and run server commands on it. I can
ping it successfully but when I try to join, it fails to connect with
authentication servers. There&#8217;s lots of reported issues online with
authentication servers but I think in my case no outbound requests are
succeeding. <code>curl google.com</code> yields no response, and neither do pings.</p>

<p>Whoops. I just remotely turned off the server&#8217;s wifi and got
disconnected. I figured I&#8217;d turn it off and on again to see if that
&#8220;rebooted&#8221; things. But, uh, kinda need internet through that whole
process. Dumbest moment of 2014.</p>

<h2>Do shells fork to start new processes?</h2>

<p>Yes. Bash will fork itself and then calls execve to transform itself
into a new process.</p>

<p>There&#8217;s also an <code>exec</code> built-in command that will replace your bash
instance with whatever you wanna run, which means when the new command
terminates, your bash terminal will close, e.g.:</p>

<pre><code>exec sleep 1
</code></pre>

<p>An &#8220;Environment list&#8221; maintains the key value pairs of env vars. When
you exec a new process, it either inherits the env of its parent or gets
a new one. In C-land, the <code>char ** environ</code> variable is exposed contain
all env vars, testable via:</p>

<pre><code>#include &lt;stdio.h&gt;
extern char **environ;
int main() {
  printf("%s\n", environ[0]);
  return 0;
}
</code></pre>

<h2>mmap</h2>

<p>Virtual memory mapping. It&#8217;s a syscall to map a region of virtual memory
to a file, or to create an anonymous mapping that doesn&#8217;t write to a
file.</p>

<h2>CGI / Rack limitations</h2>

<p><a href="http://en.wikipedia.org/wiki/Common_Gateway_Interface">Common Gateway Interface</a></p>

<p>http://blog.plataformatec.com.br/2012/06/why-your-web-framework-should-not-adopt-rack-api/</p>

<p>Shortcoming: middlewares that allocate/release resources</p>

<h2>Mac Desktop Shell Scripts</h2>

<p>Save this with <code>+x</code> chmod permissions as <code>~/Desktop/wat.command</code>.</p>

<pre><code>#!/bin/bash
echo "wat"
</code></pre>

<h2>htop</h2>

<p><code>brew install htop</code></p>

<p>It&#8217;s top but way way more bitchin. OMG, it even has a tree mode.</p>

<h2>man vs info</h2>

<p>Just discovered that there&#8217;s both <code>man bash</code> and <code>info bash</code>. <code>info</code> was
added in the 90s by GNU, who felt <code>man</code> was too crappy a manual system for
sophisticated software.</p>

<h2>Job control / monitor mode</h2>

<p>Bash (et al, but apparently not Bourne?) implement job control, the
ability to suspend resume jobs (process groups) via an interactive
shell. Job control is enabled when &#8220;monitor mode&#8221; is on. In bash, this
is enabled by default. To disable: <code>set +m</code>. To enable: <code>set -m</code>. When
disabled, you&#8217;ll see things like:</p>

<pre><code>$ fg
-bash: fg: no job control
</code></pre>

<p>You also won&#8217;t be able to ^Z out of a running process (a SIGTSTP still
fires but bash ignores it). <code>ruby -e "Process.kill(:TSTP,0)"</code> runs to
completion when monitor mode is disabled.</p>

<p>Actually hmm, interesting, if you disable monitor mode and run</p>

<pre><code>ruby -e "Process.kill(:STOP, 0); puts 'done'"
</code></pre>

<p>then it just runs to completion? How is that possible?
My guess is that the process stops, and then is immediately resumed
because there&#8217;s nothing to take its place? Seems SIGSTOP is ignored even
when you sent it from another terminal to a terminal with -m.</p>

<p>Also, you can display all the shell options via <code>echo $-</code></p>

<pre><code>himBH
hiBH # monitor mode disabled
</code></pre>

<h2>Dollar signs</h2>

<p>http://stackoverflow.com/a/5163260/914123</p>

<pre><code> 1. Positional parameters `$1,$2,$3` and their corresponding array representation, count and IFS expansion `$@`, `$#`, and `$*`.
 2. `$-` current options set for the shell.
 3. `$$` pid of the current shell (not subshell)
 4. `$_` most recent parameter (or the abs path of the command to start the current shell immediately after startup)
 5. `$IFS` the (input) field separator
 6. `$?` most recent foreground pipeline exit status
 7. `$!` PID of the most recent background command
 8. `$0` name of the shell or shell script
</code></pre>

<h2>syscalls</h2>

<p>Example: <a href="http://www.opensource.apple.com/source/tcl/tcl-5/tcl/compat/waitpid.c">waitpid</a></p>

<p>Wrapper C functions stash args in registers, stash syscall id in <code>%eax</code>,
and then runs a <code>trap</code> machine instruction, which tells the processor to
switch into kernel mode. (Recent hardware uses <code>sysenter</code> instead of
slower <code>trap</code>, which incurred interrupt overhead&#8230; TODO: learn about
interrupts!). The rest is obvious enough.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-09-20T12:30:00-04:00" pubdate data-updated="true">Sep 20<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/09/17/daily-journeaux/">
		
			Daily Journeaux</a>
	</h2>
	<div class="entry-content">
		<h2>nginx book</h2>

<p>This is nice: http://aosabook.org/en/nginx.html</p>

<p>Some random notes:</p>

<p>For CPU-bound loads, number of nginx workers should equal the number of
cores (&#8220;TCP/IP, doing SSL, or compression&#8221;). For IO-bound stuff
(&#8220;serving different sets of content from storage, or heavy proxying&#8221; &#8211;
presumably teh &#8220;different sets&#8221; is important because if it were
the same stuff, it&#8217;d probably be cached which I guess means the IO would
be negligible? unsure) &#8211; you might want 1.5-2 times the number of
cores.</p>

<h2>SSL/TLS random questions:</h2>

<p>I have so many misconceptions? For anyone who reads this, this is stream
of thought as I try to answer my own questions before looking shit up.</p>

<p>How come domains are signed and not IPs?</p>

<p>Reasoned guess: first off, everyone can encrypt data. It&#8217;s just that the
key thing that TLS brings in is certification of a sending. It&#8217;s not
enough to say &#8220;yo here&#8217;s my public key&#8221;, you still have to answer the
question &#8220;uh ok yes but who are you?&#8221;. Certificate authority to the
rescue.</p>

<p>So what if CA&#8217;s certified IPs, rather than domain names (maybe they do,
I don&#8217;t actually know at this point)? Some ideas come to mind:</p>

<ul>
<li>DNS can map to multiple IPs, and a single IP might load balance to
many different servers, all of which should be able to (de)/encrypt
incoming traffic.</li>
</ul>


<p>That&#8217;s actually probably the only reason. I was originally thinking
that since IPs can change, you might certify server A and then the next
day the IP changes to server B, and that that would mean the CA is
giving a stamp of approval to the wrong server, but then, duh, it&#8217;s key
pairs that are being validated, and server B wouldn&#8217;t have these keys
and wouldn&#8217;t know how to do the handshake. I think this is close to
correct, it&#8217;s just I&#8217;m forgetting everything that happens internally
within the handshake.</p>

<p>http://en.wikipedia.org/wiki/Transport_Layer_Security</p>

<h2>Symmetric Key</h2>

<p>A single key encrypts plaintext and decrypts the ciphertext generated
from the encryption.</p>

<p>Example: AES.</p>

<h2>Cipher suite</h2>

<p>https://www.iana.org/assignments/tls-parameters/tls-parameters.xhtml#tls-parameters-4</p>

<p>A triple of</p>

<ul>
<li>authentication</li>
<li>encryption</li>
<li>and message authentication c</li>
</ul>


<h2>SSL / TLS</h2>

<p>Lots of people use them interchaangeably, but SSL was originally created
at Netscape and used to be implemented at the application layer, living
on top of TCP. When it was IETF standardized, it was renamed TLS and
moved out of the application layer.</p>

<p>TLS provides:</p>

<ul>
<li>encryption

<ul>
<li>obfuscate data transmitted from one computer to another</li>
<li>example: plaintext means zero encryption and easily breakable
ciphertext means shitty encryption</li>
</ul>
</li>
<li>authentication</li>
<li>verify that you&#8217;re talking to who you think you&#8217;re talking to</li>
<li>example: the CA validates the certificate that a server sends you</li>
<li>integrity

<ul>
<li>detect message forgery or tampering</li>
<li>example:</li>
</ul>
</li>
</ul>


<h2>Beware the intermediaries</h2>

<p>Intermediaries are caching servers, gateways, web accelerators, content
filters, blah blah blah, all the stuff that&#8217;s come out to aid and extend
HTTP. They&#8217;re often transparent to the end user, but they come with the
limitation that if you start wanting to deviate from HTTP on port 80 in some
application specific way, you&#8217;re boned. And it&#8217;s kinda rare to find
other ports that are open: 80 and 443 (HTTPS) are usually open but
everything else is often closed. These intermediaries might improperly
try to apply their logic to the non HTTP, etc, there&#8217;s no easy way to
detect when or when not to apply.</p>

<p>Solution: HTTPS tunnel all the things. All data is obfuscated from
intermediaries and intermediaries have no way of known whether the
encrypted data is HTTP or some custom proprietary crazy thing.</p>

<h2>Self-signed certificates</h2>

<p>http://www.akadia.com/services/ssh_test_certificate.html</p>

<p>Things learned:</p>

<ul>
<li>&#8220;If the private key is no longer encrypted, it is critical that this file only be readable by the root user!&#8221;</li>
<li>You can remove the DES from the private key so that you don&#8217;t have to
type in the password all the god damn time when your server starts.
(Verified this with a node app)</li>
</ul>


<p>Turns out you could also just run the following:</p>

<pre><code>openssl req -new 
</code></pre>

<p>So why is DES required at all? I&#8217;m guessing it&#8217;s possible to generate a
CSR without it, right?</p>

<h2>ALPN: Application-Layer Protocol Negotiation</h2>

<p>Note to dummy: there&#8217;s no TLS 3 way handshake. You&#8217;re thinking of TCP
ACK SYN SYNACK that has to happen before app data is exchanged.</p>

<p>ALPN takes place during the</p>

<h2>SNI: Server Name Indication</h2>

<p><a href="https://www.ietf.org/rfc/rfc3546.txt">rfc, page 8</a></p>

<p>If you have a server that you want to host multiple sites with their own
respective TLS certificates,</p>

<h2>self-signed-certificate</h2>

<p>Useful for testing SSL before you go ahead and buy a certificate for 3rd
party validation.</p>

<h2>AES vs RSA</h2>

<p>AES is symmetric, and generally speaking symmetric encryption/decryption
is a lot faster than assymetric, hence AES is used for the
encryption/decryption of data.</p>

<h2>Sprite gotchas</h2>

<p>I used to think sprites were bitchin; save HTTP requests, combine all
your images into one. Obviously, these are lame application-level
optimizations/hacks to cover the ass of the transport layer&#8217;s (HTTP&#8217;s)
shortcomings (addressed in SPDY / HTTP 2.0).</p>

<p>Downsides of sprites:</p>

<ul>
<li>all the application-layer crap you have to do to handle it</li>
<li>change a single pixel of a single image and you&#8217;ve busted a massive
cached of all the other images in the sprite</li>
<li>memory intensive; you might not be using each image but you have to
load all of it in memory, might be too much for mobile clients</li>
</ul>


<h2>Octet</h2>

<p>It means byte. Saw it all over the place in the
<a href="https://datatracker.ietf.org/doc/draft-ietf-httpbis-http2/?include_text=1">HTTP 2 spec draft</a></p>

<h2>nginx</h2>

<p>After <code>brew install nginx</code></p>

<pre><code>Docroot is: /usr/local/var/www

The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that
nginx can run without sudo.

To have launchd start nginx at login:
    ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
Then to load nginx now:
    launchctl load ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist
Or, if you don't want/need launchctl, you can just run:
    nginx

WARNING: launchctl will fail when run under tmux.
</code></pre>

<p>What is docroot?</p>

<ul>
<li>It&#8217;s a file&#8230; not a directory?</li>
<li>But you can delete it and replace with a directory and put an
index.html in there and it works</li>
<li>So I guess there&#8217;s some default configuration of nginx that just hosts
static files from this doc root directory</li>
</ul>


<p>What do them commands does?</p>

<pre><code>ln -sfv /usr/local/opt/nginx/*.plist ~/Library/LaunchAgents
</code></pre>

<p>What are launchd and launchctl?</p>

<p><code>launchd</code> is a daemon (conventions dictate that daemons end in a <code>d</code>).
<code>launchctl</code> is what you use to control that daemon. So if you want to
schedule something to start</p>

<p>What&#8217;s the <code>mxcl</code> in <code>homebrew.mxcl.redis.plist</code>?</p>

<p>It refers to <code>mxcl</code>, maintainer of Homebrew. Just normal reverse domain
name notation. So does that mean any homebrew-installed domains get
prefixed like that? I&#8217;m guessing <code>mxcl</code> also made the Redis recipe.
Or maybe every homebrew daemon gets prefixed like that? Not sure, who
cares.</p>

<pre><code> In the launchd lexicon, a "daemon" is, by definition, a system-wide service of
 which there is one instance for all clients. An "agent" is a service that runs
 on a per-user basis. Daemons should not attempt to display UI or interact
 directly with a user's login session. Any and all work that involves interacting
 with a user should be done through agents.
</code></pre>

<p><a href="https://developer.apple.com/library/mac/technotes/tn2083/_index.html">TN2083 - Daemons and Agents</a></p>

<p>Wow, &#8220;Daemonomicon&#8221; is an awesome word: &#8220;formal definition of the types
of bg programs you can write&#8221;.</p>

<ul>
<li>bootstrap server: launchd</li>
<li>root session: first and last session. Boot-time processes and daemons
live here. User-independent. e.g. <code>mDNSResponder</code></li>
<li>login session: proceses launched by or for a user live in login
session. Login sessions are associated w authenticated users. Each
user</li>
</ul>


<p>If I</p>

<h2>Origins of TTY</h2>

<p>http://www.linusakesson.net/programming/tty/</p>

<ul>
<li>stock tickers, then ASCII teletype within a network called Telex.</li>
<li>Telex was a network that used level of current to respresent different
characters, vs different voltages used by analog telephone shit</li>
<li>Telex existed before integration w computers</li>
<li>When command lines became the norm, teletypes were used as input and
output since they were readily available on the market</li>
<li>Lots of different models, needed to standardize in some way; UNIX
philosophy dictated letting kernel handle low level word length, baud
rate, flow control, etc., later things like color output, cursor
movement, etc, was left to application (not kernel)</li>
<li>Line editing is managed by OS-provided line discipline. Default is
cooked/canonical mode. raw mode disables things like editing,
backspace, and generally disables any IO processing within the line
discipline.</li>
</ul>


<p>Skipping ahead, you can force your terminal into stty raw mode via</p>

<pre><code>stty raw #enable
stty -raw #disable
</code></pre>

<p>Now I know how to write a Ruby impl of Press Any Key</p>

<pre><code>print "Press any key... "

begin
  system("stty raw -echo")
  c = STDIN.getc
ensure
  # re-enable
  system("stty -raw echo")
end

puts "Thanks!"
</code></pre>

<p>Note that it&#8217;ll consume CTRL-C as well rather than signalling an
interrupt (hence CTRL-C prints &#8220;Thanks!&#8221; rather than terminating
immediately).</p>

<p>This is also how any text editor functions.</p>

<p>This must be what&#8217;s happening when I kill some script when it doesn&#8217;t
expect it and then my terminals fucked. Typing in <code>stty -raw</code> even
though I can&#8217;t see it probably would fix it&#8230; need to try.</p>

<p>Back to the thing:</p>

<ul>
<li>Kernel provides many line disciplines, only one attached to serial
device at a time. Default is <code>n_tty</code>. I guess that&#8217;s what we&#8217;re
configuring when we futz w <code>stty</code></li>
<li>Other disciplines are for things like packet switched data</li>
<li><a href="http://www.cs.fsu.edu/~baker/devices/lxr/http/source/linux/drivers/char/n_tty.c">tty C source code</a></li>
<li>UART (Universal Async Receiver and Transmitter): converts teletype
signal into bytes that the OS can process. OS has a UART driver.</li>
<li>TTY driver: allows user to kill/suspend an infinite looped program,
bg processes can process til they try to write to terminal (at which
point they suspend), and user input to fg process only.
(implemented in <code>tty_io.c</code>)</li>
<li>TTY Device: triplet of UART driver, line discipline, and TTY driver.</li>
<li>TTY devices live in <code>/dev</code> w file mode <code>c</code> for &#8220;Character special
file&#8221;. To manipulate one, you need ownership of the device file
(e.g. via <code>login</code>).</li>
<li>TTYs are just objects. Not alive. Other things plug into it. Those
other things have execution contexts.</li>
<li>pty = pseudoterminal, as opposed to TTY.</li>
</ul>


<p><code>ps -o stat</code> prints out <code>Ss</code> <code>Ss+</code>, etc&#8230; here&#8217;s what the capital
letters mean:</p>

<pre><code>R   Running or runnable (on run queue)
D   Uninterruptible sleep (waiting for some event)
S   Interruptible sleep (waiting for some event or signal)
T   Stopped, either by a job control signal or because it is being traced by a debugger.
Z   Zombie process, terminated but not yet reaped by its parent.
</code></pre>

<p>Most things are in <code>S</code>. An example of <code>R</code>:</p>

<pre><code>ruby -e 'loop {}'
</code></pre>

<p><code>s</code> means session group leader. <code>+</code> means process is part of foreground
process group.</p>

<ul>
<li>Ctrl Z suspends a process, puts it in <code>T</code> state.</li>
</ul>


<p>Jobs, e.g. <code>fg</code> and <code>bg</code> are just process groups. Consider</p>

<pre><code>ruby -e 'loop {}'  | grep a | grep a | grep a
</code></pre>

<p>This causes as CPU-intensive loop and will be in R state.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R+   s045    7:03.43 ruby -e loop {}
machty 45755 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S+   s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>and when I suspend:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 T    s045    7:29.05 ruby -e loop {}
machty 45755 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 T    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 T    s045    0:00.00 grep a
</code></pre>

<p>Everything below it suspends.</p>

<p><code>jobs</code> are tied to session leaders, and terminals are session leaders.
If I go to another tmux pane and type <code>jobs</code>, the suspended job <em>won&#8217;t</em>
show up; I have to be in the same terminal that started it. TODO: can I
change session IDs?</p>

<p>If I <code>bg 1</code>, the following happens:</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 45754 45014 45754      0    4 R    s045    7:39.63 ruby -e loop {}
machty 45755 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45756 45014 45754      0    4 S    s045    0:00.00 grep a
machty 45757 45014 45754      0    4 S    s045    0:00.00 grep a
</code></pre>

<p>Note how it&#8217;s back to running, but note the missing foreground <code>+</code>. <code>fg 1</code>
would bring it back.</p>

<p>Note that we could turn one of those greps into <code>R</code> if it was actively
processing data, e.g.</p>

<pre><code>USER     PID  PPID  PGID   SESS JOBC STAT   TT       TIME COMMAND
machty 46054 45014 46054      0    4 R+   s045    0:37.84 ruby -e loop { puts "a" }
machty 46055 45014 46054      0    4 R+   s045    0:45.56 grep a
machty 46056 45014 46054      0    4 R+   s045    0:27.01 grep b
machty 46057 45014 46054      0    4 S+   s045    0:00.00 grep a
</code></pre>

<p>(Actually, the first 3 R&#8217;s might be S&#8217;s if you re-run this command;
there&#8217;s a race condition as to whether the CPU is actually running code
or whether it&#8217;s blocked on an IO syscall waiting for piped data to come
in, but the last grep is always S+ because it never gets output from the
<code>grep b</code>).</p>

<p>A Job is a Processs Group.</p>

<p>If you&#8217;re just starting/stopping/piping processes, all those child
processes with have a parent process ID of <code>bash</code>&#8217;s pid.</p>

<p>What constitutes a job/process group? Piped commands for one.
Let&#8217;s see about Process Subsitution. Answer: process substitution
doesn&#8217;t consider it as a pipe. It considers it as a shit of epic
fartitude. In other words, process substitution ends up being miserably
old and mortal and definitely going to die. In other words, process
substitution is not in the same process group. It&#8217;s its own process
group. If you do <code>echo &lt;(some long living thing)</code>, the long living thing
will survive as a sibling process, in its own process GROUP WHO CARES.</p>

<p>You can only read from  / write to TTY if you&#8217;re foreground. If you&#8217;re
not <code>fg</code> and you try and write to TTY, kernel will suspend your ass.</p>

<ul>
<li><code>ioctl</code> is the UNIX swiss army knife; manipulates special files like
terminals.</li>
<li><code>ioctl</code> requests must be initated from processes, so the kernel can&#8217;t
asyncly communicate w an application unless the app asked for it.</li>
<li>Signals are how kernel communicates asyncly w a process. Messy and
error prone they are.</li>
</ul>


<p>Question: nohup detaches into its own session id to prevent closing on
SIGHUP&#8230; why does it have to do that? Why can&#8217;t it just ignore that
signal? Let&#8217;s see.</p>

<pre><code>Signal.trap(:HUP) do
  puts "I WILL NOT"
end
sleep
</code></pre>

<p>If I ssh localhost and run that in background (with <code>&amp;</code>) and then
logout, it stays running, PPID changes to 1 (root). So how is that
different than nohup? TODO: find out. Something with setsid, etc.</p>

<p>SIGINT&#8217;s originate from the terminal&#8230; is it correct to say they
originate from TTY? I think it is based on the <code>n_tty.c</code> code.
Also, in raw mode it doesn&#8217;t even fire. COOL.</p>

<ul>
<li>SIGPIPE isn&#8217;t just an error but also a way to know whoever was
listening to you has stopped listening to you, e.g. <code>yes | head</code>.</li>
<li>SIGSTOP is to SIGTSTP as SIGKILL is to SIGQUIT.</li>
<li>SIGCONT can be sent to a ^Z-suspended process. It behaves as if you
started the process with <code>&amp;</code>. It&#8217;s running, but it&#8217;s bg. In other
words, if you have a suspended process 12345, <code>bg 1</code> or
<code>kill -CONT 12345</code> would do the same thing; it&#8217;d start running in the
background, spitting out output</li>
<li>You can break shit with
<code>ruby -e 'Signal.trap(:TTIN) { puts "wat" }; sleep 1; gets' &amp;</code>
(recursive SIGTTIN). You try and write to TTY in the background and
then keep ignoring the signal that it&#8217;s failing. I don&#8217;t know what
causes the deadlock though, but <em>something</em> screwing up sounds right.</li>
<li>If you press ^Z, that sends a message to the foreground process group.
The line discipline sends <code>SIGTSTP</code> to the foreground process group.
This will suspend the whole process group, whatever the main</li>
</ul>


<p>Question: if you use pipes combined with <code>&amp;</code>, what gets put into the
background? All tasks? Answer (I think): <code>&amp;</code> ultimately results in a
process group getting put into the background, and a process group
contains any pipes, child processes, etc, so it <em>must</em> apply to all of
the different processes as a whole, and there&#8217;s no way to say that only
one of the pipe segments runs in the background.</p>

<p>Fun fact: you can reimplement the default ^Z behavior as follows:</p>

<pre><code>has_ignored = false
Signal.trap(:TSTP) do
  if has_ignored
    Process.kill(:STOP, Process.getpgrp)
  else
    has_ignored = true
    puts "ignoring"
  end
end

sleep
</code></pre>

<p>TL;DR the default SIGTSTP ^Z handler fires a STOP. You can catch TSTP
and immediately do the same for the same effect.</p>

<p>Vim&#8217;s source code (and probably everyone&#8217;s) does some variant of</p>

<pre><code>settmode(TMODE_COOK);
kill(0, SIGTSTP);       /* send ourselves a STOP signal */
</code></pre>

<p>So, you return TTY mode to cook mode.</p>

<ul>
<li>If you run something like <code>echo "wat" | less &amp;</code>, you&#8217;ll immediately
see <code>[2]+  Stopped   echo "wat" | less</code> because <code>less</code> is always going
to try and write to TTY in a raw manner&#8230;?</li>
<li>If you suspend, say, vim, vim will catch the SIGTSTP, move the cursor
to the last line of the screen w control signals (it&#8217;s still attached
to TTY) and then fires a SIGSTOP.</li>
<li>Once stopped, a SIGCHLD is sent to the session leader with the pid of
the suspended process. When all processes in fg have been suspended
(T&#8217;d), the current TTY config is stashed for later restoration
(<code>stty -g</code> is one way of doing this).</li>
</ul>


<p>So why doesn&#8217;t ^Z suspend bash?</p>

<p>Ahh, so here&#8217;s how you get TTOU to fire (and cause a process to suspend)</p>

<pre><code>ruby -r "io/console" -e "IO.console.raw { puts 'wat' }" &amp;
</code></pre>

<p>Note that if we hadn&#8217;t used <code>.raw</code> to put TTY in raw mode, it would have
just printed &#8220;wat&#8221; into the same terminal even though the process is
running in the background, but if you grab full control of the TTY with
<code>raw</code>, it&#8217;ll cause a TTOU.</p>

<p>You can go in and configure another TTY to update its rows/cols. I can
fuck w the vim in another tmux pane, tell it its skinnier/wider than it
is, but once i resized a tmux pane then BOOM it fires its own tty
commands, and tty fires a SIGWINCH, and then that causes vim to query
the tty for the current width and repaint.</p>

<p>Ah: realization: the ultimate decider in whether TTOU fires is whether
topstop</p>

<h2><code>read</code></h2>

<pre><code>read words &lt; &lt;(echo "wat")
echo $words
</code></pre>

<h2>resetting the keyboard when things go crazy</h2>

<p><code>reset</code>, or typing Escape and c.</p>

<pre><code>stty raw
reset
</code></pre>

<p>and we&#8217;re back. It resets your TTY driver, I guess.</p>

<h2><code>yes</code></h2>

<p>Repeatedly enter <code>y</code> for saying yes to everything. Like the dropper bird
from the simpsons when homer gets fat. You can also do <code>yes no</code> to say
other things.</p>

<h2>Ack</h2>

<p>is written in Perl.</p>

<h2>100 Continue status</h2>

<p>An HTTP 1.1 mechanism.</p>

<p>http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html</p>

<p>In some cases, a server knows just by looking at request headers that it
won&#8217;t process the request, making it potentially wasteful for the client to send a
giant doomed-to-fail payload. In these cases, the client can decide not
the send the full payload unless the server has told it &#8220;based on your
headers, you should Continue sending this full payload because I don&#8217;t
see any reason why it should fail, just by looking at the headers.&#8221;</p>

<p>To opt into this, the client must provide the following header:</p>

<pre><code>Expect: 100-continue
</code></pre>

<p>The server will see this, decide if the request will succeed, and if so,
it send back 100 Continue and keeps reading from the input stream.
Client then sends the whole payload.</p>

<p>Proxies can reject if it knows the next-hop server is HTTP 1.0 or less
with a 417 Expectation Failed.</p>

<h2>IOS8 breaks file uploads in Safari</h2>

<p>http://blog.fineuploader.com/2014/09/10/ios8-presents-serious-issues-that-prevent-file-uploading/</p>

<p>Jesus. No workaround? Apple, you suck.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-09-17T08:08:00-04:00" pubdate data-updated="true">Sep 17<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/09/15/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>FTP</h2>

<p>Plaintext, unless you&#8217;re using SFTP or some variant.</p>

<p>FTP uses multiple connections: 1 control connection for sending
commands and tracking current directory, etc, and a connection for
actually streaming the file data.</p>

<p>How the second connection (data) is established depends on active vs
passive mode: in active mode, the server will try to connect back to the
client at PORT+1, and in most modern cases, this will fail due to NATs
and firewalls, hence passive mode (via PASV) command is meant to get
around this. In passive mode, the client requests an IP and port from
the server (via the control connection), and then the client makes the
second connection to whatever the server returns. This works as clients can
generally connect to servers without NAT/firewall issues.</p>

<p>Note that active connections are rare. The man page for <code>ftp</code> is
telling:</p>

<pre><code>-A          Force active mode ftp.  By default, ftp will try to use passive mode
            ftp and fall back to active mode if passive is not supported by the
            server.  This option causes ftp to always use an active connection.
            It is only useful for connecting to very old servers that do not
            implement passive mode properly.
</code></pre>

<h2>Application-level gateway</h2>

<p>http://en.wikipedia.org/wiki/Application-level_gateway</p>

<p>TODO: learn more.</p>

<h2>Process per connection</h2>

<p>One way of handling a new connection is to fork and let the forked
process handle that connection. Makes sense for the parent instance to
use Ruby&#8217;s <code>Process.detach</code>, which doesn&#8217;t have a native kernel
equivalent but is just a Ruby convenience that spins up a thread that
calls <code>wait()</code> on the forked process to prevent it from becoming a
zombie if the parent process exits before the forked one.</p>

<p>Remember that forking isn&#8217;t available on Windows or JRuby.</p>

<p><code>shotgun</code> is a Ruby server that forks per connection. Why? Isn&#8217;t this
wasteful (relative to pre-forking solutions like Unicorn)? Yes, but it
has specific purpose: assuming it&#8217;s not painfully expensive to spin up
your server (like Rails), and that you don&#8217;t have a mechanism for
reloading after code changes (like Rails), <code>shotgun</code> will fork per
connection and entirely reload / spin up the rack server, less reloading
the latest version of any Ruby code, thus not requiring you to manually
restart your server.</p>

<h2>Thread per connection</h2>

<p>Typical state-sharing caveats apply when working with threads, hence
it&#8217;s useful to thing about the simple unit of concurrency that will keep
your threads isolate and minimize their access to shared data. That unit
would be a connection; each thread should get its own connection object.
Create a connection object, immediately create a new thread, and let
that connection object fall out of scope in the creator thread so that
only the newly spawned thread has access to it. Simple enough.</p>

<h2>How to verify your code is on multiple cores</h2>

<p>You have to dig in a little bit to verify that Ruby code you&#8217;re writing
is actually being processed on multiple CPU cores. There are many
variables:</p>

<ol>
<li>Does your system even have more than one core? (try <code>system_profiler | grep 'Total Number of Cores'</code> to find out, probably some other ways too)</li>
<li>Does your Ruby have a GIL? (MRI does, Rubinius and JRuby don&#8217;t)</li>
<li>Some third thing to pad my arbitrary list of bullshit.</li>
</ol>


<p>Anyway, one easy way is to run the following code:</p>

<pre><code>NUM_CORES = 2

threads = []
NUM_CORES.times do |t|
  threads &lt;&lt; Thread.new do
    log_every = 1000000
    i = 0
    loop do
      i += 1
      if i == log_every
        i = 0
        putc t.to_s
      end
    end
  end
end

threads.each(&amp;:join)
</code></pre>

<p>Running this on MRI Ruby results in 100% CPU usage. Running in JRuby
yields 200%, which means two cores are operating at 100%. Pretty rad,
yes?</p>

<p>CPU usage reported by activity monitor or <code>top -o cpu</code>.</p>

<h2>Preforking</h2>

<p>e.g Unicorn</p>

<p>What&#8217;s nice is that the kernel will handle load-balancing for us: when
there are no incoming requests, you have N forked instances blocked on
<code>accept</code>, and the kernel will choose which instance gets the next
incoming request. If all forked instances are busy, the kernel will just
queue up the request internally. If the queue gets full, you&#8217;ll get an
ECONNREFUSED. Easy peazy.</p>

<p>Unicorn (and probably Rainbows) does some extra tracking on child
processes to make sure it&#8217;s not getting stuck on long requests, etc.</p>

<p>Main disadvantage is memory usage. By the time you fork, if the parent
process is 100 mb, then 4 forks and you&#8217;re at 500 mb&#8230; unless 1) your
OS has COW and 2) you don&#8217;t write to it all that much.</p>

<h2>Reactor</h2>

<p>e.g. Node.js, Twisted, EventMachine</p>

<p>High levels of concurrency (not necessarily parallelism) achievable,
relative to threading/forking models, which hit their RAM limit much
faster (Reactor patterns mean that everything is just heap allocations
on the same thread).</p>

<p>Impacts on programming model:</p>

<ul>
<li>No processes/threads, so no shared memory, synchronization, etc, to
have to worry about</li>
<li>Don&#8217;t block the single Reactor thread (because nothing else will be able to
run). You wouldn&#8217;t have to worry about this in thread/processland.
This is why if you&#8217;re using EventMachine, your gems must be
event-machine aware, otherwise they&#8217;ll block (which would be fine in a
threading/forking environment).</li>
</ul>


<h2>Node cluster</h2>

<p>http://nodejs.org/api/cluster.html</p>

<p>Based on the fact that you can use child process forking to split heavy
duty work into process that can each live on a different core, if that&#8217;s
what you&#8217;re about.</p>

<p>Note that there&#8217;s no C-like or Ruby-like fork in Node; you can&#8217;t just
call fork and then have both the parent and newly forked child process
continue execution from that <code>fork()</code> invocation&#8230;</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-09-15T19:57:00-04:00" pubdate data-updated="true">Sep 15<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/09/06/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>netcat (nc)</h2>

<p>Utility to spinning up arbitrary tcp servers for testing, sending
packets, etc.</p>

<pre><code>Socket.new(Socket::AF_INET, Socket::SOCK_STREAM)
or symbols:
Socket.new(:INET6, :STREAM)
</code></pre>

<p>INET = internet, specifically IPv4, <code>SOCK_STREAM</code> means a TCP stream
will be set up, as opposed to <code>DGRAM</code>, which would set up UDP.</p>

<p>Set up bullshit listener:</p>

<pre><code>nc -l localhost 4481
</code></pre>

<h2>Loopback</h2>

<p><code>localhost</code> is a loopback, which is a virtual interface where any data
sent to the loopback is immediately received. <code>127.0.0.1</code> is the IP.</p>

<p>Check dat <code>/etc/hosts</code> file:</p>

<pre><code>##
# Host Database
#
# localhost is used to configure the loopback interface
# when the system is booting.  Do not change this entry.
##
</code></pre>

<p>Funny how I never notice stuff like that until someone officially
defines it for me.</p>

<h2>&#8220;well-known&#8221; ports</h2>

<p>Hosted by IANA.org, the Internet Assigned Numbers Authority.</p>

<h2>Gerrymandering</h2>

<blockquote><p>manipulate the boundaries of (an electoral constituency) so as to favor one party or class.</p></blockquote>

<p>Knew what this was, forgot the word for it.</p>

<h2>AWS Spot Instances</h2>

<p>Running interruption-tolerant applications on EC2 unused capacity, where
you can bid on price per hour and maximum bid price.</p>

<h2>Chekhov&#8217;s Gun</h2>

<p>http://en.wikipedia.org/wiki/Chekhov&#8217;s_gun</p>

<blockquote><p>Remove everything that has no relevance to the story. If you say in the first chapter that there is a rifle hanging on the wall, in the second or third chapter it absolutely must go off. If it&#8217;s not going to be fired, it shouldn&#8217;t be hanging there.</p></blockquote>

<p>Anton Chekhov is considered to be among the greatest writers of short
stories in history. Guess I should start reading.</p>

<h2>Binding to an interface</h2>

<p>You can bind to a single interface, or ALL interfaces, lol!</p>

<p><code>0.0.0.0</code> means all interfaces. I guess that means that requests to
localhost, and potentially some other external facing interface, will
route requests to this socket. So what if someone has already bound
specifically to localhost:12345 and you try to bind to <code>0.0.0.0:12345</code>?</p>

<p>Answer: I don&#8217;t know&#8230; need to learn about what other interfaces are
available</p>

<p>REVISED ANSWER: I can use the IP provided by my router.</p>

<pre><code>ruby -run -e httpd . --port=4124 --bind-address=192.168.1.3
</code></pre>

<p>Then if I type <code>localhost:4124</code> in the browser, it don&#8217;t work, but if I
type <code>192.168.1.3:4124</code> in the browser, IT WORKS. :)</p>

<p>But to the original question, it turns out you can run ALL THREE of
these:</p>

<pre><code>ruby -run -e httpd . --port=4123 --bind-address=0.0.0.0
ruby -run -e httpd . --port=4123 --bind-address=192.168.1.3
ruby -run -e httpd . --port=4123 --bind-address=localhost
</code></pre>

<p>So the first and 3rd of these should be able to respond to</p>

<pre><code>curl localhost:4123 &gt; /dev/null
</code></pre>

<p>It seems that the third (localhost) always wins. Makes sense. What about</p>

<pre><code>curl 192.168.1.3:4123 &gt; /dev/null
</code></pre>

<p>And the more specific second one always wins. So I guess the OS will
look for a match of interface+port before falling back to 0.0.0.0.
Makes sense.</p>

<h2>listen queue size</h2>

<pre><code>socket.listen(10)
</code></pre>

<p>This means your socket will buffer up to 10 connections before
<code>ECONNREFUSED</code> is return to the shits on the other side.</p>

<p>If you&#8217;re getting a lot of ECONNREFUSED, it probably means users are
already experiencing some some queue-based lag, and you should rethink
your architecture, spin up more server instances, etc. But you can also
just set to the max size via</p>

<pre><code>server.listen(Socket::SOMAXCONN)
</code></pre>

<h2>A connection is a socket</h2>

<p>When you accept() after binding, you&#8217;ll get a connection object, which
is just a Socket, but different from your server socket; it&#8217;s just a
file wrapper for that particular connection that you can write shit to.</p>

<h2>quadruple of remote/ip/port must be unique</h2>

<p>You can&#8217;t have more than one connection where</p>

<pre><code>local addr, local port, remote addr, and remote port
</code></pre>

<p>are not totally unique. Hmmm, so where is this prevented? TODO</p>

<h2>Close socket file descriptors</h2>

<p>Why, doesn&#8217;t this happen automatically on exit/GC?</p>

<ol>
<li>GC might not clean up for you fast enough;</li>
<li>Might hit file descriptor limit</li>
</ol>


<p>Wat wat wat wat in the boot.</p>

<p>You can close the read side, or close the write side, or both. This make
use of <code>shutdown</code>, and shutdown will close a side of a connection even
if you&#8217;re dup&#8217;d file descriptors (explicitly or via fork). <code>close</code>
wouldn&#8217;t actually close unless there were no other file descriptors
holding on to that socket.</p>

<h2>Keybase</h2>

<p>Uses social media accounts to prove crypto identity.</p>

<h2>Clients don&#8217;t need to bind</h2>

<p>to a port when connecting to a server. For obvious reasons. Namely that
a server needs to have a known/consistent port in order for clients to
reach it, but a client can just send from any ol po,]rt.</p>

<h2>Long ass timeouts</h2>

<pre><code>require 'socket'
socket = Socket.new(:INET, :STREAM)
remote_addr = Socket.pack_sockaddr_in(666, 'machty.com')
socket.connect(remote_addr)
</code></pre>

<p>This won&#8217;t fail any time soon. (Note if i&#8217;d given a BS DNS then it would: SocketError
exception from getaddrinfo). Only after a long ass time do you get a
ETIMEDOUT.</p>

<p>getaddrinfo seems cool. I guess it&#8217;s the C function that does a DNS
lookup? Nevermind, man <code>getaddrinfo</code> makes me cry.</p>

<p>So when does ECONNREFUSED happen vs just a long ass timeout? I guess it
means you&#8217;ve hit a server but a) no app is bound to the requested port
or b) the queue is full, and probably c) some other reason. No that&#8217;s
not valid; google.com:70 hangs for a while rather than ECONNREFUSED.</p>

<p>Maybe localhost knows what&#8217;s connected or not? I have NO IDEA.</p>

<h2><code>TIME_WAIT</code></h2>

<p>If you close a socket with pending outbound data, it won&#8217;t discard that
data but rather finish sending (and wait for ack) before totally closing
the socket. This is the <code>TIME_WAIT</code> state. Unless you&#8217;ve enabled
<code>REUSEADDR</code>, you&#8217;ll get an <code>EADDRINUSE</code> if you try to bind to a socket
that&#8217;s still in <code>TIME_WAIT</code> state.</p>

<h2><code>EAGAIN</code></h2>

<p>Commonly seen in non-blocking IO operations when there&#8217;s no data
available to read. Reading nonblockingly from a socket that hasn&#8217;t had EOF set yet but
doesn&#8217;t have data at the moment would cause that.</p>

<p>Non blocking reads will find any data in Ruby buffers, followed by
kernel buffers. If there&#8217;s nothing in there, then blocking read is
necessary.</p>

<h2>Ruby IO.write</h2>

<p><code>IO.write_nonblock</code> behavior maps to sys call <code>write()</code>, in that it can
fail to write all the data you provided it. Ruby&#8217;s <code>IO.write</code> tries to
be helpful and might internally call <code>write()</code> many times.</p>

<p>A saturated <code>write()</code> followed immediately by <code>write()</code> will cause an
<code>EAGAIN</code> because you haven&#8217;t given the kernel/network enough time to
flush the data you gave it. This is when you&#8217;d use <code>IO.select</code> to let
you know when a socket is available for writing/reading again.</p>

<p>Wat wat wat. In the BOOT.</p>

<p><code>select</code> returns an array of descriptors that are ready to be written
to. I guess it blocks?</p>

<p>Writes are blocked by TCP congestion prevention algo requirements
(cwnd, rwnd, etc).</p>

<p>There&#8217;s also <code>accept_nonblock</code> which <code>EAGAIN</code>s if there are no pending
connection on dat queue.</p>

<p><code>connect_nonblock</code> is sp</p>

<h2>TPC Resets</h2>

<p>http://en.wikipedia.org/wiki/TCP_reset_attack</p>

<p>There&#8217;s a usually-0 flag in a packet that can be set to 1 that tells the
receiver to stop using this TCP connection. Useful, for instance, when a
computer&#8217;s crashed, gets a packet it has no context for, so it tells the
sender to stop it, so that it might make a new connection and start from
there.</p>

<h2>Edge Device</h2>

<p>http://en.wikipedia.org/wiki/Edge_device</p>

<p>Basically, all the stuff that separates the public network (internet)
from your private network.</p>

<ul>
<li>routers</li>
<li>routing switches</li>
</ul>


<h2>traceroute</h2>

<p>I&#8217;ve already written about this before, but traceroute is useful for
tracing all the gateways your packet goes through to get to its
destination.</p>

<p>A gateway is any node that might forward packets along to some other
destination. Could be a router, switch, etc. Could also be a protocol
converter. Gateways could be software too.</p>

<p>Anyway, traceroute makes use of ICMP <code>TIME_EXCEEDED</code> response.</p>

<p><a href="http://en.wikipedia.org/wiki/Internet_Control_Message_Protocol">What is ICMP?</a></p>

<p>One of the many protocols that can be communicated via packets. Packets
have an 8 bit protocol field. The protocol values are decided by the
IANA (just like common/reserved ports&#8230; MIND BLOWN).</p>

<p>The list is here: http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml</p>

<h2><code>host google.com</code></h2>

<p>I noticed that the DNS lookup results via <code>host google.com</code> differed
almost each time I ran it.</p>

<pre><code>google.com has address 74.125.226.72
google.com has address 74.125.226.65
google.com has address 74.125.226.68
google.com has address 74.125.226.67
google.com has address 74.125.226.64
google.com has address 74.125.226.70
google.com has address 74.125.226.78
google.com has address 74.125.226.69
google.com has address 74.125.226.73
google.com has address 74.125.226.71
google.com has address 74.125.226.66
...
</code></pre>

<p>and then</p>

<pre><code>google.com has address 74.125.226.2
google.com has address 74.125.226.5
google.com has address 74.125.226.8
google.com has address 74.125.226.9
google.com has address 74.125.226.6
google.com has address 74.125.226.4
google.com has address 74.125.226.3
google.com has address 74.125.226.14
google.com has address 74.125.226.7
google.com has address 74.125.226.0
google.com has address 74.125.226.1
...
</code></pre>

<p>I&#8217;m asking the friendly folk at <code>##networking</code>. They turned me on to
<code>dig</code>. <code>dig</code> is the most raw and flexible DNS lookup tool. <code>host</code> is
apparently for chumps (i.e. it&#8217;s useful/quick/easy but not as much
functionality).</p>

<pre><code>dig google.com @ns1.google.com +short | sort | md5
</code></pre>

<p>This queries a specific name server&#8230;</p>

<p>OK i have a bunch of questions:</p>

<p>Why do DNS records contain
<a href="http://en.wikipedia.org/wiki/Fully_qualified_domain_name">Fully Qualified Domain Names</a>
as references to name servers? That seems to make no sense&#8230; you have
to turn something like <code>ns1.google.com</code> into an IP by querying&#8230; the
DNS system?</p>

<p>Answer: http://en.wikipedia.org/wiki/Domain_Name_System#Circular_dependencies_and_glue_records</p>

<ul>
<li>GET www.example.com /

<ul>
<li>Look up record, find its NS records</li>
<li>NS ns1.example.com</li>
<li>Need to get IP of ns1.example.com (we need to issue another DNS
request)</li>
<li>&#8230; circular dependency: you have to look up a name server&#8217;s IP
using that name server. Need some way to break dependency</li>
<li><p>Dependency broken by <code>AUTHORITY SECTION</code>, e.g.</p>

<p>;; AUTHORITY SECTION:
google.com.             60      IN      SOA     ns1.google.com. dns-admin.google.com. 1566886 7200 1800 1209600 300</p></li>
</ul>
</li>
</ul>


<p>This is called the &#8220;glue&#8221;. It&#8217;s either in Authority or Additional
section? (I should find this out.)</p>

<p>Related: http://support.dnsimple.com/articles/vanity-nameservers/</p>

<p>DNSimple allows &#8220;vanity&#8221; name servers, which lets you pretend like
you&#8217;re a bigass enough company to own/maintain your own name servers,
and anyone looking at your DNS records will see your fake name servers,
like ns1.machty.com, but these servers obviously don&#8217;t actually exist;
DNSimple provides this service by sending &#8220;glue&#8221; that maps your fake
name servers to the IP addresses of their actual name servers.</p>

<p>Top-level domains live under root (.).</p>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<p>That&#8217;s why sometimes you&#8217;ll see stuff ending in a period, like
<code>ns1.dnsimple.com.</code>.</p>

<pre><code>;; ANSWER SECTION:
dnssimple.com.          597     IN      A       184.168.221.96
</code></pre>

<p>The dot is important! You know how you can just put <code>www</code> is the record
value? You could also do a fully qualified shit e.g. <code>www.machty.com.</code>
(note the period at the end).</p>

<p>So my question is: when does the glue record get sent?</p>

<p>Gimme the NS records for www.machty.com</p>

<pre><code>$ dig machty.com NS
...
;; ANSWER SECTION:
machty.com.             3481    IN      NS      ns1.dnsimple.com.
machty.com.             3481    IN      NS      ns1a.dnsimple.com.
machty.com.             3481    IN      NS      ns2.dnsimple.com.
machty.com.             3481    IN      NS      ns2a.dnsimple.com.
machty.com.             3481    IN      NS      ns3.dnsimple.com.
machty.com.             3481    IN      NS      ns3a.dnsimple.com.
machty.com.             3481    IN      NS      ns4.dnsimple.com.
machty.com.             3481    IN      NS      ns4a.dnsimple.com.
</code></pre>

<p>Cool, so internally it&#8217;d need to look up ns1.dnsimple.com, so something
like:</p>

<pre><code>$ dig @ns1.dnsimple.com. www.machty.com
</code></pre>

<p>http://www.tldp.org/HOWTO/DNS-HOWTO-5.html</p>

<blockquote><p>+norec means that dig is asking non-recursive questions so that we get to do the recursion ourselves. The other options are to reduce the amount of dig produces so this won&#8217;t go on for too many pages:</p></blockquote>

<pre><code>a.root-servers.net. 518400  IN  A   198.41.0.4
a.root-servers.net. 518400  IN  AAAA    2001:503:ba3e:0:0:0:2:30
</code></pre>

<p>AAAA records serve the same purpose as A records, just that they are
IPv6.</p>

<p>WebPageTest.org: breaks your requests down into blah blah blah why is
this different than Network tab in devtools? Ah because it does it from
many different browsers.</p>

<p>162.212.105.24</p>

<h2>Turntable.fm</h2>

<p>Me: &#8220;there should be an app where multiple people have a playlist, but
there&#8217;s a single player that alternates between different people&#8217;s
playlists.&#8221;</p>

<p>Person next to me: &#8220;yes, that&#8217;s turntable.fm&#8221;</p>

<p>Should probably check that out.</p>

<h2>non-blocking connect</h2>

<p>http://stackoverflow.com/questions/8277970/what-are-possible-reason-for-socket-error-einprogress-in-solaris</p>

<p>There are two error codes for &#8220;shit is underway&#8221; when doing a
non-blocking connect/accept:</p>

<pre><code> [EALREADY]         The socket is non-blocking and a previous connection attempt
                    has not yet been completed.

 [EINPROGRESS]      The socket is non-blocking and the connection cannot be com-
                    pleted immediately.  It is possible to select(2) for comple-
                    tion by selecting the socket for writing.
</code></pre>

<p>Nice docs yo. The difference is that <code>EINPROGRESS</code> is the error that
gets returned if the operation has started but hasn&#8217;t finished (as
opposed to not yet being able to start because it can&#8217;t allocate the
resources it needs, file handlers, sockets, etc.). Most likely, the 3
way handshake packets have been sent, but SYN-ACK hasn&#8217;t been sent.</p>

<h2>Inversion of Control / DI</h2>

<p>Matthew Beale and I were discussing whether the proposed
<code>Ember.service()</code> violated the inversion of control that dependency
injection is meant to provide, e.g.:</p>

<pre><code>export default Controller.extend({
  foo: Ember.service() // request that 'service:foo' be injected
});
</code></pre>

<p>The fact that the consumer is requesting a specific thing to be injected
into it seems like it might be an IOC violation, but to me, all that&#8217;s
happening is that you&#8217;re specifying a provider, and it&#8217;s still up to the
outside world to decide what it&#8217;ll specifically inject into you. Also,
regardless of whether it&#8217;s explicit or not, if you use whatever is
injected into you, you are implicitly specifying a duck-typed provider
interface by the consumer; in other words, if we do things the classic
way and use <code>app.inject('controller:article', 'articleLookup', 'service:article-lookup')</code>,
this may seem like we&#8217;re moving all &#8220;control&#8221; to the injector, but
still, the article controller is going access <code>articleLookup</code>&#8217;s
properties and methods in a very specific way, which is the most
powerful / crucial way that you could specify a dependency (by
describing / using the duck type interface).</p>

<p>So, tl;dr, your consumer is always going to be specifying its
dependency, whether explicitly (<code>Ember.service()</code>) or implicitly (by
whatever methods/properties it uses from <code>this.injectedThing</code>), and it&#8217;s
therefore not a violation for a consumer to specify a Provider of the
dependency, so long as it&#8217;s still possible for the injector to disregard
the specifically-requested provider and substitute another one (e.g. a
stub) in its place.</p>

<p>This is what Angular&#8217;s <a href="https://github.com/angular/di.js">di.js</a> does
and I think it&#8217;s correct. I want it.</p>

<h2>Password-less SSH</h2>

<p>I&#8217;ve done this a bunch of times before but always forget, now I&#8217;m
writing about it:</p>

<p>The remote server you&#8217;re SSHing into needs to have your public key if
you want to be able to skip providing a password every time you ssh in.
I wanted to use a different public rsa key, so I made a new one:</p>

<pre><code>ssh-keygen
</code></pre>

<p>The optional passphrase you&#8217;re asked to supply is NOT the same password
you would have otherwise needed to use to log into SSH (which we&#8217;re
trying to avoid). Rather, it&#8217;s an additional security measure that&#8217;s
required every time you want to use your private RSA key to try and
decrypt data. I guess: if private RSA keys are a kind of password, the
passphrase is a password for your password. It means that someone who
steals your private key also needs to know your passphrase in order to
use it.</p>

<p>Anyway, let&#8217;s say I save the newly generated key pair to
<code>~/.ssh/shortcut_rsa</code> and <code>~/.ssh/shortcut_rsa.pub</code>, now I want to make
it possible to just type <code>ssh shortcut</code> and have it never ask me for a
password again. This means I need a few things:</p>

<ol>
<li><code>ssh shortcut</code> should translate into the IP I&#8217;m connecting to
(because I&#8217;d rather not type the IP every time and <code>shortcut</code> is not
a domain name that&#8217;d do the translating for me)</li>
<li><code>ssh shortcut</code> should supply the user name that the remote machine
expects (so that I don&#8217;t have to do <code>ssh remote_user_name@shortcut</code>).</li>
<li><code>ssh shortcut</code> should use the key pair I just generated w
<code>ssh-keygen</code>.</li>
</ol>


<p>To do all of these things, I need to append the following to
<code>~/.ssh/config</code>.</p>

<pre><code>Host shortcut
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>Pretty self explanatory and does the job. Note that you&#8217;ll be prompted
for the passphrase you provided for your RSA private key, but that&#8217;ll be
cached for a little while, and if you want, you can just save it to your
Apple keychain if you feel safe doing that.</p>

<p>The SSH config file also allows for wildcards, so you could literally do</p>

<pre><code>Host *
  HostName 162.123.123.123
  User remote_user_name
  IdentityFile "/Users/machty/.ssh/shortcut_rsa"
  IdentitiesOnly yes
</code></pre>

<p>and then this would cause <code>ssh somerandombullshit</code> to connect to the
same remote machine. Obviously that use case is a little nuts, but it&#8217;s
useful if you wanna say &#8220;every remote machine I connect to should use
this same RSA key pair&#8221;.</p>

<h2>say+say+say = choir</h2>

<p>I devised the most badass script.</p>

<pre><code>#!/usr/bin/env sh

# use/uncomment this instead to weed out the annoying singing voices
#voices=`say -v ? | grep en_US | grep -v Cellos | grep -v Good | grep -v Hysterical | grep -v Bad | grep -v Pipe | grep -v Bells | cut -f1 -d ' '`
voices=`say -v ? | grep en_US | cut -f1 -d ' '`
num=`echo $voices | wc -w`
echo $voices | xargs -n 1 -P $num say $* -v
</code></pre>

<h2>How many segments are sent per SSH character?</h2>

<p>http://blog.hyfather.com/blog/2013/04/18/ssh-uses-four-tcp-segments-for-each-character/</p>

<p>Answer: 4</p>

<ol>
<li>You: Hey SSH server, user pressed &#8216;b&#8217;</li>
<li>SSH: cool, got it (ack)</li>
<li>SSH: hey btw, this is what <code>bash</code> (or whatever shell) ended up doing
with that character you type (description of screen update)</li>
<li>You: cool, got it (ack)</li>
</ol>


<p>What&#8217;s the difference between a segment and a packet?</p>

<ul>
<li>Segment: TCP header + application data</li>
<li>Packet: wraps segment w IP header information; a packet is a routable
piece of data</li>
</ul>


<p>This seems like the best answer: http://superuser.com/a/505134</p>

<p>A TCP segment is not enough information to know where to route data
within a network; you need IP headers for that, and where do those shits
live? In packets.</p>

<p>Take a packet and rip off its IP head: voila, a packet. Take a packet
and rip off its TCP (or UDP) head: voila, application data.</p>

<p>Don&#8217;t forget &#8220;frames&#8221;: frames wrap packets. If you wanna send your shit
over an ethernet, you need to wrap in a frame, whether wired or
wireless. Frames have MAC addresses. MAC addresses are generally
hard-wired into some hardware and are never expected to collide, lest
undefined behavior.</p>

<p>Now my question is: does TCP ever have access to IP headers? I guess it
must get forwarded along in some way&#8230; then again I dunno.</p>

<h2>RFC3439: Some Internet Architectural Guidelines and Philosophy</h2>

<p>http://tools.ietf.org/html/rfc3439</p>

<p>Clearly I need to read this.</p>

<h2>Nagle&#8217;s Algo</h2>

<p>When sending data:</p>

<ol>
<li>If there&#8217;s enough data in local packet buffer to comprise a whole TCP
packet, send that shit.</li>
<li>If no pending data in buffers and no pending acks, send immediately.</li>
<li>If there&#8217;s a pending ack, and not enough data to fill a packet, put
data in local buffer.</li>
</ol>


<p>This prevents protocols like telnet from saturating with
one-packet-per-char traffic. For telnet, if you type a bunch of chars in
a row, you could expect that the first char would send immediately and
the following ones would buffer and then send once the first char&#8217;s ack
came back.</p>

<p>All Ruby servers disable this since Ruby does its own internal buffering
in the socket lib. You disable by sending with NODELAY.</p>

<h2>URG flag</h2>

<p>Apparently you can break the FIFO-ness of TCP with Urgent data.</p>

<p><code>Socket#send</code> is the same as <code>write</code> except that you can pass flags to
<code>send</code>, e.g.</p>

<pre><code>socket.send 'urgent data', Socket::MSG_OOB
</code></pre>

<p>OOB stands for out of band. Note that the receiver must use the same
flag w <code>recv</code> to read the OOB data or else it won&#8217;t notice it.</p>

<p>OOB is rarely used because:</p>

<ul>
<li>only one byte of urgent data can be sent</li>
<li>there are issues w <code>select</code> wherein consumed urgent data continues to
be reported as unread, requires additional state tracking to get
right, etc.</li>
</ul>


<p>You could also use OOBINLINE flag to stick in an urgent byte amidst
normal queued data, and <code>read</code> will stop once it hits an urgent thing.</p>

<p>I&#8217;m guessing OOB is only a TCP thing since in UDP there&#8217;s no concept of
connection and &#8220;in order&#8221;.</p>

<h2>Datagram</h2>

<p>Data + telegram. From RFC 1594:</p>

<blockquote><p>A self-contained, independent entity of data carrying sufficient information to be routed from the source to the destination computer without reliance on earlier exchanges between this source and destination computer and the transporting network.</p>

<p>The term datagram is often considered synonymous to packet but there are some nuances. The term datagram is generally reserved for packets of an unreliable service, which cannot notify the sender if delivery fails, while the term packet applies to any packet, reliable or not. Datagrams are the IP packets that provide a quick and unreliable service like UDP, and all IP packets are datagrams;[4] however, at the TCP layer what is termed a TCP segment is the sometimes necessary IP fragmentation of a datagram,[5] but those are referred to as &#8220;packets&#8221;.</p></blockquote>

<p>So, datagrams imply unreliability of delivery, whereas packet could
refer to reliable or unreliable packets. I guess a TCP segment is a
packet. But you can&#8217;t call it a datagram, since the protocol makes it
its business to be a shit.</p>

<h2>Bill Burr</h2>

<p>How&#8217;s your danish?</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-09-06T14:30:00-04:00" pubdate data-updated="true">Sep 6<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/08/28/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Why can&#8217;t React render() return multiple elements?</h2>

<p>you can&#8217;t do</p>

<pre><code>return &lt;div/&gt;&lt;div/&gt;
</code></pre>

<p>Pete Hunt tells me it&#8217;s because of how <code>ref</code>s work; it&#8217;s a common
pattern to do <code>this.refs.x.getDOMNode()</code>, but if the component returns
multiple DOM nodes, which one do you return?</p>

<p>It&#8217;s an admitted shortcoming but not a major major push to fix any time
soon.</p>

<h2>Ruby Fixnum vs Bignum</h2>

<pre><code>2.0.0-p353 :004 &gt; (100).class
 =&gt; Fixnum
2.0.0-p353 :005 &gt; (100234234234234234234).class
 =&gt; Bignum
</code></pre>

<h2>Postgres indexing</h2>

<p>I need to optimize. Most of the queries in my app are very specific
&#8220;SELECT WHERE bleh = wat, lol = yeah, foo = bar&#8221;. By default Rails
creates a btree index, which handles many common indexing use cases, but
there&#8217;s also a &#8220;hash&#8221; index, which Postgres only considers for usage for
<code>bleh = bleh</code> queries (you can&#8217;t use it for ordering, sorting,
whatever), so it seemed ideal for me:</p>

<blockquote><p>Hash indexes can only handle simple equality comparisons. The query planner will consider using a hash index whenever an indexed column is involved in a comparison using the = operator.</p></blockquote>

<p>But then I&#8217;d like it to match multiple columns, not just a single one,
so I&#8217;d like to consider a multi-column index, but then:</p>

<blockquote><p>Currently, only the B-tree, GiST and GIN index types support multicolumn indexes. Up to 32 columns can be specified. (This limit can be altered when building PostgreSQL; see the file pg_config_manual.h.)</p></blockquote>

<p>So I guess Hash is out of the question. So the final thing I need to
figure out is: does it make sense for me to use a multi-column index if
I have three columns that need to be <code>=</code> matched?</p>

<p>Partial indexes: http://www.postgresql.org/docs/8.2/static/indexes-partial.html</p>

<p>Useful for when you&#8217;d like to exclude common values from consideration
in an index (because indexes lose value the more duplicates there are in
a database).</p>

<h2>V8 optimizes based on AST size</h2>

<p>&#8230;and comments are part of the AST:</p>

<p>https://github.com/broccolijs/broccoli-kitchen-sink-helpers/commit/092a680f1ff8fe2d54419dd57fa9ba8a81f6f297</p>

<h2>General Theory of Reactivity</h2>

<p>https://github.com/kriskowal/gtor</p>

<p>Reactivity: reacting to external stimuli and propagating events.</p>

<ul>
<li>(functional) reactive programming</li>
<li>bindings</li>
<li><p>operational transform</p></li>
<li><p>Spatial Singular is a value, e.g. 5</p></li>
<li>Spatial Plural is an enumberable/iterable of values</li>
<li>Temporal Singular is an eventual value, e.g. a Promise</li>
<li>Temporal Plural is eventual values, e.g. Observable of values</li>
</ul>


<p>But this glazes over many particulars, and things like Rx boil too much
into a single Observable type that can perform any role.</p>

<h3>Value</h3>

<ul>
<li>Singular</li>
<li>Spatial</li>
<li>Accessible</li>
<li>Modifiable</li>
<li>Composed of a getter and a setter</li>
<li>Data flows from setter to getter</li>
</ul>


<p>Every reactive primitive features getter/setter, producer/consumer, or
writer/reader. See http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2014/Keynote-Duality</p>

<p>Arrays are the above, but plural. Generators are the
producing/writing/setting side, iterators are the read/get/consume.</p>

<p>Promises are singular and temporal. Promises are getters, and
corresponding setter is a resolver. Together, they&#8217;re a kind of
deferred.</p>

<p>Streams are a getter/setter pair of temporal plurals. Producer is a
writer and consumer is a reader. Reader is an async iterator and writer
is an async generator.</p>

<p>Remember that a value encapsulates a getter and setter&#8230; values are:
Deferred (promise + resolver, singular, temporal), Stream (reader +
writer, plural, temporal), Array (iterator + generator, spatial,
plural), and value (getter + setter, spatial, singular).</p>

<p>Promises (singular + temporal) model dependency. The API/experience of
multiple resolvers is the same regardless of who wins the race, and same
w consumers.</p>

<p>Because consumers cannot interfere with another consumer, aborting
promises is not possible; promise is only the result, not the work
leading to that result.</p>

<p>A task, similar to promise, but is unicast.</p>

<p>Unicast: http://en.wikipedia.org/wiki/Unicast - sending messages to a
  single destination</p>

<p>Broadcast: multiple possible destinations (or none)</p>

<p>Because tasks are unicast, consumers can&#8217;t clobber each other (because
there&#8217;s only one), hence they are cancellable. Can be explicitly forked
to create a task that depends on the same result</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-08-28T13:10:00-04:00" pubdate data-updated="true">Aug 28<span>th</span>, 2014</time></div>
	


	
</div></article>

<nav id="pagenavi">
    
    
        <a href="/blog/page/2/" class="next">Next</a>
    
    <div class="center"><a href="/archives">Blog Archives</a></div>
</nav></div>
	<footer id="footer" class="inner">Copyright &copy; 2014

    Alex Matchneer

<br>
Powered by Octopress.
</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'usefuldude';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-49928757-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>



</body>
</html>

