
<!DOCTYPE HTML>
<html>
<head>
	<script data-cfasync="false" type="text/javascript" src="//use.typekit.net/axj3cfp.js"></script>
	<script data-cfasync="false" type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<meta charset="utf-8">
	<title>Ember.js, random thoughts, journal  | machty's thoughtz</title>

<meta name="author" content="Alex Matchneer"> 

<meta name="description" content="I'm on Ember core and contribute to lots of stuff prefixed with "Em"."> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="machty's thoughtz" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script type="text/javascript" src="/javascripts/jquery.fancybox.pack.js"></script>

<script language="Javascript" type="text/javascript">
$(document).ready(
  function() {
    (function($) {
      $(".fancybox[data-content-id]").each(function() {
        this.href = $(this).data('content-id');
      });
      $(".fancybox").fancybox({
        beforeLoad: function() {
          var el, 
              id = $(this.element).data('title-id');

          if (id) {
            el = $('#' + id);

            if (el.length) {
              this.title = el.html();
            }
          }
          if ($(this).data('content')) {
            this.content = $(this).data('content');
          }
        },
        helpers: {
          title: {
            type: 'inside'
          }
        }
      });
    })(jQuery);
  }
);
</script>

	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">machty's thoughtz</a></h1>
<h4>Ember.js, random thoughts, journal</h4>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:machty.github.com">
			</form>
		</div>
	</div>
</nav>


</header>

	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/15/redis-b-hayes/">
		
			Redis B Hayes</a>
	</h2>
	<div class="entry-content">
		<h2>Redis&#8217;n</h2>

<p>This and other notes based on Redis in Action.</p>

<p>Questions:</p>

<ul>
<li>is it really brag-worthy to say in-memory-store? It gets persisted to
disk anyway; don&#8217;t other DBs bring as much into memory as possible for
fast lookups?

<ul>
<li>A: other databases are &#8220;primarily on-disk&#8221; but of course yes memory
caching exists.</li>
</ul>
</li>
</ul>


<p>Relation to memcached:</p>

<ul>
<li>Similar efficiency based on in-memory lookups</li>
<li>Redis features 2 persistence strategies (memcached doesn&#8217;t persist I
guess?)</li>
<li>Redis supports strings + 4 other data structures; memcached is strings</li>
</ul>


<p>ZSETs are hash of string keys to floating points, can be queried by
order, ordered by their weight.</p>

<h2>Databases: row insertion (often) fast</h2>

<p>Because no need for a random read + random write; appending to a file
(what most DBs do) is fast.</p>

<h2>ACID</h2>

<p>Set of properties that guarantee reliable database transactions</p>

<ul>
<li>Atomicity - all or nothing</li>
<li>Consistency - transactions bring database from one valid state to another</li>
<li>Isolation - are partially completed transaction visible to others?</li>
<li>Durability - post-transaction, data is committed even in power loss</li>
</ul>


<h2>Fortnight</h2>

<p>Two weeks.</p>

<h2>Heroku database URL</h2>

<pre><code>postgres://username:password@ec2-xx-xx-xx-xx-xx.compute-1.amazonaws.com:5432/d45d81ucgm3205
</code></pre>

<p>It&#8217;s just username + password at some publicly accessible EC2 URL. Your
cherished postgres instances just live on some EC2 farm. What a crock.</p>

<h2>Docker</h2>

<p>Docker images are read-only templates. Use them to generate containers.
Build other shit on top of containers.</p>

<p>Docker has its own IANA port numbers for REST and secure REST API&#8230;
what does this actually mean?</p>

<p>http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=docker#DOCKER</p>

<p>AH OK I have some more ideas:</p>

<p>Boot2Docker is what you use to run Docker on Mac OS X. Why? Because
docker depends on linux kernel specifics. Boot2Docker runs a Virtual Box
instance of some Linux-y thing</p>

<pre><code># within the virtual instance
$ uname
Linux version 3.16.4-tinycore64 (root@39d2c877bc4f) (gcc version 4.7.2 (Debian 4.7.2-5) ) #1 SMP Thu Oct 23 16:14:24 UTC 2014
</code></pre>

<p>So with the Boot2Docker setup, when you run the <code>docker</code> command on a
Mac terminal, it has to jump through some hoops to run the docker
instance on the Linux virtual box:</p>

<pre><code>Mac `docker` command
Proxy through to docker:tcuser@192.168.59.103
Run `docker` command, which talks to 
docker daemon
</code></pre>

<p>So there&#8217;s no docker daemon on OS X; the only persistent docker thing
you&#8217;ll see is Virtual box instances running the docker virtual instance
that the actual docker daemon lives on:</p>

<pre><code> /Applications/VirtualBox.app/Contents/MacOS/VBoxHeadless --comment boot2docker-vm --startvm 798082c7-01d7-4a4f-89fc-1ebf70bc1a0a --vrde config
 /Applications/VirtualBox.app/Contents/MacOS/VBoxNetDHCP --ip-address 192.168.59.99 --lower-ip 192.168.59.103 --mac-address 08:00:27:93:D3:BC --netmask 255.255.255.0 --network HostInterfaceNetworking-vboxnet0 --trunk-name vboxnet0 --trunk-type netadp --upper-ip 192.168.59.254
</code></pre>

<p>You can ssh into the docker VM box. Either w password or reusing the key
they generate for you when you install boot2docker; put this in
~/.ssh/config</p>

<pre><code>Host docker
  HostName 192.168.59.103
  User docker
  IdentityFile "/Users/machty/.ssh/id_boot2docker"
  IdentitiesOnly yes
</code></pre>

<p>(I realized later that there&#8217;s a convenient command for this:
<code>boot2docker ssh</code>&#8230; whoops!)</p>

<p>So with this config in place I&#8217;m guessing that I can either run
<code>docker version</code> or <code>ssh docker docker version</code> and see the same
thing. BOOYA both produce:</p>

<pre><code>Client version: 1.3.1
Client API version: 1.15
Go version (client): go1.3.3
Git commit (client): 4e9bbfa
OS/Arch (client): linux/amd64
Server version: 1.3.1
Server API version: 1.15
Go version (server): go1.3.3
Git commit (server): 4e9bbfa
</code></pre>

<p>So anyway, you can run commands against a docker image. This spins up a
container, runs the command, and stops the container&#8230; does it delete
the container?</p>

<pre><code>docker ps --help
</code></pre>

<p>Nevermind that I&#8217;ll figure it out later. Let&#8217;s figure out how to get a
Redis container running:</p>

<pre><code>https://registry.hub.docker.com/_/redis/
</code></pre>

<p>Use <code>docker build</code> to build from a Dockerfile, which kinda explains how
it ends up getting mounted to the outside world. So this is how you can
just have a docker instance of a thing that you can run commands
against, even in a Mac OS X setting? I know nothing, Jon Snow.</p>

<p>https://docs.docker.com/examples/running_redis_service/</p>

<pre><code>FROM        ubuntu:12.10
RUN         apt-get update &amp;&amp; apt-get install -y redis-server
EXPOSE      6379
ENTRYPOINT  ["/usr/local/bin/my-dumbass-redis-server"]
</code></pre>

<p>So this starts with the ubuntu:12.10 image, installs redis into the
container created from that image, exposes 6379&#8230; to&#8230;? What does this
mean?</p>

<blockquote><p>The EXPOSE instructions informs Docker that the container will listen on the specified network ports at runtime. Docker uses this information to interconnect containers using links (see the Docker User Guide). Note that EXPOSE only works for inter-container links. It doesn&#8217;t make ports accessible from the host. To expose ports to the host, at runtime, use the -p flag.</p></blockquote>

<p>From http://docs.docker.com/reference/builder/</p>

<p>So it&#8217;s exposed if we&#8217;re linking containers but not someone exposed to
the host app.</p>

<p>Ah I tried</p>

<pre><code>docker run -i --entrypoint=/usr/bin/redis-server dcf91
</code></pre>

<p>and then I couldn&#8217;t ctrl-C because of, something, but if i do</p>

<pre><code>docker run -it --entrypoint=/usr/bin/redis-server dcf91
</code></pre>

<p>then the -t option will attach a pseudo TTY and I can do it. This
stuff is so cray cray. Actually I lied ctrl-C doesn&#8217;t work for TODO
reasons, but Ctrl-P + Ctrl-Q detaches you from it? Seems good.</p>

<p>OK but if I do</p>

<pre><code>docker run -it -p 9191:6379 --entrypoint=/usr/bin/redis-server dcf91
</code></pre>

<p>this will run in interactive mode with ctrl-p ctrl-q supporting
detachability, mapping the container 6379 (default redis port) to the
host port 9191, and overriding the entrypoint because I didn&#8217;t know what
I was doing in the Dockerfile. I should have left it at the default
/usr/bin/redis-server because that&#8217;s where apt-get will put it.</p>

<p>ANYWAY the mapping works, but the problem is i have to SSH into the
docker host VirtualBox first to see it. How do I get beyond the
Boot2Docker wall? Wait I know I&#8217;ll just fuckin use some SSH magic.
Tunnels n shit.</p>

<pre><code>ssh docker -L 9191:localhost:9191
</code></pre>

<p>ah but this will open a login shell, which I don&#8217;t need/want for what
I&#8217;m doing:</p>

<pre><code>ssh docker -N -L 9191:localhost:9191
</code></pre>

<p>The -N stands for &#8220;Do not execute a remote command&#8221;</p>

<p>After which point I could just redis-cli but since I&#8217;m brutally low
level I&#8217;ll do</p>

<pre><code>$ nc localhost 9191
SET WAT WOOT
+OK
GET WAT
$4
WOOT
</code></pre>

<p>Booooooya. So cool.</p>

<p>OK gonna be an idiot. SSH all the way. Is that possible? It means being
able to SSH into container&#8230; sounds like you can&#8217;t do that without
going through</p>

<h2>Docker detach</h2>

<p>Docker attaching/detaching is pretty weird. I don&#8217;t know the rationale
behind it but they make it very easy to attach to a box but then not be
able to attach. Basically you have to always pass -it to run and then
can use ctrl-P ctrl-Q to detach.</p>

<p>Or, you can <code>kill -9</code> the attached processed; if you you just do <code>kill</code>,
that sends SIGTERM and that proxies through and closes the shitty
process, but again Ctrl-C doesn&#8217;t use it.</p>

<h2>Docker forwarding for OS X</h2>

<p>This is a great article</p>

<p>http://viget.com/extend/how-to-use-docker-on-os-x-the-missing-guide</p>

<p>Things learned:</p>

<ul>
<li><code>boot2docker ssh</code></li>
<li>Add <code>dockerhost</code> to /etc/hosts</li>
<li>Use <code>nsenter</code>

<ul>
<li><code>sudo nsenter -m -u -n -i -p -t $PID</code>

<ul>
<li><code>-m</code> use mount namespace of target process</li>
<li><code>-u</code> use UTS namespace of target process (UTS stands for time-sharing? legacy unix thing?)</li>
<li><code>-n</code> use network namespace of target process</li>
<li><code>-i</code> IPC</li>
<li><code>-i</code> IPC</li>
<li><code>-p</code> IPC</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>LXC Containers (vs Docker)</h2>

<p>https://linuxcontainers.org/</p>

<p>Better chroot, comparable to docker containers. Ways of containing
processes, resources, etc., dependent on modern linux kernel features,
mostly on process namespacing.</p>

<p>Excellent article comparing to Docker: http://www.flockport.com/lxc-vs-docker/</p>

<p>Things learned:</p>

<ul>
<li>yuno virtualization?

<ul>
<li>because of performance cost</li>
</ul>
</li>
<li>LXC and Docker are fast</li>
<li>Lightweight VMs</li>
<li>Is Docker a lightweight VM?</li>
</ul>


<p>A Docker container runs a single process:</p>

<blockquote><p>Docker restricts the container to a single process only. The default docker baseimage OS template is not designed to support multiple applications, processes or services like init, cron, syslog, ssh etc. As you can imagine this introduces a certain amount of complexity and has huge implications for day to day usage scenarios. Since current architectures, applications and services are designed to operate in normal multi process OS environments you would need to find a Docker way to do things or use tools that support Docker. When it comes to applications for a LAMP container you would need to build 3 containers that consume services from each other, a PHP container, an Apache container and a MySQL container. Can you build all 3 in one container? You can, but there is no way to run php-fpm, apache and mysqld in the same container without a shell script or install a separate process manager like runit or supervisor.</p></blockquote>

<p>http://docs.docker.com/articles/using_supervisord/</p>

<blockquote><p>Traditionally a Docker container runs a single process when it is launched, for example an Apache daemon or a SSH server daemon.</p></blockquote>

<p>This is the entry point. Note that <code>ubuntu</code> has no entry point. Not sure
if it&#8217;s possible to use <code>run</code> with a container that has an entry point,
since the entry point is the process that gets run.</p>

<p>So it should be possible for me to run an ubuntu netcat and portforward
at the same time:</p>

<p>All from Mac:</p>

<pre><code>$ docker run -i -p 9292:9292 --expose=[9292] ubuntu:14.04 nc -l 0.0.0.0
</code></pre>

<p>9292</p>

<p>Separate Mac terminal window:</p>

<pre><code>$ nc dockerhost 9292
</code></pre>

<p>And now these two assholes talk to each other!</p>

<p>Here are all the options I used</p>

<ul>
<li><code>-i</code>: run container interactively with terminal attached; without
this, nc immediately closes once someone connects to it since STDIN is
presumably dev null</li>
<li><code>-p 9292:9292</code>, map docker host port 9292 to container port 9292</li>
<li><code>--expose=[9292]</code> open the firewall since it wasn&#8217;t listed as exposed
in the dockerfile</li>
</ul>


<p>Shit is SO COOL.</p>

<h2>Docker vs Heroku</h2>

<p>Hmm, not even worth comparing.</p>

<h2>Nested SSH tunnels</h2>

<p>http://superuser.com/questions/96489/ssh-tunnel-via-multiple-hops</p>

<p>Map localhost:9998 to host2&#8217;s port 22.</p>

<pre><code>ssh -L 9998:host2:22 -N host1
</code></pre>

<p>Map localhost:9999 to blahbalhbablh you get the picture.</p>

<pre><code>ssh -L 9999:localhost:1234 -N -p 9998 localhost
</code></pre>

<p>Shit is sooooo crazy. I love this stuff.</p>

<h2>ProxyCommand</h2>

<p>From <code>SSH_CONFIG(5)</code>.</p>

<pre><code> ProxyCommand
         Specifies the command to use to connect to the server.  The command string
         extends to the end of the line, and is executed with the user's shell.  In the
         command string, any occurrence of `%h' will be substituted by the host name to
         connect, `%p' by the port, and `%r' by the remote user name.  The command can be
         basically anything, and should read from its standard input and write to its
         standard output.  It should eventually connect an sshd(8) server running on some
         machine, or execute sshd -i somewhere.  Host key management will be done using
         the HostName of the host being connected (defaulting to the name typed by the
         user).  Setting the command to ``none'' disables this option entirely.  Note
         that CheckHostIP is not available for connects with a proxy command.

         This directive is useful in conjunction with nc(1) and its proxy support.  For
         example, the following directive would connect via an HTTP proxy at 192.0.2.0:

            ProxyCommand /usr/bin/nc -X connect -x 192.0.2.0:8080 %h %p
</code></pre>

<p>So this proxies through an already established HTTP Connect proxy at
192.0.2.0:8080. That&#8217;s so awesome.</p>

<p>netcat even brags of this:</p>

<pre><code> Common uses include:

       o   simple TCP proxies
       o   shell-script based HTTP clients and servers
       o   network daemon testing
       o   a SOCKS or HTTP ProxyCommand for ssh(1)
       o   and much, much more
</code></pre>

<h2>get.docker.com</h2>

<pre><code>curl https://get.docker.com
</code></pre>

<p>It returns a bootstrapping shell script for setting up docker.</p>

<p>You can <code>#include</code> it when booting an EC2 instance. Pretty cool.</p>

<h2>Basic Authentication</h2>

<p>If I spin up a stupid netcat server</p>

<pre><code>nc -l localhost 9191
</code></pre>

<p>and then query it from Chrome</p>

<pre><code>http://user:password@localhost:9191
</code></pre>

<p>Here&#8217;s what I see:</p>

<pre><code>GET / HTTP/1.1
Host: localhost:9191
Connection: keep-alive
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
Cookie: blahblah
</code></pre>

<p>No reference to <code>user</code> or <code>password</code>. Which means that this information
isn&#8217;t sent up front unless the server requests basic authentication by
first sending back a 401 with the <code>WWW-Authenticate</code> header, after which
point the user and password will be sent.</p>

<p>And because it&#8217;s sent as a header (user:pass in base64) it&#8217;s encrypted
if sent over TLS. But it&#8217;ll be plaintext in your address bar :).</p>

<h2>SSH randomart</h2>

<p>You see it when you create a key pair. Why? Because it&#8217;s just an easy
ass visual way to compare keys rather than some Base64 shit.</p>

<p>You can see the randomart for an existing key by printing the
fingerprint in verbose mode:</p>

<pre><code>$ ssh-keygen -lv -f ~/.ssh/id_boot2docker.pub
2048 b2:3e:e4:d3:c1:9d:1b:75:46:0b:53:aa:18:6b:c7:c6  machty@machty.home (RSA)
+--[ RSA 2048]----+
|             ..  |
|            o..  |
|        .   .+ . |
|         * .. +  |
|      ..S.Eo o   |
|      .+oo+      |
|     o.. . o     |
|     .+ . .      |
|      .o         |
+-----------------+
</code></pre>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-15T13:16:00-05:00" pubdate data-updated="true">Nov 15<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/11/shananananananananeeees/">
		
			Shananananananananeeees</a>
	</h2>
	<div class="entry-content">
		<h2>Linux hierachy layout</h2>

<p><code>man hier</code> answers these questions.</p>

<p>Basically, <code>/usr</code> is a secondary hierarchy for libs/bins/other things
that aren&#8217;t strictly required for single-user mode (e.g. root).</p>

<p><code>/usr/local</code> is tertiary. Things you compile yourself might belong
there. Typically implies lower level of permissions. Rationale for
separting from <code>/usr</code> is that <code>/usr</code> might be some read-only thing
mounted and shared across machines, ready to be swapped out and upgraded
at any time, but <code>/usr/local</code> is crap that you can fuck wit.</p>

<p><code>brew</code> expects to install in the tertiary <code>/usr/local</code> directory:
<code>/usr/local/Cellar</code>. So you can have multiple versions of executables
installed via brew, but only one wins on the command line by way of
symlinks within <code>/usr/local/bin</code> pointing to specific executables in
<code>/usr/local/Cellar/projectname/1.23/bleh</code>. Symlinks to the rescue.</p>

<pre><code>$ sudo brew install wat
Error: Cowardly refusing to `sudo brew install`
You can use brew with sudo, but only if the brew executable is owned by root.
However, this is both not recommended and completely unsupported so do so at
your own risk.
</code></pre>

<p>I guess this is nice since it prevents all the ugliness of installing
shared executables at root privileges when they&#8217;re not needed.</p>

<h2>Raptor</h2>

<p>Ruby server. Apparently fast.</p>

<p>http://www.rubyraptor.org/how-we-made-raptor-up-to-4x-faster-than-unicorn-and-up-to-2x-faster-than-puma-torquebox/#zero_copy</p>

<ul>
<li>Uses nginx HTTP parser

<ul>
<li>due to battle-tested reliability</li>
<li>could have used PicoHTTPParser, but not much community adoption
though it claims being faster than nginc</li>
<li>could have used Mongrel&#8217;s Ragel HTTP parser, but lots of
Ruby-specific</li>
</ul>
</li>
<li>Comes w reverse proxy buffer, such as what nginx has but hyper
optimized to typical ruby raptor workflows</li>
<li>Multi-process</li>
<li>Sounds like multi-threadedness will be a paid solution that comes
later.</li>
</ul>


<p>The C++ component of Raptor is the server that consists of:</p>

<ul>
<li>Buffering reverse proxy</li>
<li>HTTP parser</li>
<li>HTTP server</li>
</ul>


<p>Apparently these are all part of the same thing.</p>

<h2>Puma Lopez mode</h2>

<p>Puma Ruby server comes with a Lopez mode named after <code>@brianmario</code> who
suggested it. It&#8217;s a tcp-only (no http) version of puma. To that guy&#8217;s
knowledge Puma is the only threaded/pre-forking Ruby server that offers
such a mode.</p>

<h2>nginx Reverse proxy buffer</h2>

<p>http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_buffering</p>

<p>I think it&#8217;s on by default, but you can disable it, configure buffer
sizes, or enable with <code>X-Accel-Buffer</code>.</p>

<h2>nginx in general</h2>

<ul>
<li>master process

<ul>
<li>manages worker process, reloads config files, etc</li>
</ul>
</li>
<li>worker processes

<ul>
<li>process requests</li>
</ul>
</li>
</ul>


<p>conf files are directives, either one liners or blocks.</p>

<ul>
<li>Block directives

<ul>
<li>same structure as normal directives</li>
<li>but have braces</li>
<li>if braces allow directives inside of them, it&#8217;s called a context</li>
</ul>
</li>
</ul>


<p>Contexts:</p>

<ul>
<li>main

<ul>
<li>events</li>
<li>http

<ul>
<li>server

<ul>
<li>location</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Catch up or move along</h2>

<p>http://unlearningeconomics.wordpress.com/2012/04/03/the-keenkrugman-debate-a-summary/</p>

<h2>30s write delay</h2>

<p>http://oldblog.antirez.com/post/redis-persistence-demystified.html</p>

<p>http://stackoverflow.com/questions/13650134/after-how-many-seconds-are-file-system-write-buffers-typically-flushed</p>

<p>http://brad.livejournal.com/2116715.html</p>

<p>Modified kernel buffers (of files on disk) wait up to 30s to be flushed
to disk. You can &#8220;force&#8221; it was fsync. But then your disks might lie to
you about what actually was persisted (verifiable via a test involving
pulling the power cord).</p>

<h2>Redis persistence</h2>

<p>http://oldblog.antirez.com/post/redis-persistence-demystified.html</p>

<p>It&#8217;s in-memory key-value, so does it ever get saved to disk?</p>

<p>Why yes it does, via:</p>

<ul>
<li>snapshotting; configure min writes since last sync, or a timeout, and
it&#8217;ll persist a snapshot to a .rdb file. Half completed transactions
(via MULTI/EXEC) don&#8217;t show up of course.</li>
<li>append-only AOF files

<ul>
<li>get rewritten based on memory contents if file grows too large</li>
<li>possible for an empty redis db (written and then deleted keys) has a
large AOF file.</li>
</ul>
</li>
</ul>


<p>Both can be enabled; it&#8217;s nice to have rdb files that you can back up.</p>

<blockquote><p>AOF rewrites are generated only using sequential I/O operations, so the whole dump process is efficient even with rotational disks (no random I/O is performed). This is also true for RDB snapshots generation. The complete lack of Random I/O accesses is a rare feature among databases, and is possible mostly because Redis serves read operations from memory, so data on disk does not need to be organized for a random access pattern, but just for a sequential loading on restart.</p></blockquote>

<p>Interesting, so usually a database that stores to disk would need to
organize data for efficient random access, but in Redis-land, everything
is loaded into memory.</p>

<p>This confused me:</p>

<blockquote><p>One of the additional benefits of RDB is the fact for a given database size, the number of I/Os on the system is bound, whatever the activity on the database is. This is a property that most traditional database systems (and the Redis other persistence, the AOF) do not have.</p></blockquote>

<p>In other words, AOFs can be large even for empty databases (due to
deletions).</p>

<p>appendfsync:</p>

<ul>
<li>appendfsync no

<ul>
<li>syncs at kernel whim (30 s on linux)</li>
</ul>
</li>
<li>appendfsync everysec

<ul>
<li>average 1 sec, at most 2 delay before buffers sent to kernel and sync&#8217;d</li>
</ul>
</li>
<li>appendfsync always

<ul>
<li>sync before each client ack</li>
<li>slowest</li>
</ul>
</li>
</ul>


<p>Default is <code>appendfsync everysec</code>, which is pretty good durability
without murdering speed.</p>

<blockquote><p>What Redis implements when appendfsync is set to always is usually called group commit. This means that instead of using an fsync call for every write operation performed, Redis is able to group this commits in a single write+fsync operation performed before sending the request to the group of clients that issued a write operation during the latest event loop iteration.</p></blockquote>

<p>Hmm that&#8217;s interesting&#8230; Redis has an event loop that can answer
multiple clients in a single iteration?</p>

<p>http://pauladamsmith.com/articles/redis-under-the-hood.html#event-loop</p>

<p>Ah, it uses epoll and the like; multiple sockets and events can have
arrived in one go, so it loops through all of those, does the necessary
reads, etc.</p>

<pre><code>/* Include the best multiplexing layer supported by this system.
 * The following should be ordered by performances, descending. */
#ifdef HAVE_EVPORT
#include "ae_evport.c"
#else
    #ifdef HAVE_EPOLL
    #include "ae_epoll.c"
    #else
        #ifdef HAVE_KQUEUE
        #include "ae_kqueue.c"
        #else
        #include "ae_select.c"
        #endif
    #endif
#endif
</code></pre>

<h2>UTF-8</h2>

<p>http://en.wikipedia.org/wiki/UTF-8</p>

<p>I can&#8217;t believe I never sat down and read this shit.</p>

<ul>
<li>backwards compat w ASCII since ascii only used the 7 bits (signed
char) to determine character.</li>
<li>81% of webpages use this encoding</li>
<li>ASCII is valid UTF-8</li>
<li>UTF-8 is variable length; the 8th bit determines length</li>
<li>there are invalid byte sequences (that you have to look out for when
reading files / raw shit)</li>
</ul>


<h2>ISO/IEC 8859</h2>

<p>http://en.wikipedia.org/wiki/ISO/IEC_8859</p>

<ul>
<li>single byte</li>
<li>all ascii is ISO</li>
<li>Seems like standard alphabet is preserved, but other 8 bit range stuff
differs.</li>
</ul>


<h2>Ruby string encoding</h2>

<p>http://stackoverflow.com/questions/20521371/set-utf-8-as-default-for-ruby-1-9-3</p>

<ul>
<li>Ruby 1.8 and below didn&#8217;t knew the concept of string encodings at all. Strings were more or less byte arrays.</li>
<li>Ruby 1.9: default string encoding is US_ASCII everywhere.</li>
<li><p>Ruby 2.0 and above: default string encoding is UTF-8.</p>

<p>  $ ruby -e &#8220;puts &#8221;.encoding&#8221;
  UTF-8</p></li>
</ul>


<h2>hiredis</h2>

<p>https://github.com/redis/hiredis</p>

<p>Presumably stands for &#8220;high(ish) level redis lib&#8221;.</p>

<p>The Ruby gem can optionally use this as a driver but it comes at the
expense of portability (JRuby can&#8217;t use this driver). But by default
Ruby just uses Ruby sockets to talk to redis.</p>

<h2>Public wifi</h2>

<p>Is there any security difference between a password-less public wifi and
one in which literally everyone knows the password?</p>

<h2>/private on os X</h2>

<p>http://unix.stackexchange.com/questions/63555/what-is-darwins-private-directory-for</p>

<p>fun fact: <code>/etc</code> is a symlink for <code>/private/etc</code> on OS X. Wacky.</p>

<h2>WEP, WPA, WPA2</h2>

<p>http://www.howtogeek.com/167783/htg-explains-the-difference-between-wep-wpa-and-wpa2-wireless-encryption-and-why-it-matters/</p>

<ul>
<li>WEP (Wired Equivalent Privacy)

<ul>
<li>oldest</li>
<li>WEP 128 most common even though there&#8217;s 256</li>
<li>major security vulnerabilities based on RC4 stream cipher cracking</li>
<li>on busy network, cracking could happen within a minute; if network
is slow, attacker can send fake packets and get replies that it can
use to crack over time.</li>
<li>passive attacks: you have to collect information. Gather shit.</li>
<li>Shamir (from RSA fame) was one of the crackahs.</li>
</ul>
</li>
<li>WPA

<ul>
<li>PSK (pre-shared key) is most common</li>
<li>256 min (over 64 and 128 WEP garbage)</li>
<li>message integrity checks (detects some MITM)</li>
<li>TKIP (temporal key integrity protocol) is predecessor to AES</li>
<li>too tied to WEP (meant for firmware progressive upgrades) and hence
prone to some WEP vulnerabilities, hence:</li>
</ul>
</li>
<li>WPA2

<ul>
<li>AES</li>
<li>CCMP (replacement for TKIP? but with TKIP fallback)</li>
</ul>
</li>
</ul>


<p>Just disable a thing called WPS and you&#8217;ll be good.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-11T06:43:00-05:00" pubdate data-updated="true">Nov 11<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/08/mr-noah/">
		
			Mr Noah</a>
	</h2>
	<div class="entry-content">
		<h2>Root/apex/base/DNS and things finally clicking</h2>

<p>They the same thing.</p>

<p>http://stackoverflow.com/a/16041655/914123</p>

<p>Also I like</p>

<pre><code>(Note: root, base, apex domains are all the same thing. Using interchangeably for google-foo.)
</code></pre>

<p>CNAME:</p>

<ul>
<li>Canonical Name record: Aliases another name</li>
<li>Use case: define CNAME for <code>ftp</code>, <code>www</code>, etc to point to the
<code>example.com</code> A record so that only the A record&#8217;s IP needs to
change</li>
<li>Can point to any ol domain, not just within <code>example.com</code>. Heroku
and other cloud services use this to have a CNAME pointing to
a domain name under the control of a dynamic name server that
can dish out different A name records (hence different IPs)</li>
<li>Can&#8217;t define CNAMEs for apex domains (e.g. <code>example.com</code>).</li>
<li>Can&#8217;t be shared with other records for that name, e.g. MX. CNAME wins
and fucks over the others, I think.</li>
</ul>


<p>A record:</p>

<ul>
<li>Points to an IP address.</li>
<li>Terminates DNS lookups</li>
</ul>


<p>ALIAS/ANAME:</p>

<p>http://blog.dnsimple.com/2011/11/introducing-alias-record/</p>

<p>http://support.dnsimple.com/articles/differences-between-a-cname-alias-url/</p>

<blockquote><p>Before going further into the details, it’s important to know that A
and CNAME records are standard DNS records, whilst ALIAS and URL
records are custom DNS records provided by DNSimple. Both of them
are translated internally into A records to ensure
compatibility with the DNS protocol.</p></blockquote>

<p>Aliases can coexist with other records at that level (so someone asking
for MX gets MX if defined for that name rather than resolving
elsewhere).</p>

<p>Ok, so DNS hosts just returns CNAMEs and A records (and others too), and
DNS hosts like DNSimple and DNS Made Easy can provide custom record
types that ultimately translate to A records. Makes sense.</p>

<p>So what about URL?</p>

<blockquote><p>This type of record uses an HTTP redirect to redirect visitors from a domain to a web site.</p></blockquote>

<p>So the A record returned from a URL record on DNSimple is going to point
to one of DNSimple&#8217;s server IPs. I set one up for
snaggletooth.alexmatchneer.com => http://www.example.com.</p>

<pre><code>$ curl -H "Host: snaggletooth.alexmatchneer.com" 50.31.209.254
&lt;a href="http://www.example.com"&gt;Moved Permanently&lt;/a&gt;
</code></pre>

<p>I also added a URL record for ugly.alexmatchneer.com to point to some
random s3 image and discovered that browsers in fact follow redirects
for images, hence this works:</p>

<pre><code>&lt;img src="http://ugly.alexmatchneer.com"/&gt;
</code></pre>

<p><img src="http://ugly.alexmatchneer.com" alt="" /></p>

<p>DNSimple is also nice enough to append the path to whatever its
forwarding, so <code>ugly.alexmatchneer.com/wat</code> forwards to the destination
specified in the URL record + <code>/wat</code>.</p>

<h2><code>dig</code> recursion</h2>

<p>Either you tell your DNS server to recurse for you, or you do it
yourself.</p>

<p>Name server does it for you (all these options just get rid of crufty
shit):</p>

<pre><code>dig +noall +answer +additional +recurse alexmatchneer.com
alexmatchneer.com.      3544    IN      A       23.235.39.133
</code></pre>

<p>You do it yourself:</p>

<pre><code>dig +noall +answer +additional +norecurse alexmatchneer.com
FWDR-68.FWDR-237.FWDR-161.FWDR-12. 3600 IN A    68.237.161.12
FWDR-71.FWDR-243.FWDR-0.FWDR-12. 3600 IN A      71.243.0.12
</code></pre>

<p>FWDR is a FiOS thing. These are from the additional section. So I guess
it means I should call them. But at what point do I go through
Verizon&#8217;s DNS? I thought I used like 4.2.2.2?</p>

<pre><code>cat /etc/resolve.conf

#
# Mac OS X Notice
#
# This file is not used by the host name and address resolution
# or the DNS query routing mechanisms used by most processes on
# this Mac OS X system.
#
# This file is automatically generated.
#
domain home
nameserver 192.168.1.1
</code></pre>

<p>I guess DNS is decided when I connect to a router. Ahhh I guess routers
perform DNS? Ok ok ok what if I tell <code>dig</code> which name server to query?</p>

<pre><code>$ dig +noall +answer +additional +norecurse @4.2.2.2 alexmatchneer.com
i.gtld-servers.net.     109080  IN      A       192.43.172.30
k.gtld-servers.net.     109080  IN      A       192.52.178.30
m.gtld-servers.net.     166299  IN      A       192.55.83.30
h.gtld-servers.net.     114566  IN      A       192.54.112.30
b.gtld-servers.net.     133590  IN      A       192.33.14.30
b.gtld-servers.net.     118573  IN      AAAA    2001:503:231d::2:30
a.gtld-servers.net.     159638  IN      A       192.5.6.30
a.gtld-servers.net.     113094  IN      AAAA    2001:503:a83e::2:30
e.gtld-servers.net.     113091  IN      A       192.12.94.30
f.gtld-servers.net.     166299  IN      A       192.35.51.30
j.gtld-servers.net.     166299  IN      A       192.48.79.30
g.gtld-servers.net.     109080  IN      A       192.42.93.30
d.gtld-servers.net.     101447  IN      A       192.31.80.30
l.gtld-servers.net.     136989  IN      A       192.41.162.30
</code></pre>

<p>WORD ok top level domains, makes sense. I bet if I let it recurse for me
it&#8217;ll gimme what I want:</p>

<pre><code>$ dig +noall +answer +additional +recurse @4.2.2.2 alexmatchneer.com
alexmatchneer.com.      3600    IN      A       23.235.46.133
</code></pre>

<p>Word. And if I use my router&#8217;s IP:</p>

<pre><code>dig +noall +answer +additional +norecurse @192.168.1.1 alexmatchneer.com
FWDR-68.FWDR-237.FWDR-161.FWDR-12. 3600 IN A    68.237.161.12
FWDR-71.FWDR-243.FWDR-0.FWDR-12. 3600 IN A      71.243.0.12
</code></pre>

<p>It refers me to some Verizon name server shit. Which is why if I type in
some nonsense domain name, I get redirected to some shitty Verizon
search page. Regardless of whether I&#8217;m in Chrome or in curl:</p>

<pre><code>$ curl oinasiodasd.asdasiodasod.asdoi
&lt;!DOCTYPE ... blah blah http://searchassist.verizon.com/
</code></pre>

<p>So what if I enable VPN? Prediction: my VPN provider will be making
queries on my behalf, presumably not behind some Verizon name server
shit.</p>

<pre><code>$ curl oinasiodasd.asdasiodasod.asdoi
curl: (6) Could not resolve host: oinasiodasd.asdasiodasod.asdoi
</code></pre>

<p>Basically (annoying caching hangover aside) dig will skip the FiOS
forwarding/recursing if I&#8217;m on VPN. All this makes sense. Perfect
sense. COMPLICATED THOUGH JESUS.</p>

<h2>VPNs and private network IPs</h2>

<p>ICANN set aside numbers like 192.168&#8230; and 10&#8230; for private networks.
VPN doesn&#8217;t interfere with that shit because it&#8217;s within that range.
Derp.</p>

<p>Ahhhh that does though that I could still use my router as a DNS, no?</p>

<p>VPN enabled:</p>

<pre><code>$ dig .
;; SERVER: 8.8.4.4#53(8.8.4.4)
</code></pre>

<p>VPN disabled:</p>

<pre><code>$ dig .
;; SERVER: 192.168.1.1#53(192.168.1.1)
</code></pre>

<p>And even w VPN enabled I could still query my Verizon router&#8217;s DNS</p>

<pre><code>$ dig +norecurse @192.168.1.1 .
FWDR-68.FWDR-237.FWDR-161.FWDR-12. 3600 IN A    68.237.161.12
FWDR-71.FWDR-243.FWDR-0.FWDR-12. 3600 IN A      71.243.0.12
</code></pre>

<p>So who the hell decides where I query from?</p>

<h2>DHCP</h2>

<p>Dynamic Host Configuration Protocol.</p>

<p>When you connect to a network, this tells you all sorts of useful
defaults:</p>

<blockquote><p>The DHCP server manages a pool of IP addresses and information about client configuration parameters such as default gateway, domain name, the name servers, and time servers.</p></blockquote>

<p>When you connect to a network, the DHCP broadcasting stuff happens and
you wind up with an IP, bingo bango bongo. When you connect to a network
but can&#8217;t establish an IP, it&#8217;s probably because DHCP hasn&#8217;t finished
yet.</p>

<p>But this is where 192.168.1.1 as a name server comes from; the Verizon
router will use DHCP to tell you to use it. Other routers might do other
things. When I tether to my phone it gives a different DNS.</p>

<h2>TXT Records</h2>

<pre><code>$ dig +short borflex.alexmatchneer.com TXT
"Another dumb thing"
"I am a big dumb ridiculous idiot!"
</code></pre>

<h2>Nested subdomains</h2>

<p>For the <code>alexmatchneer.com</code> domain, I added a CNAME for
<code>e.x.c.alexmatchneer.com</code> to point to expresscheckoutapp.com
and now it just works to nav to http://e.x.c.alexmatchneer.com</p>

<h2>Route 53</h2>

<p>Heyyyy that&#8217;s the port that DNS servers use.</p>

<h2>Rubydns</h2>

<p>https://github.com/ioquatix/rubydns</p>

<p>Pretty cool. You can make your own DNS server. I got mine to tell me I
was an idiot:</p>

<pre><code>$ dig +short @54.165.102.18 barflonkula TXT
"You are a big idiot"
</code></pre>

<h2>SOA Records</h2>

<h2>Pointilism</h2>

<p>Painting with dots. Like that Ferris Bueller painting, or some of Van
Gogh&#8217;s self portraits.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-08T08:29:00-05:00" pubdate data-updated="true">Nov 8<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/06/jaily-dournal/">
		
			Jaily Dournal</a>
	</h2>
	<div class="entry-content">
		<h2><code>rails c --sandbox</code></h2>

<p>Rolls back changes on exit.</p>

<pre><code>(0.4ms)  SAVEPOINT active_record_1
(0.2ms)  ROLLBACK TO SAVEPOINT active_record_1
</code></pre>

<p>Wraps in a transaction which is why you see the above rather than BEGIN
statements</p>

<h2>Temporarily change $stdout</h2>

<p>I wanted to get pretty-print output in Ruby. Solution, using <code>rails c</code>:</p>

<pre><code>f = File.open('tmp', 'w')
stdout_old = $stdout
$stdout = f
pp hash
$stdout = $stdout_old # could also do File.open(1)
</code></pre>

<h2>Review: difference between pipes and sockets</h2>

<ul>
<li>pipes came first in early 70s</li>
<li>pipes are always stream oriented; sockets can also be datagram
oriented.</li>
<li>pipes are unidirectional (and require two pipes for back and forth).
sockets are bi-directional.</li>
</ul>


<h2>FAT doesn&#8217;t support hardlinking</h2>

<p>I was going to try ember-cli-ramdisk mounting on file systems other than
HFS+, hoping that one FS would support more efficient reuse of freed
blocks, which might minimize paging on the grounds that if ramdisks
blocks are being reused, then additional ramdisk file allocations won&#8217;t
occur, hence memory lookups won&#8217;t occur, hence paging can&#8217;t happen.</p>

<p>Anyway, got initial builds working in FAT32, but incremental rebuilds
didn&#8217;t work due to hard-linking:</p>

<p>https://github.com/rlivsey/broccoli-concat/blob/master/index.js#L86</p>

<p>I thought we got rid of those, but then again the above use case is
fine, since hardlinks are only used concat output and not root files.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-06T16:00:00-05:00" pubdate data-updated="true">Nov 6<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/11/05/oss-cards-against-humanity/">
		
			OSS Cards Against Humanity</a>
	</h2>
	<div class="entry-content">
		<p>Why not.</p>

<h2>Black Cards</h2>

<ul>
<li>&#8220;GamerGate: it&#8217;s actually about <code>__________</code>&#8221;</li>
<li>&#8220;Ember.js: a framework for creating <code>_________</code>&#8221;</li>
</ul>


<h2>White Cards</h2>

<ul>
<li>Ethics in video game journalism</li>
<li><h1>GamerGate</h1></li>
<li>Thought Leadership</li>
<li>Brogrammers</li>
<li>Cracking the Nut</li>
<li>Destroy All Software</li>
<li>Ember.js</li>
<li>AngularJS</li>
<li>React</li>
<li>Two-way data-binding</li>
<li>Unidirectional Data Flow</li>
<li>Handlebars templates</li>
<li>Functional reactive programming</li>
<li>Hacker News</li>
<li>Stability without Stagnation</li>
<li>Ambitious Web Applications</li>
<li>Thirsty Randos</li>
</ul>


		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-11-05T12:40:00-05:00" pubdate data-updated="true">Nov 5<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/31/troll-toll-to-get-into-this-journal/">
		
			Troll Toll to Get Into This Journal</a>
	</h2>
	<div class="entry-content">
		<h2>HDIutil</h2>

<p>Trying to make some ramdisks on OS X</p>

<pre><code>hdiutil attach -nomount ram://8388608
</code></pre>

<p><code>hdiutil</code> attach will normally try to attach and mount a file system.</p>

<ul>
<li>attach: map a hardware device to some <code>/dev/wat</code> device file</li>
<li>mount: try to read the device, discover its file system, and mount it
as a directory so that you can actually cd into it, access files, etc</li>
</ul>


<p>So <code>-nomount</code> prevents the second step and just generates a dev file
mapped to ram.</p>

<pre><code>diskutil erasevolume HFS+ 'RAM Disk' /dev/wat
</code></pre>

<h2>What is a volume?</h2>

<p>Seems like a higher-level abstraction over disks and partitions.</p>

<p>http://tldp.org/HOWTO/LVM-HOWTO/whatisvolman.html</p>

<ul>
<li>Move things around more easily</li>
<li>give things better names than <code>/dev/sda</code> / sdb etc</li>
</ul>


<p>Basically let&#8217;s you overlay logical volumes on top of physical drives.
Makes it easy to move space around between various drives, make things
more sane.</p>

<pre><code>    hda1   hdc1      (PV:s on partitions or whole disks)                        
       \   /                                                                    
        \ /                                                                     
       diskvg        (VG)                                                       
       /  |  \                                                                  
      /   |   \                                                                 
  usrlv rootlv varlv (LV:s)
    |      |     |                                                              
 ext2  reiserfs  xfs (filesystems)                                        
</code></pre>

<p>Use LVM2 in Linux land.</p>

<h2>tcpdump</h2>

<p>Ahhh got it to work</p>

<pre><code>$ sudo tcpdump -t 'host machty.com'
$ ping machty.com
IP 192.168.109.90 &gt; pages.github.com: ICMP echo request, id 24129, seq 0, length 64
IP pages.github.com &gt; 192.168.109.90: ICMP echo reply, id 24129, seq 0, length 64
IP 192.168.109.90 &gt; pages.github.com: ICMP echo request, id 24129, seq 1, length 64
IP pages.github.com &gt; 192.168.109.90: ICMP echo reply, id 24129, seq 1, length 64
IP 192.168.109.90 &gt; pages.github.com: ICMP echo request, id 24129, seq 2, length 64
IP pages.github.com &gt; 192.168.109.90: ICMP echo reply, id 24129, seq 2, length 64
</code></pre>

<h2>UDP can broad/multicast</h2>

<p>And TCP cannot?</p>

<h2>Sequenced-packet sockets</h2>

<p>Combined aspects of UDP/TCP.</p>

<ul>
<li>Connection oriented</li>
<li>Datagram oriented (message boundaries preserved)</li>
<li>Reliable</li>
</ul>


<p><code>SOCK_SEQPACKET</code> type, available in UNIX domain. TCP/UDP do not support
it, but SCTP does.</p>

<p>Stream Control Transmission Protocol. Allows stream multiplexing,
preserves message boundaries unlike TCP.</p>

<pre><code>socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP);
</code></pre>

<p>So, TCP isn&#8217;t the only internet-domain stream protocol; SCTP is too.
It&#8217;s a stream of messages. Rather than bytes.</p>

<p>UDP + congestion controller = DCCP, Datagram Congestion Control
Protocol.</p>

<h2>Alternative IO</h2>

<ul>
<li><code>select</code>/<code>poll</code> to watch multiple fds for availability;

<ul>
<li>benefit over alternatives is that you don&#8217;t have to manually poll w non-blocking
reads.</li>
<li>doesn&#8217;t scale well w hundreds+ of FDs</li>
</ul>
</li>
<li>signal-driven IO; kernel notifies when IO ready, process can do other
still til its ready for IO; benefit over select/poll is that it
doesn&#8217;t block</li>
<li>epoll

<ul>
<li>application can monitor many file descriptors</li>
<li>linux specific but BSD has kqueue, and there are others</li>
<li>avoids complexities w signal programming</li>
</ul>
</li>
</ul>


<p>There&#8217;s also POSIX async IO (AIO); perform IO but don&#8217;t block, get
notified later when it goes through. Linux has thread implementation but
might have it on kernel now, who knows.</p>

<p>Since <code>epoll</code> is Linux specific, use a lib that provides a portal
evented layer to you process: use epoll if present, else fall back to
select/pool; <code>libevent</code> is one such lib.</p>

<ul>
<li>libevent

<ul>
<li>libev: high perf event loop based on libevent but without bugs

<ul>
<li>only ran on Unix, so node (which originally use libev) needed a
solution</li>
</ul>
</li>
<li>libuv: abstraction around libev or IOCP (Windows-based IO Completion
Port)

<ul>
<li>used in node</li>
<li>used in rust</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Two types of readiness notifications:</p>

<ul>
<li>level-triggered: fd is actually ready, now, for IO

<ul>
<li>poll/select &amp; epoll</li>
<li>Allows you to repeat the poll operation after a small read; no need
to read everything in a buffer at once</li>
</ul>
</li>
<li>edge-triggered: IO has occurred since last poll (but it&#8217;s possible
someone else already took care of it)

<ul>
<li>signals &amp; epoll</li>
<li>Try and read as much as possible because you have no way of knowing
whether there&#8217;s more data (without a non-blocking fail), usually by
non-blocking reads in a loop until EAGAIN or EWOULDBLOCK.</li>
</ul>
</li>
</ul>


<p>Note that epoll can do both. These constraints impact program design.</p>

<p>Non-blocking IO + edge-triggered notifications is common because there
are so many cases where blocking IO will screw you; better to non-block
in a lop and check if data is actually there.</p>

<p><code>poll</code> is like <code>select</code> but instead of grouping by operation you just
provide a list of FDs objects and say which type of IO you&#8217;re interested
in per object.</p>

<p>Readiness means an operation will not block. It doesn&#8217;t mean data will
transfer as it could mean EOF or error. The only guarantee is
non-blockage.</p>

<p>Downsides w poll/select when large number of FDs</p>

<ul>
<li>Need to initialize large structures to pass to kernel</li>
<li>Kernel needs to loop through all file descriptors</li>
<li>Program must inspect all returned FDs</li>
</ul>


<h2>Stripe</h2>

<p>You can do a one time charge, or you can save card to a customer.</p>

<p>You can create a Card in their API, but you must specify a customer or
recipient.</p>

<p>An OAuth access token acts like a secret API key:</p>

<blockquote><p>To swap this for an access_token, which acts like a secret API key&#8230;</p></blockquote>

<p>https://stripe.com/docs/connect/getting-started</p>

<p>So this error: https://support.stripe.com/questions/connect-publishable-key-error-with-shared-customers</p>

<p>Background: every Stripe API request sends in your app&#8217;s secret key for
authentication.</p>

<pre><code>Stripe.api_key = ENV['YOUR_DUMBASS_STRIPE_SECRET_KEY']
</code></pre>

<p>This makes it send automatically, but you can also override per API
request by providing a second parameter.</p>

<pre><code>charge = Stripe::Charge.create({
  ...
}, some_api_key)
</code></pre>

<p>In this case, the issue was that my implicitly provided app api key was
being provided to the API request to make a charge using a token
generated by the connected account.</p>

<p>I don&#8217;t really know why this is a problem; seems like something you
should be able to do, right? But actually you have to provide that
second parameter as the access token from when the account connected to
your app.</p>

<p>Trickay.</p>

<h2>Who&#8217;s using ports in OS X?</h2>

<pre><code>sudo lsof -nP -iTCP -sTCP:LISTEN
</code></pre>

<p>Figured I&#8217;d be able to use netstat for this, should probably look into
why I can&#8217;t.</p>

<h2>Self pipes</h2>

<p>Because <code>pselect</code> isn&#8217;t widely supported, you can use the self pipe
trick to get rid of race conditions surrounding signal handlers and
select. Recall the common race condition:</p>

<ul>
<li>Install signal handler that sets global flag to true</li>
<li>Run an IO loop that checks this global flag in order to decide whether
to perform some action.</li>
</ul>


<p>But if a signal arrives between these steps then you might start looping
without checking the flag, etc.</p>

<p>So you can self-pipe to get around this:</p>

<ol>
<li>Create a unix domain pipe, non-blocking on both ends to prevent any
sort of queueing/blocking behavior.</li>
<li>Within a signal handler, write a single byte into the pipe; <code>write</code>
is async signal safe, so we&#8217;re cool.</li>
<li>Include the pipe in <code>select</code>, always check if self-pipe is in
<code>readfs</code></li>
</ol>


<p>Unicorn uses a self pipe.</p>

<pre><code># We use SELF_PIPE differently in the master and worker processes:
#
# * The master process never closes or reinitializes this once
# initialized.  Signal handlers in the master process will write to
# it to wake up the master from IO.select in exactly the same manner
# djb describes in http://cr.yp.to/docs/selfpipe.html
#
# * The workers immediately close the pipe they inherit.  See the
# Unicorn::Worker class for the pipe workers use.
</code></pre>

<blockquote><p>Richard Stevens&#8217;s 1992 book &#8220;Advanced programming in the UNIX environment&#8221; says that you can&#8217;t safely mix select() or poll() with SIGCHLD (or other signals). The SIGCHLD might go off while select() is starting, too early to interrupt it, too late to change its timeout.</p></blockquote>

<p>This just means race conditions; anyway, Unicorn doesn&#8217;t mix select with
other FDs; rather it uses it as parent-child process communication; the
master will sleep/block on a select of the self pipe, and only the self
pipe, and will awaken, clear the pipe, and continue onward.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-31T06:45:00-04:00" pubdate data-updated="true">Oct 31<span>st</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/29/crowley-girdle/">
		
			Crowley Girdle</a>
	</h2>
	<div class="entry-content">
		<h2>Partial reads/writes for sockets?</h2>

<p>Why/how?</p>

<ul>
<li>reads: fewer bytes in the socket buffer than requested</li>
<li>writes: insufficient buffer space to transfer all requested bytes and

<ul>
<li>interrupt by signal handler (not just a signal, but a
custom-specified signal handler)</li>
<li>NONBLOCK enabled and only some of the bytes could be transferred</li>
</ul>
</li>
</ul>


<p>So it seems that <code>write</code>s just put data into the buffer, rather than
guarantee some transmission. How do you block to make sure all data was
received by the server?</p>

<ul>
<li>UDP: you can&#8217;t, since delivery is unreliable and there&#8217;s no concept of
ack</li>
<li>TCP: you <em>could</em> I guess, but at that point you&#8217;d probably want some
kind of application layer ack</li>
</ul>


<p>Blocking reads/writes only (and immediately) return 0 bytes if EOF.
Non-blocking would fire EAGAIN (or WOULDBLOCK for synack).</p>

<h2>What interrupts a blocking call?</h2>

<p>Signal handlers. And only signal handlers.</p>

<p>This article does a great job explaining why EINTR fires:
http://250bpm.com/blog:12</p>

<p>Basically, if you CTRL-C (or any other interrupt), you can&#8217;t just have
the kernel start you off back on the same syscall that was blocking, or
else you&#8217;ll have no opportunity to respond to a handled interrupt, e.g.
setting a flag in a signal handler that tells the world it&#8217;s quitting.</p>

<p>Also note that yielding the CPU (by way of a blocking sys call) is <em>not</em>
considered an &#8220;interrupt&#8221;; durr, if that were the case, then every
syscall would self-interrupt. This sounds obvious now but this shit is
complicated!</p>

<h2>Shutdown</h2>

<p><code>close</code> closes both sides of socket, shutdown only does half.</p>

<ul>
<li>shutdown read: future reads become eof. Called on UNIX domain socket,
EPIPE and SIGPIPE will happen if the peer continues to write.</li>
<li>shutdown write: Future writes yield SIG/EPIPE. Starts signalling EOF
to reading peer.</li>
</ul>


<p>Shutdown operates on the file description, closing all other descriptors
pointing to the same description. <code>shutdown</code> doesn&#8217;t touch the
descriptor; you still need to close it.</p>

<h2>recv and send</h2>

<p>Basically socket-specific <code>read</code> and <code>write</code>.</p>

<p>Basically allows granularity of read behavior; you can non-block a
read/write rather than performing an ioctl first.</p>

<ul>
<li>DONTWAIT; fire EAGAIN if nothing there (only differs</li>
</ul>


<h2>Giant Ruby IO impedance mismatch</h2>

<p>This has been plaguing me since the beginning of time, particularly as I
tried to apply examples to Ruby code: Ruby&#8217;s default IO methods don&#8217;t
map to the same-named syscalls.</p>

<p>Ruby -> C/syscall</p>

<ul>
<li>IO#read -> fread(n): uses internal C buffer, doesn&#8217;t return less than n
unless EOF</li>
<li>IO#readp -> read(n): no buffers used, only read what&#8217;s there</li>
<li>IO#read_nonblock -> read with <code>NON_BLOCK</code> set</li>
</ul>


<p><code>read_nonblock</code> is like <code>read_partial</code> with nonblock.</p>

<p>SO MORAL OF THE STORY if you&#8217;re reading C code with <code>read()</code> and want
the equivalent Ruby, use <code>readpartial</code>.</p>

<h2>sendfile</h2>

<p>Takes the shortcut between disk file and peer socket, rather than having
to buffer in user space first. Whatever fd you pass to it must be
<code>mmap</code>-able, which usually just means regular files on disk.</p>

<p>Not-unlike the Apache x-sendfile optimization (or nginx x-accel) wherein
rather than having the application logic handle the slow
buffering/serving of a file, let nginx or apache do it for you.
Restrictions obviously apply but whatevs.</p>

<h2>shutdown rd w TCP</h2>

<p>Calling <code>shutdown()</code> on the read side of a TCP socket doesn&#8217;t make a ton
of sense since there&#8217;s no good way to essentially signal an EPIPE on the
sending peer. So don&#8217;t do it, it&#8217;s unreliable.</p>

<h2><code>TIME_WAIT</code></h2>

<p>This is the period of time after an active close that&#8217;s been acked by
the peer; you chill out in this state for a little bit to make sure that
any re-transmitted duplicate packets are received and dropped.</p>

<p>This period of time can be like, 30 seconds to 2 minutes depending on
the implementation. Cray cray. I guess this is why you can&#8217;t bind to a
port immediately after killing the process that was using it.</p>

<p><code>TIME_WAIT</code> is useful for:</p>

<ul>
<li>reliable connection termination</li>
<li>allowing enough time for duplicated packets from an old connection to
not confuse a new connection</li>
</ul>


<p>It allows enough time to send acks and fins and what not.</p>

<p>Noobs try and disable it, as if they don&#8217;t need it, but they probably
do. <code>TIME_WAIT</code> ensures reliability of future connections. You can use
<code>SO_REUSEADDR</code> though, coming soon.</p>

<h2>netstat</h2>

<p>Tells you inet and unix socket information. Including send and receive
queue bytes. I just got Arq so that has a full sendQ for obvious
reasons.</p>

<p>It&#8217;s probably rare that both Send-Q and Recv-Q would be large; it means
a program is sending lots of shit (and the server can&#8217;t transmit it fast
enough) and the program isn&#8217;t reading lots of things out of the buffer.</p>

<p><code>*:*</code> means bound.</p>

<p>Get stats via <code>-s</code>. Stats for tcp <code>-sp tcp</code>.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-29T23:46:00-04:00" pubdate data-updated="true">Oct 29<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/17/gnomons-all-up-on-this-journal/">
		
			Gnomons All Up on This Journal</a>
	</h2>
	<div class="entry-content">
		<h2>timerfd</h2>

<p>Just like any other api that inverts signal-handling API into something
file handle-y, Linux has such an API for expiring timers, which means
you can use these file handles w functions like <code>select</code>, <code>poll</code>, and
<code>epoll</code>.</p>

<h2>CLOEXEC reminder</h2>

<p>I&#8217;ve already kinda learned this but I FORGET. The CLOEXEC flag is
something that appears in <code>open</code> and other APIs that create a file
handle; it means that if <code>exec</code> is ever called on a process with a
CLOEXEC handle, the handle will close rather than leak to a process that
can&#8217;t even really access that file handle.</p>

<h2>spawn = fork + exec</h2>

<p>Allows for greater degree of flexibility in what happens between those
two steps. Node only has spawn because it&#8217;s trying to be cross platform.
There&#8217;s no fork. There&#8217;s no spoon.</p>

<p><code>posix_spawn</code> exists to more directly spawn a process when <code>fork</code> is not
supported.</p>

<h2>Embedded System</h2>

<p>http://en.wikipedia.org/wiki/Embedded_system</p>

<p>Usually means you&#8217;re running software on some piece of hardware with a
dedicated purpose, limited resources, and real-time requirements. It&#8217;s a
computer system embedded into some larger mechanical whole.</p>

<h2>fork</h2>

<p>No guarantee of where parent or child is scheduled to run so don&#8217;t run
into conditions.</p>

<p><code>fork</code>ing can be wasteful especially if immediately <code>exec</code>ing, cept for
the fact that</p>

<ul>
<li>program text is marked read only and often shares the same page
mapping as parent</li>
<li>copy-on-write</li>
</ul>


<p>You can execute code in a single-purpose forked child process without
changing the resource/memory footprint of the parent. Useful if the code
in question is unspeakably/unstoppably leaky or prone to memory fragmentation.</p>

<p>Mmm mmm mmm using pipes.</p>

<pre><code>r,w = IO.pipe

if fork
  w.close
  answer = r.read
  Process.wait
  puts $?.exitstatus
  puts answer
else
  r.close
  w.write("SOME BULLSHIT")
  exit(123)
end
</code></pre>

<p>Useful for when the single byte/octet return code (<code>$?.exitstatus</code>)
won&#8217;t cut it. Insane Posse Clown.</p>

<p>BSD used to have a shit wasteful fork back in the day, then added vfork,
and then everyone else made efficient COW <code>fork</code>s, but still most people
provide an implementation of vfork which:</p>

<ul>
<li>performs zero duplication, even of VM pages (which all forks due, even
if no writes have happened yet under a COW system). Parent memory
shared until <code>exec</code> or <code>_exit</code>.</li>
<li>Parent execution suspended til then</li>
</ul>


<p>This is risky as fuck because:</p>

<ul>
<li>simply returning from a function will impact parent process&#8217;s memory.
It&#8217;s almost like a step-through longjmp, cept, no this totally breaks.
It&#8217;s not like the parent will pick up from wherever the child process
leaves off; the process counters are different between processes, so
if you return from a function in a child, you&#8217;ll fuck with the stack
frame, probably cause some SEGVs, and bite the big one.</li>
</ul>


<p>You can on the other handle futz with file handles in this time
(apparently these are duplicated? just not VM pages?)</p>

<pre><code>vfork -- spawn new process in a virtual memory efficient way
</code></pre>

<p><code>_exit</code> must be used because <code>exit</code> would flush stdio and thus fuck the
parent.</p>

<p>But don&#8217;t use vfork. It sucks. It&#8217;s obsolete. It&#8217;s not even in SUSv4.
It&#8217;s garbage shit-kicker nonsense. <code>fork</code> is pretty much just as fast
when COW exists.</p>

<p>You can actually control whether parent or child runs first via
<code>proc/sys/kernel/sched_child_runs_first</code> (or the sysctl equiv).</p>

<p>The argument for parent-first is that the TLB cache is warm with parent
stuff, so memory lookups are faster yadda yadaa I can&#8217;t imagine this
actually makes a difference unless you&#8217;re forking like a motherforker.</p>

<p>Hehehehe:</p>

<pre><code>3.times { fork }
puts "wat"
</code></pre>

<p>Results in</p>

<pre><code>wat
wat
wat
wat
wat
wat
wat
wat
</code></pre>

<p><code>atexit</code> handlers are shared w <code>fork</code>.</p>

<h2>Process rehash, new learnings</h2>

<p>Even if a parent kills a child, it has to wait or else it remains a
zombie.</p>

<p>There&#8217;s no such thing as a zombie orphan; well actually there are
transient zombie orphans; <code>init</code> will adopt them and immediately <code>wait</code>
on them, and then they&#8217;ll be collected.</p>

<p>Prediction: it gets messy to call <code>wait</code> in a SIGCHLD handler since
signals might coalesce; two SIGCHLDs might coalesce into one, and the
foolish programmer might only wait once. I bet if I looked at unicorn
I&#8217;d find a loop.</p>

<h2>KGIO</h2>

<p>http://bogomips.org/kgio/</p>

<p>Ruby gem w C extensions for Kinder, Gentler IO.</p>

<ul>
<li>Avoids expensive EAGAIN / EINPROGRESS exceptions

<ul>
<li>EAGAIN: non-blocking IO when there&#8217;s no data, so try <em>again</em> later</li>
<li>EINPROGRESS: (less common), similar to EAGAIN but distinguished for
things like <code>connect</code> in mid 3-way handshake</li>
</ul>
</li>
<li>other niceties</li>
</ul>


<p>Used in Unicorn and related Rainbows!. Can&#8217;t use in JRuby obviously but
then again no forking server model is supported in JRuby.</p>

<h2>JRuby Servers</h2>

<p>https://github.com/jruby/jruby/wiki/Servers</p>

<p>Can&#8217;t use unicorn but you can use things like Puma, or Trinidad, which
wraps rack/rails within a Tomcat container. So many things I do not
know!</p>

<h2>Isomorphic Code</h2>

<p>Can run on server or client. Not sure of the roots, but sounds like it
started in 2011, at least as way of describing JS code that runs between
both? React-router is &#8220;isomorphic&#8221;.</p>

<h2>ELF format</h2>

<p>Executable and Linking Format.</p>

<h2>Built-ins</h2>

<p>Sometimes no forking occurs because it&#8217;s quick and efficient, or because
there are desirable side effects that should make it into the current
shell process. Like <code>cd</code> (can&#8217;t change the cwd of the current process
if you&#8217;re forking). Or <code>export</code>.</p>

<h2>Why keep fd&#8217;s open on <code>exec</code>?</h2>

<p>If you&#8217;re exec&#8217;ing, shouldn&#8217;t you lose access to file handles? Not
necessarily; stream redirection via the shell is a good example where
you preserve what 0 1 2 point to.</p>

<h2>Auto-reap zombie child processes</h2>

<p>If you set the signal mask to ignore <code>SIG_CHLD</code>, potential zombie child
processes will be automatically reaped. So no need to <code>wait</code> in that
case.</p>

<p>Also, it&#8217;s implementation-defined (according to SUS) whether <code>exec</code>
resets the <code>SIG_CHLD</code> disposition after an exec (Linux preserves,
Solaris resets to default, etc).</p>

<h2><code>exec</code> clears sig handlers</h2>

<p>Of course, since sig handlers live in the text and text is replaced, so
must handled signals be reset. Everything else about signals is
preserved (cept that <code>SIG_CHLD</code> ignores may not
get reset to <code>DFL</code> depending on the implementation), but since most
processes expect to start with a clean slate, if you didn&#8217;t write the
process, you should reset everything yourself before an exec.</p>

<h2><code>system</code></h2>

<p>Runs a shell command, with all the processing/substitutions of the
command string that you would expect.</p>

<p>Inefficient; fork+execs twice, one for the shell, and one for the
process you intend to run.</p>

<p>set-user-id and set-group-id programs should never use <code>system</code>
since it opens the door to setting weird ENV vars to get unintended
programs to run, and they&#8217;ll inherit the effective user id. The
canonical example is setting IFS to <code>a</code>, and then <code>shar</code> runs and is
interpreted as <code>sh r</code>, and <code>r</code> is some script/executable that is no
running with admin privileges to do whatever it wants. Evil shit!</p>

<p>Note that modern shells reset IFS now as a rule.</p>

<h2><code>clone</code></h2>

<p>A Linux-specific sister of <code>fork</code>; it creates a new process, but starts
at the beginning of a provided function called w a provided arg. The
child process terminates if this function returns (or the exit variants
are called).</p>

<ul>
<li>you can specify termination signal (rather than always CHLD)</li>
<li>flags let you meticulously control a variety of info about what is
actually shared with the new child process: file handles, signal
dispositions, etc.</li>
</ul>


<p>So basically it&#8217;s threads&#8230; but separate processes? Is there a name for
these kinds of threads? LinuxThreads I guess.</p>

<p>Threads/processes are just kernel scheduling entities with differing
degrees of shared attributes. Processes are just, like, organizational
distinctions. Schedule wise, the scheduler doesn&#8217;t care whether it&#8217;s a
thread or a process. Blueskying of course.</p>

<h2>Mode 7</h2>

<p>http://en.wikipedia.org/wiki/Mode_7</p>

<p>The special background layer mode that enabled perspective-y effects, as
well as zooming and other cool things. F-zero relied on it, the map in
Link to Past relied on it. Any zoomy crazy shit that wasn&#8217;t a sprite
relied on it.</p>

<h2>Dyson Sphere</h2>

<p>Shell around the sun.</p>

<p>http://www.islandone.org/LEOBiblio/SETI1.HTM</p>

<p>Other lifeforms smashed apart their planets to build a dyson sphere to
capture energy, support population growth.</p>

<p>We could knock apart Jupiter, use its mass to create a sphere around sun
with a diameter twice that of Earth&#8217;s orbit. The shell would be 10 feet
thick, and make&#8230; something&#8230; habitable?</p>

<h2>Fermi Paradox</h2>

<p>http://waitbutwhy.com/2014/05/fermi-paradox.html</p>

<p>http://en.wikipedia.org/wiki/Fermi_paradox</p>

<p>The apparent contradiction between the high probability of alien life
and the fact that no one has contacted us yet.</p>

<p>Explanation 1: They don&#8217;t exist</p>

<p>Possibly due to a Great Filter; at some point in development, something
wipes them out, or there&#8217;s some point of evolution that&#8217;s reaaaally
really hard to get beyond that filters out people who made it beyond the
previous step.</p>

<p>So where does that leave <em>us</em>?</p>

<p>We&#8217;re</p>

<ul>
<li><p>rare</p>

<ul>
<li>other rare survivors might be reaaaally far away</li>
<li>the filter is behind us</li>
</ul>
</li>
<li><p>first: no one else to communicate with yet</p></li>
<li>fucked: we&#8217;re about to hit our wall like everyone else has</li>
</ul>


<p>Ah I love the potentialy reason for why intelligent life wouldn&#8217;t
broadcast data: there are potential harmful civilizations that would
destroy anyone they could find, and most advanced civilizations are
smart enough not to give away their locations to these fuckers. That&#8217;s
why we only have SETI today, and not METI (messaging to ETs), which most
scientists agree is a profoundly unwise idea.</p>

<p>Eesh, or there&#8217;s only one superpredator species, like humans on Earth,
that would wipe out another species before it got too intelligent.
Nipping the universe in the bud. Fuuuck that.</p>

<p>Or we&#8217;re not using the right technologies to communicate, or even if we
did, other minds might work much faster or slower than ours; it could
take years for them to say hello. Hahaha.</p>

<p>Or we are receiving communications but the gov is hiding it.</p>

<p>Or other civilizations see us, but we&#8217;re a look-don&#8217;t-touch zoo.</p>

<p>Or the higher civilizations are here, but we couldn&#8217;t begin to
understand them, they&#8217;re just so advanced.</p>

<p>Or we&#8217;re just so fundamentally incorrect about reality.</p>

<p>Types of civilization</p>

<ul>
<li>I: ability to use all the energy on the planet (Sagan says we&#8217;re a
0.7; just under the legal limit)</li>
<li>II: ability to harness all power of a star (e.g. Dyson sphere)</li>
<li>III: ability to harness all power of a whole galaxy</li>
</ul>


<p>http://waitbutwhy.com/ seems pretty awesome in general. Three thumbs up.</p>

<h2>fork v vfork</h2>

<p>I&#8217;ve already written about this but followup: vfork is faster, but
considering how slow the followup <code>exec</code> is, this is probably
neglibibilgigible.</p>

<h2><code>time</code> and forking</h2>

<p>Are child process CPU times included?</p>

<pre><code>N = 20000000

def slow_thing
  inc = N / 5
  N.times do |i|
    puts "." if i % inc == 0
  end
end

do_fork = true
if do_fork
  fork do
    slow_thing
  end

  Process.wait
else
  slow_thing
end
</code></pre>

<p>With forking:</p>

<pre><code>real    0m1.565s
user    0m1.544s
sys     0m0.013s
</code></pre>

<p>Without forking:</p>

<pre><code>real    0m1.480s
user    0m1.464s
sys     0m0.011s
</code></pre>

<p>Seems that yes they are (there&#8217;s no difference with the above).
Actually, quick aside: it seems that <code>time</code> is a bash builtin. Not sure
why, but if I use <code>/usr/bin/time</code> as well, not much changes</p>

<pre><code>1.42 real         1.41 user         0.00 sys
1.49 real         1.47 user         0.01 sys
</code></pre>

<p>Ah, <code>time</code> will add together all forked processes. And apparently if you
have two active processes, you might wind up with a CPU time greater
than real time. LET US FIND THE FUCK OUT.</p>

<pre><code>N = 20000000

def slow_thing
  inc = N / 5
  N.times do |i|
    puts "." if i % inc == 0
  end
end

num_forks = 2

num_forks.times do
  fork do
    slow_thing
  end
end

num_forks.times { Process.wait }
</code></pre>

<p>BOO YA</p>

<pre><code>real    0m1.636s
user    0m3.199s
sys     0m0.021s
</code></pre>

<p>How awesome is it when things start clickin.</p>

<p>So how does time actually do it?</p>

<h2>curl + tar</h2>

<pre><code>curl http://mirror.anl.gov/pub/gnu/time/time-1.7.tar.gz | tar -x
</code></pre>

<p>I guess you&#8217;re also supposed to use <code>-z</code> as well, but in my manpages:</p>

<pre><code> -z      (c mode only) Compress the resulting archive with gzip(1).  In extract
         or list modes, this option is ignored.  _Note that, unlike other tar
         implementations, this implementation recognizes gzip compression auto-
         matically when reading archives._
</code></pre>

<p>That&#8217;s so nice of them. And ridiculous that it wouldn&#8217;t always work that
way. Maybe not.</p>

<h2>Threads</h2>

<p>Every process has at least one thread.</p>

<p>Concurrency via processes has some limitations:</p>

<ul>
<li>nothing is shared so communication is limited to IPC, pipes and what
not</li>
<li>expensive due to page table duplication and file descriptor table dups
and all the things that happen during <code>fork</code></li>
</ul>


<p>Most process attributes are shared between threads. Here&#8217;s some stuff
that&#8217;s not:</p>

<ul>
<li>thread ID</li>
<li>signal mask</li>
<li>thread-specific data</li>
<li>alternate signal stack</li>
<li><code>errno</code></li>
<li>floating-point env</li>
<li>scheduling priority/policy</li>
<li>CPU affinity</li>
<li>capabilities</li>
<li>stack</li>
</ul>


<p>Of course you could share stack vars between threads but this runs the
risk of data invalidation once a function returns etc etc etc.</p>

<p>How does errno work if it&#8217;s a variable? Trick question, it&#8217;s a macro
that evals to an lvalue (so you can still manually set it yourself).</p>

<p><code>join</code> is like <code>wait</code>, it seems to free up that thread, and you wouldn&#8217;t
want to call it twice, lest terrible things happen. You must detach or
join. (Seems like the equiv in processland for detach is to set
<code>SIG_CHLD</code> to ignore).</p>

<p>Unlike processes, threads are created as peers. If A spawns B spawns C,
then A can join C. They&#8217;re all siblings in the same process cult.
There&#8217;s no concept of generic <code>Process.wait</code> to join with any ol thread.
This makes sense since some lib function could spawn a thread and you
might clobber its operation and steal its return value.</p>

<p>Once you detach a thread, you can&#8217;t join it. Again keep in mind that
threads can&#8217;t escape the fact that they live in a process; if the
process dies, so do the threads.</p>

<p>Threads can&#8217;t use the full virtual memory address space; they have to
share with all the other threads. Probably not a big deal unless you&#8217;re
doing insane shit, but still.</p>

<p>Mutexes in Linux are implemented in user spaces using futexes (fast user
space mutexes). They only cause system calls when multiple threads lock.</p>

<h2>Pitchblende</h2>

<p>Old school word for Uraninite. Basically ore ready for uranium
processing.</p>

<h2>Javascryptonomicomicon</h2>

<p>http://matasano.com/articles/javascript-cryptography/</p>

<h2>ffs ssl</h2>

<p>http://wingolog.org/archives/2014/10/17/ffs-ssl</p>

<blockquote><p>WTF their price is 49 dollars for a stupid certificate? Your domain name was only 10 dollars, and domain name resolution is an actual ongoing service, unlike certificate issuance that just happens one time.</p></blockquote>

<p>Hmm clearly I need to better understand how this all works&#8230; being a
CA, root or no, definitely requires constant service</p>

<p>Wow this is sneaky: http://thejh.net/misc/website-terminal-copy-paste</p>

<p>Never copy and paste secure stuff from a webpage. I&#8217;m so sad.</p>

<p>Lol &#8220;Well now I have to live with this confidence-inspiring dialog,
because I left off the organization&#8221;</p>

<p>TIL Organization is the name you choose that you want to pop up when
inspecting certifications.</p>

<p>Wow, googlebot still doesn&#8217;t use TLS 1.2.</p>

<h2>Condition variables</h2>

<p>Didn&#8217;t I write about this already? So forgetful!</p>

<pre><code>Loop
  Lock around shared structure
    If shared structure "empty"/unusable, wait on condition variable


(other thread):
Lock around shared structure
  Put data into it
  Signal Condition variable
</code></pre>

<p>If you didn&#8217;t do this, you&#8217;d have some wasteful CPU-hog loop that
constantly locked and unlocked the mutex to check if the shared
structure had data ready.</p>

<ul>
<li>Always re-check the condvar predicate; some other thread might have
invalidated it in the meantime.</li>
<li>Also, a looseness of predicates lends to some flexibility; a producer
doesn&#8217;t need to know the exactly logic that consumer cond var depends
on; producer can just say &#8220;hey interested people, this shared
structure changed, so chiggity check yourselves&#8221;</li>
<li>Some implementations, particularly multi-core, might wake up a cond
var for fucks sake (explicitly allowed by SUSv3</li>
</ul>


<h2>Reentrant revisited</h2>

<p>We already knew thread-safe functions aren&#8217;t necessarily reentrant (e.g.
a signal handler that locks a mutex might be reentered and deadlock the
same mutex on the same thread). A reentrant function is one that doesn&#8217;t
access globals, mutexes included (what if a shared structure, possibly a
mutex is passed on to the function? Deadlock could still occur&#8230; I
guess the answer is that a function might be itself reentrant, but a
caller might not be reentrant so the chain of calls it makes with
whatever global data it&#8217;s using isn&#8217;t going to be reentrant).</p>

<p>Not every function can be reentrant. malloc can&#8217;t be: it <em>must</em> access
global data. A <code>_r</code> suffix implies reentrancy.</p>

<h2><code>pthread_once</code></h2>

<p>The pthreads library provides facilities for ensuring that some kind of
initialization (that occurs in the function you provide it) only happens
once.</p>

<h2>Thread-specific data</h2>

<p>I guess it&#8217;s a thread-local storage, but TLS is an overlay API that&#8217;s
friendlier to program in. In C at least you use the <code>__thread</code> keyword
when declaring a variable and voila you get everything for freeee.</p>

<h2>Thread cancellation</h2>

<p>Threads can be cancelled at cancellation points, SUS-specified
lib/syscall functions, or if you&#8217;re a moron (or you have a 0.001% use
case) you can set cancelability to be async, which means it might
interrupt at any ol machine instruction.</p>

<h2>ncurses</h2>

<p>New curses. Used for writing terminal apps. Cross-terminal. Optimizes
refreshes for our remotely connected friends.</p>

<h2>Thread stacks</h2>

<p>Main thread has mucho size, thread stacks are smaller but configurable
in size.</p>

<h2>Signals and threads</h2>

<p>Horrible combination, avoid when possible. Reason being: signals existed
long before threads and never expected to integrate with them.</p>

<ul>
<li>signal dispositions are process wide (you can&#8217;t have one thread ignore
a signal and another use a specific handler, etc)</li>
<li>signals might be directed to thread or process. Thread directed if

<ul>
<li>signal is result of hardware instruction (SEGV, etc&#8230; same
reason that signals are sometimes synchronous)</li>
<li>SIGPIPE</li>
<li><code>pthread_kill</code> or <code>pthread_sigqueue</code></li>
</ul>
</li>
<li>all others are process wide</li>
<li>kernel selects arbitrary thread to handle signal (as opposed to
multiple threads handling a single sig)</li>
</ul>


<p>Shit. What the fuck is a difference between signal disposition and
signal mask?</p>

<p>Disposition: per-process structure that controls whether a signal
is a) is ignored, b) runs a custom handler, or c) invokes the default
action.</p>

<p>Mask: data structure that knows when signals are temporarily blocked,
the idea being that they should be later unblocked and the signal will
fire.</p>

<p>OK so dispositions are process-wide, but masks are thread-local; so as
one time slice begins, the kernel will look up the mask for that thread
and decide whether a pending signal should fire upon it, and if not,
wait til later. You might have some threads that block all signal
handlers.</p>

<p>Ahhhhhhh SO FUCKING FORGETFUL. Didn&#8217;t I just cover this a few days ago?
Basically I tried writign a ruby program to set the mask, but you don&#8217;t
have access to the mask in Ruby because Ruby uses it internally and is
trying to layer a nice signal API on top of it. I was trying to set up
something where a main thread had a custom handler but all the threads
it spawned blocked SIGINT so that it must be handled by the main thread.</p>

<p>But if I weren&#8217;t too lazy to write the test in C:</p>

<blockquote><p>By manipulating the per-thread signal masks, an application can control which thread(s) may handle a signal that is directed to the whole process.</p></blockquote>

<p>I mostly just wanna know how the kernel selects the thread to wake up.
Does it just loop through each of the sleeping threads and find the one
whose signal mask will allow it?</p>

<p>None of the pthread lib has async-signal-safe functions, so what&#8217;s
recommended:</p>

<ul>
<li>main thread blocks everything, all spawned threads inherit signal mask</li>
<li>single thread deblocks and is responsible for dispatching signals.</li>
</ul>


<p>Reminder: difference b/w reentrant and async-signal-safe:
async-signal-safe is a function you can call in a signal handler because
it as either a) reentrant or b) not interruptible by a signal handler.</p>

<p>So why &#8220;async&#8221;-signal-safe? There are sync signals and async signals
depending on whether hardware issued the signal, whether it&#8217;s a signal
sent to yourself, etc. I think the answer is that async-signal-safe is a
concept that exists even outside of the context of a currently running
signal handler. In other words, if you know <code>foo</code> is NOT async signal
safe, it means <code>foo</code> might be interrupted by an async signal, and if
itself were called, hell might break loose.</p>

<p>So that&#8217;s a useful concept on its own, but when applied to what you&#8217;re
allowed to call within a signal handler, the rule is &#8220;don&#8217;t call non
async-signal-safe functions&#8221; because, within a handler or no, you might
be interrupted by <em>another</em> signal handler and fuck yourself.</p>

<p>So you should always write signal handlers that are themselves reentrant
and only call async-signal-safe functions.</p>

<p>Remember, these async-signal-safe functions might not be reentrant on
their own, but because they block signal handlers from interrupting
them, they are async-signal-safe.</p>

<p><code>exec</code> wipes out all other threads entirely. Gone. No termination /
cancel handlers called.</p>

<p><code>fork</code> kills all other threads than the caller, but mutexes and
conditional variables live on in whatever state. (What about
<code>thread_t</code>s? Probably persist but point to dead threads?). Memory leaks
can happen since the killed threads don&#8217;t have an opportunity to clean
up after themselves.</p>

<p>LOVE.</p>

<p>But you can defined atfork handlers. Otherwise you probably shouldn&#8217;t
fork unless you&#8217;re also <code>exec</code>-ing.</p>

<h2>NPTL</h2>

<p>Native POSIX Threading Lib</p>

<p>The software feature in linux kernel that enabled POSIX-compliant
threads. Red Hat 9 added it first, either as a kernel module or patch to
the OSS kernel.</p>

<h2>Social Engineering</h2>

<pre><code>http://en.wikipedia.org/wiki/Social_engineering_(security)
</code></pre>

<p>It just means sneakily manipulating people into giving away their shit.
Phishing and what not.</p>

<h2>M:N</h2>

<p>aka number of threads map to number of Kernel Scheduling Entities
(processes, threads, etc, schedulable executable things).</p>

<h3>M:1</h3>

<p>Multiple threads to a single KSE. User-level threads aka green threads.
Kernel doesn&#8217;t know about these threads.  Fast context switching, but</p>

<ul>
<li>other slow syscalls block all other threads, e.g. <code>read</code>, since
control is passed from user-spacing threading lib to kernel</li>
<li>kernel can&#8217;t schedule, which means no multi-processor green threads.</li>
</ul>


<p>I&#8217;m guessing the way scheduling worked was to set interval timers and
pre-empty threads. Seems correct.</p>

<h3>1:1</h3>

<p>Kernel-level threads. Pthreads.</p>

<p>Thread creation, context switching, etc, are slower since it requires a
syscall, but it means the kernel can efficiently schedule, put them on
separate cores.</p>

<h3>M:N</h3>

<p>Some kernel, some green.</p>

<p>Keep in mind that this whole <code>M:N</code> nomenclature also applies to
processes vs threads. err, does it? Processes and green threads? I could
be bullsharting right now.</p>

<p>M:N is complex, perhaps not worth it. It was originally the suggested
implementation for NPTL.</p>

<h2>Process Group / Session</h2>

<ul>
<li>Process group

<ul>
<li>Process group leader

<ul>
<li>Process that creates the group, whose PID becomes the process group
ID</li>
</ul>
</li>
<li>New process inherits its parent&#8217;s pgid</li>
<li>Lifetime: from process group creation to when last process leaves
group id</li>
<li>premature question: can a new process take the id of a now-dead
process that used to be pg leader?</li>
<li>processes can leave by terminating or joining another group</li>
<li>pg leader can leave before others, no biggie.</li>
</ul>
</li>
<li>Session

<ul>
<li>collection of PGs</li>
<li>Session leader

<ul>
<li>Process that creates the session, whose PID becomes the session ID</li>
</ul>
</li>
<li>New process inherits its parent&#8217;s pgid</li>
<li>all processes in session share terminal</li>
</ul>
</li>
</ul>


<p>SIGHUP is sent to PG leader when terminal disconnects.</p>

<p>Login:</p>

<ul>
<li>Shell becomes session leader AND process group leader

<ul>
<li>every command it runs, it makes it process group leader (but shell
remains session leader)</li>
<li>any command forks have same process group id (the command&#8217;s pid),
and session id is shell.</li>
<li>shell can create many process groups (commands) and can foreground
one and the rest are background</li>
</ul>
</li>
</ul>


<p>You can only change process group of yourself or your children, else
ESRCH. You can only move a process between groups within the same
session. You can&#8217;t change the process group of the session leader.
You can&#8217;t child the process group of a child if it&#8217;s already called
<code>exec</code> (you might confuse the poor child); I guess this means shells
will fork and then the parent will call setpgid on the child&#8230;? Why
doesn&#8217;t the child just do it itself?</p>

<p>Answer (and I love this book for this shit: go buy the Linux Programming
Interface right now): the parent process needs to be able to send job
control signals to the newly created child (to the new process group
ID it&#8217;ll have), and the child needs to set the new pgid before it
<code>exec</code>s or else all is lost, so how do you guarantee that the new process
group on the child has been set before either the parent or child
proceed? Answer: do it on both and ignore errors on the parent.</p>

<p><code>setsid</code> establishes a process as group and session leader and
disconnects it from any controlling terminal. You can&#8217;t <code>setsid</code> if
you&#8217;re process group leader (EPERM), so you need to <code>fork</code> first to get around
that. This restriction is in place because any other process group
children will still have a pgid that points to this same process group
leader process even if it has a new session id; the only way to ensure
the numbers don&#8217;t point to the same place is to distribute new numbers,
e.g. new process ids, e.g by forking.</p>

<pre><code>if fork
  Process.wait
  puts "done"
else
  # if you hadn't forked, setsid would fail because
  # this process would be PG leader
  Process.setsid
  puts gets
end
</code></pre>

<p>The above code doesn&#8217;t error out like I thought it would&#8230; it still has
access to the terminal, but, it, umm, couldn&#8217;t open the terminal if it
wanted to?</p>

<p>When session leader opens a controlling terminal, it becomes the
controlling process for a terminal. They are LINKED. If a process
has a controlling terminal, it can open special file <code>/dev/tty</code>.</p>

<p>Ah ok so to make the above snippet break, I should have actually done</p>

<pre><code>fork do
  Process.setsid
  File.open('/dev/tty')
end
Process.wait
</code></pre>

<p>which yields</p>

<pre><code>setsid.rb:3:in `initialize': Device not configured - /dev/tty (Errno::ENXIO)
</code></pre>

<p>You open <code>/dev/tty</code> if the shell (or someone else) already redirected
your output (by <code>dup2</code>ing 0 1 2 file descriptors) and you want to get
back in touch with your <code>tty</code>. Call your <code>tty</code>. She&#8217;s your controlling
terminal.</p>

<p>AH HA this is how you can take a program with redirected input and get,
say, the users password from the terminal. Fuckin badass. Let&#8217;s try it.</p>

<pre><code>$ echo "wat" | ruby getpass.rb
here's some stuff from stdin
wat
now type something in: borflex
You wrote borflex
</code></pre>

<p>So many cool shits!</p>

<p>Note that you can also open <code>/dev/tty</code> without it becoming the
controlling terminal.</p>

<p>TTY captures special characters, converts into signals sent to members
of the foreground process group.</p>

<p>This demonstrates how a signal is delivered to literally everyone in the
foreground process group (5 &#8220;omg&#8221;s are printed).</p>

<pre><code>N = 5
N.times do
  fork do
    trap(:INT) do
      puts "omg\n"
      exit
    end
    sleep
  end
end

trap(:INT) do
  puts "main\n"
end

N.times do
  Process.wait
end
</code></pre>

<p>It&#8217;s possible for no one to be the foreground process, but rare, and not
when there&#8217;s a shell that&#8217;s monitoring for foreground process to quit
(via wait or some other signal handle).</p>

<p><code>tcgetpgrp</code> gets the foreground process group of a provided terminal fd.
<code>bash</code> and other shells make use of this when passing the terminal
around to child processes.</p>

<h2>SIGHUP</h2>

<p>This is sent when terminal connection is severed (also sends SIGCONT to
make sure the process is alive). Happens when:</p>

<ul>
<li>terminal driver detects disconnect of one form or another</li>
<li>the last pseudoterminal file handle has been closed (i don&#8217;t
understand this)</li>
</ul>


<p>You can ignore / handle SIGHUP but future reads yield EOF. (What about
output? Same thang?).</p>

<p>SIGHUP is often used to tell a daemon process to reload a config file.
Why SIGHUP? Because daemons have no controlling terminal so the single
is otherwise useless; why not put it to work in some useful way? nginx
and others do this.</p>

<p>When terminal disconnects, the controlling process (the shell) gets a
SIGHUP. Shells will terminate, but before doing that they&#8217;ll send a
SIGHUP to each of the process groups.</p>

<p><code>nohup</code> just forks, sets disposition to ignore HUP, and then <code>exec</code>s.
Easy peasy.</p>

<p>Note that shells won&#8217;t send SIGHUP to any process groups it didn&#8217;t
create.</p>

<pre><code>echo $$
</code></pre>

<p>This is like the thing that trolled me before w <code>ruby -e</code>&#8230; <code>$$</code> in a
shell command is the shell&#8217;s pid.</p>

<p>Background tasks don&#8217;t get sighup&#8217;d when you exit a terminal. SIGHUP
only gets sent to foreground processes. That seems cray cray.</p>

<h2>$$ in Ruby</h2>

<p>Everywhere I look it says it is the id of the running process. As in,
you know, the pid. But if I do</p>

<pre><code>ruby -e "puts Process.pid; puts $$"
</code></pre>

<p>I get two different numbers.</p>

<p>You know why?</p>

<p>Because, of course, <code>$$</code> means something to shells! Before the command
even runs, <code>$$</code> will be substituted with the pid of the shell! If I
change double quotes to single quotes, I get the same numbers, of
course!</p>

<pre><code>ruby -e 'puts Process.pid; puts $$'
</code></pre>

<p>This is why I started going crazy and thinking that the internet was
just wrong and that <code>$$</code> means the session id. Wrong!</p>

<h2>terminfo / termcap</h2>

<p>These are packages that some programs like vi and less make use of for
gracefully switching in and out of screen-controlling modes; vi and less
take over the screen but when you quit, you see the terminal lines from
before you ran them. This uses terminfo, which is a terminal database
which provides facilities such as that.</p>

<h2>sigtstp</h2>

<p>You can catch a suspend ^Z via sigtstp and then signal sigstop to
actually stop the process, but any parent processes listening in will
think you were stopped by sigstop rather than sigtstp, so you can do the
more complicated thing of setting disposition to default, unblocking,
raising tstp (so that it suspends this time), and then resetting the
mask upon reentry.</p>

<h2><code>init</code> and <code>wait</code></h2>

<p>I originally thought that <code>init</code> would <code>wait</code> on every orphan it
inherited, but of course, <code>wait</code> is blocking if nothing&#8217;s actually
terminated, so I think <code>init</code> actually checks the status of the
process and <code>wait</code>s only if it&#8217;s terminated. But if it inherits a
stopped process group, it won&#8217;t call wait. So you might have stopped
process groups that live on forever and no one ever terminates them.</p>

<p>Hence, upon orphaning, the kernel sends SIGHUP + SIGCONT to any
orphaning process groups that have at least one stopped process, and
these signals are sent to everyone. Of course, at some later
post-orphaning time, these orphaned processes might be stopped and would
need <em>something</em> to come along and resume or terminate them.</p>

<h2>nice values</h2>

<p>You can give processes (specific pids, groups&#8217;, users&#8217;) varying nice
values from -20 to 19, give or take. Lower means higher priority, high
means lower.</p>

<h2>The Complexity Balloon and other yehudaisms</h2>

<blockquote><p>&#8220;you can only squeeze the complexity ballooon&#8221;
- Yehuda Katz</p></blockquote>

<p>On XMLHttpRequest capitalization:</p>

<pre><code>btw: the rule for XHR is:
First acronym all caps
subsequent acronyms title-case
old Java rule
</code></pre>

<h2>Security book recommendations</h2>

<p>The art of software security assessment</p>

<p>The grey hat hackers handbook</p>

<h2>Scheduling</h2>

<p>CPUs have their own run queues, with items with different priorities.
Processes can be scheduled with RR or FIFO real-time policy.</p>

<p><code>RR</code> is round robin. Equal priority processes get a time slice and then
get thrown in back of queue at the end. They can be pre-empted by higher
order shits. How?</p>

<ul>
<li>higher order process blocked on syscall becomes unblocked (io
available, etc)</li>
<li>another process raised to higher level</li>
<li>current process raised to lower value than some other process</li>
</ul>


<p><code>RR</code> similar to standard RR <code>SCHED_OTHER</code>, difference being in the
strictness of the weighting algorithm. <code>SCHED_OTHER</code> uses nice values,
but a lower nice value than another isn&#8217;t a strict determiner of
scheduling order, but rather a weighted suggestion, where as <code>RR</code> is
brutal deterministic.</p>

<p>In <code>FIFO</code> there&#8217;s no timeslice. You have it til you&#8217;re preempted or give
up control.</p>

<p>You can lock up a system with <code>RR</code> or <code>FIFO</code>. To prevent:</p>

<ul>
<li>set low CPU limit, which causes default-terminating <code>SIGXCPU</code> to fire.</li>
<li>use <code>alarm()</code></li>
<li>use high priority watchdog process to watch others, adjust their
priorities.</li>
</ul>


<p>CPU Affinity just means the tendency for a process/thread/kernel
scheduling unit to run on the same CPU; switching CPUs involves a slow
context switch, cache invalidation, etc.</p>

<h2>Daemonizing</h2>

<ul>
<li>long-running, often started at boot</li>
<li>has no controlling terminal (hence never receives INT, TSTP, HUP,
etc); its excluded from job-control signals</li>
</ul>


<p>some examples</p>

<ul>
<li>cron</li>
<li>sshd: the ssh server that&#8217;s open for remote logins.</li>
<li>httpd: http server

<ul>
<li>ah so TCP isn&#8217;t a daemon, it&#8217;s a kernel-level IO protocol, but httpd
is a server. It&#8217;s apache, duerp.</li>
</ul>
</li>
<li>inetd: superserver daemon&#8230;? sounds like this doesn&#8217;t exist on mac.</li>
</ul>


<p>Some daemons run as kernel threads, w names bracketed.</p>

<p>To daemonize:</p>

<ul>
<li>fork: child process lives, master terminates.

<ul>
<li>returns control to terminal</li>
<li>child process lives on, and is no longer process group leader (it
inherits parent pgid which doesn&#8217;t match its new pid, so it can&#8217;t be
leader). this is needed for setsid (remember that setsid can&#8217;t be
called with process group leader, because other children processes
might be in that process group with a pgid pointing to a process
that lives in a different session, but process group members must
all live within the same session as a rule)</li>
</ul>
</li>
<li>setsid

<ul>
<li>become session leader

<ul>
<li>frees you from connected terminal</li>
<li>allows you to connect to another terminal (but&#8230; see below)</li>
</ul>
</li>
</ul>
</li>
<li>fork again

<ul>
<li>this prevents any future terminals you connect to from becoming
controlling terminal (TODO: why/when would a daemon connect to a
terminal?)</li>
<li>you don&#8217;t have to do this if you don&#8217;t open another terminal, or you
open terminals with <code>O_NOCTTY</code></li>
</ul>
</li>
<li>Clear umask (remember that umasks negate certain permissions on create
files&#8230; right? TODO: review this shit)</li>
<li>Change cwd to <code>/</code> so that in case the process was started with a cwd
on another file system that doesn&#8217;t contain <code>/</code>, that fs can be
unmounted

<ul>
<li>remember you can&#8217;t unmount &#8220;busy&#8221; FSs

<ul>
<li>files are open on it</li>
<li>processes have CWDs on it (how does it know? loop through the
processes?)</li>
</ul>
</li>
</ul>
</li>
<li>Close all file descriptors, 0, 1, 2, for similar busy FD unmount
reasons, also because you might get some TTOUs if you try and read
from stdin.</li>
<li><code>dup2</code> them to point to <code>/dev/null</code> so that lib functions and other
things don&#8217;t unexpectedly file, or you don&#8217;t open another file in
their place but some lib function things they&#8217;re std IO and then write
shit to them

<ul>
<li>reading dev null yields EOF. PRETTY EFFIN HANDY</li>
</ul>
</li>
</ul>


<p>Daemon shutdown consists of SIGTERM and a 5-second-layer SIGKILL if it
doesn&#8217;t clean up and shut down in that time (all processes concurrently
have 5 seconds to shutdown, not 5 seconds of CPU each; all SIGTERMS send
out at same time).</p>

<p>Memory leaks and fd leaks are a bigger deal for daemons since they&#8217;re so
long-lived.</p>

<p>Care must be taken to prevent multiple identical daemons from running;
Pidfiles help.</p>

<p>Logfiles can&#8217;t grow forever, and manually deleting a file if the daemon
doesn&#8217;t let go of it won&#8217;t prevent the resources from being freed until
the last handle is closed to the file. <code>logrotate()</code> can be used to aid
in this.</p>

<p>HUP is unused since daemons don&#8217;t have controlling terminals so people
classically use it to re-initialize or reload conf files.</p>

<p>Btw you can open other people&#8217;s TTYs. And it means you can write to
their screens.</p>

<p><code>syslog</code> and <code>syslogd</code> is a useful utility to global logging; write to
syslog unix domain datagram socket and blah dee blah dee blah it&#8217;ll
funnel out to wherever based on a shared conf FILE!</p>

<h2>Security</h2>

<p>Privilege via</p>

<ul>
<li>root started it</li>
<li>set-user-id or set-group-id + owned by root</li>
</ul>


<p>Guidelines:</p>

<ul>
<li>don&#8217;t use set-user/group-id unless you really need it; better to
use a child process

<ul>
<li>or if you need it, don&#8217;t give it root</li>
</ul>
</li>
<li>e.g. a process currently with set-user-id that allows unprivileged
users to write to a file they don&#8217;t have access to: much better to
set-group-id to a group specific to this process, and set group of
that file to that group. group. group. group.</li>
<li>if you&#8217;re set-user-id, only operate in that mode when you need it.</li>
<li>real id is whoever started the program</li>
<li>basically, shit is really hard and you should refer to this book every
time you need a refresher because this stuff megasucks.</li>
<li>don&#8217;t exec shells or other interpreters when you have privileges. Way
way way too open to abuse.</li>
<li>close file handlers; they&#8217;re just integers, not hard to reuse. recall
CLOEXEC</li>
</ul>


<h2>Clear out your memory</h2>

<p>Why? Because it might be paged out to a swap area that privileged
programs can read. So that seems pretty iScare. If that&#8217;s visible, why
not fuckin, fuckin, fuckin memory, man, why can&#8217;t you like open another
process and look at its memory maaaan, even without it having been paged
first.</p>

<p>Actually you can if you&#8217;re not careful. You can create special device
files that have direct access to RAM. That&#8217;s so fucking crazy. So even
<code>chroot</code> can&#8217;t even save you if you have a set-user-id-root program.
Crazy crazy crazy.</p>

<p>Also if you have a leftover open file handle to <code>/</code> then you can
<code>fchdir</code> into it and <code>chroot(".")</code> chroot back into that shiot.</p>

<h2>Use capabilities</h2>

<p>UNIX privileges are all-or-nothing; Linux adds the notion of
capabilities. Use em. They&#8217;re granular n shit.</p>

<h2>Use virtual kernels</h2>

<p>Totally isolated. They have no concept of the raw kernel. Can&#8217;t access
it. Can&#8217;t do shiot.</p>

<p>BSD <code>jail()</code> addresses lots of this stuff. SO MANY FUCKING LOOP HOLES OH
MY GOD.</p>

<h2>Time of check, time of use</h2>

<p><code>access()</code> lets you query access of user to file. If you&#8217;re
set-id-to-root and you check if some unprivileged user has access to
something, maybe a symlink, and then in between that check and whatever
you end up destructively doing, the symlink is swapped to elsewhere,
then you might clobber some shittles. Malicious user could go nutso and
fire off a bunch of <code>SIGSTOP</code>s and change runtime environment to fuck
with a privileged program.</p>

<h2>Bounds checking</h2>

<p>strcpy babeh</p>

<p>Linux now has stack address randomization which randomizes the location
of the stack in an 8 MB range in VM. Seems cool. That&#8217;s why if you print
the pointer of a var int main in a test C program, it&#8217;s different each
run. This feels similar to stretches in bcrypt and any other security
measure that makes certain operations slower to counteract brute force
attackers.</p>

<h2>DoS denial of service</h2>

<p>Local variants include fork bombing.</p>

<p>Remote DoS more common, combat w:</p>

<ul>
<li>load throttling, dropping requests when overloaded</li>
<li>timeouts</li>
<li>(throttled) logging of overloads</li>
<li>don&#8217;t crash from unexpected loads</li>
<li>avoid algorithmic complexity attacks wherein a structure known to
handle a particular series of input might get fucked and consume lots
of resources. Not insecure, necessarily, but might fuck the fuck.</li>
</ul>


<h2>Shared libs</h2>

<p>Compile w <code>-g</code> nowadays since RAM and disk are cheap. Apparently this
info doesn&#8217;t affect performance?</p>

<p>A shared lib is a <code>.a</code> file composed of <code>.o</code> files, constructed with
<code>ar</code>, as in &#8220;library archives&#8221;.</p>

<pre><code>$ ar tv /usr/lib/liby.a
rw-r--r--       0/0            40 Aug 24 21:45 2013 __.SYMDEF SORTED
rw-r--r--       0/0           920 Aug 24 21:45 2013 main.o
rw-r--r--       0/0           912 Aug 24 21:45 2013 yyerror.o
</code></pre>

<p>Variants of <code>gcc</code> and static libs</p>

<pre><code># generate wat.o
gcc -c wat.c

# generate a.out with wat.o lib
gcc lol.c wat.o otherlibarchive.a

# search standard lib directories (like /usr/lib)
# looks for /usr/lib/libwoot.a
gcc -c wat.c -lwoot

# Search a non-standard directory
gcc -c wat.c -lwoot -L/borflex/snaggletooth
</code></pre>

<p>All of the .a archive and .o object files is added to executable size.
Seems bad. Also when the processes are run, VM is increased by that
much, even though it&#8217;s all redundant read-only text shit.</p>

<p>Ah. Static libs. vs Shared libs. Shared libs are fuckin, fuckin,
dynamic, maaaan.</p>

<p>Ah note that static and global variables obviously aren&#8217;t shared between
shared libs; each process gets a copy.</p>

<p>Pros:</p>

<ul>
<li>Large shared libs between small processes mean quicker process startup
time (though the first time the shared lib is loaded into VM is
obviously slow)</li>
<li>With some limitations, you can swap out libs without relinking</li>
</ul>


<p>Cons:</p>

<ul>
<li>complexity</li>
<li>shared libs must use position-independent code

<ul>
<li>PIC is a way of compiling shared libs so that the location of
functions, statics, globals, string constants, etc, can vary, and I
don&#8217;t understand it.</li>
</ul>
</li>
</ul>


<p>Modern shared lib linking format is ELF: Executable and Linking Format.</p>

<p><code>.so</code> is shared object, shared lib, as opposed to just <code>.o</code>.</p>

<p><code>ar</code> lets you add/remove <code>.o</code>s from library archives, but not so with
<code>.so</code>s.</p>

<p>You can use <code>nm</code> (name list util, i.e. symbol table util) to list
symbols.</p>

<p>Interesting, so given the following <code>wat.c</code>:</p>

<pre><code>int WAT;
</code></pre>

<p>I see <code>_WAT</code> appear in the symbol table:</p>

<pre><code>$ gcc -c wat.c &amp;&amp; nm wat.o
0000000000000004 C _WAT
</code></pre>

<p>Note that it wouldn&#8217;t appear if I&#8217;d made it <code>static</code> or <code>extern</code>. Shit
is cool.</p>

<p>So PIC adds a global offset table to help the dynamic linking describe
where shit is.</p>

<p>Hmm what if I use <code>g++</code> on a cpp file?</p>

<pre><code>$ g++ -c wat.cpp &amp;&amp; nm wat.o
0000000000000000 S _WAT
</code></pre>

<p>What&#8217;s the difference b/w S and C? C apparently means &#8220;common&#8221; symbol,
and S means a generic &#8220;none of the above&#8221; in the <code>man nm</code>.</p>

<p>You can take a dynamic/shared lib and compile statically though, if you
want it:</p>

<ul>
<li>less complexity</li>
<li>safer against .so upgrades</li>
</ul>


<p>So what&#8217;s the difference between a .so and a .dylib? Is that a mac
thing?</p>

<h2>Dynamically loaded libraries</h2>

<p>Deferred loading whenever some plugin is loaded. As in your code does
it. Seems pretty rad. Use <code>dlopen</code>. Search a function by name, invoke
it.</p>

<p>You can use env var <code>LD_DEBUG</code> to print out some shit.</p>

<h2>IPC</h2>

<ul>
<li>byte streams: pipes, fifos, datagram sockets</li>
<li>message: message queues; can&#8217;t read them part way, all or nothing</li>
<li>pseudoterminals</li>
</ul>


<p>Different from shared mem:</p>

<ul>
<li>reads are destructive for byte streams (but yes in some cases you can
seek, multicast/broadcast)</li>
</ul>


<p>MQ (POSIX or SystemV) messages have priorities, and deliver in different
order.</p>

<p>Ah now it&#8217;s coming back to me:</p>

<ul>
<li>UNIX domain sockets

<ul>
<li>ruby: <code>Socket.pair</code></li>
<li>datagram (no need to worry about byte streams/delimiters)</li>
</ul>
</li>
<li>Pipe

<ul>
<li>ruby: <code>IO.pipe</code></li>
<li>stream</li>
<li>flow control handled by kernel</li>
</ul>
</li>
</ul>


<h2>Pipes and FIFOs</h2>

<p>Pipes are old as SHIT. Oldest method of IPC, since 3rd edition of UNIX
in early 1970s.</p>

<p>THAT&#8217;s what that dude meant. Pipes vs Sockets. We use pipes, not
sockets.</p>

<p>Pipes are constrained to related processes, FIFOs can talk between all
processes.</p>

<p>Pipes are unidirectional.</p>

<p>Can&#8217;t reorder data, can&#8217;t random access w lseek.</p>

<p>Writes up to <code>PIPE_BUF</code> are atomic, Linux has <code>PIPE_BUF</code> at 4096. If
larger, kernel might break into pieces. This means that if you have two
processes writing more than <code>PIPE_BUF</code>, the final stream might be
interleaved with both messages (both processes will still be blocked on
<code>write</code> until everything is flushed out).</p>

<p>Partial writes can occur if a write larger than <code>PIPE_BUF</code> is
interrupted by a signal handler, and call comes back with the number of
bytes written. Pretty cool. Makes sense.</p>

<p>Writes will block if kernel buffer is full.</p>

<p>Pipes only work b/w related processes, which mean they must have a
common fork ancestor. Apparently there&#8217;s another way to pass file
descriptors. But I guess it&#8217;d need translating? Because there are
descriptors and open file descriptions, and the descriptor ints are
different between shits.</p>

<p>SIGPIPE is ignored by default, but when you write to broken pipe you get
SIGPIPE and EPIPE. Such pipe.</p>

<p><code>popen</code> runs a shell command, letting you establish a single pipe,
either r or w.</p>

<p>FIFOs are like pipes except that they&#8217;re special files in th file
system. Opening a read-only FIFO blocks until someone writes, and vice
versa.</p>

<p><code>tee(1)</code> writes to stdio AND some other file, which could be a fifo. So
you can split a stream and send it to other things. Pretty cool.</p>

<p>UNRELATED: <code>bash -c "sleep 5"</code> execs sleep 5; it doesn&#8217;t create a bash
process and then fork again, it just straight up execs. Whereas when
you&#8217;re running interactive bash, all commands are forked and then
exec&#8217;d.</p>

<p>Trick with IPC w servers is that there needs to be some known file name,
which opens the door to exploitation if you&#8217;re not careful.
FIFOs (and pipes) are byte streams (rather than unix domain datagram
sockets) so you have to</p>

<ol>
<li>Use some EOM delimiter</li>
<li>Message length header</li>
<li>Fixed message size</li>
</ol>


<p>and on top of all of that everything needs to be less than the pipe
buffer size constant or else kernel might interleave messages.</p>

<p>Pipes provide synchronization by e.g. opening a pipe, forking, having
the parent blocked on a <code>read()</code> until child processes have all done
their shit and closed their end of the pipe.</p>

<p><code>popen</code> has the same considerations as <code>system</code>.</p>

<h2>System V</h2>

<p>http://en.wikipedia.org/wiki/UNIX_System_V</p>

<p>One of first commercial versions of UNIX, from 1983. Today&#8217;s descendants
are AIX, Solaris, and HP-UX.</p>

<p>System V IPC</p>

<ul>
<li>MQs

<ul>
<li>delivered in order, but each message has type, so can be selected
out of order</li>
</ul>
</li>
<li>Semaphores

<ul>
<li>kernel forbids it from going below 0, sync technique</li>
</ul>
</li>
<li>Shared mem</li>
</ul>


<p>w System V IPC you create objects (like files but unlike files). Objects
have ids, but unlike fd&#8217;s, these are system wide.</p>

<p>Semaphores don&#8217;t error when you subtract below zero; rather the kernel
will block if you try and subtract, and it&#8217;ll come back alive when
someone increments.</p>

<h2>Considered Harmful</h2>

<p>http://en.wikipedia.org/wiki/Considered_harmful</p>

<p>Popular phrase originating from &#8220;Go To Statement Considered Harmful&#8221;, a
Djikstra thing.</p>

<h2>mmap</h2>

<p>Memory mapping can either use</p>

<ul>
<li>real files</li>
<li>anonymous zero-d out files</li>
</ul>


<p>Both are shareable between processes. By:</p>

<ul>
<li>mmapping to the same region of the same file</li>
<li>forking with a previously established handle to a</li>
</ul>


<p>Mapping to same file can be configured:</p>

<ul>
<li>private: writes don&#8217;t go through to file, so process changes to the
mapping are isolated from each other. Implemented by copy-on-write.</li>
<li>shared: durp</li>
</ul>


<h2>dev zero</h2>

<p><code>/dev/zero</code> gives you null bytes. Forever!</p>

<h2>dev urandom</h2>

<p>Write seeds, read values.</p>

<p>This isn&#8217;t perfect but kinda works:</p>

<pre><code>ruby -e 'puts File.open("/dev/urandom").gets(4).unpack("l")'
</code></pre>

<p>Extra credit if you can figure out what that ain&#8217;t right</p>

<h2>Get off the aaaaaaair I&#8217;m in the STEREO</h2>

<p><code>mmap</code> can overcommit swap space due to lazy committal. Useful for
implementing things like sparse arrays (a large array might only access
bits and pieces, and if separate by a page.</p>

<pre><code>$ getconf PAGESIZE
4096
</code></pre>

<p>Daatz cool. So if you have a bajillion thingeroo and it&#8217;s allocated on a
shit, then woooop there it is.</p>

<p>Overcommitals can ran the system out of memory at which point the kernel
starts killin&#8217; shit. The kernel code that does this is the OOM
Out-of-Memory killer.</p>

<p>OOM kills with <code>SIGKILL</code>, you can look at your score with a special file
in procfs.</p>

<h2>dscacheutil</h2>

<p>Directory Service Cache Utility. Supercedes <code>lookupd</code>.</p>

<h2>VM operations</h2>

<ul>
<li>protect: set read/write protections on a VM page

<ul>
<li>applies to mmapped files, etc</li>
</ul>
</li>
<li>mlock and mlockall: keep memory in RAM; useful since an attack vector
would be to consume lots of RAM, forcing some processes to write to
disk, and then reading from the swap space.

<ul>
<li>then again, suspend mode in laptops/desktops copied ram to disk, so
you&#8217;re effed.</li>
</ul>
</li>
</ul>


<h2>traceroute UDP vs ICMP</h2>

<p>This doesn&#8217;t work</p>

<pre><code>traceroute machty.com
</code></pre>

<p>This does</p>

<pre><code>traceroute -I machty.com
</code></pre>

<p>because it uses ICMP ECHO rather than a UDP packet (which I guess gets
dropped somewhere along the way? tis a Rackspace github pages HTTP
server so UDP wouldn&#8217;t make sense anyway), and ICMP ECHOs I guess are
considered more sensible and friendly?</p>

<p>I realized this was the issue since <code>ping machty.com</code>, which uses ICMP
ECHO, works just fine.</p>

<h2>Power of Attorney</h2>

<p>Written authorized permission for one person to act on behalf of
another, even if the other disagrees. Relevant in the legal sense, as
well as health care decisions up to and including terminating care and
life support.</p>

<h2>Darwin, Mach, OS X</h2>

<p><a href="http://en.wikipedia.org/wiki/Darwin_(operating_system">Darwin wiki</a>)</p>

<p>Darwin is an an open source operating system released by Apple in 2000</p>

<ul>
<li>Composed of NeXSTEP, BSD, other freeware</li>
<li>Largely compatible with POSIX but not certified.</li>
<li>SUSv3-compatible</li>
<li>Kernel is XNU

<ul>
<li>&#8220;X is Not Unix&#8221; - stupidest naming scheme ever</li>
<li>Hybrid kernel

<ul>
<li>Combo of micro and monolithic: http://en.wikipedia.org/wiki/Hybrid_kernel</li>
<li>Micro kernels are often &lt; 10,000 lines of code, do the bare
minimum, put more things into user space (or at least a higher
privilege ring)</li>
<li>Linus thinks hybrid is just monolithic and that it&#8217;s all just
marketing</li>
</ul>
</li>
<li>Combo of Mach (microkernel) + aspects of BSD (monolithic kernel)</li>
</ul>
</li>
<li>Closed source Cocoa et al frameworks are missing, so it can&#8217;t run mac
applications</li>
</ul>


<p>http://en.wikipedia.org/wiki/Microkernel</p>

<p>So I guess OS X is Darwin + Cocoa and a bunch of other layers.</p>

<h2>POSIX IPC</h2>

<ul>
<li>Simular to System V</li>
<li>API closer to classic UNIX everything-is-a-file abstraction</li>
<li>Simpler API in general</li>
</ul>


<h2>Semaphores: portable?</h2>

<p>Does anyone use operating system semaphores in open source? I mostly see
sockets and forking and what not for IPC in server code; does anyone
use semaphores?</p>

<p>Answer: yes, libuv does (the async IO lib that Node uses). I&#8217;m sure
plenty of other people do too.</p>

<h2>Node copies in all dependencies</h2>

<p>The Node repo doesn&#8217;t use submodules or anything like that; literally
the entire codebase of a dependency, whether v8 or libuv, is copied into
the <code>/deps</code> folder.</p>

<h2>WATCHLISTS</h2>

<p>Something to Chromium devs use that mark certain portions of code as of
interest to some reviewer, presumably to prevent undesirables from
getting into the system.</p>

<p>https://github.com/joyent/node/blob/master/deps/v8/WATCHLISTS</p>

<h2>File locking</h2>

<p>Used for synchronization. Could use semaphores but the kernel already
has file locking so why not use that for files?</p>

<p>stdio lib might cause issues with buffers and locks, so either follow
some rules about immediately flushing, or just skip stdio and use <code>read</code>
and <code>write</code>, or disable the buffering.</p>

<p>Locks apply to open file descriptions (in the shared open file table in
the kernel), not descriptors, so if you dup the descriptor and
explicitly unlock it, it applies to all duplicates (it doesn&#8217;t maintain
a count or anything).</p>

<p>You can only hold a lock associated with an fd. So if all fds are
closed, the lock is unlocked.</p>

<p>If you fork a lock, then it only takes one unlock (parent or child) to
release the lock. Wacky shiznittletons. But this lends to the pattern of
&#8220;parent establishes lock, forks, and closes file descriptor so that only
the child has the lock and open fd&#8221;.</p>

<p>Locks are preserved across exec unless close-on-exec on the fd and the
fd was the last one associated with the description.</p>

<p><code>flock()</code> downsides:</p>

<ul>
<li>only whole files lockable, hamper concurrency if processes would be
otherwise able to write to the same file in separate sections</li>
<li>can only place advisory locks.

<ul>
<li>advisory locks mean the kernel doesn&#8217;t actually help prevent
reads/writes; processes could ignore advisory locks and perform IO
anyway. Mandatory locks on the other hand&#8230;</li>
</ul>
</li>
</ul>


<h2>Record locking with fcntl</h2>

<p><code>fcntl</code> allows record-locking: locking anywhere from a byte to whole
file. &#8220;record-locking&#8221; might be the wrong word since files are just byte
streams with no concept of &#8220;records&#8221; beyond what their consuming
processes decide.</p>

<p><code>fcntl</code> just stands for &#8220;file control&#8221;. I get it confused with <code>ioctl</code>.
<code>fcntl</code> is control over descriptors in a process. Basically <code>fcntl</code>
behaves almost like a kernel sys call in that it&#8217;s just setting an
integer of the command you want to perform followed by varying numbers
of arguments based on the command. So you can do arbtrary, extensible
stuff that might not already be neatly contained within some other
single purpose wrapper fn.</p>

<p>SUSv3 requires record locking for regular files and permits record
locking for other file types even if it doesn&#8217;t really make sense.</p>

<p>Write locks are exclusive (to both read and write locks). Read locks
are not (they can be shared). Nothing new here.</p>

<p><code>fcntl</code> locking works by passing <code>flock</code> structure. You can lock
relative to current file pointer.</p>

<p><code>BADF</code> if you try and read/write lock a file on a file not open for
reading/writing.</p>

<p><code>len</code> of 0 means lock from whence onward (even if bytes are added to the
file).</p>

<ul>
<li>Unlocking always immediately succeeds.</li>
<li>different sections can be locked with different types</li>
<li>locks can be split by e.g. placing a write lock in the middle of a
larger range of read locks (3 locked regions are produced)</li>
</ul>


<p>The kernel prevents deadlocks between processes. (Similar rules apply
with thread mutexes). Chooses one of the processes and unblocks fcntl
with errno <code>EDEADLK</code>. Even circular deadlocks are detected. Pretty cool.</p>

<p>fcntl locking semantics:</p>

<ul>
<li>locks not inherited cross fork()</li>
<li>locks are inherited</li>
<li>threads share record locks</li>
<li>Record locks are pid+inodenum, so, weirdly, if you close an fd, all of
its locks are released, even if they came from other fds. Kind of
crazy? (This is architectural weak sauce; should have been file
handler rather than inode, but it&#8217;s now standardized).</li>
</ul>


<h2>Mandatory Locking</h2>

<p>File system must be mounted with mandatory locking enabled. And it must
be enabled on a per-file basis by enabling set-group-id and disabling
group execute permission. This yields a capital S in <code>ls -l</code> if you&#8217;ve
done it right.</p>

<ul>
<li>most file systems support it, cept for things like VFAT which don&#8217;t
have the required permission bits</li>
<li>locked file can still be deleted</li>
<li>privileges processes can&#8217;t override a mandatory lock. A malicious user
holding on to a well known public file is a form of DOS attack.</li>
<li>mandatory locks has performance hit against IO</li>
</ul>


<p>Probably best avoided?</p>

<p>tmpfs <code>/proc/locks</code> is useful.</p>

<h2>Pidfile</h2>

<p>Create a file and place write lock on it. Any other instances will try
and do the same thing, fail, and terminate under the assumption that a
running process already has a lock on it. Alternate approaches for
networked apps use bound ports to make this same decision.</p>

<p>Often such things live in <code>/var/run</code>. Conventional to write pid to file
and use extension <code>.pid</code>.</p>

<p>You can CLOEXEC a pidfile since some servers reinitialize themselves by
<code>exec</code>ing themselves. Seems crazy?</p>

<h2>Sockets</h2>

<ul>
<li>exist in communication domain

<ul>
<li>determines how socket is identified (form of &#8220;address&#8221;)</li>
<li>range of communication (intra-computer, internet, etc)</li>
</ul>
</li>
<li>Multiple domains of sockets

<ul>
<li>UNIX domain: <code>AF_UNIX</code>. Communication b/w processes on same host
(all within the kernel)</li>
<li>IP (v4 and v6)</li>
</ul>
</li>
</ul>


<p><code>PF_UNIX</code> vs <code>AF_UNIX</code> constants: Protocol Family vs Address Family:
often synonomous, but different due to intent to support protocols
having multiple families of addresses, but this hasn&#8217;t happened.</p>

<p>Every socket impl can be stream or datagram oriented.</p>

<p>Stream socket
- &#8220;reliable&#8221;&#8230;? UNIX Domain streaming sockets? Curious to know what the overlap is with TCP.
- bi-directional, as if a pair of pipes had been established.</p>

<h3>socket()</h3>

<p>Create a socket with</p>

<ul>
<li>domain: UNIX, IPv4, IPv6</li>
<li>type: STREAM vs DATAGRAM</li>
<li>protocol (usually 0 unless you&#8217;re doing funky things with raw sockets</li>
</ul>


<h3>bind()</h3>

<ul>
<li>Binds to an address / port</li>
<li>is actually <em>optional</em>: if you don&#8217;t call <code>bind()</code> you&#8217;ll use an
ephemeral port chosen by the kernel. Though this means you&#8217;d need to
use some other mechanism for publishing.</li>
</ul>


<h3>stream sockets</h3>

<ul>
<li>socket() creates</li>
<li>server

<ul>
<li>bind()s to a specific port/address</li>
<li>listen()s, signalling the kernel that it&#8217;s ready to accept</li>
<li>accept()s to actually process a connection</li>
</ul>
</li>
<li>clients connects()</li>
<li>both can send(), recv(), write(), read(), etc</li>
</ul>


<p>Stream sockets can be active or passive</p>

<ul>
<li>active: can be used in a connect() call

<ul>
<li>usually clients</li>
</ul>
</li>
<li>passive: has been marked to <code>listen()</code> for connections

<ul>
<li>usually servers</li>
</ul>
</li>
</ul>


<h3>listen(int sockfd, int backlog)</h3>

<p>Tell the kernel to start listening for connections. <code>backlog</code> is the
number of connections you&#8217;re willing to have in a pending state before
<code>accept()</code> is called.</p>

<h3>accept()</h3>

<p>Blocks til connection arrives.</p>

<ul>
<li>creates a <em>new</em> socket, the one that you can actually perform IO on
that makes it to the peer socket.

<ul>
<li>so why are they both called sockets? one that&#8217;s used for a
establishing connections, and another that&#8217;s used within an
established connection?</li>
</ul>
</li>
</ul>


<h3>connect()</h3>

<ul>
<li>if it fails, close socket, create a new one, try again</li>
</ul>


<h3>Stream socket IO</h3>

<p>Sockets are bi-directional, which means kernel must internally maintain
two buffers, one for each direction.</p>

<p>Writing into already-closed UNIX domain socket yields SIGPIPE/EPIPE.</p>

<p>For UNIX-domain sockets, if a <code>close</code> fails to propagate or some other
shit goes down (eg a crash), then we have no way of knowing; should
build some sort of ACK into the system (or just use TCP?).</p>

<p>(then again with TCP, what&#8217;s the API for knowing that a specific write
failed? Usually you write and then move on, right? Or do all write&#8217;s
block? Seems weird brah)</p>

<h3>Datagram flow</h3>

<ul>
<li>create socket w socket()</li>
<li>bind() to known address</li>
<li>sendto() to send a datagram</li>
<li>recvfrom() to recv (the from implies that the source address will be
included in the thing)</li>
<li>close() when socket no longer needed</li>
</ul>


<p><code>recvfrom</code> takes a length, returns a single datagram, silently truncating
if less than <code>length</code>. <code>recvmsg</code> is a variant that sets <code>MSG_TRUNC</code> if
truncation occurred.</p>

<h3>Datagram <code>connect()</code></h3>

<p>Seemingly at oods with the known properties of datagram sockets, you can
actually use <code>connect</code> w dgram socks to yield a &#8220;connected datagram
socket&#8221;. This does a few things:</p>

<ul>
<li>allows you to use <code>write</code> and <code>read</code> (rather than having to pass the
address in to <code>sendto</code> and <code>recvfrom</code> all the live long day)</li>
<li>only messages from the socket peer can be <code>read</code></li>
</ul>


<h2>UNIX Domain Sockets</h2>

<p>For bidirectionality you always have to create a pair.</p>

<p>You can create a UNIX domain socket via other means by providing a file
name. You must have permissions to create this thing, and it&#8217;s a special
file of <code>stat</code> time <code>IFSOCK</code></p>

<p>Let&#8217;s do some ruby</p>

<pre><code>require 'socket'
socket = Socket.new(:UNIX, :DGRAM)

# recall that pack_sockaddr_in refers to internet, `un` refers to UNIX
# address becomes a null-packed string. The Ruby socket lib is
# actually pretty low level when it comes to this shit.
address = Socket.pack_sockaddr_un('./wat.unix.socket') 

# this will actually create a special file in the directory
socket.bind(address)
</code></pre>

<p>Verify it&#8217;s a special file (lf -F puts <code>/</code> at the end of directories and
<code>=</code> at the end of sockets). Recall that this requires directory search
permissions since it needs to read the contents of the inode rather than
just the name of the files.</p>

<pre><code>$ ls -F ./wat.unix.socket
./wat.unix.socket=
</code></pre>

<p>Note the starting &#8220;s&#8221;:</p>

<pre><code>$ ls -l ./wat.unix.socket
srwxr-xr-x  1 machty  staff  0 Oct 26 17:57 ./wat.unix.socket
</code></pre>

<p>Also you can&#8217;t open a socket like a normal file:</p>

<pre><code>f = File.open('./wat.unix.socket')
Errno::EOPNOTSUPP: Operation not supported on socket - ./wat.unix.socket
</code></pre>

<p>Note that if you tried to bind to this socket again, you&#8217;d get
EADDRINUSE. This is interesting since you always see this error in the
context of IP address/port collisions, but in this case it&#8217;s a file
pathname; that&#8217;s because address is a generic concept, the specifics of
which are dependent on which socket domain you&#8217;re using</p>

<ul>
<li>IPv4/IPv6 addresses are IP addresses</li>
<li>UNIX is pathnames</li>
</ul>


<p>Both are packed into that address struct so that sys calls can
use/expect the same struct blob.</p>

<p>STREAM sockets have active and passive. <code>passive</code> has had <code>listen()</code>
called on it.</p>

<p>I still am unclear about whether sockets are bi-directional. I think
they are. But I don&#8217;t understand how to stop blocking on <code>read()</code>. Like,
does it block until the buffer is full? I&#8217;ll figure it out later.</p>

<p>Datagrams are supposed to be unreliable, possibly delivered twice, etc,
but UNIX domain datagrams are reliable since it&#8217;s just the kernel
delivering shit (it&#8217;s only difficult to guarantee reliability over a
network). So UNIX domain datagrams are delivered in order and not
duplicated.</p>

<p>Linux allows large datagrams, but some UNIX buffers might only be 2048,
so if you&#8217;re going for portable, go for small.</p>

<p>AHHH fucking dummy, I was using the wrong ruby method. <code>IO#read</code> reads
until you&#8217;ve filled a buffer (or EOF). What you want is <code>read_nonblock</code>.
&#8220;But why do you still need to pass a max len&#8230; this is ruby it can
handle whatever&#8221; I don&#8217;t know, probably because it ultimately translates
to a syscall which needs the length? Yes I think I&#8217;m right about this
after consulting <code>io.c</code> in MRI.</p>

<h2>Socket pairs</h2>

<p><code>socketpair()</code> or <code>Socket.pair</code> returns a pair of connected sockets.
Communication is bi-directional. Benefits over manually creating this
pair include not having to have a public address. Useful for forky IPC.
Very similar to pipe approach to fork IPC cept that pipes are
unidirectional.</p>

<pre><code>require 'socket.rb'
a,b = Socket.pair(:UNIX, :DGRAM)

a.write("bullshit\n")
puts b.read_nonblock(100)
b.write("horseass\n")
puts a.read_nonblock(100)
</code></pre>

<p>Note that this example works also if we used <code>:STREAM</code>.</p>

<h2>Internet domain sockets</h2>

<p>Unlike UNIX domain datagram, internet domain datagrams (implemented on
UDP) are</p>

<ul>
<li>Unreliable, might be delivered twice or not at all.</li>
<li>Sending doesn&#8217;t block if client buffer full, just dropped silently.</li>
</ul>


<p>Network byte order is big-endian.</p>

<p>Marshalling is tricky, dealing with endianness and what not. Converting
to text is often the easiest way to make sense of things, can debug w
<code>telnet</code>, etc.</p>

<p>Clients generally don&#8217;t <code>bind()</code> when making connections / sending
datagrams, in which case the kernel provides an ephemeral port.</p>

<h2>DNS</h2>

<p>Types of requests:</p>

<ul>
<li>recursive: server handles entire task of resolution, including talking
with other DNS servers. I believe though that once you&#8217;ve made the
request, the server can make an iterative approach</li>
<li>iterative: ask <code>.</code> for <code>com.</code>, <code>com.</code> NS for <code>machty.com.</code>,
<code>machty.com.</code> NS for <code>www.machty.com.</code>.</li>
</ul>


<p>There&#8217;s a local DNS server (<code>named</code> for Linux) that you can ask for
names, and it&#8217;ll do iterative. You ask it for recursive and it does
iterative.</p>

<p>Root name servers found via <code>dig . NS</code>, e.g. &#8220;gimme all the Name Server
entries for the root domain <code>.</code>.</p>

<p><code>/etc/resolv.conf</code> configures the DNS resolver, defines how partial
domain names are resolved (they get concatted with the <code>domain</code> entry in
<code>resolve.conf</code>.</p>

<pre><code># assuming `domain home`
ssh machty # machty.home
ssh machty.home
</code></pre>

<p>Both work. But this is just a local DNS nicety, not the distributed DNS
whitchajigger.</p>

<h2>TLDs</h2>

<p>First layer of nodes immediately under the root <code>.</code> node. Two types:</p>

<ul>
<li>generic: com, edu, net, org:</li>
<li>country: co, de:</li>
</ul>


<h2>ports</h2>

<p><code>/etc/services</code> maintains known port names.</p>

<h2>getsockname</h2>

<p>This is useful when you&#8217;re using ephemeral ports (listen without
bind).</p>

<pre><code>require 'socket'
s = Socket.net(:INET, :STREAM)
s.listen(5)
s.puts s.local_address.ip_port
</code></pre>

<p><code>local_address</code> is a wrapper around <code>s.getsockname</code>, which is some null
padded garbage. For UNIX domain sockets it&#8217;ll contain the file pathname.</p>

<p>This is the difference between sockets bound at 127.0.0.1:45454 and
0.0.0.0:45455, which shows that both the local ip and port are
represented in getsockname.</p>

<pre><code>=&gt; "\x10\x02\xB1\x8E\x7F\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00"
=&gt; "\x10\x02\xB1\x8F\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
</code></pre>

<h2>UDP ephemeral port server</h2>

<p>So, <code>listen()</code> on a STREAM server will implicitly perform an ephemeral
port bind if you haven&#8217;t explicitly called <code>bind()</code> already; is it
possible to make an ephemeral UDP server, wherein the port is
ephemerally decided by the kernel? Well, yes, but you have to call bind;
the trick is to call it with port 0 to signify the kernel should pick
one for you. Why would you do this? I don&#8217;t know; probably if you wanted
some anonymous service that no attacker could guess the port of ahead of
time? But you&#8217;d still need to advertise your port somehow.</p>

<h2>UNIX v internet domain sockets</h2>

<ul>
<li>UNIX faster on some implementations</li>
<li>UNIX DGRAM delivery is reliable</li>
<li>UNIX lets you use file permissions for authentication</li>
<li>UNIX lets you pass open file descriptors when forking, etc</li>
</ul>


<p>But often internet sockets are the way to go since they work locally and
remotely.</p>

<h2>Load-balancing with DNS</h2>

<p>If you provide multiple IPs to the same DNS record, you get round-robin
resolution, babeh.</p>

<h2>inetd; inet daemon</h2>

<p>If you have infrequently used daemons that would hog a process table
entry and resources, why not give their sockets to inetd and inetd will
spin up your servers when they need them.</p>

<ul>
<li>number of processes reduced</li>
<li>inetd does the server-y stuff that its clients would otherwise have to
write.</li>
</ul>


<p>aka internet superserver.</p>

<h2>Who responds to ICMP messages?</h2>

<p>Just routers/gateways. Not apps, unless you&#8217;re opening raw sockets n shit.</p>

<p>For instance you can&#8217;t spin up a rails server on localhost:3000 and
expect <code>ping localhost:3000</code> to work, because it&#8217;s only listening to
TCP/UDP sockets. AHHHH I am saying so much ignorance: here&#8217;s the truth:</p>

<p>ICMP has no concept of port. Port is TCP/UDP concept. ALWAYS REMEMBER
THAT. ICMP is IP-only. Whatever responds to / notices an incoming ICMP
request must only have an IP address, and not expect to use a port in
any way. So gateways/hosts/routers will respond to ICMP. You can ping
your router. You can ping gateways. You can traceroute all the way to a
website. And you can ping localhost, because loopback is a gateway.</p>

<p>So how can you write a program that listens for ICMP requests? You need
a raw socket, which requires sudo:</p>

<pre><code>require 'socket'
require 'base64'

rsock = Socket.new(:INET, :RAW)

loop do
  s = rsock.recv(1024)
  enc = Base64.encode64(s)
  puts enc
end
</code></pre>

<p>Again, no concept of port; there&#8217;s no <code>bind</code> here nor does the kernel
assign an ephemeral port; it&#8217;s all raw sockets babeh.</p>

<p>From <code>ping(8)</code>:</p>

<pre><code>The ping utility uses the ICMP protocol's mandatory ECHO_REQUEST datagram to
elicit an ICMP ECHO_RESPONSE from a host or gateway.
</code></pre>

<p>So <code>ping</code> pings gateways/hosts, not servers.</p>

<h2>ECONNREFUSED</h2>

<p>This is caused by ICMP, if it decides it wants to send anything. Shit
gets dropped.</p>

<h2>MTU: Maximum Transmission Unit</h2>

<p>This is what causes IP packets to be sliced and diced.</p>

<p>http://en.wikipedia.org/wiki/Maximum_transmission_unit</p>

<p>The min MTU between two endpoints is the path MTU. The minimum allowable
MTU is well-defined, I forget what it is, but I think there&#8217;s one
guaranteed by IP.</p>

<p>You can find the path MTU (per TCP/UDP RFC) by setting do not fragment
flag and seeing if ICMP sends back a failure due to datagram size. That
said, lots of gateways silently drop ICMP to prevent DoS:</p>

<pre><code>http://en.wikipedia.org/wiki/Black_hole_(networking)
</code></pre>

<p>People might black hole to prevent pings; you can still send well formed
TCP/UDP requests but it won&#8217;t respond to ICMP <code>ECHO_REQUEST</code>s or
anything like that.</p>

<h2>Packet-switching</h2>

<blockquote><p>Packet switching is a digital networking communications method that groups all transmitted data – regardless of content, type, or structure – into suitably sized blocks, called packets.</p></blockquote>

<p>Switching I believe is how two endpoints of a physical link decide how
to send data between each other; they could either do circuit switching
and have a dedicated connection until the connection was over,
or you can packet switch, whereby you
break the communication into small packets that send all at once (and IP
might slice them to fit the link&#8217;s MTU).</p>

<h2>C Standard Library</h2>

<p>I was confused for a moment about where <code>write()</code> and <code>read()</code> and these
low level syscall wrappers lived&#8230; were they considered part of the C
standard library? Or were they in some bare-bones thing in some other
category of code that operating systems provided?</p>

<p>Naw, it&#8217;s all C Standard Library. It&#8217;s just that (I think) <code>write</code> and
<code>read</code> are so low level as to not be considered part of <code>stdio</code>, the IO
subset of the C standard lib.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-17T17:52:00-04:00" pubdate data-updated="true">Oct 17<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/10/faily-burnhole/">
		
			Faily Burnhole</a>
	</h2>
	<div class="entry-content">
		<h2>(postgres) Transactions</h2>

<p>http://www.postgresql.org/docs/8.3/static/tutorial-transactions.html</p>

<ul>
<li>group sequence of SQL into atomic (all-or-nothing) operations</li>
<li>useful for preventing invalid state of a crash occurs in the middle of
a sequence of queries</li>
<li>also, transactions are isolated from each other; one in-progress
transaction won&#8217;t see the partially complete transaction process of
another</li>
<li>postgres implicitly wraps every statement in a transaction block if
you haven&#8217;t.</li>
<li>transaction is <code>BEGIN</code> followed by <code>COMMIT</code> or <code>ROLLBACK</code>.</li>
<li>savepoints allow for finer granularity:

<ul>
<li><code>BEGIN</code></li>
<li><code>UPDATE ...</code></li>
<li><code>SAVEPOINT wat</code></li>
<li><code>UPDATE ...</code></li>
<li><code>ROLLBACK TO wat</code></li>
<li><code>UPDATE ...</code></li>
<li><code>COMMIT</code></li>
</ul>
</li>
</ul>


<p>So how can I use this for nested world environments&#8230;</p>

<h2>Sharing raised error with <code>ensure</code> block</h2>

<p>Saw a Ruby thing I hadn&#8217;t seen before at
https://github.com/rails/rails/blob/master/activerecord/lib/active_record/connection_adapters/abstract/transaction.rb#L186-L205</p>

<p>Basically, a <code>rescue</code> must precede an optional <code>ensure</code> block, but whats
cool is that the error caught be the rescue block is available to the
<code>ensure</code> block. Stripped down, the basic construct is</p>

<pre><code>def wat
  do_something_that_might_fail
  rescue Exception =&gt; e
    # do some error handling
  ensure
    # do generic stuff
    if e
      # continue to do some error handling
    end
end
</code></pre>

<h2>ramdisk + ember-cli</h2>

<p>tmpfs is a form of ramdisk. ramdisk is just a general purpose term for
when a virtual file system is provided but the data just lives on memory
rather than hard disk.</p>

<p>Some questions I need to answer:</p>

<ul>
<li>are there different rules about paging when you create a ramdisk? Does
it prevent its own memory from paging to disk any more than other
processes&#8217; virtual memory?</li>
<li>can you control paging in general? (other than going out of your way
to regularly read memory)</li>
</ul>


<p>My ember-cli builds for a decently complex project are about 2s, which
is waaaay better than the 20s they were a month ago. But I can get my 2s
down to 1s my mounting a ramdisk and symlinking my tmp folder to it:</p>

<pre><code>diskutil erasevolume HFS+ 'RAM Disk' `hdiutil attach -nomount ram://8388608`
rm -rf tmp
mkdir /Volumes/RAM\ Disk/tmp
ln -s /Volumes/RAM\ Disk/tmp tmp
</code></pre>

<h2>Photoshop and tmpfs</h2>

<p>http://www.tekrevue.com/tip/how-to-create-a-4gbs-ram-disk-in-mac-os-x/#comment-904649071</p>

<p>This comment speaks of the diminishing returns of using a ramdisk as
scratch space for Photoshop now that Photoshop is 64bit.</p>

<p>If your system is 32bit, it means running processes can only access
virtual mem addresses from 0 to 2<sup>32-1</sup> (0xFFFFFFFF or 4294967293).
On 64 bit systems, that max address is doubled to 0xFFFFFFFFFFFFFFFF, or
1.84 * 10<sup>19.</sup> If you had more than 4gig of RAM on a 32bit system, each
process would still be limited to a max of 4gig memory usage simply due
to the fact that it can&#8217;t reference memory addresses higher than 4gig.
But Photoshop often needs more than 4gig, so what&#8217;s the solution?
Scratch disks.</p>

<p>Scratch disks are like virtual memory implemented in user space. If you
need to store more temporary data than you can put into memory, just
throw it on scratch disk. The problem is that scratch disks</p>

<p>I could totally be bullshitting right now. I could be wrong. But seems
right? Less wrong?</p>

<h2>ln</h2>

<p>I never remember the argument order for <code>ln</code>.</p>

<p>It is FUCKING LEFTWARD. The thing you create on the right points to the
thing on the left.</p>

<pre><code>ln EXISTING_THING LINK

&lt;-------------
</code></pre>

<p>The thing that confused me was that i kept thinking <code>-s</code> was an option
that accepted an argument. It is not! It&#8217;s just an argless option. <code>ln</code>
always has the format of new thing on right points to left. NEVER
FORGOT.</p>

<h2>Dockyard&#8217;s fixtory</h2>

<p>https://github.com/dockyard/fixtory</p>

<p>Convenient way to populate groups of fixtures, maintain references to
the created instances, etc.</p>

<h2>Execute/search permission</h2>

<p>http://content.hccfl.edu/pollock/AUnix1/FilePermissions.htm</p>

<p>Directories have different levels of &#8220;readability&#8221; based on their read /
execute flags. A file record within a directory has a name and an inode.</p>

<p>You can read names of files in a directory (<code>ls</code>) if you have read
permissions on that directory, and permissions denied if not.</p>

<pre><code>$ ls wat
lol
$ chmod -r wat
$ ls wat
ls: wat: Permission denied
</code></pre>

<p>If you want to access the inode in any way, like to read file
attributes (permissions et al), or to read its contents, you&#8217;ll need
execute (search) permissions on the directory.</p>

<pre><code>$ chmod +r wat
$ chmod -x wat
$ ls wat
lol
$ ls -l wat
ls: wat: Permission denied
$ ls -i wat
ls: wat: Permission denied
$ cat wat/lol
cat: wat/lol: Permission denied
$ chmod +x wat
$ ls wat
lol
</code></pre>

<p>Then of course you need file read permissions to access the contents.</p>

<p>So if you&#8217;re using absolute file paths, every directory along the way
needs execute (search) permissions. But in the unusual case that you&#8217;re
able to <code>cd</code> into a directory (thus setting the process&#8217;s current
working directory, something the kernel tracks to control where relative
file lookups occur from) before a parent directory&#8217;s read permissions
are revoked, you&#8217;re grandfathered in if you&#8217;re using relative file perms
from that point on, unless of course the path you provide steps out and
in again.</p>

<pre><code>$ chmod -x ..
$ cat ../inner/woot
../inner/woot: Permission denied
$ chmod +x ..
$ cat ../inner/woot
lol
</code></pre>

<p>Basically, there&#8217;s no concept of deeper and deeper folders, just
following pointers (<code>..</code> and <code>.</code> included), and pointers have permissions
that must be adhered to in order to traverse them.</p>

<h2>dev id and inode</h2>

<p>Device id + inode uniquely identify a file across all file systems.</p>

<p>If the file itself is a special device file, the inode for that file
contains the major/minor id of the device.</p>

<h2><code>utimes(2)</code> for manually changing access/modify timestamps</h2>

<p>You can change the last modified time and last accessed time of a file.
One use case is how <code>tar</code> and <code>unzip</code> preserve the original timestamps
of archived files when they are unarchived.</p>

<p><code>ctime</code> is changed to now when you run <code>utimes</code>.</p>

<h2>group ID of newly created files</h2>

<p>This is governed by 1. how you&#8217;ve configured the file system and 2.
whether set-group-id is set on parent directory.</p>

<p>I think this is one of the rare cases where set-group-id is meaningfully
used on files rather than directories.</p>

<h2>File deletion doesn&#8217;t require file permissions</h2>

<p>You can delete a file without having any permissions on it, since all
you&#8217;re doing is modifying a parent directory.</p>

<h2>Why not have slashes for directories by default?</h2>

<pre><code>$ ls
inner   lol
$ ls -F
inner/  lol
</code></pre>

<p>Wouldn&#8217;t that slash on <code>inner/</code> be convenient to always display?
Why isn&#8217;t that a default?</p>

<p>Answer: because knowing whether a file is a normal file or a directory
requires execute/search permissions on the directory that file lives in.
You can list file/directory names with next to no permissions, but once
you start looking at inode information (such as whether a file is a
normal file or a directory), you&#8217;ll need search/execute perms, and the
default behavior of <code>ls</code> is much less likely to get permission denied
errors.</p>

<p>So thinketh I. Could be wrong.</p>

<h2>Accessing files w/o read perms</h2>

<p>Even if a directory has no read permissions, if it has execute
permissions, then files inside can still be accessed, but their names
must be known ahead of time since you won&#8217;t be able to list the file
names in that directory.</p>

<p>Seems crazy, but useful for when you have a public directory and don&#8217;t
want to list all the contents.</p>

<p>I guess this also means it&#8217;s not possible to hide a single
file/directory within a directory that has read permissions; i.e. if you
can list one file in a directory, you can list them all.</p>

<p>Neat tidbit: there is (was?) a process accounting flag ASU that&#8217;s set if
the process made use of superuser privileges, and the kernel will only
check superuser permissions last in case it can&#8217;t get privileges any
other way than so that it can avoid unnecessarily setting ASU.</p>

<p>It&#8217;s possible to wind up in a situation where an owner has less access
than a group s/he belongs to, due to the fact that the kernel
permissions algorithm will stop once it finds a matching user or group;
it won&#8217;t try to find read (etc) permissions in all matching permission
bits, it&#8217;ll just check the first set of bits it matches.</p>

<p>ACLs (Access Control Lists) allow for per-user and per-group file permissions.</p>

<h2>Sticky bit</h2>

<p>Used to be a signal for a process to stay in swap, now it&#8217;s a signal
set on directories that, when set, prevents non owners and non write
accessors from being able to delete files they don&#8217;t own.</p>

<h2>umask</h2>

<p>A mask, attached to a process, that negates certain permissions.</p>

<h2>EA: extended attrs</h2>

<p>User EAs can only be applied to files and folders, because</p>

<ul>
<li>symlinks have no meaningful permissions, which means anyone in the
world could clutter symlink w EAs if it were possible</li>
</ul>


<h2>executable permissions</h2>

<p>If no one has executable permissions on a file, then not even <code>sudo</code> can
get it to run as such.</p>

<pre><code>$ chmod -x exe
$ ./exe
-bash: ./exe: Permission denied
$ sudo ./exe
sudo: ./exe: command not found
$ chmod o+x ./exe
$ sudo ./exe
wat
</code></pre>

<p>I guess another way of thinking about it is that a file isn&#8217;t an
executable if no one has permissions to it.</p>

<h2>Processes, cwd, directories, etc</h2>

<p>Kernel tracks two attributes on running processes:</p>

<ul>
<li>root: the point from which absolute paths are looked up. Most
processes have <code>/</code></li>
<li>cwd: the directory from which relative paths are looked up</li>
</ul>


<p>(you can use <code>chroot</code> to change the root directory for a process)</p>

<p>A directory is different from a file in that 1) it is specially marked
as a directory in its inode attrs (remember this is why <code>ls -F</code>
requires execute permissions on the parent directory), and 2)
its contents are a table of filenames (read perms) and inodes
(execute/search perms).</p>

<p>You can&#8217;t use <code>read</code> on a directory, you must use other system calls,
hence <code>cat: wat: Is a directory</code>. Basically, the kernel restricts you to
certain syscalls to modify the directory; you can&#8217;t <code>read</code> / <code>write</code> it
the way you would a normal file. The error that gets thrown is <code>EISDIR</code>.</p>

<h2>inode table</h2>

<p>A filesystem has a root inode table that inode entries in directories
will refer to. The root inode table has the following features:</p>

<ul>
<li>index 0 is unused since a 0 is how directory inodes signal that an
entry is unused</li>
<li>index 1 tracks bad blocks on the disk</li>
<li><p>index 2 is <code>/</code></p>

<p>  $ ls -di /
  2 /</p></li>
</ul>


<p>Woot woot! This stuff is so awesome.</p>

<p>So it&#8217;s in this shared inode table that perms are stored. So if you hard
link, any changes to the permissions of one link affects the other:</p>

<pre><code>permstest :: touch shit1 &amp;&amp; ln shit1 shit2
permstest :: ls -l shit*
-rw-r--r--  2 machty  staff  0 Oct 14 10:40 shit1
-rw-r--r--  2 machty  staff  0 Oct 14 10:40 shit2
permstest :: chmod -rwx shit1
permstest :: ls -l shit*
----------  2 machty  staff  0 Oct 14 10:40 shit1
----------  2 machty  staff  0 Oct 14 10:40 shit2
</code></pre>

<p>TODO: Is this the same w ACLs permissions?</p>

<p>Hardlinks not supported by MS VFAT, but yes to NTFS.</p>

<p>inodes don&#8217;t have filenames&#8230; that&#8217;s only in the directory&#8217;s table;
remember that gzip and gunzip (and some other utilities) share the same
inode, and depending on <code>argv[0]</code>, do different things:</p>

<pre><code>$ ls -i `which gunzip` `which gzip`
343041 /usr/bin/gunzip  343041 /usr/bin/gzip
</code></pre>

<p>The <code>rm</code> algorithm is simple: decrement the inode counter, and if 0,
then deallocate. Reference counting, bitchez.</p>

<p>Based on the above layout, you can&#8217;t (easily) get the filename of an
open file, because multiple files might point to that inode, not to
mention that even if you wanted to loop through the file system&#8217;s inode
table, you still wouldn&#8217;t have the file name, just a matching inode
number.</p>

<p>Hardlinks can&#8217;t be created cross-file-system (since they&#8217;re just inode
numbers. symlinks can handle this though).</p>

<p>Hardlinks can&#8217;t (cept Mac due to Time Machine shit) link to directories
due to circular dependencies (e.g. a nested folder hardlinking to an
ancestor folder).</p>

<p>Symlinks can be displayed with trailing <code>@</code> via <code>ls -F</code>. They don&#8217;t bump
the inode counter. They can be created to point to nothing, or can have
their target files deleted (dangling). Like all the other extra data
displayed by <code>ls -F</code>, search perms are needed on the parent directory.
Symlinks have a symlink file type stored in the inode.</p>

<p>Tools are smart enough to avoid cirular dependencies when symlinks link
to directories, because they actually can know they&#8217;re dealing with a
symlink; a multi-hardlink doesn&#8217;t look any different than anything else.</p>

<pre><code>$ ln -s ./circle ./circle
$ ./circle
-bash: ./circle: Too many levels of symbolic links
</code></pre>

<p>For long ass symlinks (> 60 bytes), a data block (where file data is
normally stored) is used to store the target link. But lots of file
systems (<code>ext2</code>+ et al) have an optimization where if the target is less
than 60 bytes, the target is written right into the inode structure
where the data block pointers are usually kept. I tried reproducing this
with a test case of a bunch of <code>stat</code> syscalls on a small-target symlink
and a 60+ byte symlink and it didn&#8217;t make a difference, but that could
just be due to disk cache on behalf of the kernel; the kernel kept the
inode data in RAM so it was just as fast, but if the cache was cold then
symlink lookups should be a lot faster.</p>

<h2>unlinks don&#8217;t complete while files are open</h2>

<p>If there are open file descriptors, an unlinked file won&#8217;t be totally
deleted. Hence the common practice to create and unlink a temporary file
so that you&#8217;re guaranteed when the handle closes, the file will be
totally deleted. This also makes it possible to happily unlink a file
and not worry whether someone else is using it&#8230; but don&#8217;t we sometimes
get file-in-use errors, like &#8220;can&#8217;t delete this file since it&#8217;s being
used be process X&#8221; stuff? Ah, you can delete a file out from under
someone else. They might still save it if they&#8217;ve buffered the data
(think Vim&#8217;s OMG THE FILE NO LONGER EXISTS warning).</p>

<h2>NTFS vs FAT32</h2>

<p>Windows 7 prefers NTFS. Earlier versions prefer FAT. FAT doesn&#8217;t have
security-related features (I&#8217;m guessing permissions?). FAT was
originally designed for floppies, and then used on hard drives. It&#8217;s
still often used for thumb drives.</p>

<h2>Transducers</h2>

<p>http://blog.cognitect.com/blog/2014/8/6/transducers-are-coming</p>

<p>http://jlongster.com/Transducers.js&#8211;A-JavaScript-Library-for-Transformation-of-Data</p>

<p>God damn it. Guess I have to learn a new thing.</p>

<h2>Reentrant</h2>

<p><a href="wiki">http://en.wikipedia.org/wiki/Reentrancy_(computing)</a></p>

<p>Reentrancy means the function can be interrupted and re-entered without
harm. Actually I think more accurately it means it can be re-entered,
even within the same thread, without causing issue. A function can be
threadsafe and not re-entrant. e.g.</p>

<pre><code>trap :INT do
  puts "int"
end
Process.kill :INT, Process.pid
puts "boom"
</code></pre>

<p>This yields a <code>deadlock; recursive locking (ThreadError)</code> every time,
the same that would happen if you tried to double lock a mutex within
the same thread. The reason is that <code>puts</code> calls <code>write</code>, and <code>write</code>
mutexes around Ruby&#8217;s IO buffer. The signal handler doesn&#8217;t get called
synchronously at <code>Process.kill</code>, but for whatever reason, the kernel
decides to fire the signal handler during <code>write</code> in <code>puts "boom"</code>,
after the write mutex has already been locked. Then the signal handler
runs, tries to the do the same lock, and BOOM. Weird shit. But proof
that <code>puts</code> and <code>write</code> aren&#8217;t re-entrant even though they&#8217;re thread
safe. If you did <code>$stdout.sync = true</code>, they would be reentrant though
and the above error would go away.</p>

<h2>Process cwd</h2>

<p>Hmmm a process&#8217;s cwd does contain a pathname to the cwd; I thought it&#8217;d
just be some kind of inode pointer and not know the name? That said, the
beginning of the path is truncated if there&#8217;s not enough space, though
this is probably rare. That said, you can <code>readlink</code> the symlink at
<code>/proc/PID/cwd</code> (this doesn&#8217;t exist on Mac though).</p>

<h2><code>chroot</code> jail</h2>

<ul>
<li>FTP uses this so that anonymous users can&#8217;t just browse the whole
system</li>
<li>Linux doesn&#8217;t have hard-linked directories, but some UNIX varieties
do, and a hardlink outside of a <code>chroot</code> jail will compromise the jail</li>
<li>Most programs can&#8217;t run in <code>chroot</code> jail because they rely on
dynamically linked libraries, and the link targets are often absolute
and expect <code>/usr</code> to live.</li>
</ul>


<h2>Symlink perfs</h2>

<p>I was enouraged by the fact that on ext2+, symlinks whose targets are
less than 60 chars long get written into the inode rather than into a
separate data block (it&#8217;s basically written where the data block
pointers are usually saved, which amounts to ~60 bytes). Sooo I did a
quick benchmark to see if ember-cli would benefit, and alas (and go
figure?) 60 char perfs that apply to ext2 (and 3 and 4) don&#8217;t apply to
OS X&#8217;s HFS+.</p>

<p>I ran a test creating 100,000 symlinks, one where each symlink target
was 59 chars, and another with 60, and the difference is dramatic:</p>

<pre><code>Linux, ext4, 60 char symlink, 100,000

real    0m19.642s
user    0m0.468s
sys     0m3.988s

Linux, ext4, 59 char symlink, 100,000

real    0m2.005s
user    0m0.360s
sys     0m1.436s
</code></pre>

<p>I&#8217;m sad, because most ember-cli / broccoli symlinks are above the 60
limit, and this would have brought us some insane perfs, but alas alas
alas, most people do ember-cli work on OS X, not Linux. Oh god damn
well.</p>

<h2>ARS Technica on why HFS+ blows</h2>

<p>http://arstechnica.com/apple/2011/07/mac-os-x-10-7/12/#file-system</p>

<ul>
<li>HFS is from 1985</li>
<li>HFS+ (aka Mac OS Extended) released in 1998.</li>
<li>OS X (2001) unfortunately kept HFS+ around even though it sucks</li>
</ul>


<p>So yusuck:</p>

<ul>
<li>16 bit processing resolution in Mac&#8217;s implementation (Motorola 68000
hangover). Not really sure what this means, not sure why if the data
is 32+ bit why 16 is the resolution? So many things I don&#8217;t know.</li>
<li>Time resolution of HFS+ is only a second, shitty for file timing logic
in <code>make</code>, et al. Most modern fs&#8217;s have nanosecond resolution.</li>
<li>Global file lock on metadata; only one process can write to a file at a time. NOPE
that&#8217;s obviously incorrect. It means only one process can update the
file system at a time&#8230; I don&#8217;t understand? Can&#8217;t add multiple files to
a directory at the same time? Metadata?</li>
<li><p>No sparse files. The following ruby code will instantly eat a gig on
HFS+. On ext2 you could still use that gig space for other files, and
intermediate blocks would only be allocated as needed:</p>

<p>  File.open(&#8216;bigassfile_DELETE_ME&#8217;, &#8216;w&#8217;) do |f|</p>

<pre><code>f.seek(1000000000)
f.puts('l')
</code></pre>

<p>  end</p></li>
</ul>


<p>Result: Finder reports -=1gig of freespace, as expected (if there are no
sparse files). Weird though: <code>ls -l</code> reports only 87 block usage; I
would have expected a lot more give the fact that the file system is
allegedly allocating a bunch of zeroes? ANSWER: I think it&#8217;s because OS
X uses a VFS that pretends to support sparse files over HFS+, which
doesn&#8217;t, but I need to confirm this.</p>

<ul>
<li>Hard links to directories is supported, which is kinda weird.
Internally it works by hiding them in hidden a hidden directory (my
guess is to avoid cycles?)</li>
<li>No concern about data integrity. Easy for meta data to get corrupted.
Report showed that ~30% of HFS+ systems had mismatched checksum. Data
loss likely.</li>
</ul>


<h2>Endianness</h2>

<p>Not to be confused with &#8220;bit-endianness&#8221;, the atomic unit Endianness
as people normally talk about it is the byte, rather than the order of
bits. Endianness is concerned with the byte order in a &#8220;word&#8221; (the unit
of a CPU processing, e.g. 32 bit machine vs 64 bit machine refers to the
word size and has implications on the size limits of integers, memory
addresses, etc.). Whether the most significant bits appear at the
beginning or end of a word is the endianness, big-endian or
little-endian. You have to care about this stuff if you&#8217;re manually
converting bytestreams between different systems with different
endianness. Some processors are bi-endian.</p>

<h2>POODLE attack</h2>

<p>https://tools.ietf.org/html/draft-ietf-tls-downgrade-scsv-00</p>

<p>SSL 3.0 preceded TLS 1.0 and has vulnerabilities that allow an attacker
to see plaintext communication. Some clients go beyond the TLS handshake
specifications and will fall back to SSL 3.0 if a TLS handshake fails in
order to support the case where they&#8217;re talking to a legacy ass server
that runs SSL 3.0. A man in the middle can fuck with a handshake,
causing it to fail, and causing the TLS client to try communication with
SSL 3.0, and many servers supporting legacy SSL 3.0 will just happily
fall back to that, exposing the connection to SSL 3.0&#8217;s weaknesses.</p>

<p>The solution is for clients falling back to SSL 3.0 to send a backwards
compatible cipher suggestion that newer patched servers will look out
for and will treat as a signal that &#8220;this SSL 3.0 connection attempt is
only a fallback, and you shouldn&#8217;t accept this and start speaking in
3.0&#8221;. Legacy servers will just see it as a suggested cipher that they
don&#8217;t understand and will just choose another cipher that they do, and
continue communicating in their legacy 3.0 way. Case in point: upgrade
your servers.</p>

<p>The name for the patch is the TLS Signaling Cipher Suite Value (SCSV).</p>

<h2>inotify config</h2>

<p>On Linux you can configure aspects of <code>inotify</code> by writing values in to
various files in <code>/proc/sys/fs/inotify</code>. Question: why this format of
config? Why a single value in each? Why not <code>sysctl</code>?</p>

<h2>ssh escape char</h2>

<p><code>~</code> at the beginning of a line is an ssh escape char; if your connection
is hung, you can do <code>~.</code> (at the beginning of a line; you can force this
by pressing enter) and that&#8217;ll disconnect.</p>

<pre><code>Supported escape sequences:
 ~.   - terminate connection (and any multiplexed sessions)
 ~B   - send a BREAK to the remote system
 ~C   - open a command line
 ~R   - request rekey
 ~V/v - decrease/increase verbosity (LogLevel)
 ~^Z  - suspend ssh
 ~#   - list forwarded connections
 ~&amp;   - background ssh (when waiting for connections to terminate)
 ~?   - this message
 ~~   - send the escape character by typing it twice
</code></pre>

<p>Mmmm command line, this seems interesting if you&#8217;re using ssh for
proxying:</p>

<pre><code> ~C      Open command line.  Currently this allows the addition of port for-
         wardings using the -L, -R and -D options (see above).  It also
         allows the cancellation of existing port-forwardings with
         -KL[bind_address:]port for local, -KR[bind_address:]port for remote
         and -KD[bind_address:]port for dynamic port-forwardings.  !command
         allows the user to execute a local command if the PermitLocalCommand
         option is enabled in ssh_config(5).  Basic help is available, using
         the -h option.
</code></pre>

<h2>Signals</h2>

<p>Signals are sync; between generation and delivery, they are pending.
Most often sent immediately if running, or once it&#8217;s next scheduled to
run. Signals can be temporarily blocked by signal masks til the process
is ready to handle them (to prevent rude interruptions). Signals can
yield the following reponse from processes:</p>

<ul>
<li>ignore: kernel never tells process about it</li>
<li>terminate: &#8220;abnormal&#8221; (non <code>exit</code>) termination</li>
<li>core dump and terminate: core dump is image of virtual memory</li>
<li>stop execution (suspend)</li>
<li>resume execution</li>
</ul>


<p>I guess the thing I&#8217;ve learned here is that by setting signal masks,
you&#8217;re telling the kernel ahead of time what should happen when signals
are sent to this process, rather than setting some process-level
handlers that server as callbacks when these signals arrive;
particularly ignore &#8211; I thought it&#8217;d still make it to some low level
library in the process, but sounds like it&#8217;s rather just the kernel
knowing ahead of time not to even send it.</p>

<p>You can&#8217;t tell a signal that doesn&#8217;t by default terminate/core dump to
terminate/core dump, but you can install a signal handler and then call
<code>abort()</code> or whatever to send yourself a signal that <em>will</em> cause such a
thing to happen.</p>

<p>On Linux you can look up a process&#8217;s signal mask via <code>/proc/PID/status</code>.
You can also use <code>ps -p $$ -o sigmask,sig</code> to get info about signal
masks.</p>

<p><code>SEGV</code> means segmentation violation.</p>

<p><code>SIGBUS</code> is like <code>SIGSEGV</code> but in very particular situations, such as
reading past the end of a memory mapped file. BUS is hipster SEGV.</p>

<p>Send signals with <code>kill</code> (whose name is a hangover from a time in which
most if not all signals terminated a process). Different <code>pid</code> values do
different things:</p>

<ul>
<li>positive: send signal to pid</li>
<li><code>0</code>: send signal to processing group of calling process, including
calling process</li>
<li><code>&lt; -1</code>: send signal to process group dilineated by the absolute value of
the supplied pid</li>
<li><code>-1</code>: send to all processes you have permission to send to, excluding
<code>init</code>/<code>launchd</code> (pid 1) and the calling process. AKA broadcast
signals.</li>
</ul>


<p><code>init</code>/<code>launchd</code> can only be sent signals for which it has signal
handlers, to prevent accidental killing of this precious process.</p>

<p><code>CAP_KILL</code> is the privilege that allows a process to send a signal to
whatever.</p>

<p><code>SIG_CONT</code> is special in that it can be sent by unprivileged processes
to any process in the same session to allow for job-control shells to
restart stopped jobs that have changed their user IDs.</p>

<p>Null signal 0 can be used to test if a process exists and we can send a
signal to it. Of course you might troll yourself given that pids are
recycled.</p>

<p>Plain ol (non-realtime) signals don&#8217;t queue; they just internally set a
bit in the kernel and fire next time that process runs. This is why
multiple signals fired very quickly might get coalesced into one</p>

<h2>How to check if process is still running</h2>

<ul>
<li>(for child processes) <code>wait</code></li>
<li>semaphores and exclusive file locks; if you know a process locks a
file, and you can acquire the lock or semaphore, you know it must be
dead. I&#8217;m guessing pidfiles work this way?</li>
<li><code>stat</code> <code>/proc/PID</code>.</li>
<li>IPC sockets go dead, etc</li>
</ul>


<h2>async-signal-safe</h2>

<p>A function is async-signal-safe if</p>

<ol>
<li>it&#8217;s reentrant</li>
<li>it can&#8217;t be interrupted by signal handler</li>
</ol>


<p>Signal handlers should ideally only call async-signal-safe functions.
Note that if you have a signal handler installed for multiple signals,
or if you have <code>SA_NODEFER</code>, a handler function might get simultaneously
and might not be reentrant relative to itself if it mucks with globals,
even if the main app code doesn&#8217;t touch those globals.</p>

<p>In C-land (and Java) you can use the volatile keyword to prevent
variables from living in registers, or at least guaranteeing that a
write to a variable goes all the way to memory, which is an important
guarantee for when threads share and write to a global variable.</p>

<p>In JRuby, the Atomic gem is useful as a lock-free test-and-set way of
performing an update to a value, and detecting/retrying if someone else
interrupted your operation.</p>

<p>http://moonbase.rydia.net/mental/blog/programming/atomic-operations-in-ruby.html</p>

<p>Parallelism is moronically hard.</p>

<h2>Signal handler recovery</h2>

<p>You can do <code>setjmp</code> and <code>longjmp</code>&#8230; cray crqy.</p>

<p>When the kernel runs a handler, it adds a bit to the <code>sa_mask</code> and then
removes it when handler returns, so if you <code>longjmp</code>, you need to make
sure to unset it. (Presumably NODEFER prevents this bit from being set,
allowing the handler to be called multiple times?)</p>

<h2>Signal Stack</h2>

<p>Processes have a signal stack separate from the regular stack for
running signal handlers. You can use <code>sigaltstack</code> to change it to some
preallocated region, useful for when you want to catch SIGSEGV on a
stack overflow (which means there&#8217;s no more room on the process stack
for a signal frame/stack).</p>

<h2>Interrupted syscalls</h2>

<p>Blocking reads are syscalls, and if a signal hits an app during such a
syscall, when the signal handler returns and normal process flow
continues, that syscall will yield an <code>EINTR</code>. In Ruby this results in a
<code>Interrupt &lt; SignalException &lt; Exception</code> being raised. So you have to
jump through some hoops, put things in loops, to handle/ignore <code>EINTR</code>
on blocking syscalls. Orrr you can use <code>SA_RESTART</code> when establishing
signal handlers w <code>sigaction</code> so that the kernel automatically restarts
interrupted syscalls post signal handler.</p>

<p>Just realized something: on Ruby, if you don&#8217;t trap a (non-terminating)
signal handle, it&#8217;ll fire as an exception that you can caught. That&#8217;s
crazy. This must mean Ruby internally traps all trappable signals and
then checks them against any registered trap handlers in Rubyland.</p>

<h2>Framework blackboxing</h2>

<p>Exceptions in blackboxed frameworks don&#8217;t pause. So you can add
blackboxed frameworks in Chrome inspector options to ignore a framework
that keeps throwing shit. Probably other thins too; TODO: research!</p>

<h2>Cryptonomicomicon</h2>

<p>Page 17.</p>

<p>lambent: glowing, gleaming, or flickering with a soft radiance</p>

<p>gnomon: the projecting piece on a sundial that shows the time by the
position of its shadow.</p>

<h2>Why <code>sysctl</code>?</h2>

<p>In my Linux learnings I was curious as to why some settings seemed to be
stored in files while others seemed to be stored via separate utilities
like <code>sysctl</code>. Turns out <code>sysctl</code> is just a wrapper around <code>/proc/sys</code>,
and the setting variable names e.g. <code>a.b.c.d</code> would map to
<code>/proc/sys/a/b/c/d</code> and the setting would be the contents of that file.</p>

<p>So as far as global structures go, I know about:</p>

<ul>
<li>Environment variables</li>
<li>Shell variables (basically non-exported env vars, don&#8217;t get shared
with child processes).</li>
<li>Shell settings (e.g. ulimit, a per-shell set of defaults used when
invoking child processes <em>from that shell</em>; it&#8217;s not like you&#8217;re
setting system-wide settings when you set <code>ulimit</code>)</li>
<li><code>procfs</code></li>
<li>Probably lots more file based stuff I&#8217;m not thinking of. If it&#8217;s
really system-wide global stuff, it must live in a file somewhere,
right? Everything is a file?</li>
</ul>


<h2><code>TASK_UNINTERRUPTIBLE</code></h2>

<p>A risky process state, usually for operations that are quick to
complete, like waiting for a syscall to finish flushing data to disk,
but if there&#8217;s some issue, NFS or kernel bug, it might result in a hung
task that cannot be killed without a system restart. Another state,
<code>TASK_KILLABLE</code>, was added to prevent this, and it was first applied to
hung NFS.</p>

<h2>Hardware signals</h2>

<p>Linux force-delivers hardware signals even if they&#8217;re set to ignore.
Returning from a signal handler means undefined behavior because likely
the machine instruction that caused the interrupt is going to be
retried, likely causing an infinite loop. You need to <code>_exit</code> (because
<code>exit</code> flushes stdio buffers which might be locked and cause problems,
not to mention that <code>exit</code> fires <code>onexit</code> hooks) or do a <code>siglongjmp</code> to
guarantee that you&#8217;re skipping over the broke ass machine instruction.</p>

<h2>Timers</h2>

<p>3 types of timers per process: real (wall clock), virtual (user CPU),
and profile (user+kernel).</p>

<p>You can set timers on read operations by omitting <code>SA_RESTART</code> from the
<code>SIGALRM</code> registration.</p>

<h2><code>sleep</code></h2>

<p>This could be implemented otherwise with <code>sigsuspend()</code> (which allows
you to specify a temporary signal mask and block until a signal arrives
to wake it up).</p>

<p>You can use <code>sleep</code>, or <code>nanosleep</code>. <code>nanosleep</code> is limited by
resolution of software clock which uses units of time called jiffies&#8230;?
Jiffies are the amount of time the kernel lets a process execute, in HZ.
For a long time it was 100 HZ. So a jiffy was 1% of a second, or 10ms.
That seems crazy big! Maybe not? But if video games wanna run at 60 fps,
and they have to share the CPU with other things, they&#8217;re gonna need
larger jiffy. Because if the video game is alternating with only a
single other process (and in real life it should be many other
processes), then it couldn&#8217;t achieve more than 50 fps. Soooo sounds like
there&#8217;s something I don&#8217;t understand. The Jiffies did get smaller.</p>

<h2>SSLMate</h2>

<p>Buy SSL certs from your terminal. Why the fuck not?</p>

<p>https://sslmate.com/</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-10T10:24:00-04:00" pubdate data-updated="true">Oct 10<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/10/06/crowley-journal/">
		
			Crowley Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Comptroller</h2>

<p>Basically the CFO of public institutions. In charge of audits,
accountability, etc.</p>

<h2>Fetch remote branch</h2>

<p>http://stackoverflow.com/questions/945654/git-checkout-on-a-remote-branch-does-not-work</p>

<p>I was burned by this.</p>

<p>Basically, I had <code>origin</code> in the <code>+fetch</code> section when I wanted the new
branch in there</p>

<pre><code>fetch = +refs/heads/*:refs/remotes/origin/*
</code></pre>

<p>TODO: understand this fetch crap. I still don&#8217;t grok it.</p>

<h2>Amazon SES</h2>

<p>http://aws.amazon.com/ses/</p>

<p>Simple Email Service.</p>

<h2>Bash run last command substitute</h2>

<pre><code>$ ls lol
ls: wat: No such file or directory
$ ^wat^lol
ls lol
ls: lol: No such file or directory
</code></pre>

<h2>Harp. What is it?</h2>

<p>I don&#8217;t know. You tell me.</p>

<p>http://harpjs.com/</p>

<p>Static web server with built in preprocessing.</p>

<p>https://github.com/silentrob/harp-editor</p>

<h2>Candy kid</h2>

<p><img src="http://kandipatterns.com/images/kandikids.jpg" alt="" /></p>

<h2>Lissajous curve</h2>

<p>http://en.wikipedia.org/wiki/Lissajous_curve</p>

<pre><code>x=A\sin(at+\delta),\quad y=B\sin(bt),
</code></pre>

<p>Family of curves that seem bounded by a (-1,-1)x(1,1) box. What am I
doing with my life.</p>

<p>Source: cryptonomicon, bumble bee doing Lissajous across the ceiling.</p>

<h2>CSS history theft</h2>

<p>http://lcamtuf.coredump.cx/css_calc/?utm_source=html5weekly&amp;utm_medium=email</p>

<ul>
<li>Til mid 2010, a crappy site could use the <code>:visited</code> pseudo class to
render a bunch of URLs and then check the url to see if the <code>:visited</code>
styles were applied.</li>
<li>this loophole was closed by only letting specify color attributes, and
prevent color lookup via <code>getComputedStyle</code>.</li>
<li>loophole remains open for clicking a single URL, which doesn&#8217;t scale
too well.</li>
</ul>


<h2>Milquetoast</h2>

<p>Based on comic cartoon character Caspar Milquetoast, a timid, weak-willed old man,
whose namesake is breakfast comfort food consisting of toast and a white
milk-based sauce.</p>

<p>Millhouse is milqtoast, kinda, but more dweeby. Edward Norton in Fight
Club is milquetoast.</p>

<h2>Gone Girl</h2>

<p>I should see it. Once book, now David Fincher movie that makes people
not want to get married.</p>

<h2>504 Gateway Timeout</h2>

<p>Never knew what this meant, but this can be returned by an intermediary
or proxy server that doesn&#8217;t get a timely response from a backend server
it&#8217;s talking to in order to prepare a response to the client. DOS&#8217;d
servers might see this, wherein their nginx/whatever reverse proxy can
handle the load just fine, but the backend server is inundated and can&#8217;t
keep up with the load.</p>

<h2>Cairns</h2>

<p>City in far north of Queensland, Australia. Scuba.</p>

<h2>FastCGI</h2>

<p>http://en.wikipedia.org/wiki/FastCGI</p>

<p>CGI applications are processes spun up by a web server to handle an
incoming request. Unscalable since spinning up processes all the time
takes a toll on the OS, not to mention that there&#8217;s no way to do
resource sharing (DB connection sharing, in-memory caching (because
the process dies at the end of request)).</p>

<p>With FastCGI, there&#8217;s a persisting FastCGI server that owns all of the
CGI programs, and webservers interact with FastCGI via a binary protocol
(over a socket (local) or TCP connection (remote)).</p>

<p>This decoupling also allows smaller components to be restarted (rather
than having to restart the entire web server).</p>

<p><code>mod_php</code> is another answer to this problem, which takes the approach to
embedding the PHP interpreter inside Apache itself. But each Apache
child then needs to load the interpreter. FastCGI is better on memory
and not constrained to Apache (nginx implements it).</p>

<p>TODO: reverse proxy rails configuration vs Rails attached to FastCGI.</p>

<h2>Copy as curl</h2>

<p>You can copy a resource request made by Chrome as a curl command.</p>

<h2>HAR format</h2>

<p>You can save network requests (request data/headers and response etc) as
a HAR files from the Chrome debugger.</p>

<p>Stands for &#8220;HTTP ARchive&#8221;:
http://www.softwareishard.com/blog/har-12-spec/</p>

<p>HARs are JSON documents containing</p>

<h2>bcrypt stretches</h2>

<p><code>Devise.stretches</code> controls the internal bcrypt stretching amount for
bcrypt password hashing. When <code>RACK_ENV=test</code>, <code>Devise.stretches</code> is 1,
else it is 10 (or some higher number).</p>

<p>Increasing stretches drastically increases the CPU time required for
hashing passwords, which seems like an obvious anti-perf except for the
nice fact that if you&#8217;re server&#8217;s being bombed by a dictionary attack,
which sequentially tries to hash many passwords, the attack will be
thwarted by just how long the server takes to hash the password.</p>

<p>http://en.wikipedia.org/wiki/Key_stretching</p>

<h2>ActiveRecord connection pooling</h2>

<p>http://blog.plataformatec.com.br/2011/12/three-tips-to-improve-the-performance-of-your-test-suite/</p>

<p>Connection pools allow for connection reuse (rather than, say, the
shitty alternative of opening/closing a connection for every query).
The ActiveRecord connection pool has the additional stipulation that
connections are not shared between threads. This makes sense, since
otherwise if you had a multithreaded Rails application and connections
were shared between threads, then only one thread at a time could be
querying the database, and locking would occur, making shit slow.</p>

<p>So by letting each thread have its own connection to a shared resource,
threads won&#8217;t get blocked on each other. Happy fucking day.</p>

<h2>Rails dbconsole</h2>

<p>http://guides.rubyonrails.org/command_line.html#rails-dbconsole</p>

<pre><code>rails dbconsole
# or
rails db
</code></pre>

<h2>dRuby</h2>

<p>COBRA for Ruby basically.</p>

<p>http://www.ruby-doc.org/stdlib-1.9.3/libdoc/drb/rdoc/DRb.html</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-10-06T21:15:00-04:00" pubdate data-updated="true">Oct 6<span>th</span>, 2014</time></div>
	


	
</div></article>

<nav id="pagenavi">
    
    
        <a href="/blog/page/2/" class="next">Next</a>
    
    <div class="center"><a href="/archives">Blog Archives</a></div>
</nav></div>
	<footer id="footer" class="inner">Copyright &copy; 2014

    Alex Matchneer

<br>
Powered by Octopress.
</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'usefuldude';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-49928757-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>



</body>
</html>

