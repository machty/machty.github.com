
<!DOCTYPE HTML>
<html>
<head>
	<script data-cfasync="false" type="text/javascript" src="//use.typekit.net/axj3cfp.js"></script>
	<script data-cfasync="false" type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<meta charset="utf-8">
	<title>Ember.js, random thoughts, journal  | machty's thoughtz</title>

<meta name="author" content="Alex Matchneer"> 

<meta name="description" content="I'm on Ember core and contribute to lots of stuff prefixed with "Em"."> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="machty's thoughtz" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script type="text/javascript" src="/javascripts/jquery.fancybox.pack.js"></script>

<script language="Javascript" type="text/javascript">
$(document).ready(
  function() {
    (function($) {
      $(".fancybox[data-content-id]").each(function() {
        this.href = $(this).data('content-id');
      });
      $(".fancybox").fancybox({
        beforeLoad: function() {
          var el, 
              id = $(this.element).data('title-id');

          if (id) {
            el = $('#' + id);

            if (el.length) {
              this.title = el.html();
            }
          }
          if ($(this).data('content')) {
            this.content = $(this).data('content');
          }
        },
        helpers: {
          title: {
            type: 'inside'
          }
        }
      });
    })(jQuery);
  }
);
</script>

	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">machty's thoughtz</a></h1>
<h4>Ember.js, random thoughts, journal</h4>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
	<li>
    <span>
    <a href="http://www.cram.com/flashcards/alexmatchneercom-4692833" target="_blank">Flashcards</a>
    </span>
    <span>
    (<a href="/blog/2014/04/12/blog-flashcards/">explanation</a>)
    </span>
  </li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:machty.github.com">
			</form>
		</div>
	</div>
</nav>


</header>

	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/08/22/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Difference b/w XSD and DTD</h2>

<p>They both define the structure of an XML document, but what&#8217;s the
difference?</p>

<p>Awesome SO:
http://stackoverflow.com/questions/1544200/what-is-difference-between-xml-schema-and-dtd</p>

<p>DTD&#8217;s are arguably easier to grok, but the XSD has more features, but at
the expense of understanding the abstractions of data types and what
not. Seems easier to describe recursive structures in XSD than the other
bullsharticles.</p>

<p>XSD is XML, DTD stems from SGML.</p>

<p>I guess XML And HTML also stem from SGML. WHAT DO I KNOW? NOTHING!</p>

<h2>Wolf3d in React</h2>

<p>Apparently I missed this https://github.com/petehunt/wolfenstein3D-react.git</p>

<h2>Breaking the chain in React</h2>

<p>For when you want to tell React &#8220;don&#8217;t mess with my DOM, I&#8217;m doing funky
jQuery shit&#8221;.</p>

<p>Render a div that won&#8217;t invalidate:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L47</p>

<p>Re-render your own children:</p>

<p>https://gist.github.com/rpflorence/4c5044b217e0a67c2c4d#file-react-opt-out-js-L15-L18</p>

<h2>Retcon: retroactive continuity</h2>

<p>http://en.wikipedia.org/wiki/Retroactive_continuity</p>

<p>&#8220;alteration of previously established facts in the continuity of a
fictional work&#8221;</p>

<h2>CVV can mean lower rates</h2>

<p>http://security.stackexchange.com/questions/21168/how-does-amazon-bill-me-without-the-cvc-cvv-cvv2</p>

<p>There are fraud-prevention benefits to using CVV, and as such, payment
handlers will often give you a discount if the CVV is present.</p>

<h2>X-Forwarded-For</h2>

<p>Some servers fall prey to IP spoofing via setting the <code>X-Forwarded-For</code>
header. If your server isn&#8217;t careful, then given a
<code>curl -H "X-Forwarded-For: 1.2.3.4" http://www.machty.com</code>, your
server&#8217;s logs and maybe even IP-dependent application logic (e.g.
language detection) might use 1.2.3.4.</p>

<p>In Rails you can add your known proxy/load-balancing IPs to
<code>TRUSTED_PROXIES</code>. Then the <code>RemoteIp</code> rack middleware will filter out
all of those and pick the most recently set IP, which handles the case
where you might have multiple <code>X-Fowarded-By</code> headers. So the rule is:
use the rightmost, untrusted IP and treat that as the remote ip. Why?
Because when your first proxy is hit, it&#8217;ll see IP X.X.X.X and move that
to the list of <code>X-Forwarded-By</code> headers. Note that the previous
<code>X-Forwarded-By</code> headers, present or no, are untrustable and totally
spoofable.</p>

<p>http://blog.gingerlime.com/2012/rails-ip-spoofing-vulnerabilities-and-protection</p>

<p>So that&#8217;s IP spoofing via HTTP header. How else can you IP spoof?</p>

<p>http://en.wikipedia.org/wiki/IP_address_spoofing</p>

<p>You just rewrite the source IP in the TCP/UDP packet header, which also
means when the application responds, it&#8217;ll send it back to the forged
IP.</p>

<p>There are valid use cases for this as well, such as testing load
balancing software/hardware.</p>

<h2>Types of NAT</h2>

<p>http://think-like-a-computer.com/2011/09/16/types-of-nat/</p>

<h3>Full cone NAT (Static NAT) (port forwarding)</h3>

<p>Manual mapping of public IP and port to LAN IP and port.</p>

<p>e.g. all incoming traffic to port 12345, forward to 192.168.0.10:9999.</p>

<p>Blocks (drops connection):</p>

<ul>
<li>Ports that haven&#8217;t been forwarded</li>
</ul>


<h3>Restricted cone NAT (dynamic)</h3>

<p>Don&#8217;t allow incoming data from an IP unless I&#8217;ve sent packets to it
already. Note that depending on the strictness, if I initiate a
connection to WAN IP 1.2.3.4:1234, I could potentially get data from
1.2.3.4:5678, but in stricter schemes, the port must also match.</p>

<p>But regardless of this strictness, the one requirement is that they send
data to exactly my public IP and port that I sent data out of.</p>

<h3>Symmetric NAT</h3>

<p>http://think-like-a-computer.com/2011/09/19/symmetric-nat/</p>

<p>Sym NAT is like port-restricted cone NAT, but randomly generates
different public source ports when sending to different destinations.</p>

<p>Sym NATs are the only ones that cause problems with other devices behind
NATs.</p>

<h2>Vim registers</h2>

<p>So if I have</p>

<pre><code>&lt;a href="WAT"&gt;&lt;/a&gt;
</code></pre>

<p>and I want to replace the href with a yanked &#8220;LOL&#8221;, then I can <code>di"</code> in
WAT to delete it, then <code>"0P</code> to use the last-yank register 0. Registers
1,2,3,4,5&#8230; get populated with cuts. Unnamed register gets replaced by
any yanking/cutting command. Weird terminology.</p>

<h2>Ember-cli + divshot</h2>

<p>Holy shit this was awesome.</p>

<p>Divshot.com is a static deployment heroku, basically, and ember-cli has
an addon for letting you deploy there.</p>

<pre><code>npm install --save-dev ember-cli-divshot &amp;&amp; ember generate divshot
</code></pre>

<h2>brew install fuck</h2>

<p>naw, but this is a cool script for killing them all:</p>

<pre><code>#!/usr/bin/env ruby
# coding: utf-8

abort "Usage: fuck you &lt;name&gt;" unless ARGV[0] == "you" &amp;&amp; ARGV.size == 2

a = "abcdefghijklmnopqrstuvqxyz".each_char.to_a
b = "ɐqɔpǝɟƃɥıɾʞʃɯuodbɹsʇnʌʍxʎz".each_char.to_a
ws = Hash[a.zip(b)]
ws.default = -&gt;(f){f}

puts "\n  (╯°□°）╯︵ #{ARGV[1].reverse.each_char.map{|f|ws[f]}.join}\n\n"

system("killall -9 #{ARGV[1]}")
exit $?.exitstatus
</code></pre>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-08-22T16:32:00-04:00" pubdate data-updated="true">Aug 22<span>nd</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/08/15/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Incremental GC</h2>

<p>Tenderlove tweeted this: https://bugs.ruby-lang.org/issues/10137</p>

<ul>
<li>Generational GC already is implemented: distinguish/bucket old and new
generation objects; sweeping new generation objects is fast (minor GC), and the
ones that don&#8217;t get swept up get promoted to old generation, which is
less frequently swept (in a major GC)</li>
<li>Generation GC is always incremental in that it doesn&#8217;t collect ALL
unreachables, &#8230; todo http://stackoverflow.com/questions/5092134/whats-the-difference-between-generational-and-incremental-garbage-collection</li>
</ul>


		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-08-15T12:17:00-04:00" pubdate data-updated="true">Aug 15<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/08/09/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>iOS State Preservation</h2>

<p>https://developer.apple.com/library/ios/documentation/iphone/conceptual/iphoneosprogrammingguide/StatePreservation/StatePreservation.html</p>

<h2>Session token storage in localStorage</h2>

<p>Do not store session identifiers in local storage as the data is always accessible by JavaScript. Cookies can mitigate this risk using the httpOnly flag.</p>

<p>It&#8217;s risky? SAY MORE THINGS.</p>

<h2>Loading Ember CLI addons in jsbin</h2>

<h2>Forking in xargs</h2>

<p>Holy shitters, this is how I simultaneously uploaded three tracks to s3
(using my <code>to_s3</code>) script.</p>

<pre><code>find ~/Desktop -name "Audio*" -print0 | xargs -0 -n 1 -P 5 to_s3
</code></pre>

<p><code>-n 1</code> means each invocation takes a max of one arg, and <code>-P 5</code> means a
max of 5 simultaneous processes. So cool.</p>

<h2>Web audio api</h2>

<p>Finish this: http://emberjs.jsbin.com/ucanam/5964/edit</p>

<h2>Liquid Fire Global</h2>

<p>http://jsbin.com/mifuq/1/edit</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-08-09T16:15:00-04:00" pubdate data-updated="true">Aug 9<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/08/05/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>ES6 fat arrow</h2>

<pre><code>var a = this;
var fn = () =&gt; {
  console.log(this === a); // true
}
</code></pre>

<p>http://tc39wiki.calculist.org/es6/arrow-functions/</p>

<p>yuno CoffeeScript single arrow syntax?</p>

<blockquote><p>However, we don&#8217;t want CoffeeScript&#8217;s ->, it&#8217;s confusing to have two arrows and dynamic this binding is an oft-fired footgun.</p></blockquote>

<h2>SaltStack</h2>

<p>http://docs.saltstack.com/en/latest/</p>

<h2>Open Core</h2>

<p>http://en.wikipedia.org/wiki/Open_core</p>

<p>Open Source core functionality with paid/proprietary add-ons, e.g.
Sidekiq, or MySQL</p>

<p>Related:</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Crippleware">Crippleware</a>: free versions
cripple the ability to save/export/whatever</li>
<li><a href="http://en.wikipedia.org/wiki/Freemium">Freemium</a>: free core features,
pay for higher usage/capacity, e.g. most heroku add-ons</li>
</ul>


<h2>Ember First Class Actions</h2>

<p>http://emberjs.jsbin.com/ucanam/5919/edit</p>

<p>Questions:</p>

<ul>
<li>singleton vs multiples?</li>
<li>actions that depend on others?</li>
<li>link-to?

<ul>
<li>idea: a LinkView asks the router or url service for an Action
using the route params, query params, etc.</li>
<li>LinkView&#8217;s active CP is <code>action.pending</code> || present day isActive</li>
<li><p>action will internally delegate to a shared transitionTo action
that everyone in the world can see; everyone can know where it&#8217;s
going, etc etc etc.</p>

<p><code>{{link-to action=myAction}}</code>
any reason for this? what do you gain? nothing?</p></li>
</ul>
</li>
</ul>


<p>We need to separate fake link font decoration style from the underlying
action.</p>

<p>Link&#8217;s display components:</p>

<pre><code>routeDescriptor: function() {
  // when resolvedParams change, we need to recalculate
  // our route object... this should refire only when
  // params change, not when the URL changes
  this.urlService.getRouteObject('articles', 1)


  this.urlService.createRouteDescriptor({
    routeName: alias('_linkView.params.firstObject'),
    contexts: alias('_linkView.contexts'),
    queryParams: alias('_linkView.queryParams'),
    _linkView: this
  });
}//.property('resolvedParams')

createRouteDescriptor: function(_attrs) {
  var attrs = {
    router: this.router, // or maybe just `this`?
  };
  Ember.merge(attrs, _attrs);
  return RouteDescriptor.createWithMixins(attrs);
}

RouteDescriptor = Ember.Object.extend({
  // required
  router: null,
  routeName: null,
  contexts: null,
  queryParams: null,

  allParams: computed('routeName', 'contexts', 'queryParams', function() {
    // this is just a perfy thing; since all calculations depend
    // on all these params, we'll avoid the overhead of multiple
    // CPs depending on each of these params
    return this.getProperties(['routeName', 'contexts', 'queryParams']);
  }),

  path: computed('router.url', 'allParams', function() {
    var allParams = this.get('allParams');
    var router = this.get('router');

    // presently we only use router.url as a cue that the router
    // is at a new route
    var url = this.get('router.url');

    // pass crap to routerJS
  }),

  perform: function() {
    // invoke, blah blah blah, same logic as in link to.
    this.get('allParams');
  }
});

service.getRouteDescriptor('articles', 1)

{
  action:   FCA,
  isActive: true,
  path: "/some/dynamic/thing"
}
</code></pre>

<p>RouteDescriptors are objects</p>

<ul>
<li>inactive: !routeObject.active</li>
<li>active:   routeObject.active</li>
<li>visited</li>
</ul>


<p>Weird thing: ember link-to&#8217;s concept of &#8220;active&#8221; doesn&#8217;t match with
<code>&lt;a&gt;</code> tag&#8217;s concept of active; link-to &#8216;active&#8217; means you&#8217;re currently
in the route specified by that link; <code>&lt;a&gt;</code> tag&#8217;s active means you&#8217;re
currently clicking this link.</p>

<p>I think I know how to refactor link-to and LinkView and all that</p>

<p>Goals</p>

<ul>
<li>make linking/routing/active calc logic shareable</li>
<li>make it possible to click a link to make it active before a slow
transition has completed.</li>
<li><p>support calculating activeness for bootstrap wrapper <code>&lt;li&gt;</code>s and
anything else in general too.</p>

<p>  {{#link-wrapper tagName=&#8221;li&#8221; |w|}}</p>

<pre><code>{{w.link-to "wat" 1 2 3 (query-params)}}
</code></pre>

<p>  {{/link-wrapper}}</p>

<p>  {{#link-to &#8216;articles&#8217; article.id |l|}}</p>

<pre><code>{{! providing block params kicks it into
    wrapper mode }}

&lt;li class="{{l.active}}"&gt;
  {{#l.tag}}
    {{article.title}}
  {{/l.tag}}
&lt;/li&gt;
</code></pre>

<p>  {{/link-to}}</p></li>
</ul>


<h2>RFCs</h2>

<p>Rust tempered it&#8217;s freewheeling feature additions by requiring RFCs.</p>

<p>https://github.com/rust-lang/rfcs/blob/master/active/0001-rfc-process.md
https://github.com/rust-lang/rfcs/blob/master/active/0039-lifetime-elision.md</p>

<p>Sounds like we&#8217;ll be doing this for Ember.</p>

<h2>Elide</h2>

<blockquote><p>omit (a sound or syllable) when speaking: (as adj. elided) : the indication of elided consonants or vowels.</p></blockquote>

<h2>Variadic</h2>

<p>http://en.wikipedia.org/wiki/Variadic_function</p>

<p>A function that is variadic has an indefinite number of arguments.
<code>.bind</code></p>

<blockquote><p>8:50 PM <spion> bind is variadic and I think it also has to do some stuff with constructors
8:51 PM <spion> (additional arguments can be used for partial application)
8:52 PM <spion> the constructor stuff: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/bind#Bound_functions_used_as_constructors
8:53 PM <spion> (creates significant additional overhead)
8:53 PM <spion> so a simple non-variadic closure implementation of bind has a lot less work to do :P</p></blockquote>

<h2>React forms</h2>

<p>https://github.com/wingspan/wingspan-forms</p>

<p>Powerded by KendoUI</p>

<h2>Reflux</h2>

<p>https://github.com/spoike/refluxjs</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>╔═════════╗       ╔════════╗       ╔═════════════════╗
</span><span class='line'>║ Actions ║──────&gt;║ Stores ║──────&gt;║ View Components ║
</span><span class='line'>╚═════════╝       ╚════════╝       ╚═════════════════╝
</span><span class='line'>     ^                                      │
</span><span class='line'>     └──────────────────────────────────────┘</span></code></pre></td></tr></table></div></figure>


<p>Rationale: http://spoike.ghost.io/deconstructing-reactjss-flux/</p>

<h2>Promixo dedicated</h2>

<p>https://addons.heroku.com/proximo#dedicated</p>

<h2>CIDR: Classless Inter-Domain Routing</h2>

<p>http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing</p>

<p>Classful allocation of IP addresses (pre 1993) defined class A, B, C
network groups split along the 8 bit chunks. Problem is the smallest
allocation (256 addresses, assuming you were allocated something like
123.456.789.XXX) was often too small for companies, whereas the next
step up from that (123.456.XXX.XXX) was generally too huge (65536) for
companies/entities to efficiently take advantage of. SOLUTION: CIDR
blocks and subnet masks.</p>

<blockquote><p>This led to inefficiencies in address use as well as routing because the large number of allocated small (class-C) networks with individual route announcements, being geographically dispersed with little opportunity for route aggregation, created heavy demand on routing equipment.</p></blockquote>

<p>In other words, class C allocations are 123.456.789.XXX allocations,
each containing 256 addresses, with no requirement that they be
geographically grouped, such that routers had to maintain large tables
for very similar looking addresses rather than being able to rely on
some grouping rules to minimize the routing information they had to know
about. But now subnet masking is a thing and blah blah blah I&#8217;m done
learning this shit.</p>

<p>192.168.2.0/24 means that the network is identified by the first 24 bits</p>

<blockquote><p>192.168.100.0/24 represents the given IPv4 address and its associated routing prefix 192.168.100.0, or equivalently, its subnet mask 255.255.255.0 (i.e. 24 &#8220;1&#8221; bits).</p>

<p>the IPv4 block 192.168.100.0/22 represents the 1024 IPv4 addresses from 192.168.100.0 to 192.168.103.255.</p></blockquote>

<h2>TokenEx client-side encryption</h2>

<p>Original misconception:</p>

<ul>
<li>You post directly to TokenEx via AJAX, and they give you an encrypted
value that you can pass to your server and exchange for a token</li>
</ul>


<p>Correction:</p>

<ul>
<li>You only use JSEncrypt to encrypt the PAN via a public key.</li>
</ul>


<p>Wait, I don&#8217;t understand, with tokenizing, if you have a token saved in
the database, then your server, if compromised, could still send data
through to TokenEx, which would proxy it through to whomever.</p>

<h2>Form Factor</h2>

<p>https://www.pcisecuritystandards.org/documents/Mobile_Payment_Security_Guidelines_Merchants_v1.pdf</p>

<blockquote><p>The PCI Security Standards Council charter provides a forum for collaboration across the payment space
to develop security standards and guidance for the protection of payment card data wherever it may be
stored, processed, or transmitted—regardless of the <em>form factor</em> or channel used for payment.</p></blockquote>

<p>the physical size and shape of a piece of computer hardware.</p>

<p>http://en.wikipedia.org/wiki/Mobile_phone_form_factor</p>

<p>or phone.</p>

<p>what a stupid fucking phrase/word/definition.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-08-05T08:47:00-04:00" pubdate data-updated="true">Aug 5<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/08/02/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>NPM is killing me</h2>

<p>Apparently this fixed everything.</p>

<pre><code>npm cache clear &amp;&amp; npm install
</code></pre>

<p>https://www.npmjs.org/doc/cli/npm-cache.html</p>

<p>npm caches everything in <code>npm config get cache</code>, which for me is:</p>

<pre><code>~/.npm
</code></pre>

<p>Folder structure is something like</p>

<pre><code>~/.npm/PACKAGE_NAME/VERSION/
</code></pre>

<p>which contains:</p>

<ul>
<li>.cache.json

<ul>
<li>lots of overlap w the project&#8217;s package.json, with additional
cache-specific things like</li>
<li>etag, shasum</li>
<li>deployment-specific data about the package</li>
</ul>
</li>
<li>package.tgz

<ul>
<li>the original tarball downloaded for this packaage</li>
</ul>
</li>
<li>package/

<ul>
<li>the unzipped tarball</li>
</ul>
</li>
</ul>


<p>In other words</p>

<blockquote><p>Additionally, whenever a registry request is made, a .cache.json file is placed at the corresponding URI, to store the ETag and the requested data. This is stored in {cache}/{hostname}/{path}/.cache.json.</p></blockquote>

<h2>Food Shit</h2>

<p>Pok Pok is a legit ass Thai place I need to check out.</p>

<pre><code>http://pokpokny.com/
</code></pre>

<h2><code>sed</code> to select lines</h2>

<pre><code>$ git branch
  cp-qp
* master
  new-doctitle
  setup-controller-qp
</code></pre>

<p>I wanted to switch to the fourth one without typing
<code>setup-controller-qp</code>. Here&#8217;s how you could do it by using the line
number</p>

<pre><code>$ git branch | sed -n '4p' | xargs git checkout
Switched to branch 'setup-controller-qp'
</code></pre>

<p>Obviously this is just a dumb exercise since it&#8217;s waaay more typing.
This is me practicing.</p>

<p>You can also display multiple lines using a syntax similiar to cut&#8217;s
<code>-f1,2</code> syntax:</p>

<pre><code>$ git branch | sed -n '3,4p' 
  new-doctitle
  setup-controller-qp
</code></pre>

<h2>commissary</h2>

<p>From Orange is the New Black</p>

<blockquote><p>commissary: a restaurant in a movie studio, military base, prison, or other institution.</p></blockquote>

<h2>HRT</h2>

<p><a href="http://en.wikipedia.org/wiki/Hormone_replacement_therapy">Hormone replacement therapy</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-08-02T21:24:00-04:00" pubdate data-updated="true">Aug 2<span>nd</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/29/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>tar</h2>

<p>Short for Tape Archives.</p>

<p>Had a tar.xz file, just needed to</p>

<pre><code>tar xf thefile.tar.xz
</code></pre>

<h2>Dexing</h2>

<p>Convert string names to numbers to be referenced within compiled Java
whilst packaging android apps.</p>

<h2>Good Food</h2>

<p>Prince St Cafe on Prince and Mott.</p>

<ul>
<li>Awesome burger</li>
<li>Awesome lamb thing</li>
</ul>


<h2>ls -l</h2>

<p>Was curious about an <code>@</code> sign I saw next to a .txt file, from <code>ls(1)</code>:</p>

<blockquote><p>The Long Format</p>

<pre><code>If the -l option is given, the following information is displayed for
each file: file mode, number of links, owner name, group name, number
of bytes in the file, abbreviated month, day-of-month file was last
modified, hour file last modified, minute file last modified, and the
pathname.  In addition, for each directory whose contents are dis-
played, the total number of 512-byte blocks used by the files in the
directory is displayed on a line by itself, immediately before the
information for the files in the directory.  If the file or directory
has extended attributes, the permissions field printed by the -l
option is followed by a '@' character.  Otherwise, if the file or
directory has extended security information (such as an access control
list), the permissions field printed by the -l option is followed by a
'+' character.
</code></pre></blockquote>

<ul>
<li><code>@</code> extended attributes</li>
<li><code>+</code> extended security info</li>
</ul>


<h2>Interrupted System Call</h2>

<p>http://infohost.nmt.edu/~eweiss/222_book/222_book/0201433079/ch10lev1sec5.html</p>

<p>I&#8217;m getting some shit about foreman and interrupted system calls. So
what is it.</p>

<h2>&#8220;data at the edge&#8221;</h2>

<p>Keeping secure data at the edge of your infrastructure, e.g. using
tokens instead of storing CC&#8217;s in your db.</p>

<h2>PAN (primary account number)</h2>

<p>Bank card number.</p>

<p>http://en.wikipedia.org/wiki/Primary_account_number</p>

<h2>CP (card present)</h2>

<p>e.g AuthorizeNetCP</p>

<p>Cheaper rates if you can prove card present (via CVV).</p>

<h2>TokenEx</h2>

<p>ProcessTransaction</p>

<p>ProcessTransactionWithPAN</p>

<ul>
<li>pass in all the CC data; no</li>
</ul>


<h2>Levenshtein Distance</h2>

<p>The minimum number of single-element operations (add, remove,
substitute) between two sequences. Often used for spell-checking
suggestions.</p>

<p>I was thinking of using it to do an array diffing for React-ish stuff.</p>

<pre><code>Array 1: B C D E F
Array 2: A B C D E
</code></pre>

<p>Clearly the answer to how to get from 1 to 2 is</p>

<pre><code>shift A
delete E
</code></pre>

<p>But how to programmatically detect that?</p>

<h2>Ruby String Substring Shorthand</h2>

<p>https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<p>I can&#8217;t believe I didn&#8217;t know this&#8230;</p>

<pre><code>s = "alex is quite maudlin"
s['quite'] = 'very'
s =&gt; "alex is very maudlin"
</code></pre>

<p>and if the substring isn&#8217;t in there, then</p>

<pre><code>IndexError: string not matched
</code></pre>

<p>http://www.ruby-doc.org/core-2.1.2/String.html#method-i-5B-5D-3D</p>

<h2>JRuby the Hard Parts</h2>

<p>Goal: understand this talk https://speakerdeck.com/headius/jruby-the-hard-parts</p>

<h2>Learn about encodings</h2>

<p>I had to resort to this shit:</p>

<pre><code>line = line.force_encoding("iso-8859-1")
</code></pre>

<p>for a bigass file because I was running into</p>

<pre><code>http://stackoverflow.com/questions/15399530/ruby-match-invalid-byte-sequence-in-utf-8
</code></pre>

<p>Apparently you can open files as a certain encoding. Seems good.</p>

<h2>Auto-inline CSS with Roadie</h2>

<p>https://github.com/Mange/roadie</p>

<p>Useful for supporting a vast array of shitty email clients that require
inline CSS. This wouldn&#8217;t be a problem if web components.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-29T07:50:00-04:00" pubdate data-updated="true">Jul 29<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/28/daily-journal-2/">
		
			Daily Journal 2</a>
	</h2>
	<div class="entry-content">
		<h2>User and Kernel</h2>

<p>http://blog.codinghorror.com/understanding-user-and-kernel-mode/</p>

<p>Non-idle tasks.</p>

<p>The CPU graph is tasty. Red means kernel.</p>

<p>CPU hardware knows all about kernels n shit. It isn&#8217;t just a software
divide. CPU instructions and certain memory locations can only be
accessed by the kernel, enforced by hardware. User mode makes it so that
only the app crashes, not the entire system.</p>

<p>http://en.wikipedia.org/wiki/Ring_(computer_security)</p>

<p>Interesrserseting.</p>

<p>x86 CPU hardware:</p>

<ul>
<li>0 is kernel</li>
<li>3 is user</li>
</ul>


<p>1 and 2 are device drivers but they&#8217;re not often used. On Windows,
device drivers can be user or kernel mode, mostly to the user, but video
cards are often kernel level since they so perfy. In Vista+, the Windows
Driver Display Model is such that only kernel mode is used for executing
the GPU commands, but the translation from API to GPU now takes place in
userland.</p>

<p>Exceptions fire in kernel land I guess? Sometimes?</p>

<h2>Old Foreman Orphans Sidekiq</h2>

<p>After lots of starts/stops of foreman, I noticed lots of sidekiq
instances with ppid 1. They was orphans. I killed em.</p>

<h2>fspawn</h2>

<p>Refers to the fork+exec approach to spawning a process.</p>

<h2>Daemons</h2>

<p>https://github.com/ghazel/daemons</p>

<p>Library of fun little trinkets.</p>

<ul>
<li>given some-server.rb, let&#8217;s you write a some-server-control.rb</li>
<li>inline the server inside such a daemon (you can still run it
without forking via <code>run</code> command)</li>
<li>manage multiple daemons</li>
<li>Ability to take existing server and daemonize it; you do lose control
over the daemon unless you&#8217;re a <code>ps</code>/<code>kill</code> JOURNEYMAN.

<ul>
<li>this takes advantage of the <code>fork</code> <code>getsid</code></li>
</ul>
</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons.rb#L45-L53</p>

<pre><code># 1.  Forks a child (and exits the parent process, if needed)
# 2.  Becomes a session leader (which detaches the program from
#     the controlling terminal).
# 3.  Forks another child process and exits first child. This prevents
#     the potential of acquiring a controlling terminal.
# 4.  Changes the current working directory to "/".
# 5.  Clears the file creation mask (sets +umask+ to 0000).
# 6.  Closes file descriptors (reopens +STDOUT+ and +STDERR+ to point to a logfile if
#     possible).
</code></pre>

<p>Controlling terminal:</p>

<p>http://www.gnu.org/software/libc/manual/html_node/Controlling-Terminal.html</p>

<blockquote><p>An individual process disconnects from its controlling terminal when it calls setsid to become the leader of a new session.</p></blockquote>

<p>Ah I get it:</p>

<ul>
<li>first fork is to orphan the child, but it&#8217;s still connected to a
controlling terminal/session.</li>
</ul>


<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L201</p>

<p>They actually loop through all known IO files to close file
descriptors using ObjectSpace:</p>

<p>http://www.ruby-doc.org/core-2.1.2/ObjectSpace.html</p>

<p>https://github.com/ghazel/daemons/blob/master/lib/daemons/daemonize.rb#L221</p>

<p>That&#8217;s pretty rad. I guess the GC uses it too.</p>

<h2>.pid file</h2>

<p>It&#8217;s a file in a well known location that contains only the pid of
some running process, usually a daemon. Useful because daemons are often
hard to detect, kinda look like forgotten orphan processes, and there
might be multiple similar ones. But pid files let you look up the pid of
the running process so that you can send it signals.</p>

<h2><code>$0</code> or <code>$PROGRAM_NAME</code></h2>

<p>If you run this script</p>

<pre><code>fork {
  $PROGRAM_NAME = "WAT"
  sleep
}
</code></pre>

<p>then <code>ps | grep WOOT</code> yields</p>

<pre><code>62724 ttys022    0:00.00 WOOT
</code></pre>

<p>Woot wat wat wotasoasdas lol.</p>

<h2><code>pidof</code></h2>

<pre><code>brew install pidof

$ pidof bash
754 1246 1748 2308 2498 5380 20397 23552 26224 26973 48454 79258 81847 5226 5346 5443 5851 10659 25008 26375 27009 52684 88768 88882 18853 19116 19246 20275 20476 21364 43211 52269 52390 52637 54869 54974 58037 58950 59080
</code></pre>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-28T20:43:00-04:00" pubdate data-updated="true">Jul 28<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/28/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Them processes</h2>

<p>Kernel</p>


		
		<a href="/blog/2014/07/28/daily-journal/" class="more-link">Read on &rarr;</a>
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-28T08:16:00-04:00" pubdate data-updated="true">Jul 28<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/26/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>top</h2>

<blockquote><p>display and update sorted information about processes</p></blockquote>

<p><code>top</code> will display a sampled, updating list of processes, ordered by pid
by default. Order by cpu:</p>

<pre><code>top -o cpu
</code></pre>

<p>Filter by a pid</p>

<pre><code>top -pid 12345
</code></pre>

<p>Show a single sample of the pid and thread number for a given pid</p>

<pre><code>top -l1 -pid 1234 -stats pid,th
</code></pre>

<h2>Spawn 50 ruby threads&#8230;</h2>

<p>and you wind up w 52: <code>Thread.main</code> + the 50 you created + Ruby
housekeeping thread (listening for OS signals and piping them
synchronously to main thread).</p>

<p>Ruby creates legit OS threads, vs <code>_____</code> threads, whatever the
terminology is for threads that live entirely in the code.</p>

<h2>Thread#join</h2>

<p>Yes, you have to call it on a spawned thread so that the main thread
will wait on it before prematurely exiting. But did you know that
exceptions thrown in a spawned thread get re-raised on the main thread
if you do <code>.join</code>?</p>

<p><code>Thread#value</code> joins and returns the last value of the thread.</p>

<p><code>Thread#status</code> returns status for live, dead, erroed, dying threads.</p>

<p><code>Thread.stop</code> puts the thread to sleep and it won&#8217;t wake up until
someone calls <code>wakeup</code> on it</p>

<p><code>Thread.pass</code> hints the OS to schedule another thread, but this may be
ignored by the scheduler.</p>

<p><code>Thread#raise</code> lets you externally fire exceptions within another thread
but should not be used because <code>ensure</code> is busted. <code>Thread#kill</code> does
what you expect but should also be aborted for the same reasons.</p>

<p>Multiple threads mean concurrency; they <em>might</em> mean parallelism. One
CPU switching b/w threads means concurrency but not parallelism;
multiple cores means paralleilism if they&#8217;re both executing.</p>

<p>Code can&#8217;t be parallel, only concurrent. The executation of concurrent
code can be parallel if the scheduler so chooses.</p>

<h2>golang concurrency vs parallelism</h2>

<p>http://concur.rspace.googlecode.com/hg/talk/concur.html#slide-2</p>

<p>Concurrency is defined as:</p>

<blockquote><p>Programming as the composition of independently executing processes</p></blockquote>

<p>not Linux processes, but rather the famously harder to define Process.</p>

<p>Parallelism is</p>

<blockquote><p>Programming as the simultaneous execution of (possibly related) computations.</p>

<p>Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable</p></blockquote>

<p>Concurrency facilitates but doesn&#8217;t guarantee parallelism.</p>

<p>Goroutines aren&#8217;t threads; they&#8217;re similar but cheaper, won&#8217;t block
other goroutines, and multiplexed onto OS threads as necessary.</p>

<p>Synchronize via channels. I guess this is like Ruby Queue? Sounds like
you&#8217;d never do someGoroutine.value but rather use the channel primitive.</p>

<h2>ruby concurrency and you</h2>

<p>https://blog.engineyard.com/2011/ruby-concurrency-and-you</p>

<p>Green threads</p>

<ul>
<li>scheduled by VM, rather than underlying OS</li>
<li>pre 1.9 Ruby was this way (MRI)</li>
<li>managed in user space rather than kernel space</li>
</ul>


<p>Test: if i run Ruby 1.8.7 and do a top of new threads, I would expect
the thread count to be only whatever I started with.</p>

<p>BEHOLD, on 1.8.7:</p>

<pre><code>PID    #TH
84752  1
</code></pre>

<p>So old ruby didn&#8217;t even spawn another thread for housekeeping&#8230; I guess
maybe it wasn&#8217;t necessary because it didn&#8217;t have to coordinate the
signals landing at any random currently-active thread? Pretty cool.</p>

<p>I guess green threads are easy to implement in any interpreted language:
in the main loop of the interpreter you can just check if 100ms has gone
by and then move to another other known threads.</p>

<p>Early Java had green threads&#8230; I don&#8217;t know enough about Java to
comment here.</p>

<p>Ruby &lt;1.9 was smart enough to know when one of these threads was blocked
on external data so that it could &#8220;sleep&#8221; until the data arrived:</p>

<blockquote><p>MRI 1.8.7 is quite smart, and knows that when a Thread is waiting for some external event (such as a browser to send an HTTP request), the Thread can be put to sleep and be woken up when data is detected.</p></blockquote>

<p>1.9 uses native threads, but there&#8217;s still a GIL because the non-Ruby
parts of MRI 1.9 aren&#8217;t thread-safe.</p>

<p>MRI 1.9 uses the same technique as MRI 1.8 to improve the situation,
namely the GIL is released if a Thread is waiting on an external
event (normally IO) which improves responsiveness.</p>

<p>Great read:</p>

<p>http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/</p>

<p>Threads are hard, but requests are an extremely clean concurrency
primitive: controllers and the models loaded and views rendered, etc.,
are not shared between threads that are processing requests. It&#8217;s only
if you start using global state that problems arise, but why are you
doing that?</p>

<p>Why the Ruby/Rails thread FUD?</p>

<ul>
<li>Early Rails wasn&#8217;t threadsafe; essentially a mutex around each request</li>
<li>Mongrel explicitly mutexed around its Rails adapter, so even when
<code>threadsafe!</code> was added, you&#8217;d still have zero concurrency in mongrel.</li>
</ul>


<blockquote><p>For safety, Ruby does not allow a context switch while in C code unless the C code explicitly tells the VM that it’s ok to do so.</p></blockquote>

<p>And mysql was poorly written in this case. So mysql would block.</p>

<blockquote><p>A lot of people talk about the GIL (global interpreter lock) in Ruby 1.9 as a death knell for concurrency. For the uninitiated, the GIL disallows multiple CPU cores from running Ruby code simultaneously. That does mean that you’ll need one Ruby process (or thereabouts) per CPU core, but it also means that if your multithreaded code is running correctly, you should need only one process per CPU core. I’ve heard tales of six or more processes per core. Since it’s possible to fully utilize a CPU with a single process (even in Ruby 1.8), these applications could get a 4-6x improvement in RAM usage (depending on context-switching overhead) by switching to threadsafe mode and using modern drivers for blocking operations.</p></blockquote>

<p>Node vs Ruby Threading:</p>

<p>Yehuda: &#8220;the main difference is that a callback is smaller in size than a stack&#8221;</p>

<p>In other words, the context switch that happens when switching threads
includes copying over an entire stack of the thread you&#8217;re resuming and
some other details I don&#8217;t know of off the top of my head. But with
callbacks, the callbacks have no stack (is this true in Rubyland? maybe
there&#8217;s stack trace information but probably no stack. The only stack
starts from where the callback/block was created, and the same is true w
threads, but the point is that in a thread-per-request model, the stack
goes all the way up to when the request was first received, which can be
a pretty tall stack).</p>

<p>So what about Fibers? They&#8217;re cooperative, but why is their context
switch not a big deal? They have a stack size limit of 4kb. How can I
test this?</p>

<p>Here&#8217;s a nice article:</p>

<p>http://timetobleed.com/fixing-threads-in-ruby-18-a-2-10x-performance-boost/</p>

<p>Seems to suggest that the stack that needs to be copied when context
switching includes interpreter code, which has many local vars and
sometimes the stack is up to 4kb, which is cray cray.</p>

<p>Green threads: pre-emptible userland threads. userland = not kernel
land.</p>

<p>You can hack into the thread-yielding code of old Ruby to allocate
stacks on the heap so that all you have to do to context switch is
change what rsp (pointer to the bottom of the stack) points to. This
means the stack won&#8217;t grow (so you have to pick a sensible size).</p>

<p>Ruby 1.9 performs way better in the benchmarks than his hacks&#8230; why?
&#8220;Thanks. 1.9 uses pthreads which create stacks in a similar manner to
what I did.&#8221; Awesome.</p>

<p>pthreads = POSIX threads</p>

<p>http://timetobleed.com/threading-models-so-many-different-ways-to-get-stuff-done/</p>

<p>Threads models:</p>

<h3>1:1 (native threads)</h3>

<p>One kernel thread for every user thread.</p>

<p>Pros</p>

<ul>
<li>execute threads on different CPUs</li>
<li>threads don&#8217;t block each other</li>
<li>shared memory b/w threads</li>
</ul>


<p>Cons</p>

<ul>
<li>Setup overhead since creating a thread requires a system call (and
those are slow)</li>
<li>Low upper bound on the number of threads that can be created</li>
</ul>


<p><code>pthread_create</code> is the fn that makes the system call to create the
thread.</p>

<h3>1:N (green threads)</h3>

<p>&#8220;lightweight threads&#8221;</p>

<ul>
<li>thread creation, execution, cleanup are cheap</li>
<li>lots of threads can be created</li>
</ul>


<p>Cons</p>

<ul>
<li>kernel doesn&#8217;t know about it, so no parallel execution across CPUs</li>
<li>blocking IO can block all green threads</li>
</ul>


<p>Forking + threading and cross-process communication is one way around
limitations.</p>

<h3>M:N</h3>

<p>Hybrid of above</p>

<ul>
<li>Multi CPUs</li>
<li>Not all threads blocked by blocking system calls</li>
<li>Cheap</li>
</ul>


<p>Cons</p>

<ul>
<li>Really really hard to synchronize userland and kernel scheduler</li>
<li>Green threads will block within same kernel thread</li>
<li>Difficult to maintain</li>
</ul>


<p>1:1 has shown itself to be more performant, but in some cases M:N might
be the right choice.</p>

<p>TODO: read this http://www.akkadia.org/drepper/nptl-design.pdf</p>

<pre><code>b = nil

t = Thread.new do
  b = Fiber.new {
    puts "FIBER"
  }
end

while !b
  # just wait
end

b.resume
</code></pre>

<p>This results in</p>

<pre><code>fiberthread.rb:13:in `resume': fiber called across threads (FiberError)
        from fiberthread.rb:13:in `&lt;main&gt;'
</code></pre>

<p>Of course it would.</p>

<p>Use strace / dtruss to trace sys calls.</p>

<p>Spinlocks are locks that, rather than sleeping, actively busy-wait until
the lock is free. This only makes sense if the wait is expected to be
short, otherwise it might block other threads.</p>

<p>Interesting, from the wiki:</p>

<blockquote><p>Most operating systems (including Solaris, Mac OS X and FreeBSD) use a hybrid approach called &#8220;adaptive mutex&#8221;. The idea is to use a spinlock when trying to access a resource locked by a currently-running thread, but to sleep if the thread is not currently running. (The latter is always the case on single-processor systems.)</p></blockquote>

<p>The idea is that a lock by an active thread is likely to be finished
soon, and since spinlocks avoid the scheduling overhead of a context
switch, then hooray.</p>

<p>Busy-waiting in general means while-looping until some condition is
true. You can even do this in JS:</p>

<pre><code>var end = +new Date() + 1000;
while (+new Date() &lt; end) {}
</code></pre>

<p>So whether Node or EventMachine, the concept is the same: both run on
callbacks.</p>

<p>Realization: I was thinking that I could demonstrate the difference b/w
green threads and OS threads by seeing if a while(true) in a green
thread would yield to others, but the answer is:</p>

<ul>
<li>of course it would yield; each iteration of the while true is
an iteration of the interpreter loop that&#8217;s running commands, so its
timer would fire at that point.</li>
<li>the only time it&#8217;d block is if you called out to a C extension that
looped and didn&#8217;t yield back control.</li>
</ul>


<p>It seems a Fiber&#8217;s 4k stack begins at the point at which it is created.
Hmm. So does it or does it not include interpreter stuff? Well for one
it&#8217;s in the same thread as a requirement.</p>

<p>Reasons why Fibers are faster than threads:</p>

<ul>
<li>limited 4kb stack for quick context switching</li>
<li>no pre-emption means no aggressive/frequent context switching;
context-switch as infrequently as you&#8217;d like.</li>
</ul>


<p>https://github.com/eventmachine/eventmachine/blob/master/docs/old/LIGHTWEIGHT_CONCURRENCY</p>

<p>Lightweight Concurrency generally means</p>

<ul>
<li>putting thread scheduling under the control of your program</li>
</ul>


<blockquote><p>By &#8220;lighter,&#8221; we mean: less
resource-intensive in one or more dimensions, usually including memory and
CPU usage. In general, you turn to LC in the hope of improving the
performance and scalability of your programs.</p></blockquote>

<p>NOTE: race conditions can happen in concurrent environments, even if
parallelism isn&#8217;t there, e.g. preempting</p>

<p>Mac has a max 2048 thread limit.</p>

<p>&#8220;IO Bound&#8221; means your program is mostly bottlenecked by IO, such that
swapping for a faster IO would boost your program performance immensely.</p>

<p>In such a case, going multi-threaded is a no-brainer rather than
serially getting blocked on each slow thing. But if you over do it then
you might just be wasting memory/CPU resources from thread stacks and
context switching that it&#8217;s not justified.</p>

<p>&#8220;CPU bound&#8221; means doubling CPU would mean the job would get done that
much faster.</p>

<p>Quad-core with 4 threads on CPU bound means mega-wins for Rubinius but
obviously not GIL&#8217;d MRI. If you make it 5, then you get the
context-switching overhead.</p>

<p>Rails apps are combo of IO-bound and CPU-bound</p>

<p>IO:</p>

<ul>
<li>Database</li>
<li>Third party APIs</li>
<li>Files read</li>
</ul>


<p>CPU:</p>

<ul>
<li>Rendering templates</li>
<li>Rendering JSON</li>
</ul>


<p>Measure measure measure.</p>

<p>This is comically incorrect:</p>

<pre><code>Mutex.new.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>should be</p>

<pre><code>m = Mutex.new

# ...create thread...

m.synchronize do
  puts "LOL please never do this"
end
</code></pre>

<p>&#8220;critical section&#8221; refers to the part of your concurrent code that
alters shared data.</p>

<p>Memory Models describe the guarantees made to threads when
reading-from/writing-to memory, which mostly become important to think
about in a multi-threaded settings. The memory model describes how
caching occurs in the registers before actually writing out to memory,
and it describes the scope of compiler/hardware optimizations that can
be made that lead to non-determinant order of memory operations which
can fuck your shit unless you use <code>volatile</code> in Java or explicit mutexes
in Ruby.  Ruby doesn&#8217;t have a memory model spec yet. Java and Go and
others do. I guess Rust nips this in the bud w ownership.</p>

<p>Mutex is a form of a memory barrier, and I think <code>volatile</code> is too.</p>

<p>Livelocking is when <code>try_lock</code>s repeatedly fail, so the threads are
still technically alive but stuck in the same loop.</p>

<p>Best solution is to declare mutex grabbing in the same order via a mutex
hierarchy.</p>

<h2>Signals in ruby</h2>

<p>Rubyz</p>

<pre><code>Signal.trap("USR1") do
  puts "lol handling your custom user handler"
end
puts Process.pid # =&gt; e.g. 12345
</code></pre>

<p>Shellz</p>

<pre><code>kill -s USR1 12345
</code></pre>

<p>So many ways to kill a program:</p>

<ul>
<li>Abort: often self-initiated by <code>abort</code></li>
</ul>


<h2>Difference b/w seg fault and bus error</h2>

<p>http://stackoverflow.com/questions/838540/bus-error-vs-segmentation-fault</p>

<p>On most architectures I&#8217;ve used, the distinction is that:</p>

<ul>
<li>a SEGV is caused when you access memory you&#8217;re not meant to
(e.g., outside of your address space).</li>
<li>a SIGBUS is caused due to alignment issues with the CPU
(e.g., trying to read a long from an address which isn&#8217;t a multiple of 4).</li>
</ul>


<h2>Signals in C</h2>

<p>This is just for fun, but you can set up signal masks and signal
handles and all that fun crap.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;
#include &lt;unistd.h&gt;

static int gotSignal = 0;

void wat(int s) {
  printf("Got Signal %d", s);
  gotSignal = 1;
}

int main() {
  /* SIGUSR1 == 16 */
  signal(SIGUSR1, &amp;wat);

  pid_t pid = getpid();
  printf("The process id is %d", pid);

  // prevent signal from getting here
  sigset_t s;
  sigaddset(&amp;s, SIGUSR1);
  // uncomment to block the signal from arriving
  //sigprocmask(SIG_BLOCK, &amp;s, NULL);

  while(!gotSignal) {
    printf(".");
    fflush(stdout);
    sleep(1);
  }

  printf("\nDone!\n");
}
</code></pre>

<p>and you can send it usr1 via</p>

<pre><code>kill -s USR1 12345
</code></pre>

<h2>Signals in Node</h2>

<pre><code>var done = false;

process.on("SIGUSR1", function() {
  done = true;
});

console.log("pid: ", process.pid);

var timerId = setInterval(function() {
  if (done) {
    console.log("DONEZO");
    clearInterval(timerId);
  } else {
    process.stdout.write(".");
  }
}, 500);
</code></pre>

<p>Note that SIGUSR1 is reserved by node.js to start the debugger.
The above code will work but if the debugger&#8217;s enabled then that&#8217;ll also
cause it to start.</p>

<p>Seems that signals are often used to start a debugger, or some kind of
debugging operation. Interesting.</p>

<h2>Condition Variables</h2>

<p>A provider and consumer both use the same mutex. Provider locks when
providing an update. Consumer locks when trying to perform an operation,
but internally does a <code>condvar.wait(mutex)</code> with the locked <code>mutex</code> to
unlock until the <code>condvar</code> is <code>signal</code>ed by the provider.</p>

<p>So why wrap the consumer in a while loop rather than an if (see page 104
of storimer)? Because there could be multiple consumers.</p>

<p><code>ConditionVariable#signal</code> wakes up a single thread, <code>ConditionVariable#broadcast</code>
wakes up all threads.</p>

<h2><code>thread_safe</code> gem</h2>

<ul>
<li>ThreadSafe::Array</li>
<li>ThreadSafe::Hash</li>
<li>ThreadSafe::Cache

<ul>
<li>similar to Hash, but insertion order enumeration isn&#8217;t preserved,
which means it can be faster</li>
</ul>
</li>
</ul>


<h2>Immutable = threadsafe</h2>

<p>Read more about it.</p>

<h2>Globals</h2>

<p>The Ruby AST is a global (is it really an AST at that point? is
dynamically adding a method an example of modifying an AST? ASTs are for
parsing, not so much adding/removing methods from a class obj).</p>

<p>Anyway, Kaminari was bitten by this:</p>

<p>https://github.com/amatsuda/kaminari/issues/214</p>

<h2>Thread-locals</h2>

<p>Variables that are global to everything in the current thread but hidden
to everyone else. So you could do</p>

<pre><code>Thread.current[:some_service] = SomeService.new
</code></pre>

<p>which could open a new connection. Connections are nice concurrency
primitives, much like request objects in Rails. But if you have too many
threads, you might hit a max connection limit, so in that case, use
pools, lol.</p>

<p>Pools let you specify max concurrency, which is likely less than the
number of threads that might want to consume it, and then when
requesting access to a thing in a pool, it&#8217;ll block until a slot&#8217;s
available.</p>

<p>See: https://github.com/mperham/connection_pool</p>

<p>mperham is Mr Sidekiq. Mr. Concurrency in general I guess.</p>

<p>Question: is a connection pool the same as a thread pool? Probably not,
connection pool is just a resource pool that is thread-aware, but
doesn&#8217;t constitute individual threads.</p>

<h2>Rubinius Actor</h2>

<p>https://github.com/rubinius/rubinius-actor</p>

<p>Depends on core Rubinius class <code>Channel</code>. TODO: find out why <code>Channel</code>
doesn&#8217;t/can&#8217;t exist in MRI.</p>

<h2>Rubinius Ruby JITting</h2>

<p>Talking to IRC folk: one of the major reasons for Ruby all the way down
or at least Ruby most of the way down is that more of it can be JITted
rather than having the hard C/C++ boundary after which no more
optimizations can be made.</p>

<p>Also, in some benchmarks b/w Rubinius and JRuby and MRI, etc., one thing
that comes up a lot is the suggestion that the tests run for longer so
that the JIT is primed, all the optimizations have been made, etc etc
etc.</p>

<h2>Rails Batches</h2>

<p>http://api.rubyonrails.org/classes/ActiveRecord/Batches.html</p>

<pre><code>Article.find_each do |a|
  a.wat
end
</code></pre>

<p>this internally splits DB queries into batches of 1000 so that you&#8217;re
not instantiating potentially a billion Ruby objects for each row. In
the end you&#8217;ll still allocate the same amount of memory but it can be
GC&#8217;d along the way vs causing an insane spike and possibly crashing your
server.</p>

<h2>Server-sent events</h2>

<p>http://tenderlovemaking.com/2012/07/30/is-it-live.html</p>

<ol>
<li>A stream obj is added to Rails request object, quacks like IO obj.
You can write to it and close it, but it doesn&#8217;t actually stream live
to the client; it buffers, and then flushes.</li>
<li>With <code>ActionController::Live</code>, it&#8217;ll actually stream live.</li>
<li>Some WebServers, like WEBrick will thwart this by buffering the
response until it&#8217;s complete. Unicorn could work, but it&#8217;s meant for
fast responses; anything taking longer than 30s might get terminated.
Rainbows/Puma/Thin would work.</li>
</ol>


<h2>Celluloid</h2>

<p>Transforms method invocations into blocking messages. Precede w <code>async</code>
to prevent blocking (obviously still happens async);</p>

<pre><code>require 'celluloid'

class DoesStuff
  include Celluloid

  attr_accessor :i

  def foo
    # currently this displays
    # one item per second.
    # if you swap comments with
    # the line after it'll wait
    # until the very end to print them all
    # at once because the each at the end
    # will evaluate the "longest" future first
    sleep i
    #sleep (11 - i)
    i
  end
end


futures = []

10.times do |i|
  thing = DoesStuff.new
  thing.i = i

  futures &lt;&lt; thing.future.foo
end


futures.each do |f|
  puts "Completed: #{f.value.i}"
end

sleep
</code></pre>

<p>This is interesting: https://github.com/celluloid/celluloid/wiki/Frequently-Asked-Questions#q-can-i-do-blocking-io-inside-an-actor-or-do-i-have-to-use-celluloidio</p>

<p>It&#8217;s fine to have blocking IO such as waiting for a DB query to return,
or slow HTTP response, but you shouldn&#8217;t have it waiting on
<em>indefinite</em> IO; for that, use Celluloid::IO.</p>

<p>I believe that an actor can&#8217;t be handling multiple messages at the same
time. Wrong! That&#8217;s only if Erlang/Exclusive mode is on, and you have to
be careful about that because it means a higher risk of deadlock:</p>

<p>https://github.com/celluloid/celluloid/wiki/Exclusive</p>

<p>Sidekiq doesn&#8217;t make use of return values a whole lot; rather actors are
expected to send messages back to their &#8220;callers&#8221;.</p>

<p>Accessing localvars is faster than ivars: https://github.com/puma/puma/commit/fb4e23d628ad77c7978b67625d0da0e5b41fd124</p>

<h2>Compare and set (CAS)</h2>

<p>aka check-and-set</p>

<p>For platforms that support it, CAS is a mutex-free approach to
thread-safety</p>

<pre><code>a += 1
</code></pre>

<p>is not thread safe, but</p>

<pre><code>cur = a.value
new_value = cur + 1
if (!a.compare_and_set(cur, new_value)) 
  # try again
end
</code></pre>

<p>is.</p>

<p>Worth pointing out that Redis supports a form of this using WATCH.</p>

<pre><code>MULTI # begin transaction
SET foo lol
SET bar wat
EXEC # execute
</code></pre>

<p>so basically if you do</p>

<pre><code>WATCH someval
MULTI
set someval lol
EXEC
</code></pre>

<p>and someval changed after the MULTI then it will fail.</p>

<p>So why use CAS over a mutex?</p>

<blockquote><p>If the cost of retrying the operation is cheap, or rare, it may be much less expensive than using a lock.</p></blockquote>

<p>Logic checks out.</p>

<pre><code>require 'atomic'
v = Atomic.new(0)
v.update do |current|
  current + 1
end
</code></pre>

<p>This is the shorthand to the idempotent loop with CAS.</p>

<p>Lockless showed mega improvements relative to locking in Rubinius but
not JRuby for some reason.</p>

<p>Hamster is the immutability gem to check out.</p>

<h2>oni</h2>

<p>https://github.com/olery/oni</p>

<p>Uses SQS, look into it because i am such a nooblet.</p>

<h2>SQS</h2>

<p>Uses a visibility timeout after a consumer has started to receive a
message in which time it is hidden from other consumers, and in this
time it should be deleted.</p>

<ul>
<li>Supports GET/POST requests to public URLs, presuming you pass in a
valid signature

<ul>
<li>This means you could fire requests directly to SQS rather than
having to go to a server first&#8230; that is badass.</li>
</ul>
</li>
<li>Reports of scalability problems</li>
</ul>


<p><a href="http://nsono.net/amazon-sqs-vs-rabbitmq/">Alternative: RabbitMQ</a></p>

<ul>
<li>SQS: consumers must poll for messages, and SQS charges by the request,
even if the response is empty.</li>
<li>RabbitMQ supports push</li>
<li>is free and open source</li>
<li>based on erlang</li>
<li>adheres to AMQP (standard for high performance messages queues)</li>
<li>supports durable queues (crash-recoverable, written to disk)</li>
<li>delivered in order unless message requeued</li>
<li>more consistent (much less likely to deliver a message twice unless
the message actually failed)</li>
</ul>


<p>cons</p>

<ul>
<li>not necessarily highly available (because it&#8217;s a server that runs on
whatever instance you wanna put it on, so you have to manage failover,
redundancy, etc, whereas SQS is a system that handles all of that)</li>
<li>this is configurable, but the default is for RabbitMQ to drop messages
if there are no consumers; surprising to SQS folk.</li>
</ul>


<h2>Heartbeats</h2>

<p>https://www.rabbitmq.com/reliability.html</p>

<blockquote><p>In some types of network failure, packet loss can mean that disrupted TCP connections take some time to be detected by the operating system. AMQP offers a heartbeat feature to ensure that the application layer promptly finds out about disrupted connections (and also completely unresponsive peers). Heartbeats also defend against certain network equipment which may terminate &#8220;idle&#8221; TCP connections. In RabbitMQ versions 3.0 and higher, the broker will attempt to negotiate heartbeats by default (although the client can still veto them). Using earlier versions the client must be configured to request heartbeats.</p></blockquote>

<p>Re: &#8216;Heartbeats also defend against certain network equipment which may
terminate &#8220;idle&#8221; TCP connections.&#8217;: I bet that&#8217;s referring to NAT, which
manages a cache of IP translations and will go inactive if nothings been
sent to / received from an IP for a while.</p>

<p>YAY I WAS RIGHT http://stackoverflow.com/questions/865987/do-i-need-to-heartbeat-to-keep-a-tcp-connection-open#comment1713801_866003</p>

<p>So Heartbeats</p>

<ul>
<li>reassure you the connection is alive in some cases where the failure
conditions aren&#8217;t otherwise detectable</li>
<li>keep the NAT state tables warm for your IP</li>
</ul>


<h2>Celluloid::IO</h2>

<p>https://github.com/celluloid/celluloid-io</p>

<p>Provides a different class of Actor that&#8217;s heavier than normal Celluloid
actors, but contains a high performance reactor like EventMachine or
cool.io (todo: check out cool.io). So unlike EventMachine you can have
multiple loops, e.g. one in each actor (resources permitting). (Also,
does EM really force you to just have one?)</p>

<h2>Autoload</h2>

<p>Yes we know it&#8217;s not threadsafe in MRI. Recent JRuby versions make it
thread safe, but just eager load your shits before spawning threads.</p>

<h2>Requests as concurrency unit</h2>

<p>I guess in general you should always look for the concurrency unit; that
domain object that encapsulates all the data you need to get a job done
so that hopefully you&#8217;re not sharing data between threads. Each request
gets handled by its own thread.</p>

<h2>Queue</h2>

<p><code>Queue#pop</code> will suspend a thread until data is in the queue. Like a
mofuggin stream.</p>

<p>Queue is apparently the only thread-safe data structure that ships with
Ruby.</p>

<h2>JRuby</h2>

<p>Foreign function interface</p>

<p>http://en.wikipedia.org/wiki/Foreign_function_interface</p>

<p>Mechanism for languages to invoke routines from other languages.</p>

<p>Write your extension code in Ruby, FFI will call the write C / Java /
whatever stuff. It won&#8217;t even be compiled. I guess it just links into
dynamic libs?</p>

<p>JRuby obviously doesn&#8217;t support C extensions, but FFI extensions will
work.</p>

<p>JRuby</p>

<ul>
<li>has no fork(), since JVMs mostly can&#8217;t safely be forked
(<code>NotImplementedError: fork is not available on this platform</code>)</li>
<li>Fibers are native threads, rather than MRI green threads, which means
you are constrained to native thread overhead/limits.</li>
</ul>


<h2>Rubinius (rbx)</h2>

<ul>
<li>Designed for concurrency, speed.</li>
<li>Rubinius 2.0 has no GIL</li>
<li>All tools written in Ruby, including bytecode VM, compiler,
generational GC, JIT, etc</li>
<li>No continuations (because dependent on callcc, a C thing)</li>
<li>At some point, when dealing with locks and low level things, you&#8217;ll
find C++.</li>
</ul>


<p>http://rubini.us/2011/02/25/why-use-rubinius/</p>

<h2>Ruby Enterprise Edition</h2>

<p>By Phusion. No longer alive.</p>

<ul>
<li>Compatible w 1.8.7</li>
<li>End of Life since 2012</li>
<li>No more work being done, reasons being:

<ul>
<li>Rails 4 no longer supporting 1.8</li>
<li>COW patch accepted on Ruby 2.0</li>
<li>Many Ruby Enterprise Edition patches addressed in 1.9, 2.0</li>
</ul>
</li>
</ul>


<h2>MacRuby</h2>

<p>Implementation of 1.9 Ruby directly on top of Mac OS X core tech, e.g.</p>

<ul>
<li>Obj-C runtime and GC</li>
<li>LLVM compiler infrastructure</li>
</ul>


<h2>Reactive manifesto</h2>

<p>TODO: read this http://www.reactivemanifesto.org/</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-26T15:10:00-04:00" pubdate data-updated="true">Jul 26<span>th</span>, 2014</time></div>
	


	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2014/07/19/daily-journal/">
		
			Daily Journal</a>
	</h2>
	<div class="entry-content">
		<h2>Crank</h2>

<p>Meth.</p>

<p>An eccentric person, esp. one who is obsessed by a particular subject or
theory: when he first started to air his views, they labeled him a
crank | [ as modifier ] : I am used to getting crank calls from
conspiracy theorists.</p>

<h2>Roko&#8217;s modern basilisk</h2>

<p>It&#8217;s happening.</p>

<h2>Transactional UIs</h2>

<p>People build forms. Ember gives you sweet syntax sugar for 2wb.
Not for transactional UI, anything that needs a buffer.</p>

<p>Old mindset: if you need 1wb, just&#8230; don&#8217;t set on the other side of a
2wb.</p>

<p>TODO: ask kris more about the async/sync cocoa observer binding
limitations.</p>

<ul>
<li>Most observers just do something and stop.</li>
<li>And they mostly want to know the last thing they cared about.</li>
</ul>


<p>Bubbling doesn&#8217;t describe actions; actions go wherever. Bubbling only in
route hierarchy.</p>

<p>Services:</p>

<ul>
<li>session/user</li>
<li>timer</li>
<li>websocket</li>
<li>analytics</li>
</ul>


<p>Idea: components provide services to the components the render. They
have a ServiceCertificate</p>

<p>Goal:</p>

<ul>
<li>Try and associate actions with objects.</li>
<li><code>actions</code> themselves can just be passed into the <code>actions</code></li>
</ul>


<h2>Non-dynamic routes</h2>

<pre><code>resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}

resolveEntry: function(params, model, transition) {
  return model || this.store.find(params.id);
}
</code></pre>

<p>Initializers vs <code>applicationRoute#beforeModel</code>.</p>

<p>retcon for how to use controllers</p>

<p>asop to data binding</p>

<p>HTMLbars knows what parts of the template are dynamic vs static.</p>

<p>In React, if you have a conditional</p>

<h2>Skunkworks project</h2>

<blockquote><p>A skunkworks project is a project developed by a small and loosely
structured group of people who research and develop a project
primarily for the sake of radical innovation.[1] The terms
originated with Lockheed&#8217;s World War II Skunk Works project.</p></blockquote>

<p>http://en.wikipedia.org/wiki/Skunk_Works</p>

<blockquote><p>The designation &#8220;skunk works&#8221;, or &#8220;skunkworks&#8221;, is widely used
in business, engineering, and technical fields to describe a
group within an organization given a high degree of autonomy
and unhampered by bureaucracy, tasked with working on advanced
or secret projects.</p></blockquote>

<p>Lockheed Martin&#8217;s Skunk Works project made SR-71.</p>

<h2>Project Svelte</h2>

<p>http://www.trustedreviews.com/opinions/android-4-4-kitkat-s-project-svelte-what-it-is-and-why-you-should-care</p>

<blockquote><p>‘dogfooding’ – that is making its employees use and live with their own projects</p></blockquote>

<p>They dogfooded their employees by forcing them to dev on handicapped
phones. Android 4.4 was the result, apparently it was way more
performant.</p>

<h2>RACK_ENV vs RAILS_ENV</h2>

<p><code>Rails.env</code> is decided by <code>RAILS_ENV || RACK_ENV || "development"</code>. It&#8217;s
common to set <code>RACK_ENV</code> which will also set <code>RAILS_ENV</code>, but if you
have any rack middleware that behaves differently in different
environments, you might screw yourself if you&#8217;re using <code>RAILS_ENV</code>.</p>

<h2>wythoughts on blocks</h2>

<p>The reason <code>|i|</code> is ok is for the same reason you can&#8217;t do the following
in Ruby:</p>

<pre><code>a = { |it| wat }
</code></pre>

<p>You have to do</p>

<pre><code>a = proc { |it| wat }
</code></pre>

<p>Case in point you need an fn to save a block.</p>

<h2>mythoughts on mutability</h2>

<p>Can/should we swap POJOs when an observed property changes? Is there any
value to</p>

<pre><code>var pojo = {
  a: {
    b: 123
  }
};

var a = pojo.a;
Ember.set(pojo, 'a.b'
</code></pre>

<h2>ASI: automatic semicolon insertion</h2>

<p>Nuff said.</p>

<h2>old browser disagreements on ws</h2>

<pre><code>[ text ws text]
</code></pre>

<p>cloneNode produces:</p>

<ul>
<li>ie8: 1 node</li>
<li>ie9: 2 nodes</li>
<li>else: 3 nodes</li>
</ul>


<h2>NoScope</h2>

<p>http://www.thecssninja.com/javascript/noscope</p>

<p>tldr NoScope is an old IE categorization of nodes, and NoScope dictates
that innerHTML and cloneNode will strip these els.</p>

<h2>Ropes: DAG of string implementation for FF/Chrome</h2>

<p>http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=181EEF66EB411F4277C009A1D492CF75?doi=10.1.1.14.9450&amp;rep=rep1&amp;type=pdf</p>

<p>Look into this more. Too lazy to read / comment.</p>

<p>How to force Chrome to not use a rope:</p>

<ul>
<li>Less than 12 chars</li>
</ul>


<p>What does it mean to intern strings?</p>

<h2>CSP: Content Security Policy</h2>

<p>http://www.html5rocks.com/en/tutorials/security/content-security-policy/</p>

<h2>String interning</h2>

<pre><code>String.prototype.intern = (function() {
   "use strict";
   var o = {"- ": 0};
   delete o["- "];
   return function() {
       var str = this;
       o[str] = true;
       var ret = Object.keys(o)[0];
       delete o[str];
       return ret;
       try {} finally {}
   };
})();
</code></pre>

<h2>Component pinning</h2>

<p>Associating the re-render with the pre-existing fragment.</p>

<h2>localStorage on iOS Cordova webviews</h2>

<ol>
<li>Run dev, set <code>localStorage.wat = "lol"</code></li>
<li>Stop and re-run the app, and <code>localStorage.wat</code> still is &#8220;lol&#8221;</li>
<li>Delete the app, re-install, still dev, <code>localStorage.wat</code> is undefined</li>
</ol>


<p>I don&#8217;t even have to check&#8230; your app can&#8217;t run in both dev and prod.
You can&#8217;t share userSessions across dev and prod apps. Then again, our
servers could maintain keys for both APNS and APNS_SANDBOX.</p>

<h2>GCM project number vs project ID</h2>

<p>https://developers.google.com/compute/docs/faq#whatisthedifference</p>

<p>You pick project ID, they pick project number. Project number is the
Sender ID you use for GCM.</p>

<h2>Pointer comparisons for such perf</h2>

<pre><code>if (wat === false) {
}
</code></pre>

<p><code>false</code> can be implemented to just refer to a unique memory location,
such that all browsers need to comparison in the above code is <code>wat</code>&#8217;s
memory address against <code>false</code>&#8217;s.</p>

<p>Same goes with</p>

<pre><code>if (wat === undefined) {
}
</code></pre>

<p>just that the presence of <code>foo</code> in <code>cache.foo</code> is ambiguous without
testing <code>foo in cache</code>; might be easier to do <code>cache.foo = UNDEFINED</code>
where</p>

<pre><code>function UNDEFINED() {}
</code></pre>

<p>Sentinel as fuck.</p>

<h2>PushPlugin</h2>

<p>Only starts firing PNs after <code>register</code>. We need a user session to
register, right? Seems weird we can&#8217;t query it for information before
immediately registering&#8230; either way, works fine for us, at least we
killed Zalgo.</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2014-07-19T11:30:00-04:00" pubdate data-updated="true">Jul 19<span>th</span>, 2014</time></div>
	


	
</div></article>

<nav id="pagenavi">
    
    
        <a href="/blog/page/2/" class="next">Next</a>
    
    <div class="center"><a href="/archives">Blog Archives</a></div>
</nav></div>
	<footer id="footer" class="inner">Copyright &copy; 2014

    Alex Matchneer

<br>
Powered by Octopress.
</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'usefuldude';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-49928757-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>



</body>
</html>

